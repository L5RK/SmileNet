{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_14608\\3446521250.py:1: DtypeWarning: Columns (15) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  data = pd.read_csv('./OptionMetrics/options2223.csv', nrows=2_000_000)\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('./OptionMetrics/options2223.csv', nrows=2_000_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      secid  volume\n",
      "symbol                             \n",
      "RUT 220318C2280000   102434     905\n",
      "RUT 220121C2280000   102434     898\n",
      "RUT 220121P2280000   102434     895\n",
      "RUT 220318P2280000   102434     889\n",
      "RUT 220218P2240000   102434     812\n",
      "RUT 220121P2240000   102434     763\n",
      "RUT 220218C2380000   102434     706\n",
      "RUTW 220107C2340000  102434     685\n",
      "RUT 220318P2200000   102434     669\n",
      "RUTW 220103C2270000  102434     593\n",
      "RUTW 220107C2335000  102434     555\n",
      "RUT 220318P2270000   102434     521\n",
      "RUTW 220107P2080000  102434     503\n",
      "RUT 220318C2270000   102434     495\n",
      "RUTW 220429C2350000  102434     472\n",
      "RUTW 220103P2265000  102434     426\n",
      "RUTW 220103P2240000  102434     426\n",
      "RUTW 220128P2000000  102434     404\n",
      "RUTW 220128P1990000  102434     375\n",
      "RUTW 220128C2260000  102434     362\n",
      "RUTW 220107P1850000  102434     360\n",
      "RUTW 220331P2020000  102434     337\n",
      "RUTW 220331P2010000  102434     337\n",
      "RUTW 220103C2275000  102434     337\n",
      "RUTW 220103P2245000  102434     314\n",
      "RUTW 220128P2025000  102434     311\n",
      "RUTW 220128P2020000  102434     297\n",
      "RUTW 220103P2235000  102434     295\n",
      "RUTW 220128P2015000  102434     287\n",
      "RUTW 220128C2290000  102434     275\n",
      "RUTW 220128P2240000  102434     273\n",
      "RUTW 220128P2210000  102434     272\n",
      "RUT 220121C2260000   102434     255\n",
      "RUTW 220103P2260000  102434     252\n",
      "RUTW 220107P2085000  102434     251\n",
      "RUTW 220128P1980000  102434     251\n",
      "RUTW 220103P2230000  102434     245\n",
      "RUTW 220103P2250000  102434     237\n",
      "RUTW 220103C2295000  102434     234\n",
      "RUTW 220131P2020000  102434     226\n",
      "RUT 220121C2300000   102434     224\n",
      "RUTW 220105C2320000  102434     217\n",
      "RUTW 220114C2290000  102434     216\n",
      "RUTW 220131P2010000  102434     215\n",
      "RUTW 220103C2285000  102434     212\n",
      "RUT 220121C2290000   102434     212\n",
      "RUTW 220103C2280000  102434     212\n",
      "RUTW 220114C2260000  102434     201\n",
      "RUTW 220128P2010000  102434     201\n",
      "RUT 221216P1950000   102434     200\n",
      "RUT 220916P2180000   102434     200\n",
      "RUT 220318P1200000   102434     200\n",
      "RUT 220318P1500000   102434     200\n",
      "RUTW 220103P2270000  102434     183\n",
      "RUTW 220128C2460000  102434     181\n",
      "RUTW 220103C2300000  102434     171\n",
      "RUTW 220105C2325000  102434     168\n",
      "RUTW 220204P2240000  102434     162\n",
      "RUTW 220103P2255000  102434     161\n",
      "RUTW 220103C2305000  102434     160\n",
      "RUTW 220103C2260000  102434     159\n",
      "RUTW 220107C2260000  102434     153\n",
      "RUTW 220105C2300000  102434     152\n",
      "RUTW 220107P2170000  102434     151\n",
      "RUTW 220118P2150000  102434     151\n",
      "RUTW 220118P2140000  102434     151\n",
      "RUTW 220131P1900000  102434     150\n",
      "RUT 220218P2120000   102434     147\n",
      "RUTW 220131P1700000  102434     146\n",
      "RUTW 220128C2450000  102434     146\n",
      "RUTW 220103C2290000  102434     144\n",
      "RUTW 220103C2265000  102434     142\n",
      "RUTW 220228P2240000  102434     139\n",
      "RUT 220121C2420000   102434     138\n",
      "RUTW 220107C2300000  102434     136\n",
      "RUT 220121P2220000   102434     128\n",
      "RUTW 220107C2345000  102434     124\n",
      "RUTW 220107P2160000  102434     119\n",
      "RUTW 220105C2340000  102434     118\n",
      "RUT 220218P2230000   102434     118\n",
      "RUT 220121P1980000   102434     118\n",
      "RUT 220121C2430000   102434     116\n",
      "RUTW 220211P2090000  102434     115\n",
      "RUTW 220103C2250000  102434     114\n",
      "RUTW 220103C2325000  102434     113\n",
      "RUTW 220103C2310000  102434     113\n",
      "RUTW 220114C2270000  102434     112\n",
      "RUTW 220128C2440000  102434     112\n",
      "RUTW 220107P2150000  102434     112\n",
      "RUT 220121C2190000   102434     111\n",
      "RUTW 220107P2140000  102434     111\n",
      "RUTW 220128C2250000  102434     111\n",
      "RUTW 220128P2050000  102434     110\n",
      "RUTW 220107P1860000  102434     109\n",
      "RUT 220121P2000000   102434     109\n",
      "RUT 220121P2250000   102434     109\n",
      "RUTW 220107P2190000  102434     109\n",
      "RUTW 220128P2030000  102434     108\n",
      "RUTW 220107P2250000  102434     104\n",
      "RUTW 220128P2035000  102434     103\n",
      "RUT 220121P2120000   102434     102\n",
      "RUTW 220107P2165000  102434     101\n",
      "RUT 220318P2260000   102434     100\n",
      "RUT 220916C2230000   102434     100\n",
      "RUT 220121P2070000   102434     100\n",
      "RUTW 220107C2320000  102434      99\n",
      "RUTW 220128C2310000  102434      98\n",
      "RUTW 220128C2350000  102434      98\n",
      "RUTW 220107P1890000  102434      97\n",
      "RUTW 220107P1905000  102434      95\n",
      "RUTW 220107P2180000  102434      93\n",
      "RUT 220121P2050000   102434      93\n",
      "RUTW 220107P2175000  102434      92\n",
      "RUTW 220110C2360000  102434      91\n",
      "RUTW 220107P2200000  102434      89\n",
      "RUTW 220107P2195000  102434      88\n",
      "RUTW 220114C2410000  102434      88\n",
      "RUTW 220107P2220000  102434      87\n",
      "RUTW 220107P2210000  102434      87\n",
      "RUTW 220105C2290000  102434      86\n",
      "RUTW 220128C2470000  102434      84\n",
      "RUTW 220105P2265000  102434      83\n",
      "RUTW 220107C2350000  102434      82\n",
      "RUT 220121P2270000   102434      81\n",
      "RUTW 220110P2120000  102434      80\n",
      "RUTW 220105C2275000  102434      80\n",
      "RUTW 220204P2280000  102434      80\n",
      "RUTW 220204P2190000  102434      80\n",
      "RUTW 220103C2315000  102434      79\n",
      "RUT 220121P2210000   102434      79\n",
      "RUT 220121P2150000   102434      79\n",
      "RUT 220318P2230000   102434      79\n",
      "RUTW 220107C2330000  102434      78\n",
      "RUT 220218C2280000   102434      78\n",
      "RUTW 220105P2240000  102434      77\n",
      "RUTW 220105C2330000  102434      77\n",
      "RUT 220121P2100000   102434      76\n",
      "RUTW 220110P2130000  102434      76\n",
      "RUTW 220204C2450000  102434      75\n",
      "RUT 220218P1950000   102434      74\n",
      "RUTW 220105C2280000  102434      73\n",
      "RUTW 220128P1945000  102434      73\n",
      "RUTW 220128P1955000  102434      73\n",
      "RUTW 220107P2120000  102434      73\n",
      "RUTW 220128P2005000  102434      73\n",
      "RUTW 220204C2455000  102434      72\n",
      "RUTW 220105P2210000  102434      72\n",
      "RUT 220121P2230000   102434      72\n",
      "RUT 220121P1950000   102434      71\n",
      "RUT 220121P1970000   102434      71\n",
      "RUT 220121C2350000   102434      71\n",
      "RUTW 220114P2105000  102434      70\n",
      "RUTW 220128C2455000  102434      69\n",
      "RUT 220218P2030000   102434      69\n",
      "RUTW 220103C2245000  102434      69\n",
      "RUTW 220107P1940000  102434      68\n",
      "RUT 220121P2130000   102434      68\n",
      "RUTW 220103P2225000  102434      67\n",
      "RUTW 220110P2230000  102434      67\n",
      "RUTW 220110P2260000  102434      66\n",
      "RUTW 220131P2000000  102434      66\n",
      "RUT 220218P2020000   102434      66\n",
      "RUTW 220110C2350000  102434      66\n",
      "RUTW 220105P2200000  102434      66\n",
      "RUT 220218C2550000   102434      66\n",
      "RUTW 220228P2190000  102434      65\n",
      "RUTW 220107P2185000  102434      65\n",
      "RUTW 220105P2245000  102434      65\n",
      "RUT 220121P2060000   102434      65\n",
      "RUT 220121P2110000   102434      64\n",
      "RUTW 220107P2240000  102434      64\n",
      "RUTW 220105P2230000  102434      64\n",
      "RUTW 220331P2150000  102434      64\n",
      "RUTW 220105P2250000  102434      64\n",
      "RUT 220121P2260000   102434      64\n",
      "RUTW 220114C2320000  102434      63\n",
      "RUTW 220204C2460000  102434      62\n",
      "RUTW 220103C2255000  102434      62\n",
      "RUTW 220228P2290000  102434      61\n",
      "RUTW 220103P2280000  102434      61\n",
      "RUT 220121P2170000   102434      61\n",
      "RUTW 220103P2275000  102434      60\n",
      "RUTW 220228P2250000  102434      60\n",
      "RUTW 220131C2420000  102434      60\n",
      "RUTW 220105C2310000  102434      59\n",
      "RUTW 220107P2145000  102434      59\n",
      "RUTW 220105C2315000  102434      59\n",
      "RUTW 220105P2270000  102434      59\n",
      "RUTW 220105C2240000  102434      59\n",
      "RUTW 220204P1995000  102434      59\n",
      "RUTW 220128P2260000  102434      58\n",
      "RUT 220218P2190000   102434      58\n",
      "RUTW 220107C2325000  102434      58\n",
      "RUT 220121P2200000   102434      58\n",
      "RUTW 220131C2450000  102434      58\n",
      "RUTW 220107C2250000  102434      57\n",
      "RUT 220121P2090000   102434      57\n",
      "RUTW 220114P2270000  102434      57\n",
      "RUT 220121P2160000   102434      57\n",
      "RUTW 220114P2055000  102434      55\n",
      "RUT 220218P1940000   102434      55\n",
      "RUTW 220114C2400000  102434      55\n",
      "RUTW 220107P2130000  102434      55\n",
      "RUT 220218C2360000   102434      54\n",
      "RUTW 220105C2230000  102434      54\n",
      "RUTW 220114P2115000  102434      53\n",
      "RUT 220121C2320000   102434      53\n",
      "RUTW 220110P2250000  102434      53\n",
      "RUTW 220107P2280000  102434      52\n",
      "RUTW 220107P2110000  102434      51\n",
      "RUTW 220114P2230000  102434      51\n",
      "RUTW 220131P1800000  102434      50\n",
      "RUTW 220128C2465000  102434      50\n",
      "RUTW 220204C2445000  102434      50\n",
      "RUTW 220331C1500000  102434      50\n",
      "RUTW 220331C1550000  102434      50\n",
      "RUT 220318C2260000   102434      50\n",
      "RUTW 220128C2490000  102434      50\n",
      "RUT 220218P2170000   102434      50\n",
      "RUTW 220103P2220000  102434      50\n",
      "RUTW 220331P1350000  102434      50\n",
      "RUT 220218P2270000   102434      49\n",
      "RUT 220218P2250000   102434      49\n",
      "RUTW 220105P2260000  102434      49\n",
      "RUT 220121C2400000   102434      48\n",
      "RUTW 220107P2260000  102434      48\n",
      "RUT 220121C2450000   102434      48\n",
      "RUTW 220131P2080000  102434      48\n",
      "RUTW 220107P2100000  102434      48\n",
      "RUTW 220105P2220000  102434      47\n",
      "RUT 220121C2270000   102434      47\n",
      "RUT 220218C2470000   102434      47\n",
      "RUTW 220114P2250000  102434      47\n",
      "RUTW 220107P2230000  102434      47\n",
      "RUTW 220110C2325000  102434      47\n",
      "RUTW 220103C2320000  102434      47\n",
      "RUTW 220131P2090000  102434      46\n",
      "RUTW 220105P2185000  102434      46\n",
      "RUTW 220110C2295000  102434      46\n",
      "RUTW 220114P2065000  102434      46\n",
      "RUT 220617C2580000   102434      46\n",
      "RUT 220121C2360000   102434      45\n",
      "RUT 220218C2540000   102434      45\n",
      "RUTW 220107P2135000  102434      45\n",
      "RUT 220218P2290000   102434      45\n",
      "RUT 220121C2310000   102434      44\n",
      "RUTW 220103C2220000  102434      44\n",
      "RUTW 220110P2200000  102434      44\n",
      "RUTW 220107C2295000  102434      43\n",
      "RUTW 220105P2225000  102434      43\n",
      "RUTW 220228P2300000  102434      42\n",
      "RUTW 220107C2255000  102434      42\n",
      "RUT 220218P2000000   102434      42\n",
      "RUTW 220107P2265000  102434      42\n",
      "RUT 220218P1900000   102434      42\n",
      "RUTW 220107P2255000  102434      42\n",
      "RUTW 220128P2060000  102434      41\n",
      "RUT 220218C2480000   102434      41\n",
      "RUTW 220128C2270000  102434      41\n",
      "RUTW 220128P2055000  102434      41\n",
      "RUTW 220105P2180000  102434      41\n",
      "RUTW 220128C2320000  102434      41\n",
      "RUTW 220103C2200000  102434      41\n",
      "RUT 220121P2190000   102434      40\n",
      "RUTW 220105C2245000  102434      40\n",
      "RUTW 220107C2270000  102434      40\n",
      "RUTW 220107C2180000  102434      40\n",
      "RUT 220218P2100000   102434      40\n",
      "RUTW 220110C2335000  102434      40\n",
      "RUTW 220114P2040000  102434      40\n",
      "RUTW 220131P2070000  102434      40\n",
      "RUTW 220128P2265000  102434      40\n",
      "RUTW 220429P2150000  102434      40\n",
      "RUT 220715P2150000   102434      40\n",
      "RUT 220121C2100000   102434      40\n",
      "RUTW 220103C2230000  102434      40\n",
      "RUT 220318P2190000   102434      39\n",
      "RUT 220218P2200000   102434      39\n",
      "RUTW 220112C2370000  102434      39\n",
      "RUT 220218C2350000   102434      39\n",
      "RUTW 220131C2410000  102434      38\n",
      "RUT 220121P2040000   102434      38\n",
      "RUT 220318C2300000   102434      38\n",
      "RUTW 220107P2235000  102434      38\n",
      "RUTW 220105C2260000  102434      38\n",
      "RUT 220218P1910000   102434      38\n",
      "RUT 220218C2420000   102434      37\n",
      "RUTW 220103P2175000  102434      37\n",
      "RUTW 220107C2315000  102434      37\n",
      "RUTW 220110P2160000  102434      37\n",
      "RUTW 220228P2200000  102434      36\n",
      "RUTW 220110C2270000  102434      36\n",
      "RUT 220121C2250000   102434      36\n",
      "RUTW 220107C2310000  102434      36\n",
      "RUTW 220112P2250000  102434      36\n",
      "RUT 220318P2220000   102434      36\n",
      "RUTW 220107C2265000  102434      36\n",
      "RUTW 220107C2290000  102434      36\n",
      "RUTW 220131P2100000  102434      35\n",
      "RUT 220218P2070000   102434      35\n",
      "RUT 220121P2180000   102434      35\n",
      "RUTW 220228P2270000  102434      35\n",
      "RUTW 220103P2210000  102434      35\n",
      "RUTW 220107P2245000  102434      34\n",
      "RUT 220218P2210000   102434      34\n",
      "RUTW 220112P2150000  102434      34\n",
      "RUTW 220131P2040000  102434      34\n",
      "RUTW 220131P2030000  102434      33\n",
      "RUT 220218C2250000   102434      33\n",
      "RUT 220218P1800000   102434      33\n",
      "RUTW 220105C2285000  102434      33\n",
      "RUTW 220103P2200000  102434      33\n",
      "RUTW 220110P2280000  102434      33\n",
      "RUTW 220110P2225000  102434      33\n",
      "RUTW 220107P2270000  102434      32\n",
      "RUTW 220105P2195000  102434      32\n",
      "RUT 220218P2260000   102434      32\n",
      "RUT 220218C2270000   102434      32\n",
      "RUTW 220131P1970000  102434      31\n",
      "RUTW 220105C2220000  102434      31\n",
      "RUTW 220114C2330000  102434      31\n",
      "RUTW 220110P2190000  102434      31\n",
      "RUTW 220107C2230000  102434      31\n",
      "RUT 220218C2230000   102434      31\n",
      "RUTW 220103C2215000  102434      31\n",
      "RUT 220121P2080000   102434      31\n",
      "RUTW 220110P2110000  102434      31\n",
      "RUTW 220131C2350000  102434      31\n",
      "RUTW 220204P2020000  102434      31\n",
      "RUTW 220112P2135000  102434      30\n",
      "RUT 220121P1830000   102434      30\n",
      "RUTW 220112C2385000  102434      30\n",
      "RUTW 220128C2400000  102434      30\n",
      "RUTW 220128P2065000  102434      30\n",
      "RUTW 220110P2010000  102434      30\n",
      "RUTW 220211C2400000  102434      30\n",
      "RUTW 220103C2335000  102434      30\n",
      "RUTW 220103P2190000  102434      30\n",
      "RUTW 220110P2270000  102434      30\n",
      "RUTW 220114P2050000  102434      30\n",
      "RUT 220121P1840000   102434      30\n",
      "RUT 220121C2470000   102434      30\n",
      "RUTW 220131C2440000  102434      30\n",
      "RUTW 220204P1990000  102434      29\n",
      "RUTW 220103P2185000  102434      29\n",
      "RUTW 220105C2350000  102434      29\n",
      "RUTW 220105P2255000  102434      29\n",
      "RUT 220218C2400000   102434      28\n",
      "RUTW 220114C2415000  102434      28\n",
      "RUTW 220107P2095000  102434      28\n",
      "RUTW 220110C2370000  102434      28\n",
      "RUT 220218C2200000   102434      28\n",
      "RUTW 220228C2350000  102434      28\n",
      "RUTW 220228P2230000  102434      28\n",
      "RUT 220218P2180000   102434      27\n",
      "RUT 220218C2600000   102434      27\n",
      "RUT 220218C2450000   102434      27\n",
      "RUTW 220131C2430000  102434      27\n",
      "RUT 220121P2030000   102434      27\n",
      "RUTW 220103C2240000  102434      27\n",
      "RUTW 220114P1935000  102434      27\n",
      "RUTW 220114P2060000  102434      27\n",
      "RUTW 220110P2155000  102434      26\n",
      "RUTW 220128P2100000  102434      26\n",
      "RUT 220218C2460000   102434      26\n",
      "RUT 220218P2040000   102434      26\n",
      "RUT 220121C2380000   102434      26\n",
      "RUTW 220105C2270000  102434      26\n",
      "RUT 220318P2250000   102434      26\n",
      "RUTW 220107C2360000  102434      26\n",
      "RUTW 220105C2265000  102434      26\n",
      "RUTW 220107C2390000  102434      26\n",
      "RUTW 220103P2215000  102434      25\n",
      "RUT 220318C2250000   102434      25\n",
      "RUTW 220105C2255000  102434      25\n",
      "RUTW 220131P1960000  102434      25\n",
      "RUTW 220131P1650000  102434      25\n",
      "RUT 220218C2410000   102434      25\n",
      "RUTW 220112P2180000  102434      25\n",
      "RUTW 220103C2330000  102434      25\n",
      "RUTW 220331P1500000  102434      25\n",
      "RUTW 220105P2280000  102434      25\n",
      "RUTW 220105P2275000  102434      25\n",
      "RUTW 220128P2045000  102434      24\n",
      "RUTW 220103P2195000  102434      24\n",
      "RUTW 220118P2270000  102434      24\n",
      "RUTW 220131P2110000  102434      24\n",
      "RUTW 220105P2215000  102434      24\n",
      "RUTW 220114P1760000  102434      24\n",
      "RUTW 220114P1770000  102434      24\n",
      "RUTW 220107P2205000  102434      24\n",
      "RUTW 220204P2040000  102434      24\n",
      "RUT 220218P2060000   102434      24\n",
      "RUTW 220128C2445000  102434      24\n",
      "RUTW 220204P2000000  102434      23\n",
      "RUT 220121P2140000   102434      23\n",
      "RUTW 220110P2290000  102434      23\n",
      "RUTW 220114P2255000  102434      23\n",
      "RUTW 220110C2305000  102434      23\n",
      "RUT 220218C2300000   102434      23\n",
      "RUTW 220114P2135000  102434      23\n",
      "RUTW 220114C2425000  102434      23\n",
      "RUTW 220128C2405000  102434      23\n",
      "RUT 220121P1960000   102434      23\n",
      "RUTW 220114P2260000  102434      23\n",
      "RUTW 220105C2305000  102434      23\n",
      "RUT 220218P2160000   102434      23\n",
      "RUTW 220114P2095000  102434      22\n",
      "RUTW 220114C2300000  102434      22\n",
      "RUTW 220105P2190000  102434      22\n",
      "RUTW 220107P2300000  102434      22\n",
      "RUTW 220211P2250000  102434      22\n",
      "RUT 220121P1790000   102434      22\n",
      "RUTW 220211C2250000  102434      22\n",
      "RUTW 220211P2200000  102434      22\n",
      "RUTW 220128P2250000  102434      22\n",
      "RUTW 220211C2290000  102434      22\n",
      "RUTW 220110C2385000  102434      22\n",
      "RUTW 220211C2300000  102434      22\n",
      "RUTW 220131P1600000  102434      22\n",
      "RUTW 220131P1990000  102434      22\n",
      "RUTW 220114P2160000  102434      22\n",
      "RUTW 220114P2125000  102434      22\n",
      "RUTW 220228P2050000  102434      21\n",
      "RUTW 220110P2115000  102434      21\n",
      "RUT 220318P2240000   102434      21\n",
      "RUT 220218C2260000   102434      21\n",
      "RUTW 220110C2380000  102434      21\n",
      "RUT 220121C2220000   102434      21\n",
      "RUTW 220112P2140000  102434      21\n",
      "RUTW 220105C2235000  102434      21\n",
      "RUTW 220228C2250000  102434      21\n",
      "RUTW 220110C2355000  102434      21\n",
      "RUTW 220105P2140000  102434      21\n",
      "RUTW 220110P2175000  102434      21\n",
      "RUTW 220128P1750000  102434      20\n",
      "RUTW 220103P2300000  102434      20\n",
      "RUTW 220105P2150000  102434      20\n",
      "RUTW 220211C2240000  102434      20\n",
      "RUTW 220107P1800000  102434      20\n",
      "RUTW 220107P1810000  102434      20\n",
      "RUTW 220105P2235000  102434      20\n",
      "RUTW 220114C2420000  102434      20\n",
      "RUTW 220110C2375000  102434      20\n",
      "RUT 220218P1850000   102434      20\n",
      "RUT 220318P2170000   102434      20\n",
      "RUTW 220204C2500000  102434      20\n",
      "RUTW 220331C2250000  102434      20\n",
      "RUTW 220128P1995000  102434      20\n",
      "RUTW 220107P2215000  102434      20\n",
      "RUTW 220107C2130000  102434      20\n",
      "RUTW 220114P1930000  102434      20\n",
      "RUTW 220107C2210000  102434      20\n",
      "RUTW 220103P2180000  102434      20\n",
      "RUTW 220204C2240000  102434      20\n",
      "RUT 220121P2320000   102434      20\n",
      "RUTW 220128P2200000  102434      19\n",
      "RUTW 220114P2220000  102434      19\n",
      "RUT 220318C2350000   102434      19\n",
      "RUTW 220107P2125000  102434      19\n",
      "RUTW 220128C2300000  102434      19\n",
      "RUTW 220114P2035000  102434      19\n",
      "RUTW 220128P2190000  102434      19\n",
      "RUTW 220228P2220000  102434      19\n",
      "RUTW 220228P2280000  102434      19\n",
      "RUTW 220107P1945000  102434      19\n",
      "RUTW 220105P2205000  102434      19\n",
      "RUTW 220110C2285000  102434      18\n",
      "RUTW 220114P2210000  102434      18\n",
      "RUT 220121P1760000   102434      18\n",
      "RUTW 220204C2290000  102434      18\n",
      "RUTW 220107P2070000  102434      18\n",
      "RUTW 220110P2240000  102434      18\n",
      "RUTW 220107P2155000  102434      18\n",
      "RUTW 220110P2220000  102434      18\n",
      "RUT 220218P2140000   102434      18\n",
      "RUT 220218C2440000   102434      18\n",
      "RUTW 220114C2345000  102434      18\n",
      "RUTW 220107C2400000  102434      18\n",
      "RUT 220121C2410000   102434      18\n",
      "RUTW 220110C2420000  102434      18\n",
      "RUTW 220114P2100000  102434      18\n",
      "RUT 220218C2520000   102434      18\n",
      "RUTW 220110P2150000  102434      18\n",
      "RUTW 220114C2310000  102434      18\n",
      "RUT 220121P2020000   102434      18\n",
      "RUTW 220228P2310000  102434      17\n",
      "RUT 220218P1930000   102434      17\n",
      "RUT 220121P1990000   102434      17\n",
      "RUT 220218P2050000   102434      17\n",
      "RUTW 220112C2330000  102434      17\n",
      "RUTW 220110C2275000  102434      17\n",
      "RUT 220121C2370000   102434      17\n",
      "RUTW 220110P2275000  102434      17\n",
      "RUTW 220211C2270000  102434      17\n",
      "RUTW 220128P2040000  102434      17\n",
      "RUTW 220204C2440000  102434      17\n",
      "RUTW 220112C2290000  102434      16\n",
      "RUTW 220112P2260000  102434      16\n",
      "RUTW 220131P1940000  102434      16\n",
      "RUTW 220128P2095000  102434      16\n",
      "RUT 220121P1940000   102434      16\n",
      "RUTW 220107C2370000  102434      16\n",
      "RUTW 220105C2250000  102434      16\n",
      "RUTW 220110P2235000  102434      16\n",
      "RUTW 220118P2260000  102434      16\n",
      "RUTW 220228P2180000  102434      16\n",
      "RUTW 220114C2380000  102434      16\n",
      "RUT 220318P2100000   102434      15\n",
      "RUTW 220105C2400000  102434      15\n",
      "RUTW 220128P2135000  102434      15\n",
      "RUTW 220204C2510000  102434      15\n",
      "RUTW 220114P1980000  102434      15\n",
      "RUTW 220118P2290000  102434      15\n",
      "RUTW 220114P2240000  102434      15\n",
      "RUTW 220112C2265000  102434      15\n",
      "RUTW 220114P2265000  102434      15\n",
      "RUTW 220204P1910000  102434      15\n",
      "RUT 220121P2290000   102434      15\n",
      "RUT 220218P1650000   102434      15\n",
      "RUT 220218P2080000   102434      15\n",
      "RUTW 220204P1920000  102434      15\n",
      "RUTW 220204P1945000  102434      15\n",
      "RUTW 220204P1955000  102434      15\n",
      "RUT 220121C2330000   102434      15\n",
      "RUTW 220131P1930000  102434      15\n",
      "RUT 220218C2370000   102434      15\n",
      "RUTW 220103P2205000  102434      15\n",
      "RUTW 220107P1795000  102434      15\n",
      "RUT 220121P1750000   102434      15\n",
      "RUTW 220114P2090000  102434      15\n",
      "RUTW 220110C2245000  102434      15\n",
      "RUTW 220105P2100000  102434      15\n",
      "RUTW 220118P2250000  102434      15\n",
      "RUT 220121P1800000   102434      15\n",
      "RUTW 220103C2345000  102434      15\n",
      "RUTW 220114P2140000  102434      15\n",
      "RUTW 220110C2260000  102434      15\n",
      "RUTW 220107P1805000  102434      15\n",
      "RUTW 220105C2345000  102434      15\n",
      "RUTW 220107P2090000  102434      15\n",
      "RUT 220121P1860000   102434      15\n",
      "RUTW 220110C2250000  102434      14\n",
      "RUTW 220114C2280000  102434      14\n",
      "RUTW 220228P2320000  102434      14\n",
      "RUTW 220128C2435000  102434      14\n",
      "RUTW 220112C2260000  102434      14\n",
      "RUTW 220114C2395000  102434      14\n",
      "RUTW 220105P2160000  102434      14\n",
      "RUTW 220228P2260000  102434      14\n",
      "RUTW 220105P2170000  102434      14\n",
      "RUTW 220105P2175000  102434      14\n",
      "RUTW 220228P2060000  102434      14\n",
      "RUTW 220114P2185000  102434      14\n",
      "RUTW 220110P2140000  102434      14\n",
      "RUT 220218C2430000   102434      14\n",
      "RUTW 220118P2135000  102434      14\n",
      "RUTW 220114P2145000  102434      14\n",
      "RUT 220218C2310000   102434      13\n",
      "RUTW 220131P2120000  102434      13\n",
      "RUTW 220110C2330000  102434      13\n",
      "RUTW 220103P2285000  102434      13\n",
      "RUTW 220103P2290000  102434      13\n",
      "RUTW 220103P2295000  102434      13\n",
      "RUT 220218P1750000   102434      13\n",
      "RUT 220121P2310000   102434      13\n",
      "RUTW 220107C2305000  102434      13\n",
      "RUTW 220228P2030000  102434      13\n",
      "RUTW 220131P2050000  102434      13\n",
      "RUTW 220228P2070000  102434      12\n",
      "RUTW 220112P2255000  102434      12\n",
      "RUT 220218P2090000   102434      12\n",
      "RUTW 220110P2210000  102434      12\n",
      "RUTW 220204P2035000  102434      12\n",
      "RUTW 220204P1965000  102434      12\n",
      "RUTW 220204P1970000  102434      12\n",
      "RUTW 220331C2350000  102434      12\n",
      "RUTW 220107C2410000  102434      12\n",
      "RUT 220218P1990000   102434      12\n",
      "RUTW 220211P1830000  102434      12\n",
      "RUTW 220131C2400000  102434      12\n",
      "RUT 220121C2460000   102434      12\n",
      "RUT 220121P2010000   102434      12\n",
      "RUTW 220107P2290000  102434      12\n",
      "RUTW 220131C2170000  102434      12\n",
      "RUTW 220128P2130000  102434      12\n",
      "RUTW 220128P2140000  102434      12\n",
      "RUTW 220114C2405000  102434      12\n",
      "RUT 220218C2500000   102434      12\n",
      "RUTW 220118C2310000  102434      11\n",
      "RUT 220121P1890000   102434      11\n",
      "RUTW 220118C2260000  102434      11\n",
      "RUTW 220128C2240000  102434      11\n",
      "RUTW 220131P2280000  102434      11\n",
      "RUTW 220114C2390000  102434      11\n",
      "RUT 220218P2150000   102434      11\n",
      "RUTW 220128C2170000  102434      11\n",
      "RUTW 220112C2350000  102434      11\n",
      "RUTW 220114C2285000  102434      11\n",
      "RUTW 220128P1970000  102434      11\n",
      "RUTW 220204P2045000  102434      11\n",
      "RUTW 220110C2255000  102434      11\n",
      "RUT 220218C2320000   102434      11\n",
      "RUTW 220228P1990000  102434      11\n",
      "RUT 220218P1960000   102434      11\n",
      "RUTW 220118C2320000  102434      11\n",
      "RUTW 220114P2280000  102434      11\n",
      "RUTW 220128P2280000  102434      10\n",
      "RUTW 220204C2420000  102434      10\n",
      "RUTW 220103P2080000  102434      10\n",
      "RUTW 220105P2135000  102434      10\n",
      "RUTW 220110C2235000  102434      10\n",
      "RUTW 220105C2195000  102434      10\n",
      "RUTW 220228P2110000  102434      10\n",
      "RUTW 220105C2215000  102434      10\n",
      "RUTW 220114P2195000  102434      10\n",
      "RUTW 220114P2180000  102434      10\n",
      "RUTW 220110C2300000  102434      10\n",
      "RUTW 220128C2190000  102434      10\n",
      "RUT 220218C2510000   102434      10\n",
      "RUTW 220204C2410000  102434      10\n",
      "RUTW 220118P2210000  102434      10\n",
      "RUTW 220228P2040000  102434      10\n",
      "RUTW 220128P1895000  102434      10\n",
      "RUTW 220228P2010000  102434      10\n",
      "RUT 220318C2160000   102434      10\n",
      "RUTW 220128P1950000  102434      10\n",
      "RUTW 220114C2200000  102434      10\n",
      "RUTW 220131P1950000  102434      10\n",
      "RUTW 220110P2300000  102434      10\n",
      "RUTW 220110P2295000  102434      10\n",
      "RUT 220121C2240000   102434      10\n",
      "RUTW 220204P2010000  102434      10\n",
      "RUT 220121C2510000   102434      10\n",
      "RUT 220121C2520000   102434      10\n",
      "RUTW 220204P1975000  102434      10\n",
      "RUTW 220107C2235000  102434      10\n",
      "RUTW 220114P2290000  102434      10\n",
      "RUTW 220118P2230000  102434      10\n",
      "RUTW 220110C2320000  102434      10\n",
      "RUTW 220107P2275000  102434      10\n",
      "RUTW 220211P2280000  102434      10\n",
      "RUTW 220107C2420000  102434      10\n",
      "RUTW 220228C2280000  102434      10\n",
      "RUTW 220118C2200000  102434      10\n",
      "RUTW 220105C2395000  102434      10\n",
      "RUTW 220105C2390000  102434      10\n",
      "RUTW 220228C2550000  102434      10\n",
      "RUTW 220112P2175000  102434      10\n",
      "RUTW 220128C2480000  102434      10\n",
      "RUT 220218P2130000   102434      10\n",
      "RUTW 220107C2435000  102434      10\n",
      "RUTW 220107C2430000  102434      10\n",
      "RUTW 220112P2230000  102434      10\n",
      "RUTW 220105P1920000  102434      10\n",
      "RUT 220218P1970000   102434      10\n",
      "RUTW 220107C2385000  102434      10\n",
      "RUTW 220128P2075000  102434       9\n",
      "RUTW 220131P2240000  102434       9\n",
      "RUTW 220110P2180000  102434       9\n",
      "RUT 220218C2490000   102434       9\n",
      "RUTW 220211C2360000  102434       9\n",
      "RUTW 220118C2350000  102434       9\n",
      "RUTW 220110P2205000  102434       9\n",
      "RUT 220318C2750000   102434       9\n",
      "RUT 220218P1920000   102434       9\n",
      "RUTW 220204P2260000  102434       9\n",
      "RUT 231215C3350000   102434       9\n",
      "RUT 231215C3400000   102434       9\n",
      "RUTW 220131P2230000  102434       9\n",
      "RUTW 220131C2460000  102434       9\n",
      "RUTW 220118P1950000  102434       9\n",
      "RUT 220318C2450000   102434       9\n",
      "RUT 220121P1900000   102434       9\n",
      "RUT 220318C2360000   102434       9\n",
      "RUTW 220118P2100000  102434       9\n",
      "RUT 220121P1730000   102434       9\n",
      "RUT 220121C2200000   102434       9\n",
      "RUT 220218C2330000   102434       9\n",
      "RUT 220121P2360000   102434       9\n",
      "RUT 220218C2340000   102434       9\n",
      "RUT 220218P2300000   102434       9\n",
      "RUTW 220107C2280000  102434       9\n",
      "RUT 220121P1720000   102434       9\n",
      "RUTW 220107P1950000  102434       9\n",
      "RUTW 220110C2315000  102434       9\n",
      "RUTW 220114P2170000  102434       9\n",
      "RUTW 220107P2225000  102434       9\n",
      "RUTW 220114P2190000  102434       9\n",
      "RUTW 220228P2210000  102434       9\n",
      "RUT 220121P2300000   102434       8\n",
      "RUTW 220204C2340000  102434       8\n",
      "RUTW 220103C2210000  102434       8\n",
      "RUTW 220118C2305000  102434       8\n",
      "RUTW 220331P1700000  102434       8\n",
      "RUT 220218P2110000   102434       8\n",
      "RUTW 220204P2060000  102434       8\n",
      "RUTW 220105C2365000  102434       8\n",
      "RUTW 220107P2010000  102434       8\n",
      "RUTW 220110C2290000  102434       8\n",
      "RUTW 220103C2340000  102434       8\n",
      "RUTW 220110C2310000  102434       8\n",
      "RUTW 220128C2410000  102434       8\n",
      "RUTW 220228P1960000  102434       8\n",
      "RUTW 220211C2450000  102434       8\n",
      "RUTW 220228P2080000  102434       8\n",
      "RUTW 220110P2050000  102434       8\n",
      "RUT 220121C2210000   102434       8\n",
      "RUT 220318C2400000   102434       8\n",
      "RUT 220121P1770000   102434       8\n",
      "RUTW 220110P2165000  102434       8\n",
      "RUTW 220128P2150000  102434       8\n",
      "RUTW 220228C2440000  102434       8\n",
      "RUTW 220110C2340000  102434       8\n",
      "RUTW 220112P2000000  102434       8\n",
      "RUTW 220112P1990000  102434       8\n",
      "RUTW 220112C2360000  102434       8\n",
      "RUTW 220211C2340000  102434       8\n",
      "RUT 220318P1800000   102434       8\n",
      "RUTW 220110P2185000  102434       8\n",
      "RUT 220318C2700000   102434       8\n",
      "RUTW 220110P2255000  102434       8\n",
      "RUTW 220531C2100000  102434       8\n",
      "RUT 220121P1880000   102434       7\n",
      "RUT 220916C2470000   102434       7\n",
      "RUTW 220211C2440000  102434       7\n",
      "RUTW 220107C2285000  102434       7\n",
      "RUT 220121P1930000   102434       7\n",
      "RUTW 220112C2275000  102434       7\n",
      "RUTW 220112P2270000  102434       7\n",
      "RUTW 220118C2375000  102434       7\n",
      "RUTW 220107C2355000  102434       7\n",
      "RUTW 220128C2420000  102434       7\n",
      "RUTW 220107P2320000  102434       7\n",
      "RUTW 220128C2280000  102434       7\n",
      "RUTW 220114P2120000  102434       7\n",
      "RUT 220318P2050000   102434       7\n",
      "RUTW 220114C2295000  102434       7\n",
      "RUT 220218P2010000   102434       7\n",
      "RUTW 220110P2040000  102434       7\n",
      "RUTW 220118P2255000  102434       7\n",
      "RUT 220218P1700000   102434       7\n",
      "RUTW 220110P2215000  102434       7\n",
      "RUTW 220128P2125000  102434       7\n",
      "RUTW 220110P2265000  102434       7\n",
      "RUTW 220131P2170000  102434       7\n",
      "RUT 220218C2610000   102434       7\n",
      "RUTW 220110P2135000  102434       7\n",
      "RUTW 220128P2110000  102434       7\n",
      "RUTW 220105P2290000  102434       7\n",
      "RUT 220318C2180000   102434       6\n",
      "RUTW 220211C2500000  102434       6\n",
      "RUTW 220110P2195000  102434       6\n",
      "RUTW 220128P2105000  102434       6\n",
      "RUTW 220114C2385000  102434       6\n",
      "RUTW 220118P2205000  102434       6\n",
      "RUTW 220204P2105000  102434       6\n",
      "RUTW 220131P2310000  102434       6\n",
      "RUTW 220211P2240000  102434       6\n",
      "RUTW 220107P2015000  102434       6\n",
      "RUTW 220331P1990000  102434       6\n",
      "RUTW 220204P2095000  102434       6\n",
      "RUT 220121C2230000   102434       6\n",
      "RUTW 220110P2245000  102434       6\n",
      "RUT 220218C2390000   102434       6\n",
      "RUTW 220131C2380000  102434       6\n",
      "RUTW 220114C2340000  102434       6\n",
      "RUTW 220105C2360000  102434       6\n",
      "RUTW 220114C2230000  102434       6\n",
      "RUTW 220211P2060000  102434       6\n",
      "RUTW 220118C2370000  102434       6\n",
      "RUTW 220128C2475000  102434       6\n",
      "RUTW 220118C2380000  102434       6\n",
      "RUTW 220114C2430000  102434       6\n",
      "RUTW 220118C2265000  102434       6\n",
      "RUTW 220114P2150000  102434       6\n",
      "RUTW 220114C2335000  102434       6\n",
      "RUTW 220103P2135000  102434       6\n",
      "RUTW 220107P1995000  102434       6\n",
      "RUTW 220204P2070000  102434       6\n",
      "RUTW 220112P2220000  102434       6\n",
      "RUTW 220107P2050000  102434       6\n",
      "RUTW 220531P2200000  102434       6\n",
      "RUTW 220110P2125000  102434       6\n",
      "RUTW 220112C2285000  102434       6\n",
      "RUT 220218C2180000   102434       6\n",
      "RUTW 220118P2215000  102434       6\n",
      "RUTW 220110C2280000  102434       6\n",
      "RUTW 220112C2345000  102434       6\n",
      "RUTW 220228C2420000  102434       6\n",
      "RUT 241220C3200000   102434       6\n",
      "RUTW 220228P2000000  102434       6\n",
      "RUT 220318P1850000   102434       6\n",
      "RUT 220121P1780000   102434       6\n",
      "RUT 220218P1980000   102434       6\n",
      "RUTW 220228C2340000  102434       6\n",
      "RUTW 220128C2380000  102434       6\n",
      "RUTW 220228C2470000  102434       6\n",
      "RUTW 220105P2165000  102434       6\n",
      "RUTW 220204P2205000  102434       6\n",
      "RUTW 220228P2100000  102434       6\n",
      "RUTW 220228C2480000  102434       6\n",
      "RUTW 220204P2200000  102434       6\n",
      "RUTW 220204C2470000  102434       5\n",
      "RUTW 220105P2145000  102434       5\n",
      "RUTW 220131P2140000  102434       5\n",
      "RUT 220318P1950000   102434       5\n",
      "RUT 231215P500000    102434       5\n",
      "RUTW 220103P2165000  102434       5\n",
      "RUTW 220331P2040000  102434       5\n",
      "RUTW 220107P1990000  102434       5\n",
      "RUTW 220204C2475000  102434       5\n",
      "RUTW 220204C2490000  102434       5\n",
      "RUTW 220204C2345000  102434       5\n",
      "RUT 220121C2500000   102434       5\n",
      "RUTW 220118P2105000  102434       5\n",
      "RUTW 220114P1825000  102434       5\n",
      "RUTW 220131C2390000  102434       5\n",
      "RUTW 220112P2200000  102434       5\n",
      "RUTW 220110C2345000  102434       5\n",
      "RUTW 220110C2265000  102434       5\n",
      "RUTW 220107C2275000  102434       5\n",
      "RUTW 220112C2240000  102434       5\n",
      "RUTW 220118C2340000  102434       5\n",
      "RUTW 220107P2115000  102434       5\n",
      "RUTW 220105P2125000  102434       5\n",
      "RUTW 220211P2010000  102434       5\n",
      "RUT 220318P2210000   102434       5\n",
      "RUTW 220114P2245000  102434       5\n",
      "RUTW 220211C2550000  102434       5\n",
      "RUTW 220114P2355000  102434       5\n",
      "RUTW 220204C2550000  102434       5\n",
      "RUTW 220105C2210000  102434       5\n",
      "RUTW 220131P2250000  102434       5\n",
      "RUTW 220204C2300000  102434       5\n",
      "RUTW 220107P2340000  102434       5\n",
      "RUTW 220118P2055000  102434       5\n",
      "RUT 220218P1550000   102434       5\n",
      "RUTW 220118P2045000  102434       5\n",
      "RUTW 220128P2195000  102434       5\n",
      "RUTW 220228P2330000  102434       5\n",
      "RUTW 220204P2275000  102434       5\n",
      "RUTW 220112P2275000  102434       5\n",
      "RUTW 220112P2240000  102434       5\n",
      "RUTW 220118C2385000  102434       5\n",
      "RUTW 220114P2030000  102434       5\n",
      "RUTW 220331C2400000  102434       5\n",
      "RUTW 220114P1960000  102434       5\n",
      "RUTW 220114P1950000  102434       5\n",
      "RUT 220121P1740000   102434       5\n",
      "RUTW 220228C2330000  102434       5\n",
      "RUTW 220105C2425000  102434       5\n",
      "RUTW 220114C2510000  102434       5\n",
      "RUTW 220105C2370000  102434       5\n",
      "RUTW 220128P1975000  102434       5\n",
      "RUT 221216C2450000   102434       5\n",
      "RUTW 220128P2180000  102434       5\n",
      "RUTW 220114P2130000  102434       5\n",
      "RUTW 220228C2230000  102434       5\n",
      "RUTW 220211C2275000  102434       5\n",
      "RUT 221216C2500000   102434       5\n",
      "RUTW 220128C2425000  102434       5\n",
      "RUTW 220228P2140000  102434       5\n",
      "RUTW 220105P2080000  102434       4\n",
      "RUTW 220118C2295000  102434       4\n",
      "RUT 220218P2340000   102434       4\n",
      "RUTW 220204P2215000  102434       4\n",
      "RUTW 220118C2345000  102434       4\n",
      "RUTW 220429P2100000  102434       4\n",
      "RUTW 220228C2500000  102434       4\n",
      "RUTW 220204C2280000  102434       4\n",
      "RUTW 220107C2175000  102434       4\n",
      "RUTW 220107P2105000  102434       4\n",
      "RUT 220218P2330000   102434       4\n",
      "RUTW 220204C2350000  102434       4\n",
      "RUTW 220131P1980000  102434       4\n",
      "RUTW 220112C2300000  102434       4\n",
      "RUTW 220105P2295000  102434       4\n",
      "RUTW 220228P2130000  102434       4\n",
      "RUT 220617C2100000   102434       4\n",
      "RUTW 220211P1980000  102434       4\n",
      "RUTW 220128C2355000  102434       4\n",
      "RUTW 220211P1960000  102434       4\n",
      "RUTW 220110P2100000  102434       4\n",
      "RUTW 220118C2500000  102434       4\n",
      "RUTW 220228C2510000  102434       4\n",
      "RUTW 220112C2305000  102434       4\n",
      "RUTW 220211C2445000  102434       4\n",
      "RUTW 220105P2300000  102434       4\n",
      "RUTW 220128P2155000  102434       4\n",
      "RUTW 220128C2305000  102434       4\n",
      "RUT 220218C2170000   102434       4\n",
      "RUTW 220128C2200000  102434       4\n",
      "RUTW 220204P2255000  102434       4\n",
      "RUT 241220C2600000   102434       4\n",
      "RUTW 220228P2150000  102434       4\n",
      "RUTW 220131P2270000  102434       4\n",
      "RUTW 220228P2170000  102434       4\n",
      "RUTW 220128P2120000  102434       4\n",
      "RUTW 220128P2235000  102434       4\n",
      "RUTW 220118C2400000  102434       4\n",
      "RUTW 220105C2295000  102434       4\n",
      "RUT 220318C2600000   102434       4\n",
      "RUT 220318C2550000   102434       4\n",
      "RUTW 220103C2235000  102434       4\n",
      "RUTW 220128C2230000  102434       4\n",
      "RUT 220121C2480000   102434       4\n",
      "RUTW 220128P2205000  102434       4\n",
      "RUTW 220204C2190000  102434       4\n",
      "RUTW 220131P2190000  102434       4\n",
      "RUTW 220114C2360000  102434       4\n",
      "RUTW 220114C2350000  102434       4\n",
      "RUT 220121C2340000   102434       4\n",
      "RUTW 220114P2110000  102434       4\n",
      "RUTW 220103C2170000  102434       4\n",
      "RUTW 220131C2490000  102434       4\n",
      "RUTW 220128P2090000  102434       4\n",
      "RUTW 220112P2235000  102434       4\n",
      "RUTW 220211P2050000  102434       4\n",
      "RUTW 220211C2465000  102434       4\n",
      "RUTW 220118P2000000  102434       4\n",
      "RUT 220218P2220000   102434       4\n",
      "RUTW 220128P2070000  102434       4\n",
      "RUTW 220131C2280000  102434       4\n",
      "RUTW 220204P2100000  102434       4\n",
      "RUTW 220204P2115000  102434       4\n",
      "RUTW 220204C2225000  102434       4\n",
      "RUTW 220118P2050000  102434       4\n",
      "RUT 230616P1960000   102434       4\n",
      "RUTW 220228C2320000  102434       3\n",
      "RUTW 220114P2085000  102434       3\n",
      "RUT 220218P2280000   102434       3\n",
      "RUTW 220114P2155000  102434       3\n",
      "RUTW 220114P2075000  102434       3\n",
      "RUTW 220118C2280000  102434       3\n",
      "RUTW 220114P2045000  102434       3\n",
      "RUTW 220114P1985000  102434       3\n",
      "RUTW 220204P1800000  102434       3\n",
      "RUTW 220211P2215000  102434       3\n",
      "RUTW 220128C2275000  102434       3\n",
      "RUTW 220105C2355000  102434       3\n",
      "RUTW 220103C2350000  102434       3\n",
      "RUTW 220105P2115000  102434       3\n",
      "RUTW 220128C2295000  102434       3\n",
      "RUTW 220211C2420000  102434       3\n",
      "RUTW 220118P2110000  102434       3\n",
      "RUTW 220128C2255000  102434       3\n",
      "RUTW 220128P2225000  102434       3\n",
      "RUTW 220114C2315000  102434       3\n",
      "RUTW 220228C2360000  102434       3\n",
      "RUTW 220105C2335000  102434       3\n",
      "RUTW 220118P2200000  102434       3\n",
      "RUTW 220114P2205000  102434       3\n",
      "RUTW 220331P1750000  102434       3\n",
      "RUTW 220128P2185000  102434       3\n",
      "RUTW 220107C2245000  102434       3\n",
      "RUTW 220128C2360000  102434       3\n",
      "RUTW 220211P2095000  102434       3\n",
      "RUTW 220211C2245000  102434       3\n",
      "RUT 220121P2350000   102434       3\n",
      "RUTW 220131C2320000  102434       3\n",
      "RUT 220318C2380000   102434       3\n",
      "RUTW 220131P2210000  102434       3\n",
      "RUTW 220114P1765000  102434       3\n",
      "RUT 220121P1910000   102434       3\n",
      "RUTW 220112P2265000  102434       3\n",
      "RUTW 220429P2010000  102434       3\n",
      "RUTW 220112C2280000  102434       3\n",
      "RUTW 220112C2295000  102434       3\n",
      "RUT 220617P2200000   102434       3\n",
      "RUTW 220107P2390000  102434       3\n",
      "RUTW 220128C2345000  102434       3\n",
      "RUTW 220114P1775000  102434       3\n",
      "RUTW 220103P2160000  102434       3\n",
      "RUTW 220112P2195000  102434       3\n",
      "RUTW 220118P2245000  102434       3\n",
      "RUT 220218C2240000   102434       3\n",
      "RUTW 220211P2080000  102434       3\n",
      "RUTW 220128P1900000  102434       3\n",
      "RUTW 220107P1270000  102434       3\n",
      "RUTW 220204P2125000  102434       3\n",
      "RUTW 220429C1940000  102434       3\n",
      "RUTW 220118C2325000  102434       3\n",
      "RUTW 220204C2230000  102434       3\n",
      "RUT 220121C2390000   102434       3\n",
      "RUTW 220211P2255000  102434       3\n",
      "RUTW 220118C2355000  102434       3\n",
      "RUTW 220128P2080000  102434       2\n",
      "RUTW 220114C2375000  102434       2\n",
      "RUTW 220128P2085000  102434       2\n",
      "RUTW 220105P2285000  102434       2\n",
      "RUTW 220114P2070000  102434       2\n",
      "RUT 220121P1920000   102434       2\n",
      "RUTW 220114C2365000  102434       2\n",
      "RUTW 220114C2130000  102434       2\n",
      "RUTW 220211P2130000  102434       2\n",
      "RUTW 220114P2080000  102434       2\n",
      "RUTW 220103P2320000  102434       2\n",
      "RUTW 220118C2240000  102434       2\n",
      "RUT 230616C2630000   102434       2\n",
      "RUTW 220211P1590000  102434       2\n",
      "RUT 220218C2750000   102434       2\n",
      "RUTW 220429P1500000  102434       2\n",
      "RUTW 220211P2105000  102434       2\n",
      "RUTW 220331P2260000  102434       2\n",
      "RUT 230616P2000000   102434       2\n",
      "RUTW 220131C2650000  102434       2\n",
      "RUTW 220204P2230000  102434       2\n",
      "RUT 220218C2290000   102434       2\n",
      "RUTW 220211P2185000  102434       2\n",
      "RUTW 220228C2450000  102434       2\n",
      "RUTW 220128P2145000  102434       2\n",
      "RUTW 220128P1905000  102434       2\n",
      "RUTW 220228C2520000  102434       2\n",
      "RUTW 220128P2300000  102434       2\n",
      "RUTW 220128C2365000  102434       2\n",
      "RUTW 220331C2340000  102434       2\n",
      "RUTW 220204P2290000  102434       2\n",
      "RUTW 220128C2415000  102434       2\n",
      "RUTW 220211P2180000  102434       2\n",
      "RUTW 220228P1920000  102434       2\n",
      "RUTW 220105C2430000  102434       2\n",
      "RUTW 220107P1275000  102434       2\n",
      "RUTW 220128C2430000  102434       2\n",
      "RUTW 220204P2220000  102434       2\n",
      "RUTW 220114C2450000  102434       2\n",
      "RUTW 220204P2210000  102434       2\n",
      "RUTW 220228C2270000  102434       2\n",
      "RUTW 220128C2285000  102434       2\n",
      "RUTW 220211C2475000  102434       2\n",
      "RUT 220218C2850000   102434       2\n",
      "RUT 220121P2340000   102434       2\n",
      "RUTW 220204P2155000  102434       2\n",
      "RUTW 220228P1840000  102434       2\n",
      "RUT 220121P2330000   102434       2\n",
      "RUTW 220211C2495000  102434       2\n",
      "RUT 220121P1870000   102434       2\n",
      "RUTW 220131P2060000  102434       2\n",
      "RUT 220121P1150000   102434       2\n",
      "RUTW 220105P2105000  102434       2\n",
      "RUTW 220204C2330000  102434       2\n",
      "RUTW 220105P2035000  102434       2\n",
      "RUTW 220105P2325000  102434       2\n",
      "RUT 220318P1400000   102434       2\n",
      "RUTW 220429P2260000  102434       2\n",
      "RUTW 220211P2030000  102434       2\n",
      "RUTW 220114P2200000  102434       2\n",
      "RUTW 220114C2245000  102434       2\n",
      "RUTW 220107P2055000  102434       2\n",
      "RUTW 220211C2430000  102434       2\n",
      "RUTW 220112C2255000  102434       2\n",
      "RUTW 220107C2150000  102434       2\n",
      "RUTW 220105P2095000  102434       2\n",
      "RUTW 220112C2325000  102434       2\n",
      "RUTW 220118P2275000  102434       2\n",
      "RUTW 220112P2165000  102434       2\n",
      "RUTW 220107P2285000  102434       2\n",
      "RUTW 220112C2355000  102434       2\n",
      "RUT 220318P1700000   102434       2\n",
      "RUTW 220128P2275000  102434       2\n",
      "RUTW 220128P2115000  102434       2\n",
      "RUTW 220114P2235000  102434       2\n",
      "RUTW 220107P2315000  102434       2\n",
      "RUTW 220114P2225000  102434       2\n",
      "RUTW 220114C2265000  102434       2\n",
      "RUT 220318P1900000   102434       2\n",
      "RUTW 220204C2430000  102434       2\n",
      "RUTW 220118C2315000  102434       2\n",
      "RUTW 220103C2355000  102434       2\n",
      "RUTW 220112P2190000  102434       2\n",
      "RUTW 220131C2240000  102434       2\n",
      "RUTW 220105P2030000  102434       2\n",
      "RUTW 220114C2205000  102434       2\n",
      "RUTW 220331P2100000  102434       2\n",
      "RUT 220121C2170000   102434       2\n",
      "RUTW 220211P1965000  102434       2\n",
      "RUTW 220112P2225000  102434       2\n",
      "RUTW 220114P2165000  102434       2\n",
      "RUTW 220103P2150000  102434       2\n",
      "RUTW 220103P2140000  102434       2\n",
      "RUTW 220128P2220000  102434       2\n",
      "RUTW 220103P2130000  102434       2\n",
      "RUTW 220112P2145000  102434       2\n",
      "RUTW 220131P2220000  102434       2\n",
      "RUTW 220204C2175000  102434       2\n",
      "RUT 220121C2550000   102434       2\n",
      "RUTW 220131C2300000  102434       2\n",
      "RUTW 220128C2225000  102434       2\n",
      "RUTW 220107C2380000  102434       2\n",
      "RUTW 220211C2100000  102434       2\n",
      "RUTW 220211P2040000  102434       2\n",
      "RUTW 220228C2620000  102434       2\n",
      "RUTW 220112P2205000  102434       2\n",
      "RUTW 220204C2275000  102434       2\n",
      "RUT 220121C2600000   102434       2\n",
      "RUTW 220211P1915000  102434       2\n",
      "RUTW 220114C2305000  102434       2\n",
      "RUTW 220107C2200000  102434       2\n",
      "RUTW 220107P2040000  102434       2\n",
      "RUTW 220105P2320000  102434       2\n",
      "RUTW 220331C2330000  102434       1\n",
      "RUTW 220128C2330000  102434       1\n",
      "RUTW 220331C2600000  102434       1\n",
      "RUTW 220228P2120000  102434       1\n",
      "RUTW 220114P1890000  102434       1\n",
      "RUTW 220114C2050000  102434       1\n",
      "RUTW 220114P1430000  102434       1\n",
      "RUT 220617P1500000   102434       1\n",
      "RUTW 220114C2180000  102434       1\n",
      "RUTW 220114P1735000  102434       1\n",
      "RUT 230616P1940000   102434       1\n",
      "RUTW 220204P2110000  102434       1\n",
      "RUTW 220228P2160000  102434       1\n",
      "RUTW 220211C2285000  102434       1\n",
      "RUTW 220114C2070000  102434       1\n",
      "RUT 220617P1920000   102434       1\n",
      "RUT 230616P2020000   102434       1\n",
      "RUTW 220211C2255000  102434       1\n",
      "RUTW 220204P2245000  102434       1\n",
      "RUT 231215P1600000   102434       1\n",
      "RUTW 220204P2250000  102434       1\n",
      "RUTW 220204P2265000  102434       1\n",
      "RUTW 220204P2270000  102434       1\n",
      "RUTW 220429C2440000  102434       1\n",
      "RUTW 220114C2000000  102434       1\n",
      "RUTW 220204P2295000  102434       1\n",
      "RUTW 220228P1950000  102434       1\n",
      "RUTW 220228P1970000  102434       1\n",
      "RUTW 220429C2340000  102434       1\n",
      "RUTW 220204P2340000  102434       1\n",
      "RUTW 220228P2020000  102434       1\n",
      "RUTW 220114P1410000  102434       1\n",
      "RUTW 220204P2050000  102434       1\n",
      "RUTW 220118P2280000  102434       1\n",
      "RUTW 220114P1885000  102434       1\n",
      "RUTW 220114P1835000  102434       1\n",
      "RUT 220715C2570000   102434       1\n",
      "RUTW 220128C2265000  102434       1\n",
      "RUTW 220128C2245000  102434       1\n",
      "RUTW 220211C2425000  102434       1\n",
      "RUTW 220114C2370000  102434       1\n",
      "RUT 230616C2640000   102434       1\n",
      "RUTW 220118P2170000  102434       1\n",
      "RUTW 220118P2180000  102434       1\n",
      "RUTW 220429P2200000  102434       1\n",
      "RUTW 220118P2220000  102434       1\n",
      "RUTW 220331P1930000  102434       1\n",
      "RUTW 220331P1940000  102434       1\n",
      "RUTW 220114C2255000  102434       1\n",
      "RUTW 220331P2170000  102434       1\n",
      "RUTW 220211C2380000  102434       1\n",
      "RUTW 220114C2240000  102434       1\n",
      "RUTW 220118P2235000  102434       1\n",
      "RUTW 220204P1885000  102434       1\n",
      "RUTW 220211C2375000  102434       1\n",
      "RUTW 220204P1900000  102434       1\n",
      "RUTW 220429P2000000  102434       1\n",
      "RUTW 220204P1985000  102434       1\n",
      "RUTW 220118P2265000  102434       1\n",
      "RUTW 220331P2060000  102434       1\n",
      "RUTW 220331P2070000  102434       1\n",
      "RUT 220617P2260000   102434       1\n",
      "RUTW 220429P2190000  102434       1\n",
      "RUT 220121P2400000   102434       1\n",
      "RUTW 220128C2370000  102434       1\n",
      "RUTW 220107P2000000  102434       1\n",
      "RUTW 220118C2220000  102434       1\n",
      "RUTW 220211P2210000  102434       1\n",
      "RUTW 220128P2165000  102434       1\n",
      "RUTW 220107P1915000  102434       1\n",
      "RUTW 220211P1870000  102434       1\n",
      "RUTW 220107P1970000  102434       1\n",
      "RUTW 220630P2250000  102434       1\n",
      "RUT 220218P1200000   102434       1\n",
      "RUTW 220107C2070000  102434       1\n",
      "RUTW 220118C2275000  102434       1\n",
      "RUTW 220107C2405000  102434       1\n",
      "RUTW 220107C2375000  102434       1\n",
      "RUTW 220107C2365000  102434       1\n",
      "RUTW 220107P2035000  102434       1\n",
      "RUTW 220118C2290000  102434       1\n",
      "RUTW 220211P1935000  102434       1\n",
      "RUT 220121P1580000   102434       1\n",
      "RUTW 220118C2210000  102434       1\n",
      "RUTW 220128P2230000  102434       1\n",
      "RUTW 220128P2245000  102434       1\n",
      "RUTW 220103P2305000  102434       1\n",
      "RUT 220218C2560000   102434       1\n",
      "RUTW 220211P2195000  102434       1\n",
      "RUTW 220103P2310000  102434       1\n",
      "RUTW 220103P2315000  102434       1\n",
      "RUTW 220103P2325000  102434       1\n",
      "RUTW 220110P2105000  102434       1\n",
      "RUTW 220103P2340000  102434       1\n",
      "RUTW 220110C2390000  102434       1\n",
      "RUTW 220110C2395000  102434       1\n",
      "RUTW 220103P2350000  102434       1\n",
      "RUTW 220103P2360000  102434       1\n",
      "RUTW 220128P2270000  102434       1\n",
      "RUT 220318C2320000   102434       1\n",
      "RUTW 220110C2410000  102434       1\n",
      "RUTW 220118C2300000  102434       1\n",
      "RUTW 220107C2065000  102434       1\n",
      "RUTW 220103P2145000  102434       1\n",
      "RUTW 220105C2225000  102434       1\n",
      "RUTW 220211P2070000  102434       1\n",
      "RUTW 220211P2300000  102434       1\n",
      "RUT 220218P2380000   102434       1\n",
      "RUTW 220211P2075000  102434       1\n",
      "RUTW 220118C2365000  102434       1\n",
      "RUTW 220105C2375000  102434       1\n",
      "RUTW 220211P2110000  102434       1\n",
      "RUTW 220211P2120000  102434       1\n",
      "RUTW 220107P2330000  102434       1\n",
      "RUTW 220105C2200000  102434       1\n",
      "RUTW 220128P1920000  102434       1\n",
      "RUTW 220110P2060000  102434       1\n",
      "RUTW 220110P2080000  102434       1\n",
      "RUTW 220110P2085000  102434       1\n",
      "RUTW 220110P2090000  102434       1\n",
      "RUTW 220128P1965000  102434       1\n",
      "RUT 220218P2310000   102434       1\n",
      "RUTW 220128P1830000  102434       1\n",
      "RUTW 220630P1400000  102434       1\n",
      "RUTW 220118C2360000  102434       1\n",
      "RUTW 220131C2100000  102434       1\n",
      "RUTW 220211P1985000  102434       1\n",
      "RUTW 220211P2000000  102434       1\n",
      "RUT 220218P1450000   102434       1\n",
      "RUT 220218P1600000   102434       1\n",
      "RUT 220916C2400000   102434       1\n",
      "RUTW 220131C2230000  102434       1\n",
      "RUTW 220131C2250000  102434       1\n",
      "RUTW 220630P1850000  102434       1\n",
      "RUTW 220131C2260000  102434       1\n",
      "RUT 220121C2490000   102434       1\n",
      "RUT 220121C2160000   102434       1\n",
      "RUT 220121C2150000   102434       1\n",
      "RUTW 220630P1840000  102434       1\n",
      "RUT 220121C2140000   102434       1\n",
      "RUTW 220103P2170000  102434       1\n",
      "RUT 220318C2390000   102434       1\n",
      "RUT 220318C2410000   102434       1\n",
      "RUTW 220103C2380000  102434       1\n",
      "RUTW 220228C2100000  102434       1\n",
      "RUTW 220103C2165000  102434       1\n",
      "RUTW 220103C2225000  102434       1\n",
      "RUTW 220531C2330000  102434       1\n",
      "RUT 220218C2130000   102434       1\n",
      "RUT 220218C2110000   102434       1\n",
      "RUT 220218C2160000   102434       1\n",
      "RUT 220218C2220000   102434       1\n",
      "RUT 220318P2180000   102434       1\n",
      "RUTW 220114P2015000  102434       1\n",
      "RUT 220318P2160000   102434       1\n",
      "RUT 220318P2150000   102434       1\n",
      "RUTW 220131C2800000  102434       1\n",
      "RUTW 220114P2215000  102434       1\n",
      "RUT 220318P2000000   102434       1\n",
      "RUTW 220131P1450000  102434       1\n",
      "RUTW 220211C2575000  102434       1\n",
      "RUTW 220112C2340000  102434       1\n",
      "RUTW 220114P2020000  102434       1\n",
      "RUTW 220114P2010000  102434       1\n",
      "RUTW 220112C2270000  102434       1\n",
      "RUTW 220228C2430000  102434       1\n",
      "RUT 220617C2340000   102434       1\n",
      "RUT 220617C2300000   102434       1\n",
      "RUT 220218C2140000   102434       1\n",
      "RUTW 220112P2185000  102434       1\n",
      "RUTW 220112P2170000  102434       1\n",
      "RUTW 220112P2160000  102434       1\n",
      "RUTW 220114P1945000  102434       1\n",
      "RUTW 220112P2065000  102434       1\n",
      "RUTW 220228C2410000  102434       1\n",
      "RUTW 220114P2000000  102434       1\n",
      "RUTW 220228C2400000  102434       1\n",
      "RUTW 220228C2390000  102434       1\n",
      "RUTW 220228C2370000  102434       1\n",
      "RUTW 220228C2290000  102434       1\n",
      "RUTW 220228C2260000  102434       1\n",
      "RUT 220121P2370000   102434       1\n",
      "RUTW 220228C2180000  102434       1\n",
      "RUTW 220114P1990000  102434       1\n",
      "RUTW 220112C2310000  102434       1\n",
      "RUTW 220204C2400000  102434       1\n",
      "RUTW 220112C2250000  102434       1\n",
      "RUTW 220131P1920000  102434       1\n",
      "RUTW 220114P2275000  102434       1\n",
      "RUTW 220112C2100000  102434       1\n",
      "RUTW 220114P2320000  102434       1\n",
      "RUTW 220131P2160000  102434       1\n",
      "RUTW 220131P2180000  102434       1\n",
      "RUTW 220131P2320000  102434       1\n",
      "RUTW 220114P2330000  102434       1\n",
      "RUTW 220105P2360000  102434       1\n",
      "RUTW 220105P2350000  102434       1\n",
      "RUTW 220211P2190000  102434       1\n",
      "RUTW 220114P2360000  102434       1\n",
      "RUTW 220103P2075000  102434       1\n",
      "RUTW 220103P2095000  102434       1\n",
      "RUTW 220105P2340000  102434       1\n",
      "RUTW 220105P2315000  102434       1\n",
      "RUTW 220114P2315000  102434       1\n",
      "RUTW 220131P2130000  102434       1\n",
      "RUTW 220128P1985000  102434       1\n",
      "RUTW 220131P1880000  102434       1\n",
      "RUTW 220211C2525000  102434       1\n",
      "RUTW 220131C2750000  102434       1\n",
      "RUTW 220131P1890000  102434       1\n",
      "RUTW 220204C2255000  102434       1\n",
      "RUTW 220211C2510000  102434       1\n",
      "RUTW 220204C2295000  102434       1\n",
      "RUTW 220118C2395000  102434       0\n",
      "RUTW 220118P2420000  102434       0\n",
      "RUTW 220118P2410000  102434       0\n",
      "RUTW 220118P2425000  102434       0\n",
      "RUTW 220118C2420000  102434       0\n",
      "RUTW 220118P2365000  102434       0\n",
      "RUTW 220118P2415000  102434       0\n",
      "RUTW 220118C2415000  102434       0\n",
      "RUTW 220118P2430000  102434       0\n",
      "RUTW 220118P2405000  102434       0\n",
      "RUTW 220118P2350000  102434       0\n",
      "RUTW 220118C2410000  102434       0\n",
      "RUTW 220118C2405000  102434       0\n",
      "RUTW 220118P2355000  102434       0\n",
      "RUTW 220118P2375000  102434       0\n",
      "RUTW 220118P2360000  102434       0\n",
      "RUTW 220118P2380000  102434       0\n",
      "RUTW 220118P2435000  102434       0\n",
      "RUTW 220118P2385000  102434       0\n",
      "RUTW 220118P2390000  102434       0\n",
      "RUTW 220118P2395000  102434       0\n",
      "RUTW 220118P2400000  102434       0\n",
      "RUTW 220118P2370000  102434       0\n",
      "RUTW 220118P2505000  102434       0\n",
      "RUTW 220118P2440000  102434       0\n",
      "RUTW 220118P2550000  102434       0\n",
      "RUTW 220118P2570000  102434       0\n",
      "RUTW 220118P2565000  102434       0\n",
      "RUTW 220118C2145000  102434       0\n",
      "RUTW 220118C2150000  102434       0\n",
      "RUTW 220118P2560000  102434       0\n",
      "RUTW 220118P2555000  102434       0\n",
      "RUTW 220118P2545000  102434       0\n",
      "RUTW 220118C2140000  102434       0\n",
      "RUTW 220118P2540000  102434       0\n",
      "RUTW 220118P2535000  102434       0\n",
      "RUTW 220118P2530000  102434       0\n",
      "RUTW 220118C2155000  102434       0\n",
      "RUTW 220118P2525000  102434       0\n",
      "RUTW 220118P2520000  102434       0\n",
      "RUTW 220118P2575000  102434       0\n",
      "RUTW 220118P2580000  102434       0\n",
      "RUTW 220118P2445000  102434       0\n",
      "RUTW 220118P2620000  102434       0\n",
      "RUTW 220118C2125000  102434       0\n",
      "RUTW 220118C2130000  102434       0\n",
      "RUTW 220118P2640000  102434       0\n",
      "RUTW 220118P2635000  102434       0\n",
      "RUTW 220118P2630000  102434       0\n",
      "RUTW 220118P2625000  102434       0\n",
      "RUTW 220118P2615000  102434       0\n",
      "RUTW 220118P2585000  102434       0\n",
      "RUTW 220118P2610000  102434       0\n",
      "RUTW 220118C2135000  102434       0\n",
      "RUTW 220118P2605000  102434       0\n",
      "RUTW 220118P2600000  102434       0\n",
      "RUTW 220118P2595000  102434       0\n",
      "RUTW 220118P2590000  102434       0\n",
      "RUTW 220118P2515000  102434       0\n",
      "RUTW 220118C2160000  102434       0\n",
      "RUTW 220118C2165000  102434       0\n",
      "RUTW 220118P2480000  102434       0\n",
      "RUTW 220118P2500000  102434       0\n",
      "RUTW 220118C2330000  102434       0\n",
      "RUTW 220118C2335000  102434       0\n",
      "RUTW 220118P2495000  102434       0\n",
      "RUTW 220118P2490000  102434       0\n",
      "RUTW 220118P2485000  102434       0\n",
      "RUTW 220118P2475000  102434       0\n",
      "RUTW 220118C2170000  102434       0\n",
      "RUTW 220118P2470000  102434       0\n",
      "RUTW 220118P2465000  102434       0\n",
      "RUTW 220118P2460000  102434       0\n",
      "RUTW 220118P2455000  102434       0\n",
      "RUTW 220118C2390000  102434       0\n",
      "RUTW 220118P2450000  102434       0\n",
      "RUTW 220118C2285000  102434       0\n",
      "RUTW 220118P2340000  102434       0\n",
      "RUTW 220118C2270000  102434       0\n",
      "RUTW 220118C2255000  102434       0\n",
      "RUTW 220118C2250000  102434       0\n",
      "RUTW 220118C2245000  102434       0\n",
      "RUTW 220118C2235000  102434       0\n",
      "RUTW 220118P2510000  102434       0\n",
      "RUTW 220118C2230000  102434       0\n",
      "RUTW 220118C2225000  102434       0\n",
      "RUTW 220118C2215000  102434       0\n",
      "RUTW 220118C2205000  102434       0\n",
      "RUTW 220118C2195000  102434       0\n",
      "RUTW 220118C2190000  102434       0\n",
      "RUTW 220118C2185000  102434       0\n",
      "RUTW 220118C2180000  102434       0\n",
      "RUTW 220118C2175000  102434       0\n",
      "RUTW 220118P2345000  102434       0\n",
      "RUTW 220118P2095000  102434       0\n",
      "RUTW 220118P2335000  102434       0\n",
      "RUTW 220118C2695000  102434       0\n",
      "RUTW 220118P1855000  102434       0\n",
      "RUTW 220118P1850000  102434       0\n",
      "RUTW 220118P1845000  102434       0\n",
      "RUTW 220118P1840000  102434       0\n",
      "RUTW 220118P1835000  102434       0\n",
      "RUTW 220118P1830000  102434       0\n",
      "RUTW 220118P1825000  102434       0\n",
      "RUTW 220118P1820000  102434       0\n",
      "RUTW 220118P1815000  102434       0\n",
      "RUTW 220118P1810000  102434       0\n",
      "RUTW 220118C2715000  102434       0\n",
      "RUTW 220118C2710000  102434       0\n",
      "RUTW 220118C2705000  102434       0\n",
      "RUTW 220118C2700000  102434       0\n",
      "RUTW 220118C2690000  102434       0\n",
      "RUTW 220118P1860000  102434       0\n",
      "RUTW 220118P2060000  102434       0\n",
      "RUTW 220118C2685000  102434       0\n",
      "RUTW 220118C2680000  102434       0\n",
      "RUTW 220118C2675000  102434       0\n",
      "RUTW 220118P2065000  102434       0\n",
      "RUTW 220118P2070000  102434       0\n",
      "RUTW 220118C2670000  102434       0\n",
      "RUTW 220118C2665000  102434       0\n",
      "RUTW 220118C2660000  102434       0\n",
      "RUTW 220118C2655000  102434       0\n",
      "RUTW 220118C2650000  102434       0\n",
      "RUTW 220118C2645000  102434       0\n",
      "RUTW 220118C2640000  102434       0\n",
      "RUTW 220118C2635000  102434       0\n",
      "RUTW 220118P2040000  102434       0\n",
      "RUTW 220118P1865000  102434       0\n",
      "RUTW 220118C2625000  102434       0\n",
      "RUTW 220118P1915000  102434       0\n",
      "RUTW 220118P1955000  102434       0\n",
      "RUTW 220118P1945000  102434       0\n",
      "RUTW 220118P1940000  102434       0\n",
      "RUTW 220118P1935000  102434       0\n",
      "RUTW 220118P1930000  102434       0\n",
      "RUTW 220118P1925000  102434       0\n",
      "RUTW 220118P1965000  102434       0\n",
      "RUTW 220118P1970000  102434       0\n",
      "RUTW 220118P1975000  102434       0\n",
      "RUTW 220118P1980000  102434       0\n",
      "RUTW 220118P1985000  102434       0\n",
      "RUTW 220118P1990000  102434       0\n",
      "RUTW 220118P1920000  102434       0\n",
      "RUTW 220118P1995000  102434       0\n",
      "RUTW 220118P1910000  102434       0\n",
      "RUTW 220118P2035000  102434       0\n",
      "RUTW 220118P2005000  102434       0\n",
      "RUTW 220118P2010000  102434       0\n",
      "RUTW 220118P2015000  102434       0\n",
      "RUTW 220118P1905000  102434       0\n",
      "RUTW 220118P2020000  102434       0\n",
      "RUTW 220118P1900000  102434       0\n",
      "RUTW 220118P1895000  102434       0\n",
      "RUTW 220118P1890000  102434       0\n",
      "RUTW 220118P1885000  102434       0\n",
      "RUTW 220118P1880000  102434       0\n",
      "RUTW 220118P1875000  102434       0\n",
      "RUTW 220118P2025000  102434       0\n",
      "RUTW 220118P2030000  102434       0\n",
      "RUTW 220118P1870000  102434       0\n",
      "RUTW 220118C2630000  102434       0\n",
      "RUTW 220118C2620000  102434       0\n",
      "RUTW 220118P2330000  102434       0\n",
      "RUTW 220118P2160000  102434       0\n",
      "RUTW 220118C2445000  102434       0\n",
      "RUTW 220118C2440000  102434       0\n",
      "RUTW 220118C2435000  102434       0\n",
      "RUTW 220118P2085000  102434       0\n",
      "RUTW 220118P2090000  102434       0\n",
      "RUTW 220118P1960000  102434       0\n",
      "RUTW 220118C2430000  102434       0\n",
      "RUTW 220118P2115000  102434       0\n",
      "RUTW 220118P2120000  102434       0\n",
      "RUTW 220118P2125000  102434       0\n",
      "RUTW 220118P2130000  102434       0\n",
      "RUTW 220118P2145000  102434       0\n",
      "RUTW 220118C2425000  102434       0\n",
      "RUTW 220118P2155000  102434       0\n",
      "RUTW 220118P2165000  102434       0\n",
      "RUTW 220118C2455000  102434       0\n",
      "RUTW 220118P2175000  102434       0\n",
      "RUTW 220118P2185000  102434       0\n",
      "RUTW 220118P2190000  102434       0\n",
      "RUTW 220118P2195000  102434       0\n",
      "RUTW 220118P2225000  102434       0\n",
      "RUTW 220118P2240000  102434       0\n",
      "RUTW 220118P2285000  102434       0\n",
      "RUTW 220118P2295000  102434       0\n",
      "RUTW 220118P2300000  102434       0\n",
      "RUTW 220118P2305000  102434       0\n",
      "RUTW 220118P2310000  102434       0\n",
      "RUTW 220118P2315000  102434       0\n",
      "RUTW 220118P2320000  102434       0\n",
      "RUTW 220118P2325000  102434       0\n",
      "RUTW 220118C2450000  102434       0\n",
      "RUTW 220118C2460000  102434       0\n",
      "RUTW 220118P2645000  102434       0\n",
      "RUTW 220118C2540000  102434       0\n",
      "RUTW 220118C2610000  102434       0\n",
      "RUTW 220118C2605000  102434       0\n",
      "RUTW 220118C2600000  102434       0\n",
      "RUTW 220118C2595000  102434       0\n",
      "RUTW 220118C2590000  102434       0\n",
      "RUTW 220118C2585000  102434       0\n",
      "RUTW 220118C2580000  102434       0\n",
      "RUTW 220118C2575000  102434       0\n",
      "RUTW 220118C2570000  102434       0\n",
      "RUTW 220118C2565000  102434       0\n",
      "RUTW 220118C2560000  102434       0\n",
      "RUTW 220118C2555000  102434       0\n",
      "RUTW 220118C2550000  102434       0\n",
      "RUTW 220118C2545000  102434       0\n",
      "RUTW 220118C2535000  102434       0\n",
      "RUTW 220118C2465000  102434       0\n",
      "RUTW 220118C2530000  102434       0\n",
      "RUTW 220118P2075000  102434       0\n",
      "RUTW 220118C2525000  102434       0\n",
      "RUTW 220118C2520000  102434       0\n",
      "RUTW 220118C2515000  102434       0\n",
      "RUTW 220118C2510000  102434       0\n",
      "RUTW 220118C2505000  102434       0\n",
      "RUTW 220118C2495000  102434       0\n",
      "RUTW 220118C2490000  102434       0\n",
      "RUTW 220118C2485000  102434       0\n",
      "RUTW 220118C2480000  102434       0\n",
      "RUTW 220118P2080000  102434       0\n",
      "RUTW 220118C2475000  102434       0\n",
      "RUTW 220118C2470000  102434       0\n",
      "RUTW 220118C2615000  102434       0\n",
      "RUTW 220128P1305000  102434       0\n",
      "RUTW 220118P2650000  102434       0\n",
      "RUTW 220128P1770000  102434       0\n",
      "RUTW 220128P1595000  102434       0\n",
      "RUTW 220128P1590000  102434       0\n",
      "RUTW 220128P1585000  102434       0\n",
      "RUTW 220128P1580000  102434       0\n",
      "RUTW 220128P1575000  102434       0\n",
      "RUTW 220128P1570000  102434       0\n",
      "RUTW 220128P1565000  102434       0\n",
      "RUTW 220128P1560000  102434       0\n",
      "RUTW 220128P1555000  102434       0\n",
      "RUTW 220128P1550000  102434       0\n",
      "RUTW 220128P1545000  102434       0\n",
      "RUTW 220128P1540000  102434       0\n",
      "RUTW 220128P1535000  102434       0\n",
      "RUTW 220128P1530000  102434       0\n",
      "RUTW 220128P1525000  102434       0\n",
      "RUTW 220128P1520000  102434       0\n",
      "RUTW 220128P1515000  102434       0\n",
      "RUTW 220128P1510000  102434       0\n",
      "RUTW 220128P1505000  102434       0\n",
      "RUTW 220128P1500000  102434       0\n",
      "RUTW 220128P1495000  102434       0\n",
      "RUTW 220128P1490000  102434       0\n",
      "RUTW 220128P1485000  102434       0\n",
      "RUTW 220128P1480000  102434       0\n",
      "RUTW 220128P1475000  102434       0\n",
      "RUTW 220128P1470000  102434       0\n",
      "RUTW 220128P1465000  102434       0\n",
      "RUTW 220128P1460000  102434       0\n",
      "RUTW 220128P1455000  102434       0\n",
      "RUTW 220128P1600000  102434       0\n",
      "RUTW 220128P1605000  102434       0\n",
      "RUTW 220128P1610000  102434       0\n",
      "RUTW 220128P1690000  102434       0\n",
      "RUTW 220128P1760000  102434       0\n",
      "RUTW 220128P1755000  102434       0\n",
      "RUTW 220128P1745000  102434       0\n",
      "RUTW 220128P1740000  102434       0\n",
      "RUTW 220128P1735000  102434       0\n",
      "RUTW 220128P1730000  102434       0\n",
      "RUTW 220128P1725000  102434       0\n",
      "RUTW 220128P1720000  102434       0\n",
      "RUTW 220128P1715000  102434       0\n",
      "RUTW 220128P1710000  102434       0\n",
      "RUTW 220128P1705000  102434       0\n",
      "RUTW 220128P1700000  102434       0\n",
      "RUTW 220128P1695000  102434       0\n",
      "RUTW 220128P1685000  102434       0\n",
      "RUTW 220128P1615000  102434       0\n",
      "RUTW 220128P1680000  102434       0\n",
      "RUTW 220128P1675000  102434       0\n",
      "RUTW 220128P1670000  102434       0\n",
      "RUTW 220128P1665000  102434       0\n",
      "RUTW 220128P1660000  102434       0\n",
      "RUTW 220128P1655000  102434       0\n",
      "RUTW 220128P1650000  102434       0\n",
      "RUTW 220128P1645000  102434       0\n",
      "RUTW 220128P1640000  102434       0\n",
      "RUTW 220128P1635000  102434       0\n",
      "RUTW 220128P1630000  102434       0\n",
      "RUTW 220128P1625000  102434       0\n",
      "RUTW 220128P1620000  102434       0\n",
      "RUTW 220128P1450000  102434       0\n",
      "RUTW 220128P1445000  102434       0\n",
      "RUTW 220128P1440000  102434       0\n",
      "RUTW 220128C2760000  102434       0\n",
      "RUTW 220128P1270000  102434       0\n",
      "RUTW 220128P1265000  102434       0\n",
      "RUTW 220128P1260000  102434       0\n",
      "RUTW 220128P1255000  102434       0\n",
      "RUTW 220128P1250000  102434       0\n",
      "RUTW 220128P1245000  102434       0\n",
      "RUTW 220128P1240000  102434       0\n",
      "RUTW 220128P1235000  102434       0\n",
      "RUTW 220128P1230000  102434       0\n",
      "RUTW 220128C2780000  102434       0\n",
      "RUTW 220128C2775000  102434       0\n",
      "RUTW 220128C2770000  102434       0\n",
      "RUTW 220128C2765000  102434       0\n",
      "RUTW 220128C2755000  102434       0\n",
      "RUTW 220128P1280000  102434       0\n",
      "RUTW 220128C2750000  102434       0\n",
      "RUTW 220128C2745000  102434       0\n",
      "RUTW 220128C2740000  102434       0\n",
      "RUTW 220128C2735000  102434       0\n",
      "RUTW 220128C2730000  102434       0\n",
      "RUTW 220128C2725000  102434       0\n",
      "RUTW 220128C2720000  102434       0\n",
      "RUTW 220128C2715000  102434       0\n",
      "RUTW 220128C2710000  102434       0\n",
      "RUTW 220128C2705000  102434       0\n",
      "RUTW 220128C2700000  102434       0\n",
      "RUTW 220128C2695000  102434       0\n",
      "RUTW 220128C2690000  102434       0\n",
      "RUTW 220128P1275000  102434       0\n",
      "RUTW 220128P1285000  102434       0\n",
      "RUTW 220128P1435000  102434       0\n",
      "RUTW 220128P1365000  102434       0\n",
      "RUTW 220128P1430000  102434       0\n",
      "RUTW 220128P1425000  102434       0\n",
      "RUTW 220128P1420000  102434       0\n",
      "RUTW 220128P1415000  102434       0\n",
      "RUTW 220128P1410000  102434       0\n",
      "RUTW 220128P1405000  102434       0\n",
      "RUTW 220128P1400000  102434       0\n",
      "RUTW 220128P1395000  102434       0\n",
      "RUTW 220128P1390000  102434       0\n",
      "RUTW 220128P1385000  102434       0\n",
      "RUTW 220128P1380000  102434       0\n",
      "RUTW 220128P1375000  102434       0\n",
      "RUTW 220128P1370000  102434       0\n",
      "RUTW 220128P1360000  102434       0\n",
      "RUTW 220128P1290000  102434       0\n",
      "RUTW 220128P1355000  102434       0\n",
      "RUTW 220128P1350000  102434       0\n",
      "RUTW 220128P1345000  102434       0\n",
      "RUTW 220128P1340000  102434       0\n",
      "RUTW 220128P1335000  102434       0\n",
      "RUTW 220128P1330000  102434       0\n",
      "RUTW 220128P1325000  102434       0\n",
      "RUTW 220128P1320000  102434       0\n",
      "RUTW 220128P1315000  102434       0\n",
      "RUTW 220128P1310000  102434       0\n",
      "RUTW 220118C2115000  102434       0\n",
      "RUTW 220128P1300000  102434       0\n",
      "RUTW 220128P1295000  102434       0\n",
      "RUTW 220128P1765000  102434       0\n",
      "RUTW 220128P1775000  102434       0\n",
      "RUTW 220118P2655000  102434       0\n",
      "RUTW 220128P1780000  102434       0\n",
      "RUTW 220128P2585000  102434       0\n",
      "RUTW 220128P2580000  102434       0\n",
      "RUTW 220128P2575000  102434       0\n",
      "RUTW 220128P2570000  102434       0\n",
      "RUTW 220128P2565000  102434       0\n",
      "RUTW 220128P2560000  102434       0\n",
      "RUTW 220128P2555000  102434       0\n",
      "RUTW 220128P2550000  102434       0\n",
      "RUTW 220128P2545000  102434       0\n",
      "RUTW 220128P2540000  102434       0\n",
      "RUTW 220128P2535000  102434       0\n",
      "RUTW 220128P2530000  102434       0\n",
      "RUTW 220128P2525000  102434       0\n",
      "RUTW 220128P2520000  102434       0\n",
      "RUTW 220128P2515000  102434       0\n",
      "RUTW 220128P2510000  102434       0\n",
      "RUTW 220128P2505000  102434       0\n",
      "RUTW 220128P2500000  102434       0\n",
      "RUTW 220128P2495000  102434       0\n",
      "RUTW 220128P2490000  102434       0\n",
      "RUTW 220128P2485000  102434       0\n",
      "RUTW 220128P2480000  102434       0\n",
      "RUTW 220128P2475000  102434       0\n",
      "RUTW 220128P2470000  102434       0\n",
      "RUTW 220128P2465000  102434       0\n",
      "RUTW 220128P2460000  102434       0\n",
      "RUTW 220128P2455000  102434       0\n",
      "RUTW 220128P2450000  102434       0\n",
      "RUTW 220128P2445000  102434       0\n",
      "RUTW 220128P2590000  102434       0\n",
      "RUTW 220128P2595000  102434       0\n",
      "RUTW 220128P2600000  102434       0\n",
      "RUTW 220128P2680000  102434       0\n",
      "RUTW 220128P2745000  102434       0\n",
      "RUTW 220128P2740000  102434       0\n",
      "RUTW 220128P2735000  102434       0\n",
      "RUTW 220128P2730000  102434       0\n",
      "RUTW 220128P2725000  102434       0\n",
      "RUTW 220128P2720000  102434       0\n",
      "RUTW 220128P2715000  102434       0\n",
      "RUTW 220128P2710000  102434       0\n",
      "RUTW 220128P2705000  102434       0\n",
      "RUTW 220128P2700000  102434       0\n",
      "RUTW 220128P2695000  102434       0\n",
      "RUTW 220128P2690000  102434       0\n",
      "RUTW 220128P2685000  102434       0\n",
      "RUTW 220128P2675000  102434       0\n",
      "RUTW 220128P2605000  102434       0\n",
      "RUTW 220128P2670000  102434       0\n",
      "RUTW 220128P2665000  102434       0\n",
      "RUTW 220128P2660000  102434       0\n",
      "RUTW 220128P2655000  102434       0\n",
      "RUTW 220128P2650000  102434       0\n",
      "RUTW 220128P2645000  102434       0\n",
      "RUTW 220128P2640000  102434       0\n",
      "RUTW 220128P2635000  102434       0\n",
      "RUTW 220128P2630000  102434       0\n",
      "RUTW 220128P2625000  102434       0\n",
      "RUTW 220128P2620000  102434       0\n",
      "RUTW 220128P2615000  102434       0\n",
      "RUTW 220128P2610000  102434       0\n",
      "RUTW 220128P2440000  102434       0\n",
      "RUTW 220128P2435000  102434       0\n",
      "RUTW 220128P2430000  102434       0\n",
      "RUTW 220128P1860000  102434       0\n",
      "RUTW 220128P1960000  102434       0\n",
      "RUTW 220128P1940000  102434       0\n",
      "RUTW 220128P1935000  102434       0\n",
      "RUTW 220128P1930000  102434       0\n",
      "RUTW 220128P1925000  102434       0\n",
      "RUTW 220128P1915000  102434       0\n",
      "RUTW 220128P1910000  102434       0\n",
      "RUTW 220128P1890000  102434       0\n",
      "RUTW 220128P1885000  102434       0\n",
      "RUTW 220128P1880000  102434       0\n",
      "RUTW 220128P1875000  102434       0\n",
      "RUTW 220128P1870000  102434       0\n",
      "RUTW 220128P1865000  102434       0\n",
      "RUTW 220128P1855000  102434       0\n",
      "RUTW 220128P2170000  102434       0\n",
      "RUTW 220128P1850000  102434       0\n",
      "RUTW 220128P1845000  102434       0\n",
      "RUTW 220128P1840000  102434       0\n",
      "RUTW 220128P1835000  102434       0\n",
      "RUTW 220128P1825000  102434       0\n",
      "RUTW 220128P1820000  102434       0\n",
      "RUTW 220128P1815000  102434       0\n",
      "RUTW 220128P1810000  102434       0\n",
      "RUTW 220128P1805000  102434       0\n",
      "RUTW 220128P1800000  102434       0\n",
      "RUTW 220128P1795000  102434       0\n",
      "RUTW 220128P1790000  102434       0\n",
      "RUTW 220128P1785000  102434       0\n",
      "RUTW 220128P2160000  102434       0\n",
      "RUTW 220128P2175000  102434       0\n",
      "RUTW 220128P2425000  102434       0\n",
      "RUTW 220128P2355000  102434       0\n",
      "RUTW 220128P2420000  102434       0\n",
      "RUTW 220128P2415000  102434       0\n",
      "RUTW 220128P2410000  102434       0\n",
      "RUTW 220128P2405000  102434       0\n",
      "RUTW 220128P2400000  102434       0\n",
      "RUTW 220128P2395000  102434       0\n",
      "RUTW 220128P2390000  102434       0\n",
      "RUTW 220128P2385000  102434       0\n",
      "RUTW 220128P2380000  102434       0\n",
      "RUTW 220128P2375000  102434       0\n",
      "RUTW 220128P2370000  102434       0\n",
      "RUTW 220128P2365000  102434       0\n",
      "RUTW 220128P2360000  102434       0\n",
      "RUTW 220128P2350000  102434       0\n",
      "RUTW 220128P2215000  102434       0\n",
      "RUTW 220128P2345000  102434       0\n",
      "RUTW 220128P2340000  102434       0\n",
      "RUTW 220128P2335000  102434       0\n",
      "RUTW 220128P2330000  102434       0\n",
      "RUTW 220128P2325000  102434       0\n",
      "RUTW 220128P2320000  102434       0\n",
      "RUTW 220128P2315000  102434       0\n",
      "RUTW 220128P2310000  102434       0\n",
      "RUTW 220128P2305000  102434       0\n",
      "RUTW 220128P2295000  102434       0\n",
      "RUTW 220128P2290000  102434       0\n",
      "RUTW 220128P2285000  102434       0\n",
      "RUTW 220128P2255000  102434       0\n",
      "RUTW 220128C2685000  102434       0\n",
      "RUTW 220128C2680000  102434       0\n",
      "RUTW 220128C2675000  102434       0\n",
      "RUTW 220128C2670000  102434       0\n",
      "RUTW 220128C1630000  102434       0\n",
      "RUTW 220128C1625000  102434       0\n",
      "RUTW 220128C1620000  102434       0\n",
      "RUTW 220128C1615000  102434       0\n",
      "RUTW 220128C1610000  102434       0\n",
      "RUTW 220128C1605000  102434       0\n",
      "RUTW 220128C1600000  102434       0\n",
      "RUTW 220128C1595000  102434       0\n",
      "RUTW 220128C1590000  102434       0\n",
      "RUTW 220128C1585000  102434       0\n",
      "RUTW 220128C1580000  102434       0\n",
      "RUTW 220128C1575000  102434       0\n",
      "RUTW 220128C1570000  102434       0\n",
      "RUTW 220128C1565000  102434       0\n",
      "RUTW 220128C1560000  102434       0\n",
      "RUTW 220128C1555000  102434       0\n",
      "RUTW 220128C1550000  102434       0\n",
      "RUTW 220128C1545000  102434       0\n",
      "RUTW 220128C1540000  102434       0\n",
      "RUTW 220128C1535000  102434       0\n",
      "RUTW 220128C1530000  102434       0\n",
      "RUTW 220128C1525000  102434       0\n",
      "RUTW 220128C1520000  102434       0\n",
      "RUTW 220128C1515000  102434       0\n",
      "RUTW 220128C1510000  102434       0\n",
      "RUTW 220128C1505000  102434       0\n",
      "RUTW 220128C1500000  102434       0\n",
      "RUTW 220128C1495000  102434       0\n",
      "RUTW 220128C1490000  102434       0\n",
      "RUTW 220128C1635000  102434       0\n",
      "RUTW 220128C1640000  102434       0\n",
      "RUTW 220128C1645000  102434       0\n",
      "RUTW 220128C1725000  102434       0\n",
      "RUTW 220128C1790000  102434       0\n",
      "RUTW 220128C1785000  102434       0\n",
      "RUTW 220128C1780000  102434       0\n",
      "RUTW 220128C1775000  102434       0\n",
      "RUTW 220128C1770000  102434       0\n",
      "RUTW 220128C1765000  102434       0\n",
      "RUTW 220128C1760000  102434       0\n",
      "RUTW 220128C1755000  102434       0\n",
      "RUTW 220128C1750000  102434       0\n",
      "RUTW 220128C1745000  102434       0\n",
      "RUTW 220128C1740000  102434       0\n",
      "RUTW 220128C1735000  102434       0\n",
      "RUTW 220128C1730000  102434       0\n",
      "RUTW 220128C1720000  102434       0\n",
      "RUTW 220128C1650000  102434       0\n",
      "RUTW 220128C1715000  102434       0\n",
      "RUTW 220128C1710000  102434       0\n",
      "RUTW 220128C1705000  102434       0\n",
      "RUTW 220128C1700000  102434       0\n",
      "RUTW 220128C1695000  102434       0\n",
      "RUTW 220128C1690000  102434       0\n",
      "RUTW 220128C1685000  102434       0\n",
      "RUTW 220128C1680000  102434       0\n",
      "RUTW 220128C1675000  102434       0\n",
      "RUTW 220128C1670000  102434       0\n",
      "RUTW 220128C1665000  102434       0\n",
      "RUTW 220128C1660000  102434       0\n",
      "RUTW 220128C1655000  102434       0\n",
      "RUTW 220128C1485000  102434       0\n",
      "RUTW 220128C1480000  102434       0\n",
      "RUTW 220128C1475000  102434       0\n",
      "RUTW 220128C1240000  102434       0\n",
      "RUTW 220128C1305000  102434       0\n",
      "RUTW 220128C1300000  102434       0\n",
      "RUTW 220128C1295000  102434       0\n",
      "RUTW 220128C1290000  102434       0\n",
      "RUTW 220128C1285000  102434       0\n",
      "RUTW 220128C1280000  102434       0\n",
      "RUTW 220128C1275000  102434       0\n",
      "RUTW 220128C1270000  102434       0\n",
      "RUTW 220128C1265000  102434       0\n",
      "RUTW 220128C1260000  102434       0\n",
      "RUTW 220128C1255000  102434       0\n",
      "RUTW 220128C1250000  102434       0\n",
      "RUTW 220128C1245000  102434       0\n",
      "RUTW 220128C1235000  102434       0\n",
      "RUTW 220128C1315000  102434       0\n",
      "RUTW 220128C1230000  102434       0\n",
      "RUTW 220118P2715000  102434       0\n",
      "RUTW 220118P2710000  102434       0\n",
      "RUTW 220118P2705000  102434       0\n",
      "RUTW 220118P2700000  102434       0\n",
      "RUTW 220118P2695000  102434       0\n",
      "RUTW 220118P2690000  102434       0\n",
      "RUTW 220118P2685000  102434       0\n",
      "RUTW 220118P2680000  102434       0\n",
      "RUTW 220118P2675000  102434       0\n",
      "RUTW 220118P2670000  102434       0\n",
      "RUTW 220118P2665000  102434       0\n",
      "RUTW 220118P2660000  102434       0\n",
      "RUTW 220128C1310000  102434       0\n",
      "RUTW 220128C1320000  102434       0\n",
      "RUTW 220128C1470000  102434       0\n",
      "RUTW 220128C1400000  102434       0\n",
      "RUTW 220128C1465000  102434       0\n",
      "RUTW 220128C1460000  102434       0\n",
      "RUTW 220128C1455000  102434       0\n",
      "RUTW 220128C1450000  102434       0\n",
      "RUTW 220128C1445000  102434       0\n",
      "RUTW 220128C1440000  102434       0\n",
      "RUTW 220128C1435000  102434       0\n",
      "RUTW 220128C1430000  102434       0\n",
      "RUTW 220128C1425000  102434       0\n",
      "RUTW 220128C1420000  102434       0\n",
      "RUTW 220128C1415000  102434       0\n",
      "RUTW 220128C1410000  102434       0\n",
      "RUTW 220128C1405000  102434       0\n",
      "RUTW 220128C1395000  102434       0\n",
      "RUTW 220128C1325000  102434       0\n",
      "RUTW 220128C1390000  102434       0\n",
      "RUTW 220128C1385000  102434       0\n",
      "RUTW 220128C1380000  102434       0\n",
      "RUTW 220128C1375000  102434       0\n",
      "RUTW 220128C1370000  102434       0\n",
      "RUTW 220128C1365000  102434       0\n",
      "RUTW 220128C1360000  102434       0\n",
      "RUTW 220128C1355000  102434       0\n",
      "RUTW 220128C1350000  102434       0\n",
      "RUTW 220128C1345000  102434       0\n",
      "RUTW 220128C1340000  102434       0\n",
      "RUTW 220128C1335000  102434       0\n",
      "RUTW 220128C1330000  102434       0\n",
      "RUTW 220128C1795000  102434       0\n",
      "RUTW 220128C1800000  102434       0\n",
      "RUTW 220128C1805000  102434       0\n",
      "RUTW 220128C2220000  102434       0\n",
      "RUTW 220128C2505000  102434       0\n",
      "RUTW 220128C2500000  102434       0\n",
      "RUTW 220128C2495000  102434       0\n",
      "RUTW 220128C2485000  102434       0\n",
      "RUTW 220128C2395000  102434       0\n",
      "RUTW 220128C2390000  102434       0\n",
      "RUTW 220128C2385000  102434       0\n",
      "RUTW 220128C2375000  102434       0\n",
      "RUTW 220128C2340000  102434       0\n",
      "RUTW 220128C2335000  102434       0\n",
      "RUTW 220128C2325000  102434       0\n",
      "RUTW 220128C2315000  102434       0\n",
      "RUTW 220128C2235000  102434       0\n",
      "RUTW 220128C2215000  102434       0\n",
      "RUTW 220128C2515000  102434       0\n",
      "RUTW 220128C2210000  102434       0\n",
      "RUTW 220128C2205000  102434       0\n",
      "RUTW 220128C2195000  102434       0\n",
      "RUTW 220128C2185000  102434       0\n",
      "RUTW 220128C2180000  102434       0\n",
      "RUTW 220128C2175000  102434       0\n",
      "RUTW 220128C2165000  102434       0\n",
      "RUTW 220128C2160000  102434       0\n",
      "RUTW 220128C2155000  102434       0\n",
      "RUTW 220128C2150000  102434       0\n",
      "RUTW 220128C2145000  102434       0\n",
      "RUTW 220128C2140000  102434       0\n",
      "RUTW 220128C2135000  102434       0\n",
      "RUTW 220128C2510000  102434       0\n",
      "RUTW 220128C2520000  102434       0\n",
      "RUTW 220128C2125000  102434       0\n",
      "RUTW 220128C2600000  102434       0\n",
      "RUTW 220128C2665000  102434       0\n",
      "RUTW 220128C2660000  102434       0\n",
      "RUTW 220128C2655000  102434       0\n",
      "RUTW 220128C2650000  102434       0\n",
      "RUTW 220128C2645000  102434       0\n",
      "RUTW 220128C2640000  102434       0\n",
      "RUTW 220128C2635000  102434       0\n",
      "RUTW 220128C2630000  102434       0\n",
      "RUTW 220128C2625000  102434       0\n",
      "RUTW 220128C2620000  102434       0\n",
      "RUTW 220128C2615000  102434       0\n",
      "RUTW 220128C2610000  102434       0\n",
      "RUTW 220128C2605000  102434       0\n",
      "RUTW 220128C2595000  102434       0\n",
      "RUTW 220128C2525000  102434       0\n",
      "RUTW 220128C2590000  102434       0\n",
      "RUTW 220128C2585000  102434       0\n",
      "RUTW 220128C2580000  102434       0\n",
      "RUTW 220128C2575000  102434       0\n",
      "RUTW 220128C2570000  102434       0\n",
      "RUTW 220128C2565000  102434       0\n",
      "RUTW 220128C2560000  102434       0\n",
      "RUTW 220128C2555000  102434       0\n",
      "RUTW 220128C2550000  102434       0\n",
      "RUTW 220128C2545000  102434       0\n",
      "RUTW 220128C2540000  102434       0\n",
      "RUTW 220128C2535000  102434       0\n",
      "RUTW 220128C2530000  102434       0\n",
      "RUTW 220128C2130000  102434       0\n",
      "RUTW 220128C2120000  102434       0\n",
      "RUTW 220128C1810000  102434       0\n",
      "RUTW 220128C1885000  102434       0\n",
      "RUTW 220128C1950000  102434       0\n",
      "RUTW 220128C1945000  102434       0\n",
      "RUTW 220128C1940000  102434       0\n",
      "RUTW 220128C1935000  102434       0\n",
      "RUTW 220128C1930000  102434       0\n",
      "RUTW 220128C1925000  102434       0\n",
      "RUTW 220128C1920000  102434       0\n",
      "RUTW 220128C1915000  102434       0\n",
      "RUTW 220128C1910000  102434       0\n",
      "RUTW 220128C1905000  102434       0\n",
      "RUTW 220128C1900000  102434       0\n",
      "RUTW 220128C1895000  102434       0\n",
      "RUTW 220128C1890000  102434       0\n",
      "RUTW 220128C1880000  102434       0\n",
      "RUTW 220128C1960000  102434       0\n",
      "RUTW 220128C1875000  102434       0\n",
      "RUTW 220128C1870000  102434       0\n",
      "RUTW 220128C1865000  102434       0\n",
      "RUTW 220128C1860000  102434       0\n",
      "RUTW 220128C1855000  102434       0\n",
      "RUTW 220128C1850000  102434       0\n",
      "RUTW 220128C1845000  102434       0\n",
      "RUTW 220128C1840000  102434       0\n",
      "RUTW 220128C1835000  102434       0\n",
      "RUTW 220128C1830000  102434       0\n",
      "RUTW 220128C1825000  102434       0\n",
      "RUTW 220128C1820000  102434       0\n",
      "RUTW 220128C1815000  102434       0\n",
      "RUTW 220128C1955000  102434       0\n",
      "RUTW 220128C1965000  102434       0\n",
      "RUTW 220128C2115000  102434       0\n",
      "RUTW 220128C2045000  102434       0\n",
      "RUTW 220128C2110000  102434       0\n",
      "RUTW 220128C2105000  102434       0\n",
      "RUTW 220128C2100000  102434       0\n",
      "RUTW 220128C2095000  102434       0\n",
      "RUTW 220128C2090000  102434       0\n",
      "RUTW 220128C2085000  102434       0\n",
      "RUTW 220128C2080000  102434       0\n",
      "RUTW 220128C2075000  102434       0\n",
      "RUTW 220128C2070000  102434       0\n",
      "RUTW 220128C2065000  102434       0\n",
      "RUTW 220128C2060000  102434       0\n",
      "RUTW 220128C2055000  102434       0\n",
      "RUTW 220128C2050000  102434       0\n",
      "RUTW 220128C2040000  102434       0\n",
      "RUTW 220128C1970000  102434       0\n",
      "RUTW 220128C2035000  102434       0\n",
      "RUTW 220128C2030000  102434       0\n",
      "RUTW 220128C2025000  102434       0\n",
      "RUTW 220128C2020000  102434       0\n",
      "RUTW 220128C2015000  102434       0\n",
      "RUTW 220128C2010000  102434       0\n",
      "RUTW 220128C2005000  102434       0\n",
      "RUTW 220128C2000000  102434       0\n",
      "RUTW 220128C1995000  102434       0\n",
      "RUTW 220128C1990000  102434       0\n",
      "RUTW 220128C1985000  102434       0\n",
      "RUTW 220128C1980000  102434       0\n",
      "RUTW 220128C1975000  102434       0\n",
      "RUTW 220118C2120000  102434       0\n",
      "RLG 220121C1950000   100222       0\n",
      "RUTW 220118C2110000  102434       0\n",
      "RUTW 220110P2470000  102434       0\n",
      "RUTW 220110P2430000  102434       0\n",
      "RUTW 220110P2435000  102434       0\n",
      "RUTW 220110P2440000  102434       0\n",
      "RUTW 220110P2445000  102434       0\n",
      "RUTW 220110P2450000  102434       0\n",
      "RUTW 220110P2455000  102434       0\n",
      "RUTW 220110P2460000  102434       0\n",
      "RUTW 220110P2465000  102434       0\n",
      "RUTW 220110P2475000  102434       0\n",
      "RUTW 220110P2315000  102434       0\n",
      "RUTW 220110P2480000  102434       0\n",
      "RUTW 220110P2485000  102434       0\n",
      "RUTW 220110P2490000  102434       0\n",
      "RUTW 220110P2495000  102434       0\n",
      "RUTW 220110P2500000  102434       0\n",
      "RUTW 220110P2505000  102434       0\n",
      "RUTW 220110P2510000  102434       0\n",
      "RUTW 220110P2515000  102434       0\n",
      "RUTW 220110P2425000  102434       0\n",
      "RUTW 220110P2420000  102434       0\n",
      "RUTW 220110P2415000  102434       0\n",
      "RUTW 220110P2410000  102434       0\n",
      "RUTW 220110P2325000  102434       0\n",
      "RUTW 220110P2330000  102434       0\n",
      "RUTW 220110P2335000  102434       0\n",
      "RUTW 220110P2340000  102434       0\n",
      "RUTW 220110P2345000  102434       0\n",
      "RUTW 220110P2350000  102434       0\n",
      "RUTW 220110P2355000  102434       0\n",
      "RUTW 220110P2360000  102434       0\n",
      "RUTW 220110P2365000  102434       0\n",
      "RUTW 220110P2370000  102434       0\n",
      "RUTW 220110P2375000  102434       0\n",
      "RUTW 220110P2380000  102434       0\n",
      "RUTW 220110P2385000  102434       0\n",
      "RUTW 220110P2390000  102434       0\n",
      "RUTW 220110P2395000  102434       0\n",
      "RUTW 220110P2400000  102434       0\n",
      "RUTW 220110P2405000  102434       0\n",
      "RUTW 220110P2520000  102434       0\n",
      "RUTW 220110P2525000  102434       0\n",
      "RUTW 220110P2530000  102434       0\n",
      "RUTW 220110P2635000  102434       0\n",
      "RUTW 220110P2645000  102434       0\n",
      "RUTW 220112C1810000  102434       0\n",
      "RUTW 220112C1815000  102434       0\n",
      "RUTW 220112C1820000  102434       0\n",
      "RUTW 220112C1825000  102434       0\n",
      "RUTW 220112C1830000  102434       0\n",
      "RUTW 220112C1835000  102434       0\n",
      "RUTW 220112C1840000  102434       0\n",
      "RUTW 220112C1845000  102434       0\n",
      "RUTW 220112C1850000  102434       0\n",
      "RUTW 220112C1855000  102434       0\n",
      "RUTW 220112C1860000  102434       0\n",
      "RUTW 220112C1865000  102434       0\n",
      "RUTW 220112C1870000  102434       0\n",
      "RUTW 220112C1875000  102434       0\n",
      "RUTW 220112C1880000  102434       0\n",
      "RUTW 220112C1885000  102434       0\n",
      "RUTW 220110P2640000  102434       0\n",
      "RUTW 220110P2630000  102434       0\n",
      "RUTW 220110P2535000  102434       0\n",
      "RUTW 220110P2625000  102434       0\n",
      "RUTW 220110P2540000  102434       0\n",
      "RUTW 220110P2545000  102434       0\n",
      "RUTW 220110P2550000  102434       0\n",
      "RUTW 220110P2555000  102434       0\n",
      "RUTW 220110P2560000  102434       0\n",
      "RUTW 220110P2565000  102434       0\n",
      "RUTW 220110P2570000  102434       0\n",
      "RUTW 220110P2575000  102434       0\n",
      "RUTW 220110P2580000  102434       0\n",
      "RUTW 220110P2585000  102434       0\n",
      "RUTW 220110P2590000  102434       0\n",
      "RUTW 220110P2595000  102434       0\n",
      "RUTW 220110P2600000  102434       0\n",
      "RUTW 220110P2605000  102434       0\n",
      "RUTW 220110P2610000  102434       0\n",
      "RUTW 220110P2615000  102434       0\n",
      "RUTW 220110P2620000  102434       0\n",
      "RUTW 220110P2320000  102434       0\n",
      "RUTW 220110P2310000  102434       0\n",
      "RUTW 220110C2550000  102434       0\n",
      "RUTW 220110P1820000  102434       0\n",
      "RUTW 220110P1780000  102434       0\n",
      "RUTW 220110P1785000  102434       0\n",
      "RUTW 220110P1790000  102434       0\n",
      "RUTW 220110P1795000  102434       0\n",
      "RUTW 220110P1800000  102434       0\n",
      "RUTW 220110P1805000  102434       0\n",
      "RUTW 220110P1810000  102434       0\n",
      "RUTW 220110P1815000  102434       0\n",
      "RUTW 220110P1825000  102434       0\n",
      "RUTW 220110P2305000  102434       0\n",
      "RUTW 220110P1830000  102434       0\n",
      "RUTW 220110P1835000  102434       0\n",
      "RUTW 220110P1840000  102434       0\n",
      "RUTW 220110P1845000  102434       0\n",
      "RUTW 220110P1850000  102434       0\n",
      "RUTW 220110P1855000  102434       0\n",
      "RUTW 220110P1860000  102434       0\n",
      "RUTW 220110P1865000  102434       0\n",
      "RUTW 220110P1775000  102434       0\n",
      "RUTW 220110P1770000  102434       0\n",
      "RUTW 220110P1765000  102434       0\n",
      "RUTW 220110C2645000  102434       0\n",
      "RUTW 220110C2560000  102434       0\n",
      "RUTW 220110C2565000  102434       0\n",
      "RUTW 220110C2570000  102434       0\n",
      "RUTW 220110C2575000  102434       0\n",
      "RUTW 220110C2580000  102434       0\n",
      "RUTW 220110C2585000  102434       0\n",
      "RUTW 220110C2590000  102434       0\n",
      "RUTW 220110C2595000  102434       0\n",
      "RUTW 220110C2600000  102434       0\n",
      "RUTW 220110C2605000  102434       0\n",
      "RUTW 220110C2610000  102434       0\n",
      "RUTW 220110C2615000  102434       0\n",
      "RUTW 220110C2620000  102434       0\n",
      "RUTW 220110C2625000  102434       0\n",
      "RUTW 220110C2630000  102434       0\n",
      "RUTW 220110C2635000  102434       0\n",
      "RUTW 220110C2640000  102434       0\n",
      "RUTW 220110P1870000  102434       0\n",
      "RUTW 220110P1875000  102434       0\n",
      "RUTW 220110P1880000  102434       0\n",
      "RUTW 220110P1985000  102434       0\n",
      "RUTW 220110P1995000  102434       0\n",
      "RUTW 220110P2000000  102434       0\n",
      "RUTW 220110P2005000  102434       0\n",
      "RUTW 220110P2015000  102434       0\n",
      "RUTW 220110P2020000  102434       0\n",
      "RUTW 220110P2025000  102434       0\n",
      "RUTW 220110P2030000  102434       0\n",
      "RUTW 220110P2035000  102434       0\n",
      "RUTW 220110P2045000  102434       0\n",
      "RUTW 220110P2055000  102434       0\n",
      "RUTW 220110P2065000  102434       0\n",
      "RUTW 220110P2070000  102434       0\n",
      "RUTW 220110P2075000  102434       0\n",
      "RUTW 220110P2095000  102434       0\n",
      "RUTW 220110P2145000  102434       0\n",
      "RUTW 220110P2170000  102434       0\n",
      "RUTW 220110P2285000  102434       0\n",
      "RUTW 220110P1990000  102434       0\n",
      "RUTW 220110P1980000  102434       0\n",
      "RUTW 220110P1885000  102434       0\n",
      "RUTW 220110P1975000  102434       0\n",
      "RUTW 220110P1890000  102434       0\n",
      "RUTW 220110P1895000  102434       0\n",
      "RUTW 220110P1900000  102434       0\n",
      "RUTW 220110P1905000  102434       0\n",
      "RUTW 220110P1910000  102434       0\n",
      "RUTW 220110P1915000  102434       0\n",
      "RUTW 220110P1920000  102434       0\n",
      "RUTW 220110P1925000  102434       0\n",
      "RUTW 220110P1930000  102434       0\n",
      "RUTW 220110P1935000  102434       0\n",
      "RUTW 220110P1940000  102434       0\n",
      "RUTW 220110P1945000  102434       0\n",
      "RUTW 220110P1950000  102434       0\n",
      "RUTW 220110P1955000  102434       0\n",
      "RUTW 220110P1960000  102434       0\n",
      "RUTW 220110P1965000  102434       0\n",
      "RUTW 220110P1970000  102434       0\n",
      "RUTW 220112C1890000  102434       0\n",
      "RUTW 220112C1895000  102434       0\n",
      "RUTW 220112C1900000  102434       0\n",
      "RUTW 220112C2595000  102434       0\n",
      "RUTW 220112C2555000  102434       0\n",
      "RUTW 220112C2560000  102434       0\n",
      "RUTW 220112C2565000  102434       0\n",
      "RUTW 220112C2570000  102434       0\n",
      "RUTW 220112C2575000  102434       0\n",
      "RUTW 220112C2580000  102434       0\n",
      "RUTW 220112C2585000  102434       0\n",
      "RUTW 220112C2590000  102434       0\n",
      "RUTW 220112C2600000  102434       0\n",
      "RUTW 220112C1905000  102434       0\n",
      "RUTW 220112C2605000  102434       0\n",
      "RUTW 220112C2610000  102434       0\n",
      "RUTW 220112C2615000  102434       0\n",
      "RUTW 220112C2620000  102434       0\n",
      "RUTW 220112C2625000  102434       0\n",
      "RUTW 220112C2630000  102434       0\n",
      "RUTW 220112C2635000  102434       0\n",
      "RUTW 220112C2640000  102434       0\n",
      "RUTW 220112C2550000  102434       0\n",
      "RUTW 220112C2545000  102434       0\n",
      "RUTW 220112C2540000  102434       0\n",
      "RUTW 220112C2535000  102434       0\n",
      "RUTW 220112C2450000  102434       0\n",
      "RUTW 220112C2455000  102434       0\n",
      "RUTW 220112C2460000  102434       0\n",
      "RUTW 220112C2465000  102434       0\n",
      "RUTW 220112C2470000  102434       0\n",
      "RUTW 220112C2475000  102434       0\n",
      "RUTW 220112C2480000  102434       0\n",
      "RUTW 220112C2485000  102434       0\n",
      "RUTW 220112C2490000  102434       0\n",
      "RUTW 220112C2495000  102434       0\n",
      "RUTW 220112C2500000  102434       0\n",
      "RUTW 220112C2505000  102434       0\n",
      "RUTW 220112C2510000  102434       0\n",
      "RUTW 220112C2515000  102434       0\n",
      "RUTW 220112C2520000  102434       0\n",
      "RUTW 220112C2525000  102434       0\n",
      "RUTW 220112C2530000  102434       0\n",
      "RUTW 220112C2645000  102434       0\n",
      "RUTW 220112C2650000  102434       0\n",
      "RUTW 220112C2655000  102434       0\n",
      "RUTW 220112P1855000  102434       0\n",
      "RUTW 220112P1865000  102434       0\n",
      "RUTW 220112P1870000  102434       0\n",
      "RUTW 220112P1875000  102434       0\n",
      "RUTW 220112P1880000  102434       0\n",
      "RUTW 220112P1885000  102434       0\n",
      "RUTW 220112P1890000  102434       0\n",
      "RUTW 220112P1895000  102434       0\n",
      "RUTW 220112P1900000  102434       0\n",
      "RUTW 220112P1905000  102434       0\n",
      "RUTW 220112P1910000  102434       0\n",
      "RUTW 220112P1915000  102434       0\n",
      "RUTW 220112P1920000  102434       0\n",
      "RUTW 220112P1925000  102434       0\n",
      "RUTW 220112P1930000  102434       0\n",
      "RUTW 220112P1935000  102434       0\n",
      "RUTW 220112P1940000  102434       0\n",
      "RUTW 220112P1945000  102434       0\n",
      "RUTW 220112P1860000  102434       0\n",
      "RUTW 220112P1850000  102434       0\n",
      "RUTW 220112C2660000  102434       0\n",
      "RUTW 220112P1845000  102434       0\n",
      "RUTW 220112C2665000  102434       0\n",
      "RUTW 220112C2670000  102434       0\n",
      "RUTW 220112C2675000  102434       0\n",
      "RUTW 220112C2680000  102434       0\n",
      "RUTW 220112C2685000  102434       0\n",
      "RUTW 220112C2690000  102434       0\n",
      "RUTW 220112C2695000  102434       0\n",
      "RUTW 220112C2700000  102434       0\n",
      "RUTW 220112C2705000  102434       0\n",
      "RUTW 220112C2710000  102434       0\n",
      "RUTW 220112P1810000  102434       0\n",
      "RUTW 220112P1815000  102434       0\n",
      "RUTW 220112P1820000  102434       0\n",
      "RUTW 220112P1825000  102434       0\n",
      "RUTW 220112P1830000  102434       0\n",
      "RUTW 220112P1835000  102434       0\n",
      "RUTW 220112P1840000  102434       0\n",
      "RUTW 220112C2445000  102434       0\n",
      "RUTW 220112C2440000  102434       0\n",
      "RUTW 220112C2435000  102434       0\n",
      "RUTW 220112C2005000  102434       0\n",
      "RUTW 220112C2015000  102434       0\n",
      "RUTW 220112C2020000  102434       0\n",
      "RUTW 220112C2025000  102434       0\n",
      "RUTW 220112C2030000  102434       0\n",
      "RUTW 220112C2035000  102434       0\n",
      "RUTW 220112C2040000  102434       0\n",
      "RUTW 220112C2045000  102434       0\n",
      "RUTW 220112C2050000  102434       0\n",
      "RUTW 220112C2055000  102434       0\n",
      "RUTW 220112C2060000  102434       0\n",
      "RUTW 220112C2065000  102434       0\n",
      "RUTW 220112C2070000  102434       0\n",
      "RUTW 220112C2075000  102434       0\n",
      "RUTW 220112C2080000  102434       0\n",
      "RUTW 220112C2085000  102434       0\n",
      "RUTW 220112C2090000  102434       0\n",
      "RUTW 220112C2095000  102434       0\n",
      "RUTW 220112C2010000  102434       0\n",
      "RUTW 220112C2000000  102434       0\n",
      "RUTW 220112C2110000  102434       0\n",
      "RUTW 220112C1995000  102434       0\n",
      "RUTW 220112C1910000  102434       0\n",
      "RUTW 220112C1915000  102434       0\n",
      "RUTW 220112C1920000  102434       0\n",
      "RUTW 220112C1925000  102434       0\n",
      "RUTW 220112C1930000  102434       0\n",
      "RUTW 220112C1935000  102434       0\n",
      "RUTW 220112C1940000  102434       0\n",
      "RUTW 220112C1945000  102434       0\n",
      "RUTW 220112C1950000  102434       0\n",
      "RUTW 220112C1955000  102434       0\n",
      "RUTW 220112C1960000  102434       0\n",
      "RUTW 220112C1965000  102434       0\n",
      "RUTW 220112C1970000  102434       0\n",
      "RUTW 220112C1975000  102434       0\n",
      "RUTW 220112C1980000  102434       0\n",
      "RUTW 220112C1985000  102434       0\n",
      "RUTW 220112C1990000  102434       0\n",
      "RUTW 220112C2105000  102434       0\n",
      "RUTW 220112C2115000  102434       0\n",
      "RUTW 220112C2430000  102434       0\n",
      "RUTW 220112C2220000  102434       0\n",
      "RUTW 220112C2230000  102434       0\n",
      "RUTW 220112C2235000  102434       0\n",
      "RUTW 220112C2245000  102434       0\n",
      "RUTW 220112C2315000  102434       0\n",
      "RUTW 220112C2320000  102434       0\n",
      "RUTW 220112C2335000  102434       0\n",
      "RUTW 220112C2365000  102434       0\n",
      "RUTW 220112C2375000  102434       0\n",
      "RUTW 220112C2380000  102434       0\n",
      "RUTW 220112C2390000  102434       0\n",
      "RUTW 220112C2395000  102434       0\n",
      "RUTW 220112C2400000  102434       0\n",
      "RUTW 220112C2405000  102434       0\n",
      "RUTW 220112C2410000  102434       0\n",
      "RUTW 220112C2415000  102434       0\n",
      "RUTW 220112C2420000  102434       0\n",
      "RUTW 220112C2425000  102434       0\n",
      "RUTW 220112C2225000  102434       0\n",
      "RUTW 220112C2215000  102434       0\n",
      "RUTW 220112C2120000  102434       0\n",
      "RUTW 220112C2210000  102434       0\n",
      "RUTW 220112C2125000  102434       0\n",
      "RUTW 220112C2130000  102434       0\n",
      "RUTW 220112C2135000  102434       0\n",
      "RUTW 220112C2140000  102434       0\n",
      "RUTW 220112C2145000  102434       0\n",
      "RUTW 220112C2150000  102434       0\n",
      "RUTW 220112C2155000  102434       0\n",
      "RUTW 220112C2160000  102434       0\n",
      "RUTW 220112C2165000  102434       0\n",
      "RUTW 220112C2170000  102434       0\n",
      "RUTW 220112C2175000  102434       0\n",
      "RUTW 220112C2180000  102434       0\n",
      "RUTW 220112C2185000  102434       0\n",
      "RUTW 220112C2190000  102434       0\n",
      "RUTW 220112C2195000  102434       0\n",
      "RUTW 220112C2200000  102434       0\n",
      "RUTW 220112C2205000  102434       0\n",
      "RUTW 220110C2555000  102434       0\n",
      "RUTW 220110C2545000  102434       0\n",
      "RUTW 220112P1955000  102434       0\n",
      "RUTW 220107P2360000  102434       0\n",
      "RUTW 220107P2295000  102434       0\n",
      "RUTW 220107P2305000  102434       0\n",
      "RUTW 220107P2310000  102434       0\n",
      "RUTW 220107P2325000  102434       0\n",
      "RUTW 220107P2335000  102434       0\n",
      "RUTW 220107P2345000  102434       0\n",
      "RUTW 220107P2350000  102434       0\n",
      "RUTW 220107P2355000  102434       0\n",
      "RUTW 220107P2365000  102434       0\n",
      "RUTW 220107P1880000  102434       0\n",
      "RUTW 220107P2370000  102434       0\n",
      "RUTW 220107P2375000  102434       0\n",
      "RUTW 220107P2380000  102434       0\n",
      "RUTW 220107P2385000  102434       0\n",
      "RUTW 220107P2395000  102434       0\n",
      "RUTW 220107P2400000  102434       0\n",
      "RUTW 220107P2405000  102434       0\n",
      "RUTW 220107P2410000  102434       0\n",
      "RUTW 220107P2075000  102434       0\n",
      "RUTW 220107P2065000  102434       0\n",
      "RUTW 220107P2060000  102434       0\n",
      "RUTW 220107P2045000  102434       0\n",
      "RUTW 220107P1895000  102434       0\n",
      "RUTW 220107P1900000  102434       0\n",
      "RUTW 220107P1910000  102434       0\n",
      "RUTW 220107P1920000  102434       0\n",
      "RUTW 220107P1925000  102434       0\n",
      "RUTW 220107P1930000  102434       0\n",
      "RUTW 220107P1935000  102434       0\n",
      "RUTW 220107P1955000  102434       0\n",
      "RUTW 220107P1960000  102434       0\n",
      "RUTW 220107P1965000  102434       0\n",
      "RUTW 220107P1975000  102434       0\n",
      "RUTW 220107P1980000  102434       0\n",
      "RUTW 220107P1985000  102434       0\n",
      "RUTW 220107P2005000  102434       0\n",
      "RUTW 220107P2020000  102434       0\n",
      "RUTW 220107P2025000  102434       0\n",
      "RUTW 220107P2030000  102434       0\n",
      "RUTW 220107P2415000  102434       0\n",
      "RUTW 220107P2420000  102434       0\n",
      "RUTW 220107P2425000  102434       0\n",
      "RUTW 220107P2530000  102434       0\n",
      "RUTW 220107P2540000  102434       0\n",
      "RUTW 220107P2545000  102434       0\n",
      "RUTW 220107P2550000  102434       0\n",
      "RUTW 220107P2555000  102434       0\n",
      "RUTW 220107P2560000  102434       0\n",
      "RUTW 220107P2565000  102434       0\n",
      "RUTW 220107P2570000  102434       0\n",
      "RUTW 220107P2575000  102434       0\n",
      "RUTW 220107P2580000  102434       0\n",
      "RUTW 220107P2585000  102434       0\n",
      "RUTW 220107P2590000  102434       0\n",
      "RUTW 220107P2595000  102434       0\n",
      "RUTW 220107P2600000  102434       0\n",
      "RUTW 220107P2605000  102434       0\n",
      "RUTW 220107P2610000  102434       0\n",
      "RUTW 220107P2615000  102434       0\n",
      "RUTW 220107P2620000  102434       0\n",
      "RUTW 220107P2535000  102434       0\n",
      "RUTW 220107P2525000  102434       0\n",
      "RUTW 220107P2430000  102434       0\n",
      "RUTW 220107P2520000  102434       0\n",
      "RUTW 220107P2435000  102434       0\n",
      "RUTW 220107P2440000  102434       0\n",
      "RUTW 220107P2445000  102434       0\n",
      "RUTW 220107P2450000  102434       0\n",
      "RUTW 220107P2455000  102434       0\n",
      "RUTW 220107P2460000  102434       0\n",
      "RUTW 220107P2465000  102434       0\n",
      "RUTW 220107P2470000  102434       0\n",
      "RUTW 220107P2475000  102434       0\n",
      "RUTW 220107P2480000  102434       0\n",
      "RUTW 220107P2485000  102434       0\n",
      "RUTW 220107P2490000  102434       0\n",
      "RUTW 220107P2495000  102434       0\n",
      "RUTW 220107P2500000  102434       0\n",
      "RUTW 220107P2505000  102434       0\n",
      "RUTW 220107P2510000  102434       0\n",
      "RUTW 220107P2515000  102434       0\n",
      "RUTW 220107P1885000  102434       0\n",
      "RUTW 220107P1875000  102434       0\n",
      "RUTW 220110C2540000  102434       0\n",
      "RUTW 220107P1580000  102434       0\n",
      "RUTW 220107P1540000  102434       0\n",
      "RUTW 220107P1545000  102434       0\n",
      "RUTW 220107P1550000  102434       0\n",
      "RUTW 220107P1555000  102434       0\n",
      "RUTW 220107P1560000  102434       0\n",
      "RUTW 220107P1565000  102434       0\n",
      "RUTW 220107P1570000  102434       0\n",
      "RUTW 220107P1575000  102434       0\n",
      "RUTW 220107P1585000  102434       0\n",
      "RUTW 220107P1870000  102434       0\n",
      "RUTW 220107P1590000  102434       0\n",
      "RUTW 220107P1595000  102434       0\n",
      "RUTW 220107P1600000  102434       0\n",
      "RUTW 220107P1605000  102434       0\n",
      "RUTW 220107P1610000  102434       0\n",
      "RUTW 220107P1615000  102434       0\n",
      "RUTW 220107P1620000  102434       0\n",
      "RUTW 220107P1625000  102434       0\n",
      "RUTW 220107P1535000  102434       0\n",
      "RUTW 220107P1530000  102434       0\n",
      "RUTW 220107P1525000  102434       0\n",
      "RUTW 220107P1520000  102434       0\n",
      "RUTW 220107P1435000  102434       0\n",
      "RUTW 220107P1440000  102434       0\n",
      "RUTW 220107P1445000  102434       0\n",
      "RUTW 220107P1450000  102434       0\n",
      "RUTW 220107P1455000  102434       0\n",
      "RUTW 220107P1460000  102434       0\n",
      "RUTW 220107P1465000  102434       0\n",
      "RUTW 220107P1470000  102434       0\n",
      "RUTW 220107P1475000  102434       0\n",
      "RUTW 220107P1480000  102434       0\n",
      "RUTW 220107P1485000  102434       0\n",
      "RUTW 220107P1490000  102434       0\n",
      "RUTW 220107P1495000  102434       0\n",
      "RUTW 220107P1500000  102434       0\n",
      "RUTW 220107P1505000  102434       0\n",
      "RUTW 220107P1510000  102434       0\n",
      "RUTW 220107P1515000  102434       0\n",
      "RUTW 220107P1630000  102434       0\n",
      "RUTW 220107P1635000  102434       0\n",
      "RUTW 220107P1640000  102434       0\n",
      "RUTW 220107P1745000  102434       0\n",
      "RUTW 220107P1755000  102434       0\n",
      "RUTW 220107P1760000  102434       0\n",
      "RUTW 220107P1765000  102434       0\n",
      "RUTW 220107P1770000  102434       0\n",
      "RUTW 220107P1775000  102434       0\n",
      "RUTW 220107P1780000  102434       0\n",
      "RUTW 220107P1785000  102434       0\n",
      "RUTW 220107P1790000  102434       0\n",
      "RUTW 220107P1815000  102434       0\n",
      "RUTW 220107P1820000  102434       0\n",
      "RUTW 220107P1825000  102434       0\n",
      "RUTW 220107P1830000  102434       0\n",
      "RUTW 220107P1835000  102434       0\n",
      "RUTW 220107P1840000  102434       0\n",
      "RUTW 220107P1845000  102434       0\n",
      "RUTW 220107P1855000  102434       0\n",
      "RUTW 220107P1865000  102434       0\n",
      "RUTW 220107P1750000  102434       0\n",
      "RUTW 220107P1740000  102434       0\n",
      "RUTW 220107P1645000  102434       0\n",
      "RUTW 220107P1735000  102434       0\n",
      "RUTW 220107P1650000  102434       0\n",
      "RUTW 220107P1655000  102434       0\n",
      "RUTW 220107P1660000  102434       0\n",
      "RUTW 220107P1665000  102434       0\n",
      "RUTW 220107P1670000  102434       0\n",
      "RUTW 220107P1675000  102434       0\n",
      "RUTW 220107P1680000  102434       0\n",
      "RUTW 220107P1685000  102434       0\n",
      "RUTW 220107P1690000  102434       0\n",
      "RUTW 220107P1695000  102434       0\n",
      "RUTW 220107P1700000  102434       0\n",
      "RUTW 220107P1705000  102434       0\n",
      "RUTW 220107P1710000  102434       0\n",
      "RUTW 220107P1715000  102434       0\n",
      "RUTW 220107P1720000  102434       0\n",
      "RUTW 220107P1725000  102434       0\n",
      "RUTW 220107P1730000  102434       0\n",
      "RUTW 220107P2625000  102434       0\n",
      "RUTW 220107P2630000  102434       0\n",
      "RUTW 220107P2635000  102434       0\n",
      "RUTW 220110C2115000  102434       0\n",
      "RUTW 220110C2075000  102434       0\n",
      "RUTW 220110C2080000  102434       0\n",
      "RUTW 220110C2085000  102434       0\n",
      "RUTW 220110C2090000  102434       0\n",
      "RUTW 220110C2095000  102434       0\n",
      "RUTW 220110C2100000  102434       0\n",
      "RUTW 220110C2105000  102434       0\n",
      "RUTW 220110C2110000  102434       0\n",
      "RUTW 220110C2120000  102434       0\n",
      "RUTW 220107P2640000  102434       0\n",
      "RUTW 220110C2125000  102434       0\n",
      "RUTW 220110C2130000  102434       0\n",
      "RUTW 220110C2135000  102434       0\n",
      "RUTW 220110C2140000  102434       0\n",
      "RUTW 220110C2145000  102434       0\n",
      "RUTW 220110C2150000  102434       0\n",
      "RUTW 220110C2155000  102434       0\n",
      "RUTW 220110C2160000  102434       0\n",
      "RUTW 220110C2070000  102434       0\n",
      "RUTW 220110C2065000  102434       0\n",
      "RUTW 220110C2060000  102434       0\n",
      "RUTW 220110C2055000  102434       0\n",
      "RUTW 220110C1970000  102434       0\n",
      "RUTW 220110C1975000  102434       0\n",
      "RUTW 220110C1980000  102434       0\n",
      "RUTW 220110C1985000  102434       0\n",
      "RUTW 220110C1990000  102434       0\n",
      "RUTW 220110C1995000  102434       0\n",
      "RUTW 220110C2000000  102434       0\n",
      "RUTW 220110C2005000  102434       0\n",
      "RUTW 220110C2010000  102434       0\n",
      "RUTW 220110C2015000  102434       0\n",
      "RUTW 220110C2020000  102434       0\n",
      "RUTW 220110C2025000  102434       0\n",
      "RUTW 220110C2030000  102434       0\n",
      "RUTW 220110C2035000  102434       0\n",
      "RUTW 220110C2040000  102434       0\n",
      "RUTW 220110C2045000  102434       0\n",
      "RUTW 220110C2050000  102434       0\n",
      "RUTW 220110C2165000  102434       0\n",
      "RUTW 220110C2170000  102434       0\n",
      "RUTW 220110C2175000  102434       0\n",
      "RUTW 220110C2445000  102434       0\n",
      "RUTW 220110C2455000  102434       0\n",
      "RUTW 220110C2460000  102434       0\n",
      "RUTW 220110C2465000  102434       0\n",
      "RUTW 220110C2470000  102434       0\n",
      "RUTW 220110C2475000  102434       0\n",
      "RUTW 220110C2480000  102434       0\n",
      "RUTW 220110C2485000  102434       0\n",
      "RUTW 220110C2490000  102434       0\n",
      "RUTW 220110C2495000  102434       0\n",
      "RUTW 220110C2500000  102434       0\n",
      "RUTW 220110C2505000  102434       0\n",
      "RUTW 220110C2510000  102434       0\n",
      "RUTW 220110C2515000  102434       0\n",
      "RUTW 220110C2520000  102434       0\n",
      "RUTW 220110C2525000  102434       0\n",
      "RUTW 220110C2530000  102434       0\n",
      "RUTW 220110C2535000  102434       0\n",
      "RUTW 220110C2450000  102434       0\n",
      "RUTW 220110C2440000  102434       0\n",
      "RUTW 220110C2180000  102434       0\n",
      "RUTW 220110C2435000  102434       0\n",
      "RUTW 220110C2185000  102434       0\n",
      "RUTW 220110C2190000  102434       0\n",
      "RUTW 220110C2195000  102434       0\n",
      "RUTW 220110C2200000  102434       0\n",
      "RUTW 220110C2205000  102434       0\n",
      "RUTW 220110C2210000  102434       0\n",
      "RUTW 220110C2215000  102434       0\n",
      "RUTW 220110C2220000  102434       0\n",
      "RUTW 220110C2225000  102434       0\n",
      "RUTW 220110C2230000  102434       0\n",
      "RUTW 220110C2240000  102434       0\n",
      "RUTW 220110C2365000  102434       0\n",
      "RUTW 220110C2400000  102434       0\n",
      "RUTW 220110C2405000  102434       0\n",
      "RUTW 220110C2415000  102434       0\n",
      "RUTW 220110C2425000  102434       0\n",
      "RUTW 220110C2430000  102434       0\n",
      "RUTW 220110C1965000  102434       0\n",
      "RUTW 220110C1960000  102434       0\n",
      "RUTW 220110C1955000  102434       0\n",
      "RUTW 220107P2740000  102434       0\n",
      "RUTW 220107P2750000  102434       0\n",
      "RUTW 220107P2755000  102434       0\n",
      "RUTW 220107P2760000  102434       0\n",
      "RUTW 220107P2765000  102434       0\n",
      "RUTW 220107P2770000  102434       0\n",
      "RUTW 220107P2775000  102434       0\n",
      "RUTW 220107P2780000  102434       0\n",
      "RUTW 220107P2785000  102434       0\n",
      "RUTW 220107P2790000  102434       0\n",
      "RUTW 220107P2795000  102434       0\n",
      "RUTW 220107P2800000  102434       0\n",
      "RUTW 220107P2805000  102434       0\n",
      "RUTW 220107P2810000  102434       0\n",
      "RUTW 220107P2815000  102434       0\n",
      "RUTW 220107P2820000  102434       0\n",
      "RUTW 220107P2825000  102434       0\n",
      "RUTW 220107P2830000  102434       0\n",
      "RUTW 220107P2745000  102434       0\n",
      "RUTW 220107P2735000  102434       0\n",
      "RUTW 220107P2840000  102434       0\n",
      "RUTW 220107P2730000  102434       0\n",
      "RUTW 220107P2645000  102434       0\n",
      "RUTW 220107P2650000  102434       0\n",
      "RUTW 220107P2655000  102434       0\n",
      "RUTW 220107P2660000  102434       0\n",
      "RUTW 220107P2665000  102434       0\n",
      "RUTW 220107P2670000  102434       0\n",
      "RUTW 220107P2675000  102434       0\n",
      "RUTW 220107P2680000  102434       0\n",
      "RUTW 220107P2685000  102434       0\n",
      "RUTW 220107P2690000  102434       0\n",
      "RUTW 220107P2695000  102434       0\n",
      "RUTW 220107P2700000  102434       0\n",
      "RUTW 220107P2705000  102434       0\n",
      "RUTW 220107P2710000  102434       0\n",
      "RUTW 220107P2715000  102434       0\n",
      "RUTW 220107P2720000  102434       0\n",
      "RUTW 220107P2725000  102434       0\n",
      "RUTW 220107P2835000  102434       0\n",
      "RUTW 220107P2845000  102434       0\n",
      "RUTW 220110C1950000  102434       0\n",
      "RUTW 220110C1855000  102434       0\n",
      "RUTW 220110C1865000  102434       0\n",
      "RUTW 220110C1870000  102434       0\n",
      "RUTW 220110C1875000  102434       0\n",
      "RUTW 220110C1880000  102434       0\n",
      "RUTW 220110C1885000  102434       0\n",
      "RUTW 220110C1890000  102434       0\n",
      "RUTW 220110C1895000  102434       0\n",
      "RUTW 220110C1900000  102434       0\n",
      "RUTW 220110C1905000  102434       0\n",
      "RUTW 220110C1910000  102434       0\n",
      "RUTW 220110C1915000  102434       0\n",
      "RUTW 220110C1920000  102434       0\n",
      "RUTW 220110C1925000  102434       0\n",
      "RUTW 220110C1930000  102434       0\n",
      "RUTW 220110C1935000  102434       0\n",
      "RUTW 220110C1940000  102434       0\n",
      "RUTW 220110C1945000  102434       0\n",
      "RUTW 220110C1860000  102434       0\n",
      "RUTW 220110C1850000  102434       0\n",
      "RUTW 220107P2850000  102434       0\n",
      "RUTW 220110C1845000  102434       0\n",
      "RUTW 220107P2855000  102434       0\n",
      "RUTW 220110C1765000  102434       0\n",
      "RUTW 220110C1770000  102434       0\n",
      "RUTW 220110C1775000  102434       0\n",
      "RUTW 220110C1780000  102434       0\n",
      "RUTW 220110C1785000  102434       0\n",
      "RUTW 220110C1790000  102434       0\n",
      "RUTW 220110C1795000  102434       0\n",
      "RUTW 220110C1800000  102434       0\n",
      "RUTW 220110C1805000  102434       0\n",
      "RUTW 220110C1810000  102434       0\n",
      "RUTW 220110C1815000  102434       0\n",
      "RUTW 220110C1820000  102434       0\n",
      "RUTW 220110C1825000  102434       0\n",
      "RUTW 220110C1830000  102434       0\n",
      "RUTW 220110C1835000  102434       0\n",
      "RUTW 220110C1840000  102434       0\n",
      "RUTW 220112P1950000  102434       0\n",
      "RUTW 220112P1960000  102434       0\n",
      "RUTW 220118C2105000  102434       0\n",
      "RUTW 220114P1575000  102434       0\n",
      "RUTW 220114P1535000  102434       0\n",
      "RUTW 220114P1540000  102434       0\n",
      "RUTW 220114P1545000  102434       0\n",
      "RUTW 220114P1550000  102434       0\n",
      "RUTW 220114P1555000  102434       0\n",
      "RUTW 220114P1560000  102434       0\n",
      "RUTW 220114P1565000  102434       0\n",
      "RUTW 220114P1570000  102434       0\n",
      "RUTW 220114P1580000  102434       0\n",
      "RUTW 220114P1415000  102434       0\n",
      "RUTW 220114P1585000  102434       0\n",
      "RUTW 220114P1590000  102434       0\n",
      "RUTW 220114P1595000  102434       0\n",
      "RUTW 220114P1600000  102434       0\n",
      "RUTW 220114P1605000  102434       0\n",
      "RUTW 220114P1610000  102434       0\n",
      "RUTW 220114P1615000  102434       0\n",
      "RUTW 220114P1620000  102434       0\n",
      "RUTW 220114P1530000  102434       0\n",
      "RUTW 220114P1525000  102434       0\n",
      "RUTW 220114P1520000  102434       0\n",
      "RUTW 220114P1515000  102434       0\n",
      "RUTW 220114P1425000  102434       0\n",
      "RUTW 220114P1435000  102434       0\n",
      "RUTW 220114P1440000  102434       0\n",
      "RUTW 220114P1445000  102434       0\n",
      "RUTW 220114P1450000  102434       0\n",
      "RUTW 220114P1455000  102434       0\n",
      "RUTW 220114P1460000  102434       0\n",
      "RUTW 220114P1465000  102434       0\n",
      "RUTW 220114P1470000  102434       0\n",
      "RUTW 220114P1475000  102434       0\n",
      "RUTW 220114P1480000  102434       0\n",
      "RUTW 220114P1485000  102434       0\n",
      "RUTW 220114P1490000  102434       0\n",
      "RUTW 220114P1495000  102434       0\n",
      "RUTW 220114P1500000  102434       0\n",
      "RUTW 220114P1505000  102434       0\n",
      "RUTW 220114P1510000  102434       0\n",
      "RUTW 220114P1625000  102434       0\n",
      "RUTW 220114P1630000  102434       0\n",
      "RUTW 220114P1635000  102434       0\n",
      "RUTW 220114P1745000  102434       0\n",
      "RUTW 220114P1755000  102434       0\n",
      "RUTW 220114P1780000  102434       0\n",
      "RUTW 220114P1785000  102434       0\n",
      "RUTW 220114P1790000  102434       0\n",
      "RUTW 220114P1795000  102434       0\n",
      "RUTW 220114P1800000  102434       0\n",
      "RUTW 220114P1805000  102434       0\n",
      "RUTW 220114P1810000  102434       0\n",
      "RUTW 220114P1815000  102434       0\n",
      "RUTW 220114P1820000  102434       0\n",
      "RUTW 220114P1830000  102434       0\n",
      "RUTW 220114P1840000  102434       0\n",
      "RUTW 220114P1845000  102434       0\n",
      "RUTW 220114P1850000  102434       0\n",
      "RUTW 220114P1855000  102434       0\n",
      "RUTW 220114P1860000  102434       0\n",
      "RUTW 220114P1865000  102434       0\n",
      "RUTW 220114P1750000  102434       0\n",
      "RUTW 220114P1740000  102434       0\n",
      "RUTW 220114P1640000  102434       0\n",
      "RUTW 220114P1730000  102434       0\n",
      "RUTW 220114P1645000  102434       0\n",
      "RUTW 220114P1650000  102434       0\n",
      "RUTW 220114P1655000  102434       0\n",
      "RUTW 220128P2750000  102434       0\n",
      "RUTW 220114P1665000  102434       0\n",
      "RUTW 220114P1670000  102434       0\n",
      "RUTW 220114P1675000  102434       0\n",
      "RUTW 220114P1680000  102434       0\n",
      "RUTW 220114P1685000  102434       0\n",
      "RUTW 220114P1690000  102434       0\n",
      "RUTW 220114P1695000  102434       0\n",
      "RUTW 220114P1700000  102434       0\n",
      "RUTW 220114P1705000  102434       0\n",
      "RUTW 220114P1710000  102434       0\n",
      "RUTW 220114P1715000  102434       0\n",
      "RUTW 220114P1720000  102434       0\n",
      "RUTW 220114P1725000  102434       0\n",
      "RUTW 220114P1420000  102434       0\n",
      "RUTW 220114P1405000  102434       0\n",
      "RUTW 220114C2530000  102434       0\n",
      "RUTW 220114C2685000  102434       0\n",
      "RUTW 220114C2645000  102434       0\n",
      "RUTW 220114C2650000  102434       0\n",
      "RUTW 220114C2655000  102434       0\n",
      "RUTW 220114C2660000  102434       0\n",
      "RUTW 220114C2665000  102434       0\n",
      "RUTW 220114C2670000  102434       0\n",
      "RUTW 220114C2675000  102434       0\n",
      "RUTW 220114C2680000  102434       0\n",
      "RUTW 220114C2690000  102434       0\n",
      "RUTW 220114P1400000  102434       0\n",
      "RUTW 220114C2695000  102434       0\n",
      "RUTW 220114C2700000  102434       0\n",
      "RUTW 220114C2705000  102434       0\n",
      "RUTW 220114C2710000  102434       0\n",
      "RUTW 220114C2715000  102434       0\n",
      "RUTW 220114C2720000  102434       0\n",
      "RUTW 220114C2725000  102434       0\n",
      "RUTW 220114C2730000  102434       0\n",
      "RUTW 220114C2640000  102434       0\n",
      "RUTW 220114C2635000  102434       0\n",
      "RUTW 220114C2630000  102434       0\n",
      "RUTW 220114C2625000  102434       0\n",
      "RUTW 220114C2540000  102434       0\n",
      "RUTW 220114C2545000  102434       0\n",
      "RUTW 220114C2550000  102434       0\n",
      "RUTW 220114C2555000  102434       0\n",
      "RUTW 220114C2560000  102434       0\n",
      "RUTW 220114C2565000  102434       0\n",
      "RUTW 220114C2570000  102434       0\n",
      "RUTW 220114C2575000  102434       0\n",
      "RUTW 220114C2580000  102434       0\n",
      "RUTW 220114C2585000  102434       0\n",
      "RUTW 220114C2590000  102434       0\n",
      "RUTW 220114C2595000  102434       0\n",
      "RUTW 220114C2600000  102434       0\n",
      "RUTW 220114C2605000  102434       0\n",
      "RUTW 220114C2610000  102434       0\n",
      "RUTW 220114C2615000  102434       0\n",
      "RUTW 220114C2620000  102434       0\n",
      "RUTW 220114C2735000  102434       0\n",
      "RUTW 220114C2740000  102434       0\n",
      "RUTW 220114C2745000  102434       0\n",
      "RUTW 220114P1305000  102434       0\n",
      "RUTW 220114P1315000  102434       0\n",
      "RUTW 220114P1320000  102434       0\n",
      "RUTW 220114P1325000  102434       0\n",
      "RUTW 220114P1330000  102434       0\n",
      "RUTW 220114P1335000  102434       0\n",
      "RUTW 220114P1340000  102434       0\n",
      "RUTW 220114P1345000  102434       0\n",
      "RUTW 220114P1350000  102434       0\n",
      "RUTW 220114P1355000  102434       0\n",
      "RUTW 220114P1360000  102434       0\n",
      "RUTW 220114P1365000  102434       0\n",
      "RUTW 220114P1370000  102434       0\n",
      "RUTW 220114P1375000  102434       0\n",
      "RUTW 220114P1380000  102434       0\n",
      "RUTW 220114P1385000  102434       0\n",
      "RUTW 220114P1390000  102434       0\n",
      "RUTW 220114P1395000  102434       0\n",
      "RUTW 220114P1310000  102434       0\n",
      "RUTW 220114P1300000  102434       0\n",
      "RUTW 220114C2750000  102434       0\n",
      "RUTW 220114P1295000  102434       0\n",
      "RUTW 220114C2755000  102434       0\n",
      "RUTW 220114C2760000  102434       0\n",
      "RUTW 220114C2765000  102434       0\n",
      "RUTW 220114P1225000  102434       0\n",
      "RUTW 220114P1230000  102434       0\n",
      "RUTW 220114P1235000  102434       0\n",
      "RUTW 220114P1240000  102434       0\n",
      "RUTW 220114P1245000  102434       0\n",
      "RUTW 220114P1250000  102434       0\n",
      "RUTW 220114P1255000  102434       0\n",
      "RUTW 220114P1260000  102434       0\n",
      "RUTW 220114P1265000  102434       0\n",
      "RUTW 220114P1270000  102434       0\n",
      "RUTW 220114P1275000  102434       0\n",
      "RUTW 220114P1280000  102434       0\n",
      "RUTW 220114P1285000  102434       0\n",
      "RUTW 220114P1290000  102434       0\n",
      "RUTW 220114P1870000  102434       0\n",
      "RUTW 220114P1875000  102434       0\n",
      "RUTW 220114P1880000  102434       0\n",
      "RUTW 220118C1845000  102434       0\n",
      "RUTW 220114P2765000  102434       0\n",
      "RUTW 220118C1810000  102434       0\n",
      "RUTW 220118C1815000  102434       0\n",
      "RUTW 220118C1820000  102434       0\n",
      "RUTW 220118C1825000  102434       0\n",
      "RUTW 220118C1830000  102434       0\n",
      "RUTW 220118C1835000  102434       0\n",
      "RUTW 220118C1840000  102434       0\n",
      "RUTW 220118C1850000  102434       0\n",
      "RUTW 220114P1895000  102434       0\n",
      "RUTW 220118C1855000  102434       0\n",
      "RUTW 220118C1860000  102434       0\n",
      "RUTW 220118C1865000  102434       0\n",
      "RUTW 220118C1870000  102434       0\n",
      "RUTW 220118C1875000  102434       0\n",
      "RUTW 220118C1880000  102434       0\n",
      "RUTW 220118C1885000  102434       0\n",
      "RUTW 220118C1890000  102434       0\n",
      "RUTW 220114P2760000  102434       0\n",
      "RUTW 220114P2755000  102434       0\n",
      "RUTW 220114P2750000  102434       0\n",
      "RUTW 220114P2745000  102434       0\n",
      "RUTW 220114P2660000  102434       0\n",
      "RUTW 220114P2665000  102434       0\n",
      "RUTW 220114P2670000  102434       0\n",
      "RUTW 220114P2675000  102434       0\n",
      "RUTW 220114P2680000  102434       0\n",
      "RUTW 220114P2685000  102434       0\n",
      "RUTW 220114P2690000  102434       0\n",
      "RUTW 220114P2695000  102434       0\n",
      "RUTW 220114P2700000  102434       0\n",
      "RUTW 220114P2705000  102434       0\n",
      "RUTW 220114P2710000  102434       0\n",
      "RUTW 220114P2715000  102434       0\n",
      "RUTW 220114P2720000  102434       0\n",
      "RUTW 220114P2725000  102434       0\n",
      "RUTW 220114P2730000  102434       0\n",
      "RUTW 220114P2735000  102434       0\n",
      "RUTW 220114P2740000  102434       0\n",
      "RUTW 220118C1895000  102434       0\n",
      "RUTW 220118C1900000  102434       0\n",
      "RUTW 220118C1905000  102434       0\n",
      "RUTW 220118C2010000  102434       0\n",
      "RUTW 220118C2020000  102434       0\n",
      "RUTW 220118C2025000  102434       0\n",
      "RUTW 220118C2030000  102434       0\n",
      "RUTW 220118C2035000  102434       0\n",
      "RUTW 220118C2040000  102434       0\n",
      "RUTW 220118C2045000  102434       0\n",
      "RUTW 220118C2050000  102434       0\n",
      "RUTW 220118C2055000  102434       0\n",
      "RUTW 220118C2060000  102434       0\n",
      "RUTW 220118C2065000  102434       0\n",
      "RUTW 220118C2070000  102434       0\n",
      "RUTW 220118C2075000  102434       0\n",
      "RUTW 220118C2080000  102434       0\n",
      "RUTW 220118C2085000  102434       0\n",
      "RUTW 220118C2090000  102434       0\n",
      "RUTW 220118C2095000  102434       0\n",
      "RUTW 220118C2100000  102434       0\n",
      "RUTW 220118C2015000  102434       0\n",
      "RUTW 220118C2005000  102434       0\n",
      "RUTW 220118C1910000  102434       0\n",
      "RUTW 220118C2000000  102434       0\n",
      "RUTW 220118C1915000  102434       0\n",
      "RUTW 220118C1920000  102434       0\n",
      "RUTW 220118C1925000  102434       0\n",
      "RUTW 220118C1930000  102434       0\n",
      "RUTW 220118C1935000  102434       0\n",
      "RUTW 220118C1940000  102434       0\n",
      "RUTW 220118C1945000  102434       0\n",
      "RUTW 220118C1950000  102434       0\n",
      "RUTW 220118C1955000  102434       0\n",
      "RUTW 220118C1960000  102434       0\n",
      "RUTW 220118C1965000  102434       0\n",
      "RUTW 220118C1970000  102434       0\n",
      "RUTW 220118C1975000  102434       0\n",
      "RUTW 220118C1980000  102434       0\n",
      "RUTW 220118C1985000  102434       0\n",
      "RUTW 220118C1990000  102434       0\n",
      "RUTW 220118C1995000  102434       0\n",
      "RUTW 220114P2655000  102434       0\n",
      "RUTW 220114P2650000  102434       0\n",
      "RUTW 220114P2645000  102434       0\n",
      "RUTW 220114P2310000  102434       0\n",
      "RUTW 220114P2335000  102434       0\n",
      "RUTW 220114P2340000  102434       0\n",
      "RUTW 220114P2345000  102434       0\n",
      "RUTW 220114P2350000  102434       0\n",
      "RUTW 220114P2365000  102434       0\n",
      "RUTW 220114P2370000  102434       0\n",
      "RUTW 220114P2375000  102434       0\n",
      "RUTW 220114P2380000  102434       0\n",
      "RUTW 220114P2385000  102434       0\n",
      "RUTW 220114P2390000  102434       0\n",
      "RUTW 220114P2395000  102434       0\n",
      "RUTW 220114P2400000  102434       0\n",
      "RUTW 220114P2405000  102434       0\n",
      "RUTW 220114P2410000  102434       0\n",
      "RUTW 220114P2415000  102434       0\n",
      "RUTW 220114P2420000  102434       0\n",
      "RUTW 220114P2425000  102434       0\n",
      "RUTW 220114P2325000  102434       0\n",
      "RUTW 220114P2305000  102434       0\n",
      "RUTW 220114P2435000  102434       0\n",
      "RUTW 220114P2300000  102434       0\n",
      "RUTW 220114P1900000  102434       0\n",
      "RUTW 220114P1905000  102434       0\n",
      "RUTW 220114P1910000  102434       0\n",
      "RUTW 220114P1915000  102434       0\n",
      "RUTW 220114P1920000  102434       0\n",
      "RUTW 220114P1925000  102434       0\n",
      "RUTW 220114P1940000  102434       0\n",
      "RUTW 220114P1955000  102434       0\n",
      "RUTW 220114P1965000  102434       0\n",
      "RUTW 220114P1970000  102434       0\n",
      "RUTW 220114P1975000  102434       0\n",
      "RUTW 220114P1995000  102434       0\n",
      "RUTW 220114P2005000  102434       0\n",
      "RUTW 220114P2025000  102434       0\n",
      "RUTW 220114P2175000  102434       0\n",
      "RUTW 220114P2285000  102434       0\n",
      "RUTW 220114P2295000  102434       0\n",
      "RUTW 220114P2430000  102434       0\n",
      "RUTW 220114P2440000  102434       0\n",
      "RUTW 220114P2640000  102434       0\n",
      "RUTW 220114P2545000  102434       0\n",
      "RUTW 220114P2555000  102434       0\n",
      "RUTW 220114P2560000  102434       0\n",
      "RUTW 220114P2565000  102434       0\n",
      "RUTW 220114P2570000  102434       0\n",
      "RUTW 220114P2575000  102434       0\n",
      "RUTW 220114P2580000  102434       0\n",
      "RUTW 220114P2585000  102434       0\n",
      "RUTW 220114P2590000  102434       0\n",
      "RUTW 220114P2595000  102434       0\n",
      "RUTW 220114P2600000  102434       0\n",
      "RUTW 220114P2605000  102434       0\n",
      "RUTW 220114P2610000  102434       0\n",
      "RUTW 220114P2615000  102434       0\n",
      "RUTW 220114P2620000  102434       0\n",
      "RUTW 220114P2625000  102434       0\n",
      "RUTW 220114P2630000  102434       0\n",
      "RUTW 220114P2635000  102434       0\n",
      "RUTW 220114P2550000  102434       0\n",
      "RUTW 220114P2540000  102434       0\n",
      "RUTW 220114P2445000  102434       0\n",
      "RUTW 220114P2535000  102434       0\n",
      "RUTW 220114P2450000  102434       0\n",
      "RUTW 220114P2455000  102434       0\n",
      "RUTW 220114P2460000  102434       0\n",
      "RUTW 220114P2465000  102434       0\n",
      "RUTW 220114P2470000  102434       0\n",
      "RUTW 220114P2475000  102434       0\n",
      "RUTW 220114P2480000  102434       0\n",
      "RUTW 220114P2485000  102434       0\n",
      "RUTW 220114P2490000  102434       0\n",
      "RUTW 220114P2495000  102434       0\n",
      "RUTW 220114P2500000  102434       0\n",
      "RUTW 220114P2505000  102434       0\n",
      "RUTW 220114P2510000  102434       0\n",
      "RUTW 220114P2515000  102434       0\n",
      "RUTW 220114P2520000  102434       0\n",
      "RUTW 220114P2525000  102434       0\n",
      "RUTW 220114P2530000  102434       0\n",
      "RUTW 220114C2535000  102434       0\n",
      "RUTW 220114C2525000  102434       0\n",
      "RUTW 220112P1965000  102434       0\n",
      "RUTW 220112P2680000  102434       0\n",
      "RUTW 220112P2640000  102434       0\n",
      "RUTW 220112P2645000  102434       0\n",
      "RUTW 220112P2650000  102434       0\n",
      "RUTW 220112P2655000  102434       0\n",
      "RUTW 220112P2660000  102434       0\n",
      "RUTW 220112P2665000  102434       0\n",
      "RUTW 220112P2670000  102434       0\n",
      "RUTW 220112P2675000  102434       0\n",
      "RUTW 220112P2685000  102434       0\n",
      "RUTW 220112P2525000  102434       0\n",
      "RUTW 220112P2690000  102434       0\n",
      "RUTW 220112P2695000  102434       0\n",
      "RUTW 220112P2700000  102434       0\n",
      "RUTW 220112P2705000  102434       0\n",
      "RUTW 220112P2710000  102434       0\n",
      "RUTW 220114C1225000  102434       0\n",
      "RUTW 220114C1230000  102434       0\n",
      "RUTW 220114C1235000  102434       0\n",
      "RUTW 220112P2635000  102434       0\n",
      "RUTW 220112P2630000  102434       0\n",
      "RUTW 220112P2625000  102434       0\n",
      "RUTW 220112P2620000  102434       0\n",
      "RUTW 220112P2535000  102434       0\n",
      "RUTW 220112P2540000  102434       0\n",
      "RUTW 220112P2545000  102434       0\n",
      "RUTW 220112P2550000  102434       0\n",
      "RUTW 220112P2555000  102434       0\n",
      "RUTW 220112P2560000  102434       0\n",
      "RUTW 220112P2565000  102434       0\n",
      "RUTW 220112P2570000  102434       0\n",
      "RUTW 220112P2575000  102434       0\n",
      "RUTW 220112P2580000  102434       0\n",
      "RUTW 220112P2585000  102434       0\n",
      "RUTW 220112P2590000  102434       0\n",
      "RUTW 220112P2595000  102434       0\n",
      "RUTW 220112P2600000  102434       0\n",
      "RUTW 220112P2605000  102434       0\n",
      "RUTW 220112P2610000  102434       0\n",
      "RUTW 220112P2615000  102434       0\n",
      "RUTW 220114C1240000  102434       0\n",
      "RUTW 220114C1245000  102434       0\n",
      "RUTW 220114C1250000  102434       0\n",
      "RUTW 220114C1355000  102434       0\n",
      "RUTW 220114C1365000  102434       0\n",
      "RUTW 220114C1370000  102434       0\n",
      "RUTW 220114C1375000  102434       0\n",
      "RUTW 220114C1380000  102434       0\n",
      "RUTW 220114C1385000  102434       0\n",
      "RUTW 220114C1390000  102434       0\n",
      "RUTW 220114C1395000  102434       0\n",
      "RUTW 220114C1400000  102434       0\n",
      "RUTW 220114C1405000  102434       0\n",
      "RUTW 220114C1410000  102434       0\n",
      "RUTW 220114C1415000  102434       0\n",
      "RUTW 220114C1420000  102434       0\n",
      "RUTW 220114C1425000  102434       0\n",
      "RUTW 220114C1430000  102434       0\n",
      "RUTW 220114C1435000  102434       0\n",
      "RUTW 220114C1440000  102434       0\n",
      "RUTW 220114C1445000  102434       0\n",
      "RUTW 220114C1360000  102434       0\n",
      "RUTW 220114C1350000  102434       0\n",
      "RUTW 220114C1255000  102434       0\n",
      "RUTW 220114C1345000  102434       0\n",
      "RUTW 220114C1260000  102434       0\n",
      "RUTW 220114C1265000  102434       0\n",
      "RUTW 220114C1270000  102434       0\n",
      "RUTW 220114C1275000  102434       0\n",
      "RUTW 220114C1280000  102434       0\n",
      "RUTW 220114C1285000  102434       0\n",
      "RUTW 220114C1290000  102434       0\n",
      "RUTW 220114C1295000  102434       0\n",
      "RUTW 220114C1300000  102434       0\n",
      "RUTW 220114C1305000  102434       0\n",
      "RUTW 220114C1310000  102434       0\n",
      "RUTW 220114C1315000  102434       0\n",
      "RUTW 220114C1320000  102434       0\n",
      "RUTW 220114C1325000  102434       0\n",
      "RUTW 220114C1330000  102434       0\n",
      "RUTW 220114C1335000  102434       0\n",
      "RUTW 220114C1340000  102434       0\n",
      "RUTW 220112P2530000  102434       0\n",
      "RUTW 220112P2520000  102434       0\n",
      "RUTW 220114C2520000  102434       0\n",
      "RUTW 220112P2130000  102434       0\n",
      "RUTW 220112P2090000  102434       0\n",
      "RUTW 220112P2095000  102434       0\n",
      "RUTW 220112P2100000  102434       0\n",
      "RUTW 220112P2105000  102434       0\n",
      "RUTW 220112P2110000  102434       0\n",
      "RUTW 220112P2115000  102434       0\n",
      "RUTW 220112P2120000  102434       0\n",
      "RUTW 220112P2125000  102434       0\n",
      "RUTW 220112P2155000  102434       0\n",
      "RUTW 220112P2515000  102434       0\n",
      "RUTW 220112P2210000  102434       0\n",
      "RUTW 220112P2215000  102434       0\n",
      "RUTW 220112P2245000  102434       0\n",
      "RUTW 220112P2280000  102434       0\n",
      "RUTW 220112P2285000  102434       0\n",
      "RUTW 220112P2290000  102434       0\n",
      "RUTW 220112P2295000  102434       0\n",
      "RUTW 220112P2300000  102434       0\n",
      "RUTW 220112P2085000  102434       0\n",
      "RUTW 220112P2080000  102434       0\n",
      "RUTW 220112P2075000  102434       0\n",
      "RUTW 220112P2070000  102434       0\n",
      "RUTW 220112P1970000  102434       0\n",
      "RUTW 220112P1975000  102434       0\n",
      "RUTW 220112P1980000  102434       0\n",
      "RUTW 220112P1985000  102434       0\n",
      "RUTW 220112P1995000  102434       0\n",
      "RUTW 220112P2005000  102434       0\n",
      "RUTW 220112P2010000  102434       0\n",
      "RUTW 220112P2015000  102434       0\n",
      "RUTW 220112P2020000  102434       0\n",
      "RUTW 220112P2025000  102434       0\n",
      "RUTW 220112P2030000  102434       0\n",
      "RUTW 220112P2035000  102434       0\n",
      "RUTW 220112P2040000  102434       0\n",
      "RUTW 220112P2045000  102434       0\n",
      "RUTW 220112P2050000  102434       0\n",
      "RUTW 220112P2055000  102434       0\n",
      "RUTW 220112P2060000  102434       0\n",
      "RUTW 220112P2305000  102434       0\n",
      "RUTW 220112P2310000  102434       0\n",
      "RUTW 220112P2315000  102434       0\n",
      "RUTW 220112P2420000  102434       0\n",
      "RUTW 220112P2430000  102434       0\n",
      "RUTW 220112P2435000  102434       0\n",
      "RUTW 220112P2440000  102434       0\n",
      "RUTW 220112P2445000  102434       0\n",
      "RUTW 220112P2450000  102434       0\n",
      "RUTW 220112P2455000  102434       0\n",
      "RUTW 220112P2460000  102434       0\n",
      "RUTW 220112P2465000  102434       0\n",
      "RUTW 220112P2470000  102434       0\n",
      "RUTW 220112P2475000  102434       0\n",
      "RUTW 220112P2480000  102434       0\n",
      "RUTW 220112P2485000  102434       0\n",
      "RUTW 220112P2490000  102434       0\n",
      "RUTW 220112P2495000  102434       0\n",
      "RUTW 220112P2500000  102434       0\n",
      "RUTW 220112P2505000  102434       0\n",
      "RUTW 220112P2510000  102434       0\n",
      "RUTW 220112P2425000  102434       0\n",
      "RUTW 220112P2415000  102434       0\n",
      "RUTW 220112P2320000  102434       0\n",
      "RUTW 220112P2410000  102434       0\n",
      "RUTW 220112P2325000  102434       0\n",
      "RUTW 220112P2330000  102434       0\n",
      "RUTW 220112P2335000  102434       0\n",
      "RUTW 220112P2340000  102434       0\n",
      "RUTW 220112P2345000  102434       0\n",
      "RUTW 220112P2350000  102434       0\n",
      "RUTW 220112P2355000  102434       0\n",
      "RUTW 220112P2360000  102434       0\n",
      "RUTW 220112P2365000  102434       0\n",
      "RUTW 220112P2370000  102434       0\n",
      "RUTW 220112P2375000  102434       0\n",
      "RUTW 220112P2380000  102434       0\n",
      "RUTW 220112P2385000  102434       0\n",
      "RUTW 220112P2390000  102434       0\n",
      "RUTW 220112P2395000  102434       0\n",
      "RUTW 220112P2400000  102434       0\n",
      "RUTW 220112P2405000  102434       0\n",
      "RUTW 220114C1450000  102434       0\n",
      "RUTW 220114C1455000  102434       0\n",
      "RUTW 220114C1460000  102434       0\n",
      "RUTW 220114C2040000  102434       0\n",
      "RUTW 220114C1995000  102434       0\n",
      "RUTW 220114C2005000  102434       0\n",
      "RUTW 220114C2010000  102434       0\n",
      "RUTW 220114C2015000  102434       0\n",
      "RUTW 220114C2020000  102434       0\n",
      "RUTW 220114C2025000  102434       0\n",
      "RUTW 220114C2030000  102434       0\n",
      "RUTW 220114C2035000  102434       0\n",
      "RUTW 220114C2045000  102434       0\n",
      "RUTW 220114C1465000  102434       0\n",
      "RUTW 220114C2055000  102434       0\n",
      "RUTW 220114C2060000  102434       0\n",
      "RUTW 220114C2065000  102434       0\n",
      "RUTW 220114C2075000  102434       0\n",
      "RUTW 220114C2080000  102434       0\n",
      "RUTW 220114C2085000  102434       0\n",
      "RUTW 220114C2090000  102434       0\n",
      "RUTW 220114C2095000  102434       0\n",
      "RUTW 220114C1990000  102434       0\n",
      "RUTW 220114C1985000  102434       0\n",
      "RUTW 220114C1980000  102434       0\n",
      "RUTW 220114C1975000  102434       0\n",
      "RUTW 220114C1890000  102434       0\n",
      "RUTW 220114C1895000  102434       0\n",
      "RUTW 220114C1900000  102434       0\n",
      "RUTW 220114C1905000  102434       0\n",
      "RUTW 220114C1910000  102434       0\n",
      "RUTW 220114C1915000  102434       0\n",
      "RUTW 220114C1920000  102434       0\n",
      "RUTW 220114C1925000  102434       0\n",
      "RUTW 220114C1930000  102434       0\n",
      "RUTW 220114C1935000  102434       0\n",
      "RUTW 220114C1940000  102434       0\n",
      "RUTW 220114C1945000  102434       0\n",
      "RUTW 220114C1950000  102434       0\n",
      "RUTW 220114C1955000  102434       0\n",
      "RUTW 220114C1960000  102434       0\n",
      "RUTW 220114C1965000  102434       0\n",
      "RUTW 220114C1970000  102434       0\n",
      "RUTW 220114C2100000  102434       0\n",
      "RUTW 220114C2105000  102434       0\n",
      "RUTW 220114C2110000  102434       0\n",
      "RUTW 220114C2250000  102434       0\n",
      "RUTW 220114C2325000  102434       0\n",
      "RUTW 220114C2355000  102434       0\n",
      "RUTW 220114C2435000  102434       0\n",
      "RUTW 220114C2440000  102434       0\n",
      "RUTW 220114C2445000  102434       0\n",
      "RUTW 220114C2455000  102434       0\n",
      "RUTW 220114C2460000  102434       0\n",
      "RUTW 220114C2465000  102434       0\n",
      "RUTW 220114C2470000  102434       0\n",
      "RUTW 220114C2475000  102434       0\n",
      "RUTW 220114C2480000  102434       0\n",
      "RUTW 220114C2485000  102434       0\n",
      "RUTW 220114C2490000  102434       0\n",
      "RUTW 220114C2495000  102434       0\n",
      "RUTW 220114C2500000  102434       0\n",
      "RUTW 220114C2505000  102434       0\n",
      "RUTW 220114C2515000  102434       0\n",
      "RUTW 220114C2275000  102434       0\n",
      "RUTW 220114C2235000  102434       0\n",
      "RUTW 220114C2115000  102434       0\n",
      "RUTW 220114C2225000  102434       0\n",
      "RUTW 220114C2120000  102434       0\n",
      "RUTW 220114C2125000  102434       0\n",
      "RUTW 220114C2135000  102434       0\n",
      "RUTW 220114C2140000  102434       0\n",
      "RUTW 220114C2145000  102434       0\n",
      "RUTW 220114C2150000  102434       0\n",
      "RUTW 220114C2155000  102434       0\n",
      "RUTW 220114C2160000  102434       0\n",
      "RUTW 220114C2165000  102434       0\n",
      "RUTW 220114C2170000  102434       0\n",
      "RUTW 220114C2175000  102434       0\n",
      "RUTW 220114C2185000  102434       0\n",
      "RUTW 220114C2190000  102434       0\n",
      "RUTW 220114C2195000  102434       0\n",
      "RUTW 220114C2210000  102434       0\n",
      "RUTW 220114C2215000  102434       0\n",
      "RUTW 220114C2220000  102434       0\n",
      "RUTW 220114C1885000  102434       0\n",
      "RUTW 220114C1880000  102434       0\n",
      "RUTW 220114C1875000  102434       0\n",
      "RUTW 220114C1565000  102434       0\n",
      "RUTW 220114C1575000  102434       0\n",
      "RUTW 220114C1580000  102434       0\n",
      "RUTW 220114C1585000  102434       0\n",
      "RUTW 220114C1590000  102434       0\n",
      "RUTW 220114C1595000  102434       0\n",
      "RUTW 220114C1600000  102434       0\n",
      "RUTW 220114C1605000  102434       0\n",
      "RUTW 220114C1610000  102434       0\n",
      "RUTW 220114C1615000  102434       0\n",
      "RUTW 220114C1620000  102434       0\n",
      "RUTW 220114C1625000  102434       0\n",
      "RUTW 220114C1630000  102434       0\n",
      "RUTW 220114C1635000  102434       0\n",
      "RUTW 220114C1640000  102434       0\n",
      "RUTW 220114C1645000  102434       0\n",
      "RUTW 220114C1650000  102434       0\n",
      "RUTW 220114C1655000  102434       0\n",
      "RUTW 220114C1570000  102434       0\n",
      "RUTW 220114C1560000  102434       0\n",
      "RUTW 220114C1665000  102434       0\n",
      "RUTW 220114C1555000  102434       0\n",
      "RUTW 220114C1470000  102434       0\n",
      "RUTW 220114C1475000  102434       0\n",
      "RUTW 220114C1480000  102434       0\n",
      "RUTW 220114C1485000  102434       0\n",
      "RUTW 220114C1490000  102434       0\n",
      "RUTW 220114C1495000  102434       0\n",
      "RUTW 220114C1500000  102434       0\n",
      "RUTW 220114C1505000  102434       0\n",
      "RUTW 220114C1510000  102434       0\n",
      "RUTW 220114C1515000  102434       0\n",
      "RUTW 220114C1520000  102434       0\n",
      "RUTW 220114C1525000  102434       0\n",
      "RUTW 220114C1530000  102434       0\n",
      "RUTW 220114C1535000  102434       0\n",
      "RUTW 220114C1540000  102434       0\n",
      "RUTW 220114C1545000  102434       0\n",
      "RUTW 220114C1550000  102434       0\n",
      "RUTW 220114C1660000  102434       0\n",
      "RUTW 220114C1670000  102434       0\n",
      "RUTW 220114C1870000  102434       0\n",
      "RUTW 220114C1775000  102434       0\n",
      "RUTW 220114C1785000  102434       0\n",
      "RUTW 220114C1790000  102434       0\n",
      "RUTW 220114C1795000  102434       0\n",
      "RUTW 220114C1800000  102434       0\n",
      "RUTW 220114C1805000  102434       0\n",
      "RUTW 220114C1810000  102434       0\n",
      "RUTW 220114C1815000  102434       0\n",
      "RUTW 220114C1820000  102434       0\n",
      "RUTW 220114C1825000  102434       0\n",
      "RUTW 220114C1830000  102434       0\n",
      "RUTW 220114C1835000  102434       0\n",
      "RUTW 220114C1840000  102434       0\n",
      "RUTW 220114C1845000  102434       0\n",
      "RUTW 220114C1850000  102434       0\n",
      "RUTW 220114C1855000  102434       0\n",
      "RUTW 220114C1860000  102434       0\n",
      "RUTW 220114C1865000  102434       0\n",
      "RUTW 220114C1780000  102434       0\n",
      "RUTW 220114C1770000  102434       0\n",
      "RUTW 220114C1675000  102434       0\n",
      "RUTW 220114C1765000  102434       0\n",
      "RUTW 220114C1680000  102434       0\n",
      "RUTW 220114C1685000  102434       0\n",
      "RUTW 220114C1690000  102434       0\n",
      "RUTW 220114C1695000  102434       0\n",
      "RUTW 220114C1700000  102434       0\n",
      "RUTW 220114C1705000  102434       0\n",
      "RUTW 220114C1710000  102434       0\n",
      "RUTW 220114C1715000  102434       0\n",
      "RUTW 220114C1720000  102434       0\n",
      "RUTW 220114C1725000  102434       0\n",
      "RUTW 220114C1730000  102434       0\n",
      "RUTW 220114C1735000  102434       0\n",
      "RUTW 220114C1740000  102434       0\n",
      "RUTW 220114C1745000  102434       0\n",
      "RUTW 220114C1750000  102434       0\n",
      "RUTW 220114C1755000  102434       0\n",
      "RUTW 220114C1760000  102434       0\n",
      "RUTW 220114P1660000  102434       0\n",
      "RUTW 220131C2670000  102434       0\n",
      "RUTW 220128P2755000  102434       0\n",
      "RUTW 220531C2395000  102434       0\n",
      "RUTW 220531C2350000  102434       0\n",
      "RUTW 220531C2355000  102434       0\n",
      "RUTW 220531C2360000  102434       0\n",
      "RUTW 220531C2365000  102434       0\n",
      "RUTW 220531C2370000  102434       0\n",
      "RUTW 220531C2375000  102434       0\n",
      "RUTW 220531C2380000  102434       0\n",
      "RUTW 220531C2385000  102434       0\n",
      "RUTW 220531C2390000  102434       0\n",
      "RUTW 220531C2400000  102434       0\n",
      "RUTW 220531C2455000  102434       0\n",
      "RUTW 220531C2405000  102434       0\n",
      "RUTW 220531C2410000  102434       0\n",
      "RUTW 220531C2415000  102434       0\n",
      "RUTW 220531C2420000  102434       0\n",
      "RUTW 220531C2425000  102434       0\n",
      "RUTW 220531C2430000  102434       0\n",
      "RUTW 220531C2435000  102434       0\n",
      "RUTW 220531C2440000  102434       0\n",
      "RUTW 220531C2445000  102434       0\n",
      "RUTW 220531C2345000  102434       0\n",
      "RUTW 220531C2340000  102434       0\n",
      "RUTW 220531C2335000  102434       0\n",
      "RUTW 220531C2325000  102434       0\n",
      "RUTW 220531C2230000  102434       0\n",
      "RUTW 220531C2235000  102434       0\n",
      "RUTW 220531C2240000  102434       0\n",
      "RUTW 220531C2245000  102434       0\n",
      "RUTW 220531C2250000  102434       0\n",
      "RUTW 220531C2255000  102434       0\n",
      "RUTW 220531C2260000  102434       0\n",
      "RUTW 220531C2265000  102434       0\n",
      "RUTW 220531C2270000  102434       0\n",
      "RUTW 220531C2275000  102434       0\n",
      "RUTW 220531C2280000  102434       0\n",
      "RUTW 220531C2285000  102434       0\n",
      "RUTW 220531C2290000  102434       0\n",
      "RUTW 220531C2295000  102434       0\n",
      "RUTW 220531C2300000  102434       0\n",
      "RUTW 220531C2305000  102434       0\n",
      "RUTW 220531C2310000  102434       0\n",
      "RUTW 220531C2315000  102434       0\n",
      "RUTW 220531C2320000  102434       0\n",
      "RUTW 220531C2450000  102434       0\n",
      "RUTW 220531C2460000  102434       0\n",
      "RUTW 220531C2950000  102434       0\n",
      "RUTW 220531C2630000  102434       0\n",
      "RUTW 220531C2585000  102434       0\n",
      "RUTW 220531C2590000  102434       0\n",
      "RUTW 220531C2595000  102434       0\n",
      "RUTW 220531C2600000  102434       0\n",
      "RUTW 220531C2605000  102434       0\n",
      "RUTW 220531C2610000  102434       0\n",
      "RUTW 220531C2615000  102434       0\n",
      "RUTW 220531C2620000  102434       0\n",
      "RUTW 220531C2625000  102434       0\n",
      "RUTW 220531C2635000  102434       0\n",
      "RUTW 220531C2465000  102434       0\n",
      "RUTW 220531C2640000  102434       0\n",
      "RUTW 220531C2645000  102434       0\n",
      "RUTW 220531C2650000  102434       0\n",
      "RUTW 220531C2655000  102434       0\n",
      "RUTW 220531C2660000  102434       0\n",
      "RUTW 220531C2700000  102434       0\n",
      "RUTW 220531C2750000  102434       0\n",
      "RUTW 220531C2800000  102434       0\n",
      "RUTW 220531C2850000  102434       0\n",
      "RUTW 220531C2580000  102434       0\n",
      "RUTW 220531C2575000  102434       0\n",
      "RUTW 220531C2570000  102434       0\n",
      "RUTW 220531C2565000  102434       0\n",
      "RUTW 220531C2470000  102434       0\n",
      "RUTW 220531C2475000  102434       0\n",
      "RUTW 220531C2480000  102434       0\n",
      "RUTW 220531C2485000  102434       0\n",
      "RUTW 220531C2490000  102434       0\n",
      "RUTW 220531C2495000  102434       0\n",
      "RUTW 220531C2500000  102434       0\n",
      "RUTW 220531C2505000  102434       0\n",
      "RUTW 220531C2510000  102434       0\n",
      "RUTW 220531C2515000  102434       0\n",
      "RUTW 220531C2520000  102434       0\n",
      "RUTW 220531C2525000  102434       0\n",
      "RUTW 220531C2530000  102434       0\n",
      "RUTW 220531C2535000  102434       0\n",
      "RUTW 220531C2540000  102434       0\n",
      "RUTW 220531C2545000  102434       0\n",
      "RUTW 220531C2550000  102434       0\n",
      "RUTW 220531C2555000  102434       0\n",
      "RUTW 220531C2560000  102434       0\n",
      "RUTW 220531C2225000  102434       0\n",
      "RUTW 220531C2220000  102434       0\n",
      "RUTW 220531C2215000  102434       0\n",
      "RUTW 220531C1920000  102434       0\n",
      "RUTW 220531C1875000  102434       0\n",
      "RUTW 220531C1880000  102434       0\n",
      "RUTW 220531C1885000  102434       0\n",
      "RUTW 220531C1890000  102434       0\n",
      "RUTW 220531C1895000  102434       0\n",
      "RUTW 220531C1900000  102434       0\n",
      "RUTW 220531C1905000  102434       0\n",
      "RUTW 220531C1910000  102434       0\n",
      "RUTW 220531C1915000  102434       0\n",
      "RUTW 220531C1925000  102434       0\n",
      "RUTW 220531C2210000  102434       0\n",
      "RUTW 220531C1930000  102434       0\n",
      "RUTW 220531C1935000  102434       0\n",
      "RUTW 220531C1940000  102434       0\n",
      "RUTW 220531C1945000  102434       0\n",
      "RUTW 220531C1950000  102434       0\n",
      "RUTW 220531C1955000  102434       0\n",
      "RUTW 220531C1960000  102434       0\n",
      "RUTW 220531C1965000  102434       0\n",
      "RUTW 220531C1970000  102434       0\n",
      "RUTW 220531C1870000  102434       0\n",
      "RUTW 220531C1865000  102434       0\n",
      "RUTW 220531C1860000  102434       0\n",
      "RUTW 220531C1855000  102434       0\n",
      "RUTW 220531C1600000  102434       0\n",
      "RUTW 220531C1650000  102434       0\n",
      "RUTW 220531C1700000  102434       0\n",
      "RUTW 220531C1750000  102434       0\n",
      "RUTW 220531C1780000  102434       0\n",
      "RUTW 220531C1785000  102434       0\n",
      "RUTW 220531C1790000  102434       0\n",
      "RUTW 220531C1795000  102434       0\n",
      "RUTW 220531C1800000  102434       0\n",
      "RUTW 220531C1805000  102434       0\n",
      "RUTW 220531C1810000  102434       0\n",
      "RUTW 220531C1815000  102434       0\n",
      "RUTW 220531C1820000  102434       0\n",
      "RUTW 220531C1825000  102434       0\n",
      "RUTW 220531C1830000  102434       0\n",
      "RUTW 220531C1835000  102434       0\n",
      "RUTW 220531C1840000  102434       0\n",
      "RUTW 220531C1845000  102434       0\n",
      "RUTW 220531C1850000  102434       0\n",
      "RUTW 220531C1975000  102434       0\n",
      "RUTW 220531C1980000  102434       0\n",
      "RUTW 220531C1985000  102434       0\n",
      "RUTW 220531C2105000  102434       0\n",
      "RUTW 220531C2115000  102434       0\n",
      "RUTW 220531C2120000  102434       0\n",
      "RUTW 220531C2125000  102434       0\n",
      "RUTW 220531C2130000  102434       0\n",
      "RUTW 220531C2135000  102434       0\n",
      "RUTW 220531C2140000  102434       0\n",
      "RUTW 220531C2145000  102434       0\n",
      "RUTW 220531C2150000  102434       0\n",
      "RUTW 220531C2155000  102434       0\n",
      "RUTW 220531C2160000  102434       0\n",
      "RUTW 220531C2165000  102434       0\n",
      "RUTW 220531C2170000  102434       0\n",
      "RUTW 220531C2175000  102434       0\n",
      "RUTW 220531C2180000  102434       0\n",
      "RUTW 220531C2185000  102434       0\n",
      "RUTW 220531C2190000  102434       0\n",
      "RUTW 220531C2195000  102434       0\n",
      "RUTW 220531C2200000  102434       0\n",
      "RUTW 220531C2205000  102434       0\n",
      "RUTW 220531C2110000  102434       0\n",
      "RUTW 220531C2095000  102434       0\n",
      "RUTW 220531C1990000  102434       0\n",
      "RUTW 220531C2090000  102434       0\n",
      "RUTW 220531C1995000  102434       0\n",
      "RUTW 220531C2000000  102434       0\n",
      "RUTW 220531C2005000  102434       0\n",
      "RUTW 220531C2010000  102434       0\n",
      "RUTW 220531C2015000  102434       0\n",
      "RUTW 220531C2020000  102434       0\n",
      "RUTW 220531C2025000  102434       0\n",
      "RUTW 220531C2030000  102434       0\n",
      "RUTW 220531C2035000  102434       0\n",
      "RUTW 220531C2040000  102434       0\n",
      "RUTW 220531C2045000  102434       0\n",
      "RUTW 220531C2050000  102434       0\n",
      "RUTW 220531C2055000  102434       0\n",
      "RUTW 220531C2060000  102434       0\n",
      "RUTW 220531C2065000  102434       0\n",
      "RUTW 220531C2070000  102434       0\n",
      "RUTW 220531C2075000  102434       0\n",
      "RUTW 220531C2080000  102434       0\n",
      "RUTW 220531C2085000  102434       0\n",
      "RUTW 220531C2900000  102434       0\n",
      "RUTW 220531C3000000  102434       0\n",
      "RUTW 220531C1500000  102434       0\n",
      "RUTW 220531P2320000  102434       0\n",
      "RUTW 220531P2275000  102434       0\n",
      "RUTW 220531P2280000  102434       0\n",
      "RUTW 220531P2285000  102434       0\n",
      "RUTW 220531P2290000  102434       0\n",
      "RUTW 220531P2295000  102434       0\n",
      "RUTW 220531P2300000  102434       0\n",
      "RUTW 220531P2305000  102434       0\n",
      "RUTW 220531P2310000  102434       0\n",
      "RUTW 220531P2315000  102434       0\n",
      "RUTW 220531P2325000  102434       0\n",
      "RUTW 220531P2380000  102434       0\n",
      "RUTW 220531P2330000  102434       0\n",
      "RUTW 220531P2335000  102434       0\n",
      "RUTW 220531P2340000  102434       0\n",
      "RUTW 220531P2345000  102434       0\n",
      "RUTW 220531P2350000  102434       0\n",
      "RUTW 220531P2355000  102434       0\n",
      "RUTW 220531P2360000  102434       0\n",
      "RUTW 220531P2365000  102434       0\n",
      "RUTW 220531P2370000  102434       0\n",
      "RUTW 220531P2270000  102434       0\n",
      "RUTW 220531P2265000  102434       0\n",
      "RUTW 220531P2260000  102434       0\n",
      "RUTW 220531P2255000  102434       0\n",
      "RUTW 220531P2155000  102434       0\n",
      "RUTW 220531P2160000  102434       0\n",
      "RUTW 220531P2165000  102434       0\n",
      "RUTW 220531P2170000  102434       0\n",
      "RUTW 220531P2175000  102434       0\n",
      "RUTW 220531P2180000  102434       0\n",
      "RUTW 220531P2185000  102434       0\n",
      "RUTW 220531P2190000  102434       0\n",
      "RUTW 220531P2195000  102434       0\n",
      "RUTW 220531P2205000  102434       0\n",
      "RUTW 220531P2210000  102434       0\n",
      "RUTW 220531P2215000  102434       0\n",
      "RUTW 220531P2220000  102434       0\n",
      "RUTW 220531P2225000  102434       0\n",
      "RUTW 220531P2230000  102434       0\n",
      "RUTW 220531P2235000  102434       0\n",
      "RUTW 220531P2240000  102434       0\n",
      "RUTW 220531P2245000  102434       0\n",
      "RUTW 220531P2250000  102434       0\n",
      "RUTW 220531P2375000  102434       0\n",
      "RUTW 220531P2385000  102434       0\n",
      "RUTW 220531C3050000  102434       0\n",
      "RUTW 220531P2555000  102434       0\n",
      "RUTW 220531P2510000  102434       0\n",
      "RUTW 220531P2515000  102434       0\n",
      "RUTW 220531P2520000  102434       0\n",
      "RUTW 220531P2525000  102434       0\n",
      "RUTW 220531P2530000  102434       0\n",
      "RUTW 220531P2535000  102434       0\n",
      "RUTW 220531P2540000  102434       0\n",
      "RUTW 220531P2545000  102434       0\n",
      "RUTW 220531P2550000  102434       0\n",
      "RUTW 220531P2560000  102434       0\n",
      "RUTW 220531P2390000  102434       0\n",
      "RUTW 220531P2565000  102434       0\n",
      "RUTW 220531P2570000  102434       0\n",
      "RUTW 220531P2575000  102434       0\n",
      "RUTW 220531P2580000  102434       0\n",
      "RUTW 220531P2585000  102434       0\n",
      "RUTW 220531P2590000  102434       0\n",
      "RUTW 220531P2595000  102434       0\n",
      "RUTW 220531P2600000  102434       0\n",
      "RUTW 220531P2605000  102434       0\n",
      "RUTW 220531P2505000  102434       0\n",
      "RUTW 220531P2500000  102434       0\n",
      "RUTW 220531P2495000  102434       0\n",
      "RUTW 220531P2490000  102434       0\n",
      "RUTW 220531P2395000  102434       0\n",
      "RUTW 220531P2400000  102434       0\n",
      "RUTW 220531P2405000  102434       0\n",
      "RUTW 220531P2410000  102434       0\n",
      "RUTW 220531P2415000  102434       0\n",
      "RUTW 220531P2420000  102434       0\n",
      "RUTW 220531P2425000  102434       0\n",
      "RUTW 220531P2430000  102434       0\n",
      "RUTW 220531P2435000  102434       0\n",
      "RUTW 220531P2440000  102434       0\n",
      "RUTW 220531P2445000  102434       0\n",
      "RUTW 220531P2450000  102434       0\n",
      "RUTW 220531P2455000  102434       0\n",
      "RUTW 220531P2460000  102434       0\n",
      "RUTW 220531P2465000  102434       0\n",
      "RUTW 220531P2470000  102434       0\n",
      "RUTW 220531P2475000  102434       0\n",
      "RUTW 220531P2480000  102434       0\n",
      "RUTW 220531P2485000  102434       0\n",
      "RUTW 220531P2150000  102434       0\n",
      "RUTW 220531P2145000  102434       0\n",
      "RUTW 220531P2140000  102434       0\n",
      "RUTW 220531P1850000  102434       0\n",
      "RUTW 220531P1805000  102434       0\n",
      "RUTW 220531P1810000  102434       0\n",
      "RUTW 220531P1815000  102434       0\n",
      "RUTW 220531P1820000  102434       0\n",
      "RUTW 220531P1825000  102434       0\n",
      "RUTW 220531P1830000  102434       0\n",
      "RUTW 220531P1835000  102434       0\n",
      "RUTW 220531P1840000  102434       0\n",
      "RUTW 220531P1845000  102434       0\n",
      "RUTW 220531P1855000  102434       0\n",
      "RUTW 220531P2135000  102434       0\n",
      "RUTW 220531P1860000  102434       0\n",
      "RUTW 220531P1865000  102434       0\n",
      "RUTW 220531P1870000  102434       0\n",
      "RUTW 220531P1875000  102434       0\n",
      "RUTW 220531P1880000  102434       0\n",
      "RUTW 220531P1885000  102434       0\n",
      "RUTW 220531P1890000  102434       0\n",
      "RUTW 220531P1895000  102434       0\n",
      "RUTW 220531P1900000  102434       0\n",
      "RUTW 220531P1800000  102434       0\n",
      "RUTW 220531P1795000  102434       0\n",
      "RUTW 220531P1790000  102434       0\n",
      "RUTW 220531P1785000  102434       0\n",
      "RUTW 220531C3100000  102434       0\n",
      "RUTW 220531C3150000  102434       0\n",
      "RUTW 220531C3200000  102434       0\n",
      "RUTW 220531C3250000  102434       0\n",
      "RUTW 220531C3300000  102434       0\n",
      "RUTW 220531P1150000  102434       0\n",
      "RUTW 220531P1200000  102434       0\n",
      "RUTW 220531P1250000  102434       0\n",
      "RUTW 220531P1300000  102434       0\n",
      "RUTW 220531P1350000  102434       0\n",
      "RUTW 220531P1400000  102434       0\n",
      "RUTW 220531P1450000  102434       0\n",
      "RUTW 220531P1500000  102434       0\n",
      "RUTW 220531P1550000  102434       0\n",
      "RUTW 220531P1600000  102434       0\n",
      "RUTW 220531P1650000  102434       0\n",
      "RUTW 220531P1700000  102434       0\n",
      "RUTW 220531P1750000  102434       0\n",
      "RUTW 220531P1780000  102434       0\n",
      "RUTW 220531P1905000  102434       0\n",
      "RUTW 220531P1910000  102434       0\n",
      "RUTW 220531P1915000  102434       0\n",
      "RUTW 220531P2030000  102434       0\n",
      "RUTW 220531P2040000  102434       0\n",
      "RUTW 220531P2045000  102434       0\n",
      "RUTW 220531P2050000  102434       0\n",
      "RUTW 220531P2055000  102434       0\n",
      "RUTW 220531P2060000  102434       0\n",
      "RUTW 220531P2065000  102434       0\n",
      "RUTW 220531P2070000  102434       0\n",
      "RUTW 220531P2075000  102434       0\n",
      "RUTW 220531P2080000  102434       0\n",
      "RUTW 220531P2085000  102434       0\n",
      "RUTW 220531P2090000  102434       0\n",
      "RUTW 220531P2095000  102434       0\n",
      "RUTW 220531P2100000  102434       0\n",
      "RUTW 220531P2105000  102434       0\n",
      "RUTW 220531P2110000  102434       0\n",
      "RUTW 220531P2115000  102434       0\n",
      "RUTW 220531P2120000  102434       0\n",
      "RUTW 220531P2125000  102434       0\n",
      "RUTW 220531P2130000  102434       0\n",
      "RUTW 220531P2035000  102434       0\n",
      "RUTW 220531P2025000  102434       0\n",
      "RUTW 220531P1920000  102434       0\n",
      "RUTW 220531P2020000  102434       0\n",
      "RUTW 220531P1925000  102434       0\n",
      "RUTW 220531P1930000  102434       0\n",
      "RUTW 220531P1935000  102434       0\n",
      "RUTW 220531P1940000  102434       0\n",
      "RUTW 220531P1945000  102434       0\n",
      "RUTW 220531P1950000  102434       0\n",
      "RUTW 220531P1955000  102434       0\n",
      "RUTW 220531P1960000  102434       0\n",
      "RUTW 220531P1965000  102434       0\n",
      "RUTW 220531P1970000  102434       0\n",
      "RUTW 220531P1975000  102434       0\n",
      "RUTW 220531P1980000  102434       0\n",
      "RUTW 220531P1985000  102434       0\n",
      "RUTW 220531P1990000  102434       0\n",
      "RUTW 220531P1995000  102434       0\n",
      "RUTW 220531P2000000  102434       0\n",
      "RUTW 220531P2005000  102434       0\n",
      "RUTW 220531P2010000  102434       0\n",
      "RUTW 220531P2015000  102434       0\n",
      "RUTW 220531C1550000  102434       0\n",
      "RUTW 220531C1450000  102434       0\n",
      "RUTW 220128P2760000  102434       0\n",
      "RUTW 220331P2750000  102434       0\n",
      "RUTW 220331P2640000  102434       0\n",
      "RUTW 220331P2650000  102434       0\n",
      "RUTW 220331P2660000  102434       0\n",
      "RUTW 220331P2670000  102434       0\n",
      "RUTW 220331P2680000  102434       0\n",
      "RUTW 220331P2690000  102434       0\n",
      "RUTW 220331P2700000  102434       0\n",
      "RUTW 220331P2710000  102434       0\n",
      "RUTW 220331P2720000  102434       0\n",
      "RUTW 220331P2800000  102434       0\n",
      "RUTW 220331P3350000  102434       0\n",
      "RUTW 220331P2850000  102434       0\n",
      "RUTW 220331P2900000  102434       0\n",
      "RUTW 220331P2950000  102434       0\n",
      "RUTW 220331P3000000  102434       0\n",
      "RUTW 220331P3050000  102434       0\n",
      "RUTW 220331P3100000  102434       0\n",
      "RUTW 220331P3150000  102434       0\n",
      "RUTW 220331P3200000  102434       0\n",
      "RUTW 220331P3250000  102434       0\n",
      "RUTW 220331P2630000  102434       0\n",
      "RUTW 220331P2620000  102434       0\n",
      "RUTW 220331P2610000  102434       0\n",
      "RUTW 220331P2600000  102434       0\n",
      "RUTW 220331P2410000  102434       0\n",
      "RUTW 220331P2420000  102434       0\n",
      "RUTW 220331P2430000  102434       0\n",
      "RUTW 220331P2440000  102434       0\n",
      "RUTW 220331P2450000  102434       0\n",
      "RUTW 220331P2460000  102434       0\n",
      "RUTW 220331P2470000  102434       0\n",
      "RUTW 220331P2480000  102434       0\n",
      "RUTW 220331P2490000  102434       0\n",
      "RUTW 220331P2500000  102434       0\n",
      "RUTW 220331P2510000  102434       0\n",
      "RUTW 220331P2520000  102434       0\n",
      "RUTW 220331P2530000  102434       0\n",
      "RUTW 220331P2540000  102434       0\n",
      "RUTW 220331P2550000  102434       0\n",
      "RUTW 220331P2560000  102434       0\n",
      "RUTW 220331P2570000  102434       0\n",
      "RUTW 220331P2580000  102434       0\n",
      "RUTW 220331P2590000  102434       0\n",
      "RUTW 220331P3300000  102434       0\n",
      "RUTW 220331P3400000  102434       0\n",
      "RUTW 220429C2180000  102434       0\n",
      "RUTW 220429C2060000  102434       0\n",
      "RUTW 220429C1970000  102434       0\n",
      "RUTW 220429C1980000  102434       0\n",
      "RUTW 220429C1990000  102434       0\n",
      "RUTW 220429C2000000  102434       0\n",
      "RUTW 220429C2010000  102434       0\n",
      "RUTW 220429C2020000  102434       0\n",
      "RUTW 220429C2030000  102434       0\n",
      "RUTW 220429C2040000  102434       0\n",
      "RUTW 220429C2050000  102434       0\n",
      "RUTW 220429C2070000  102434       0\n",
      "RUTW 220429C1200000  102434       0\n",
      "RUTW 220429C2080000  102434       0\n",
      "RUTW 220429C2090000  102434       0\n",
      "RUTW 220429C2100000  102434       0\n",
      "RUTW 220429C2110000  102434       0\n",
      "RUTW 220429C2120000  102434       0\n",
      "RUTW 220429C2130000  102434       0\n",
      "RUTW 220429C2140000  102434       0\n",
      "RUTW 220429C2150000  102434       0\n",
      "RUTW 220429C2160000  102434       0\n",
      "RUTW 220429C1960000  102434       0\n",
      "RUTW 220429C1950000  102434       0\n",
      "RUTW 220429C1930000  102434       0\n",
      "RUTW 220429C1920000  102434       0\n",
      "RUTW 220429C1250000  102434       0\n",
      "RUTW 220429C1300000  102434       0\n",
      "RUTW 220429C1350000  102434       0\n",
      "RUTW 220429C1400000  102434       0\n",
      "RUTW 220429C1450000  102434       0\n",
      "RUTW 220429C1500000  102434       0\n",
      "RUTW 220429C1550000  102434       0\n",
      "RUTW 220429C1600000  102434       0\n",
      "RUTW 220429C1650000  102434       0\n",
      "RUTW 220429C1700000  102434       0\n",
      "RUTW 220429C1750000  102434       0\n",
      "RUTW 220429C1800000  102434       0\n",
      "RUTW 220429C1850000  102434       0\n",
      "RUTW 220429C1860000  102434       0\n",
      "RUTW 220429C1870000  102434       0\n",
      "RUTW 220429C1880000  102434       0\n",
      "RUTW 220429C1890000  102434       0\n",
      "RUTW 220429C1900000  102434       0\n",
      "RUTW 220429C1910000  102434       0\n",
      "RUTW 220331P2400000  102434       0\n",
      "RUTW 220331P2390000  102434       0\n",
      "RUTW 220331P2380000  102434       0\n",
      "RUTW 220331C3350000  102434       0\n",
      "RUTW 220331C2900000  102434       0\n",
      "RUTW 220331C2950000  102434       0\n",
      "RUTW 220331C3000000  102434       0\n",
      "RUTW 220331C3050000  102434       0\n",
      "RUTW 220331C3100000  102434       0\n",
      "RUTW 220331C3150000  102434       0\n",
      "RUTW 220331C3200000  102434       0\n",
      "RUTW 220331C3250000  102434       0\n",
      "RUTW 220331C3300000  102434       0\n",
      "RUTW 220331C3400000  102434       0\n",
      "RUTW 220331P2370000  102434       0\n",
      "RUTW 220331P1100000  102434       0\n",
      "RUTW 220331P1150000  102434       0\n",
      "RUTW 220331P1200000  102434       0\n",
      "RUTW 220331P1250000  102434       0\n",
      "RUTW 220331P1300000  102434       0\n",
      "RUTW 220331P1400000  102434       0\n",
      "RUTW 220331P1450000  102434       0\n",
      "RUTW 220331P1550000  102434       0\n",
      "RUTW 220331P1600000  102434       0\n",
      "RUTW 220331C2850000  102434       0\n",
      "RUTW 220331C2800000  102434       0\n",
      "RUTW 220331C2750000  102434       0\n",
      "RUTW 220331C2720000  102434       0\n",
      "RUTW 220331C2520000  102434       0\n",
      "RUTW 220331C2530000  102434       0\n",
      "RUTW 220331C2540000  102434       0\n",
      "RUTW 220331C2550000  102434       0\n",
      "RUTW 220331C2560000  102434       0\n",
      "RUTW 220331C2570000  102434       0\n",
      "RUTW 220331C2580000  102434       0\n",
      "RUTW 220331C2590000  102434       0\n",
      "RUTW 220331C2610000  102434       0\n",
      "RUTW 220331C2620000  102434       0\n",
      "RUTW 220331C2630000  102434       0\n",
      "RUTW 220331C2640000  102434       0\n",
      "RUTW 220331C2650000  102434       0\n",
      "RUTW 220331C2660000  102434       0\n",
      "RUTW 220331C2670000  102434       0\n",
      "RUTW 220331C2680000  102434       0\n",
      "RUTW 220331C2690000  102434       0\n",
      "RUTW 220331C2700000  102434       0\n",
      "RUTW 220331C2710000  102434       0\n",
      "RUTW 220331P1650000  102434       0\n",
      "RUTW 220331P1800000  102434       0\n",
      "RUTW 220331P1810000  102434       0\n",
      "RUTW 220331P2130000  102434       0\n",
      "RUTW 220331P2160000  102434       0\n",
      "RUTW 220331P2180000  102434       0\n",
      "RUTW 220331P2190000  102434       0\n",
      "RUTW 220331P2200000  102434       0\n",
      "RUTW 220331P2210000  102434       0\n",
      "RUTW 220331P2220000  102434       0\n",
      "RUTW 220331P2230000  102434       0\n",
      "RUTW 220331P2240000  102434       0\n",
      "RUTW 220331P2250000  102434       0\n",
      "RUTW 220331P2270000  102434       0\n",
      "RUTW 220331P2280000  102434       0\n",
      "RUTW 220331P2290000  102434       0\n",
      "RUTW 220331P2300000  102434       0\n",
      "RUTW 220331P2310000  102434       0\n",
      "RUTW 220331P2320000  102434       0\n",
      "RUTW 220331P2330000  102434       0\n",
      "RUTW 220331P2340000  102434       0\n",
      "RUTW 220331P2350000  102434       0\n",
      "RUTW 220331P2360000  102434       0\n",
      "RUTW 220331P2140000  102434       0\n",
      "RUTW 220331P2120000  102434       0\n",
      "RUTW 220331P1820000  102434       0\n",
      "RUTW 220331P2110000  102434       0\n",
      "RUTW 220331P1830000  102434       0\n",
      "RUTW 220331P1840000  102434       0\n",
      "RUTW 220331P1850000  102434       0\n",
      "RUTW 220331P1860000  102434       0\n",
      "RUTW 220331P1870000  102434       0\n",
      "RUTW 220331P1880000  102434       0\n",
      "RUTW 220331P1890000  102434       0\n",
      "RUTW 220331P1900000  102434       0\n",
      "RUTW 220331P1910000  102434       0\n",
      "RUTW 220331P1920000  102434       0\n",
      "RUTW 220331P1950000  102434       0\n",
      "RUTW 220331P1960000  102434       0\n",
      "RUTW 220331P1970000  102434       0\n",
      "RUTW 220331P1980000  102434       0\n",
      "RUTW 220331P2000000  102434       0\n",
      "RUTW 220331P2030000  102434       0\n",
      "RUTW 220331P2050000  102434       0\n",
      "RUTW 220331P2080000  102434       0\n",
      "RUTW 220331P2090000  102434       0\n",
      "RUTW 220429C2170000  102434       0\n",
      "RUTW 220429C2190000  102434       0\n",
      "RUTW 220531C1400000  102434       0\n",
      "RUTW 220429P2380000  102434       0\n",
      "RUTW 220429P2290000  102434       0\n",
      "RUTW 220429P2300000  102434       0\n",
      "RUTW 220429P2310000  102434       0\n",
      "RUTW 220429P2320000  102434       0\n",
      "RUTW 220429P2330000  102434       0\n",
      "RUTW 220429P2340000  102434       0\n",
      "RUTW 220429P2350000  102434       0\n",
      "RUTW 220429P2360000  102434       0\n",
      "RUTW 220429P2370000  102434       0\n",
      "RUTW 220429P2390000  102434       0\n",
      "RUTW 220429P2500000  102434       0\n",
      "RUTW 220429P2400000  102434       0\n",
      "RUTW 220429P2410000  102434       0\n",
      "RUTW 220429P2420000  102434       0\n",
      "RUTW 220429P2430000  102434       0\n",
      "RUTW 220429P2440000  102434       0\n",
      "RUTW 220429P2450000  102434       0\n",
      "RUTW 220429P2460000  102434       0\n",
      "RUTW 220429P2470000  102434       0\n",
      "RUTW 220429P2480000  102434       0\n",
      "RUTW 220429P2280000  102434       0\n",
      "RUTW 220429P2270000  102434       0\n",
      "RUTW 220429P2250000  102434       0\n",
      "RUTW 220429P2240000  102434       0\n",
      "RUTW 220429P1990000  102434       0\n",
      "RUTW 220429P2020000  102434       0\n",
      "RUTW 220429P2030000  102434       0\n",
      "RUTW 220429P2040000  102434       0\n",
      "RUTW 220429P2050000  102434       0\n",
      "RUTW 220429P2060000  102434       0\n",
      "RUTW 220429P2070000  102434       0\n",
      "RUTW 220429P2080000  102434       0\n",
      "RUTW 220429P2090000  102434       0\n",
      "RUTW 220429P2110000  102434       0\n",
      "RUTW 220429P2120000  102434       0\n",
      "RUTW 220429P2130000  102434       0\n",
      "RUTW 220429P2140000  102434       0\n",
      "RUTW 220429P2160000  102434       0\n",
      "RUTW 220429P2170000  102434       0\n",
      "RUTW 220429P2180000  102434       0\n",
      "RUTW 220429P2210000  102434       0\n",
      "RUTW 220429P2220000  102434       0\n",
      "RUTW 220429P2230000  102434       0\n",
      "RUTW 220429P2490000  102434       0\n",
      "RUTW 220429P2510000  102434       0\n",
      "RUTW 220429C2200000  102434       0\n",
      "RUTW 220429P3200000  102434       0\n",
      "RUTW 220429P2760000  102434       0\n",
      "RUTW 220429P2800000  102434       0\n",
      "RUTW 220429P2850000  102434       0\n",
      "RUTW 220429P2900000  102434       0\n",
      "RUTW 220429P2950000  102434       0\n",
      "RUTW 220429P3000000  102434       0\n",
      "RUTW 220429P3050000  102434       0\n",
      "RUTW 220429P3100000  102434       0\n",
      "RUTW 220429P3150000  102434       0\n",
      "RUTW 220429P3250000  102434       0\n",
      "RUTW 220429P2520000  102434       0\n",
      "RUTW 220429P3300000  102434       0\n",
      "RUTW 220429P3350000  102434       0\n",
      "RUTW 220429P3400000  102434       0\n",
      "RUTW 220429P3450000  102434       0\n",
      "RUTW 220531C1150000  102434       0\n",
      "RUTW 220531C1200000  102434       0\n",
      "RUTW 220531C1250000  102434       0\n",
      "RUTW 220531C1300000  102434       0\n",
      "RUTW 220531C1350000  102434       0\n",
      "RUTW 220429P2750000  102434       0\n",
      "RUTW 220429P2740000  102434       0\n",
      "RUTW 220429P2730000  102434       0\n",
      "RUTW 220429P2720000  102434       0\n",
      "RUTW 220429P2530000  102434       0\n",
      "RUTW 220429P2540000  102434       0\n",
      "RUTW 220429P2550000  102434       0\n",
      "RUTW 220429P2560000  102434       0\n",
      "RUTW 220429P2570000  102434       0\n",
      "RUTW 220429P2580000  102434       0\n",
      "RUTW 220429P2590000  102434       0\n",
      "RUTW 220429P2600000  102434       0\n",
      "RUTW 220429P2610000  102434       0\n",
      "RUTW 220429P2620000  102434       0\n",
      "RUTW 220429P2630000  102434       0\n",
      "RUTW 220429P2640000  102434       0\n",
      "RUTW 220429P2650000  102434       0\n",
      "RUTW 220429P2660000  102434       0\n",
      "RUTW 220429P2670000  102434       0\n",
      "RUTW 220429P2680000  102434       0\n",
      "RUTW 220429P2690000  102434       0\n",
      "RUTW 220429P2700000  102434       0\n",
      "RUTW 220429P2710000  102434       0\n",
      "RUTW 220429P1980000  102434       0\n",
      "RUTW 220429P1970000  102434       0\n",
      "RUTW 220429P1960000  102434       0\n",
      "RUTW 220429C2560000  102434       0\n",
      "RUTW 220429C2470000  102434       0\n",
      "RUTW 220429C2480000  102434       0\n",
      "RUTW 220429C2490000  102434       0\n",
      "RUTW 220429C2500000  102434       0\n",
      "RUTW 220429C2510000  102434       0\n",
      "RUTW 220429C2520000  102434       0\n",
      "RUTW 220429C2530000  102434       0\n",
      "RUTW 220429C2540000  102434       0\n",
      "RUTW 220429C2550000  102434       0\n",
      "RUTW 220429C2570000  102434       0\n",
      "RUTW 220429P1950000  102434       0\n",
      "RUTW 220429C2580000  102434       0\n",
      "RUTW 220429C2590000  102434       0\n",
      "RUTW 220429C2600000  102434       0\n",
      "RUTW 220429C2610000  102434       0\n",
      "RUTW 220429C2620000  102434       0\n",
      "RUTW 220429C2630000  102434       0\n",
      "RUTW 220429C2640000  102434       0\n",
      "RUTW 220429C2650000  102434       0\n",
      "RUTW 220429C2660000  102434       0\n",
      "RUTW 220429C2460000  102434       0\n",
      "RUTW 220429C2450000  102434       0\n",
      "RUTW 220429C2430000  102434       0\n",
      "RUTW 220429C2420000  102434       0\n",
      "RUTW 220429C2210000  102434       0\n",
      "RUTW 220429C2220000  102434       0\n",
      "RUTW 220429C2230000  102434       0\n",
      "RUTW 220429C2240000  102434       0\n",
      "RUTW 220429C2250000  102434       0\n",
      "RUTW 220429C2260000  102434       0\n",
      "RUTW 220429C2270000  102434       0\n",
      "RUTW 220429C2280000  102434       0\n",
      "RUTW 220429C2290000  102434       0\n",
      "RUTW 220429C2300000  102434       0\n",
      "RUTW 220429C2310000  102434       0\n",
      "RUTW 220429C2320000  102434       0\n",
      "RUTW 220429C2330000  102434       0\n",
      "RUTW 220429C2360000  102434       0\n",
      "RUTW 220429C2370000  102434       0\n",
      "RUTW 220429C2380000  102434       0\n",
      "RUTW 220429C2390000  102434       0\n",
      "RUTW 220429C2400000  102434       0\n",
      "RUTW 220429C2410000  102434       0\n",
      "RUTW 220429C2670000  102434       0\n",
      "RUTW 220429C2680000  102434       0\n",
      "RUTW 220429C2690000  102434       0\n",
      "RUTW 220429P1250000  102434       0\n",
      "RUTW 220429P1350000  102434       0\n",
      "RUTW 220429P1400000  102434       0\n",
      "RUTW 220429P1450000  102434       0\n",
      "RUTW 220429P1550000  102434       0\n",
      "RUTW 220429P1600000  102434       0\n",
      "RUTW 220429P1650000  102434       0\n",
      "RUTW 220429P1700000  102434       0\n",
      "RUTW 220429P1750000  102434       0\n",
      "RUTW 220429P1800000  102434       0\n",
      "RUTW 220429P1850000  102434       0\n",
      "RUTW 220429P1860000  102434       0\n",
      "RUTW 220429P1870000  102434       0\n",
      "RUTW 220429P1880000  102434       0\n",
      "RUTW 220429P1890000  102434       0\n",
      "RUTW 220429P1900000  102434       0\n",
      "RUTW 220429P1910000  102434       0\n",
      "RUTW 220429P1920000  102434       0\n",
      "RUTW 220429P1930000  102434       0\n",
      "RUTW 220429P1940000  102434       0\n",
      "RUTW 220429P1300000  102434       0\n",
      "RUTW 220429P1200000  102434       0\n",
      "RUTW 220429C2700000  102434       0\n",
      "RUTW 220429C3450000  102434       0\n",
      "RUTW 220429C2710000  102434       0\n",
      "RUTW 220429C2720000  102434       0\n",
      "RUTW 220429C2730000  102434       0\n",
      "RUTW 220429C2740000  102434       0\n",
      "RUTW 220429C2750000  102434       0\n",
      "RUTW 220429C2760000  102434       0\n",
      "RUTW 220429C2800000  102434       0\n",
      "RUTW 220429C2850000  102434       0\n",
      "RUTW 220429C2900000  102434       0\n",
      "RUTW 220429C2950000  102434       0\n",
      "RUTW 220429C3000000  102434       0\n",
      "RUTW 220429C3050000  102434       0\n",
      "RUTW 220429C3100000  102434       0\n",
      "RUTW 220429C3150000  102434       0\n",
      "RUTW 220429C3200000  102434       0\n",
      "RUTW 220429C3250000  102434       0\n",
      "RUTW 220429C3300000  102434       0\n",
      "RUTW 220429C3350000  102434       0\n",
      "RUTW 220429C3400000  102434       0\n",
      "RUTW 220531P2610000  102434       0\n",
      "RUTW 220531P2615000  102434       0\n",
      "RUTW 220531P2620000  102434       0\n",
      "RUTW 220930P3150000  102434       0\n",
      "RUTW 220930P2700000  102434       0\n",
      "RUTW 220930P2750000  102434       0\n",
      "RUTW 220930P2800000  102434       0\n",
      "RUTW 220930P2850000  102434       0\n",
      "RUTW 220930P2900000  102434       0\n",
      "RUTW 220930P2950000  102434       0\n",
      "RUTW 220930P3000000  102434       0\n",
      "RUTW 220930P3050000  102434       0\n",
      "RUTW 220930P3100000  102434       0\n",
      "RUTW 220930P3200000  102434       0\n",
      "RUTW 221230C1400000  102434       0\n",
      "RUTW 220930P3250000  102434       0\n",
      "RUTW 220930P3300000  102434       0\n",
      "RUTW 220930P3350000  102434       0\n",
      "RUTW 220930P3400000  102434       0\n",
      "RUTW 221230C1100000  102434       0\n",
      "RUTW 221230C1150000  102434       0\n",
      "RUTW 221230C1200000  102434       0\n",
      "RUTW 221230C1250000  102434       0\n",
      "RUTW 221230C1300000  102434       0\n",
      "RUTW 220930P2650000  102434       0\n",
      "RUTW 220930P2640000  102434       0\n",
      "RUTW 220930P2630000  102434       0\n",
      "RUTW 220930P2620000  102434       0\n",
      "RUTW 220930P2430000  102434       0\n",
      "RUTW 220930P2440000  102434       0\n",
      "RUTW 220930P2450000  102434       0\n",
      "RUTW 220930P2460000  102434       0\n",
      "RUTW 220930P2470000  102434       0\n",
      "RUTW 220930P2480000  102434       0\n",
      "RUTW 220930P2490000  102434       0\n",
      "RUTW 220930P2500000  102434       0\n",
      "RUTW 220930P2510000  102434       0\n",
      "RUTW 220930P2520000  102434       0\n",
      "RUTW 220930P2530000  102434       0\n",
      "RUTW 220930P2540000  102434       0\n",
      "RUTW 220930P2550000  102434       0\n",
      "RUTW 220930P2560000  102434       0\n",
      "RUTW 220930P2570000  102434       0\n",
      "RUTW 220930P2580000  102434       0\n",
      "RUTW 220930P2590000  102434       0\n",
      "RUTW 220930P2600000  102434       0\n",
      "RUTW 220930P2610000  102434       0\n",
      "RUTW 221230C1350000  102434       0\n",
      "RUTW 221230C1450000  102434       0\n",
      "RUTW 221230C2190000  102434       0\n",
      "RUTW 221230C2070000  102434       0\n",
      "RUTW 221230C1980000  102434       0\n",
      "RUTW 221230C1990000  102434       0\n",
      "RUTW 221230C2000000  102434       0\n",
      "RUTW 221230C2010000  102434       0\n",
      "RUTW 221230C2020000  102434       0\n",
      "RUTW 221230C2030000  102434       0\n",
      "RUTW 221230C2040000  102434       0\n",
      "RUTW 221230C2050000  102434       0\n",
      "RUTW 221230C2060000  102434       0\n",
      "RUTW 221230C2080000  102434       0\n",
      "RUTW 221230C1500000  102434       0\n",
      "RUTW 221230C2090000  102434       0\n",
      "RUTW 221230C2100000  102434       0\n",
      "RUTW 221230C2110000  102434       0\n",
      "RUTW 221230C2120000  102434       0\n",
      "RUTW 221230C2130000  102434       0\n",
      "RUTW 221230C2140000  102434       0\n",
      "RUTW 221230C2150000  102434       0\n",
      "RUTW 221230C2160000  102434       0\n",
      "RUTW 221230C2170000  102434       0\n",
      "RUTW 221230C1970000  102434       0\n",
      "RUTW 221230C1960000  102434       0\n",
      "RUTW 221230C1950000  102434       0\n",
      "RUTW 221230C1940000  102434       0\n",
      "RUTW 221230C1550000  102434       0\n",
      "RUTW 221230C1600000  102434       0\n",
      "RUTW 221230C1650000  102434       0\n",
      "RUTW 221230C1700000  102434       0\n",
      "RUTW 221230C1750000  102434       0\n",
      "RUTW 221230C1800000  102434       0\n",
      "RUTW 221230C1810000  102434       0\n",
      "RUTW 221230C1820000  102434       0\n",
      "RUTW 221230C1830000  102434       0\n",
      "RUTW 221230C1840000  102434       0\n",
      "RUTW 221230C1850000  102434       0\n",
      "RUTW 221230C1860000  102434       0\n",
      "RUTW 221230C1870000  102434       0\n",
      "RUTW 221230C1880000  102434       0\n",
      "RUTW 221230C1890000  102434       0\n",
      "RUTW 221230C1900000  102434       0\n",
      "RUTW 221230C1910000  102434       0\n",
      "RUTW 221230C1920000  102434       0\n",
      "RUTW 221230C1930000  102434       0\n",
      "RUTW 220930P2420000  102434       0\n",
      "RUTW 220930P2410000  102434       0\n",
      "RUTW 220930P2400000  102434       0\n",
      "RUTW 220930P1820000  102434       0\n",
      "RUTW 220930P1650000  102434       0\n",
      "RUTW 220930P1700000  102434       0\n",
      "RUTW 220930P1750000  102434       0\n",
      "RUTW 220930P1760000  102434       0\n",
      "RUTW 220930P1770000  102434       0\n",
      "RUTW 220930P1780000  102434       0\n",
      "RUTW 220930P1790000  102434       0\n",
      "RUTW 220930P1800000  102434       0\n",
      "RUTW 220930P1810000  102434       0\n",
      "RUTW 220930P1830000  102434       0\n",
      "RUTW 220930P2390000  102434       0\n",
      "RUTW 220930P1840000  102434       0\n",
      "RUTW 220930P1850000  102434       0\n",
      "RUTW 220930P1860000  102434       0\n",
      "RUTW 220930P1870000  102434       0\n",
      "RUTW 220930P1880000  102434       0\n",
      "RUTW 220930P1890000  102434       0\n",
      "RUTW 220930P1900000  102434       0\n",
      "RUTW 220930P1910000  102434       0\n",
      "RUTW 220930P1920000  102434       0\n",
      "RUTW 220930P1600000  102434       0\n",
      "RUTW 220930P1550000  102434       0\n",
      "RUTW 220930P1500000  102434       0\n",
      "RUTW 220930P1450000  102434       0\n",
      "RUTW 220930C2850000  102434       0\n",
      "RUTW 220930C2900000  102434       0\n",
      "RUTW 220930C2950000  102434       0\n",
      "RUTW 220930C3000000  102434       0\n",
      "RUTW 220930C3050000  102434       0\n",
      "RUTW 220930C3100000  102434       0\n",
      "RUTW 220930C3150000  102434       0\n",
      "RUTW 220930C3200000  102434       0\n",
      "RUTW 220930C3250000  102434       0\n",
      "RUTW 220930C3300000  102434       0\n",
      "RUTW 220930C3350000  102434       0\n",
      "RUTW 220930C3400000  102434       0\n",
      "RUTW 220930P1100000  102434       0\n",
      "RUTW 220930P1150000  102434       0\n",
      "RUTW 220930P1200000  102434       0\n",
      "RUTW 220930P1250000  102434       0\n",
      "RUTW 220930P1300000  102434       0\n",
      "RUTW 220930P1350000  102434       0\n",
      "RUTW 220930P1400000  102434       0\n",
      "RUTW 220930P1930000  102434       0\n",
      "RUTW 220930P1940000  102434       0\n",
      "RUTW 220930P1950000  102434       0\n",
      "RUTW 220930P2180000  102434       0\n",
      "RUTW 220930P2200000  102434       0\n",
      "RUTW 220930P2210000  102434       0\n",
      "RUTW 220930P2220000  102434       0\n",
      "RUTW 220930P2230000  102434       0\n",
      "RUTW 220930P2240000  102434       0\n",
      "RUTW 220930P2250000  102434       0\n",
      "RUTW 220930P2260000  102434       0\n",
      "RUTW 220930P2270000  102434       0\n",
      "RUTW 220930P2280000  102434       0\n",
      "RUTW 220930P2290000  102434       0\n",
      "RUTW 220930P2300000  102434       0\n",
      "RUTW 220930P2310000  102434       0\n",
      "RUTW 220930P2320000  102434       0\n",
      "RUTW 220930P2330000  102434       0\n",
      "RUTW 220930P2340000  102434       0\n",
      "RUTW 220930P2350000  102434       0\n",
      "RUTW 220930P2360000  102434       0\n",
      "RUTW 220930P2370000  102434       0\n",
      "RUTW 220930P2380000  102434       0\n",
      "RUTW 220930P2190000  102434       0\n",
      "RUTW 220930P2170000  102434       0\n",
      "RUTW 220930P1960000  102434       0\n",
      "RUTW 220930P2160000  102434       0\n",
      "RUTW 220930P1970000  102434       0\n",
      "RUTW 220930P1980000  102434       0\n",
      "RUTW 220930P1990000  102434       0\n",
      "RUTW 220930P2000000  102434       0\n",
      "RUTW 220930P2010000  102434       0\n",
      "RUTW 220930P2020000  102434       0\n",
      "RUTW 220930P2030000  102434       0\n",
      "RUTW 220930P2040000  102434       0\n",
      "RUTW 220930P2050000  102434       0\n",
      "RUTW 220930P2060000  102434       0\n",
      "RUTW 220930P2070000  102434       0\n",
      "RUTW 220930P2080000  102434       0\n",
      "RUTW 220930P2090000  102434       0\n",
      "RUTW 220930P2100000  102434       0\n",
      "RUTW 220930P2110000  102434       0\n",
      "RUTW 220930P2120000  102434       0\n",
      "RUTW 220930P2130000  102434       0\n",
      "RUTW 220930P2140000  102434       0\n",
      "RUTW 220930P2150000  102434       0\n",
      "RUTW 221230C2180000  102434       0\n",
      "RUTW 221230C2200000  102434       0\n",
      "RUTW 220531P2625000  102434       0\n",
      "RUTW 221230P2270000  102434       0\n",
      "RUTW 221230P2180000  102434       0\n",
      "RUTW 221230P2190000  102434       0\n",
      "RUTW 221230P2200000  102434       0\n",
      "RUTW 221230P2210000  102434       0\n",
      "RUTW 221230P2220000  102434       0\n",
      "RUTW 221230P2230000  102434       0\n",
      "RUTW 221230P2240000  102434       0\n",
      "RUTW 221230P2250000  102434       0\n",
      "RUTW 221230P2260000  102434       0\n",
      "RUTW 221230P2280000  102434       0\n",
      "RUTW 221230P2390000  102434       0\n",
      "RUTW 221230P2290000  102434       0\n",
      "RUTW 221230P2300000  102434       0\n",
      "RUTW 221230P2310000  102434       0\n",
      "RUTW 221230P2320000  102434       0\n",
      "RUTW 221230P2330000  102434       0\n",
      "RUTW 221230P2340000  102434       0\n",
      "RUTW 221230P2350000  102434       0\n",
      "RUTW 221230P2360000  102434       0\n",
      "RUTW 221230P2370000  102434       0\n",
      "RUTW 221230P2170000  102434       0\n",
      "RUTW 221230P2160000  102434       0\n",
      "RUTW 221230P2150000  102434       0\n",
      "RUTW 221230P2140000  102434       0\n",
      "RUTW 221230P1950000  102434       0\n",
      "RUTW 221230P1960000  102434       0\n",
      "RUTW 221230P1970000  102434       0\n",
      "RUTW 221230P1980000  102434       0\n",
      "RUTW 221230P1990000  102434       0\n",
      "RUTW 221230P2000000  102434       0\n",
      "RUTW 221230P2010000  102434       0\n",
      "RUTW 221230P2020000  102434       0\n",
      "RUTW 221230P2030000  102434       0\n",
      "RUTW 221230P2040000  102434       0\n",
      "RUTW 221230P2050000  102434       0\n",
      "RUTW 221230P2060000  102434       0\n",
      "RUTW 221230P2070000  102434       0\n",
      "RUTW 221230P2080000  102434       0\n",
      "RUTW 221230P2090000  102434       0\n",
      "RUTW 221230P2100000  102434       0\n",
      "RUTW 221230P2110000  102434       0\n",
      "RUTW 221230P2120000  102434       0\n",
      "RUTW 221230P2130000  102434       0\n",
      "RUTW 221230P2380000  102434       0\n",
      "RUTW 221230P2400000  102434       0\n",
      "RUTW 221230C2210000  102434       0\n",
      "RUTW 221230P2850000  102434       0\n",
      "RUTW 221230P2650000  102434       0\n",
      "RUTW 221230P2660000  102434       0\n",
      "RUTW 221230P2670000  102434       0\n",
      "RUTW 221230P2680000  102434       0\n",
      "RUTW 221230P2690000  102434       0\n",
      "RUTW 221230P2700000  102434       0\n",
      "RUTW 221230P2710000  102434       0\n",
      "RUTW 221230P2750000  102434       0\n",
      "RUTW 221230P2800000  102434       0\n",
      "RUTW 221230P2900000  102434       0\n",
      "RUTW 221230P2410000  102434       0\n",
      "RUTW 221230P2950000  102434       0\n",
      "RUTW 221230P3000000  102434       0\n",
      "RUTW 221230P3050000  102434       0\n",
      "RUTW 221230P3100000  102434       0\n",
      "RUTW 221230P3150000  102434       0\n",
      "RUTW 221230P3200000  102434       0\n",
      "RUTW 221230P3250000  102434       0\n",
      "RUTW 221230P3300000  102434       0\n",
      "RUTW 221230P3350000  102434       0\n",
      "RUTW 221230P2640000  102434       0\n",
      "RUTW 221230P2630000  102434       0\n",
      "RUTW 221230P2620000  102434       0\n",
      "RUTW 221230P2610000  102434       0\n",
      "RUTW 221230P2420000  102434       0\n",
      "RUTW 221230P2430000  102434       0\n",
      "RUTW 221230P2440000  102434       0\n",
      "RUTW 221230P2450000  102434       0\n",
      "RUTW 221230P2460000  102434       0\n",
      "RUTW 221230P2470000  102434       0\n",
      "RUTW 221230P2480000  102434       0\n",
      "RUTW 221230P2490000  102434       0\n",
      "RUTW 221230P2500000  102434       0\n",
      "RUTW 221230P2510000  102434       0\n",
      "RUTW 221230P2520000  102434       0\n",
      "RUTW 221230P2530000  102434       0\n",
      "RUTW 221230P2540000  102434       0\n",
      "RUTW 221230P2550000  102434       0\n",
      "RUTW 221230P2560000  102434       0\n",
      "RUTW 221230P2570000  102434       0\n",
      "RUTW 221230P2580000  102434       0\n",
      "RUTW 221230P2590000  102434       0\n",
      "RUTW 221230P2600000  102434       0\n",
      "RUTW 221230P1940000  102434       0\n",
      "RUTW 221230P1930000  102434       0\n",
      "RUTW 221230P1920000  102434       0\n",
      "RUTW 221230C2540000  102434       0\n",
      "RUTW 221230C2450000  102434       0\n",
      "RUTW 221230C2460000  102434       0\n",
      "RUTW 221230C2470000  102434       0\n",
      "RUTW 221230C2480000  102434       0\n",
      "RUTW 221230C2490000  102434       0\n",
      "RUTW 221230C2500000  102434       0\n",
      "RUTW 221230C2510000  102434       0\n",
      "RUTW 221230C2520000  102434       0\n",
      "RUTW 221230C2530000  102434       0\n",
      "RUTW 221230C2550000  102434       0\n",
      "RUTW 221230P1910000  102434       0\n",
      "RUTW 221230C2560000  102434       0\n",
      "RUTW 221230C2570000  102434       0\n",
      "RUTW 221230C2580000  102434       0\n",
      "RUTW 221230C2590000  102434       0\n",
      "RUTW 221230C2600000  102434       0\n",
      "RUTW 221230C2610000  102434       0\n",
      "RUTW 221230C2620000  102434       0\n",
      "RUTW 221230C2630000  102434       0\n",
      "RUTW 221230C2640000  102434       0\n",
      "RUTW 221230C2440000  102434       0\n",
      "RUTW 221230C2430000  102434       0\n",
      "RUTW 221230C2420000  102434       0\n",
      "RUTW 221230C2410000  102434       0\n",
      "RUTW 221230C2220000  102434       0\n",
      "RUTW 221230C2230000  102434       0\n",
      "RUTW 221230C2240000  102434       0\n",
      "RUTW 221230C2250000  102434       0\n",
      "RUTW 221230C2260000  102434       0\n",
      "RUTW 221230C2270000  102434       0\n",
      "RUTW 221230C2280000  102434       0\n",
      "RUTW 221230C2290000  102434       0\n",
      "RUTW 221230C2300000  102434       0\n",
      "RUTW 221230C2310000  102434       0\n",
      "RUTW 221230C2320000  102434       0\n",
      "RUTW 221230C2330000  102434       0\n",
      "RUTW 221230C2340000  102434       0\n",
      "RUTW 221230C2350000  102434       0\n",
      "RUTW 221230C2360000  102434       0\n",
      "RUTW 221230C2370000  102434       0\n",
      "RUTW 221230C2380000  102434       0\n",
      "RUTW 221230C2390000  102434       0\n",
      "RUTW 221230C2400000  102434       0\n",
      "RUTW 221230C2650000  102434       0\n",
      "RUTW 221230C2660000  102434       0\n",
      "RUTW 221230C2670000  102434       0\n",
      "RUTW 221230P1300000  102434       0\n",
      "RUTW 221230P1400000  102434       0\n",
      "RUTW 221230P1450000  102434       0\n",
      "RUTW 221230P1500000  102434       0\n",
      "RUTW 221230P1550000  102434       0\n",
      "RUTW 221230P1600000  102434       0\n",
      "RUTW 221230P1650000  102434       0\n",
      "RUTW 221230P1700000  102434       0\n",
      "RUTW 221230P1750000  102434       0\n",
      "RUTW 221230P1800000  102434       0\n",
      "RUTW 221230P1810000  102434       0\n",
      "RUTW 221230P1820000  102434       0\n",
      "RUTW 221230P1830000  102434       0\n",
      "RUTW 221230P1840000  102434       0\n",
      "RUTW 221230P1850000  102434       0\n",
      "RUTW 221230P1860000  102434       0\n",
      "RUTW 221230P1870000  102434       0\n",
      "RUTW 221230P1880000  102434       0\n",
      "RUTW 221230P1890000  102434       0\n",
      "RUTW 221230P1900000  102434       0\n",
      "RUTW 221230P1350000  102434       0\n",
      "RUTW 221230P1250000  102434       0\n",
      "RUTW 221230C2680000  102434       0\n",
      "RUTW 221230P1200000  102434       0\n",
      "RUTW 221230C2690000  102434       0\n",
      "RUTW 221230C2700000  102434       0\n",
      "RUTW 221230C2710000  102434       0\n",
      "RUTW 221230C2750000  102434       0\n",
      "RUTW 221230C2800000  102434       0\n",
      "RUTW 221230C2850000  102434       0\n",
      "RUTW 221230C2900000  102434       0\n",
      "RUTW 221230C2950000  102434       0\n",
      "RUTW 221230C3000000  102434       0\n",
      "RUTW 221230C3050000  102434       0\n",
      "RUTW 221230C3100000  102434       0\n",
      "RUTW 221230C3150000  102434       0\n",
      "RUTW 221230C3200000  102434       0\n",
      "RUTW 221230C3250000  102434       0\n",
      "RUTW 221230C3300000  102434       0\n",
      "RUTW 221230C3350000  102434       0\n",
      "RUTW 221230C3400000  102434       0\n",
      "RUTW 221230P1100000  102434       0\n",
      "RUTW 221230P1150000  102434       0\n",
      "RUTW 220930C2800000  102434       0\n",
      "RUTW 220930C2750000  102434       0\n",
      "RUTW 220930C2700000  102434       0\n",
      "RUTW 220630C2740000  102434       0\n",
      "RUTW 220630C2650000  102434       0\n",
      "RUTW 220630C2660000  102434       0\n",
      "RUTW 220630C2670000  102434       0\n",
      "RUTW 220630C2680000  102434       0\n",
      "RUTW 220630C2690000  102434       0\n",
      "RUTW 220630C2700000  102434       0\n",
      "RUTW 220630C2710000  102434       0\n",
      "RUTW 220630C2720000  102434       0\n",
      "RUTW 220630C2730000  102434       0\n",
      "RUTW 220630C2750000  102434       0\n",
      "RUTW 220630C3150000  102434       0\n",
      "RUTW 220630C2760000  102434       0\n",
      "RUTW 220630C2770000  102434       0\n",
      "RUTW 220630C2780000  102434       0\n",
      "RUTW 220630C2800000  102434       0\n",
      "RUTW 220630C2850000  102434       0\n",
      "RUTW 220630C2900000  102434       0\n",
      "RUTW 220630C2950000  102434       0\n",
      "RUTW 220630C3000000  102434       0\n",
      "RUTW 220630C3050000  102434       0\n",
      "RUTW 220630C2640000  102434       0\n",
      "RUTW 220630C2630000  102434       0\n",
      "RUTW 220630C2620000  102434       0\n",
      "RUTW 220630C2610000  102434       0\n",
      "RUTW 220630C2420000  102434       0\n",
      "RUTW 220630C2430000  102434       0\n",
      "RUTW 220630C2440000  102434       0\n",
      "RUTW 220630C2450000  102434       0\n",
      "RUTW 220630C2460000  102434       0\n",
      "RUTW 220630C2470000  102434       0\n",
      "RUTW 220630C2480000  102434       0\n",
      "RUTW 220630C2490000  102434       0\n",
      "RUTW 220630C2500000  102434       0\n",
      "RUTW 220630C2510000  102434       0\n",
      "RUTW 220630C2520000  102434       0\n",
      "RUTW 220630C2530000  102434       0\n",
      "RUTW 220630C2540000  102434       0\n",
      "RUTW 220630C2550000  102434       0\n",
      "RUTW 220630C2560000  102434       0\n",
      "RUTW 220630C2570000  102434       0\n",
      "RUTW 220630C2580000  102434       0\n",
      "RUTW 220630C2590000  102434       0\n",
      "RUTW 220630C2600000  102434       0\n",
      "RUTW 220630C3100000  102434       0\n",
      "RUTW 220630C3200000  102434       0\n",
      "RUTW 220930C2650000  102434       0\n",
      "RUTW 220630P1990000  102434       0\n",
      "RUTW 220630P1900000  102434       0\n",
      "RUTW 220630P1910000  102434       0\n",
      "RUTW 220630P1920000  102434       0\n",
      "RUTW 220630P1930000  102434       0\n",
      "RUTW 220630P1940000  102434       0\n",
      "RUTW 220630P1950000  102434       0\n",
      "RUTW 220630P1960000  102434       0\n",
      "RUTW 220630P1970000  102434       0\n",
      "RUTW 220630P1980000  102434       0\n",
      "RUTW 220630P2000000  102434       0\n",
      "RUTW 220630C3250000  102434       0\n",
      "RUTW 220630P2010000  102434       0\n",
      "RUTW 220630P2020000  102434       0\n",
      "RUTW 220630P2030000  102434       0\n",
      "RUTW 220630P2040000  102434       0\n",
      "RUTW 220630P2050000  102434       0\n",
      "RUTW 220630P2060000  102434       0\n",
      "RUTW 220630P2070000  102434       0\n",
      "RUTW 220630P2080000  102434       0\n",
      "RUTW 220630P2090000  102434       0\n",
      "RUTW 220630P1890000  102434       0\n",
      "RUTW 220630P1880000  102434       0\n",
      "RUTW 220630P1870000  102434       0\n",
      "RUTW 220630P1860000  102434       0\n",
      "RUTW 220630C3300000  102434       0\n",
      "RUTW 220630C3350000  102434       0\n",
      "RUTW 220630C3400000  102434       0\n",
      "RUTW 220630C3450000  102434       0\n",
      "RUTW 220630C3500000  102434       0\n",
      "RUTW 220630P1100000  102434       0\n",
      "RUTW 220630P1150000  102434       0\n",
      "RUTW 220630P1200000  102434       0\n",
      "RUTW 220630P1250000  102434       0\n",
      "RUTW 220630P1300000  102434       0\n",
      "RUTW 220630P1350000  102434       0\n",
      "RUTW 220630P1450000  102434       0\n",
      "RUTW 220630P1500000  102434       0\n",
      "RUTW 220630P1550000  102434       0\n",
      "RUTW 220630P1600000  102434       0\n",
      "RUTW 220630P1650000  102434       0\n",
      "RUTW 220630P1700000  102434       0\n",
      "RUTW 220630P1750000  102434       0\n",
      "RUTW 220630P1800000  102434       0\n",
      "RUTW 220630C2410000  102434       0\n",
      "RUTW 220630C2400000  102434       0\n",
      "RUTW 220630C2390000  102434       0\n",
      "RUTW 220630C1700000  102434       0\n",
      "RUTW 220630C1250000  102434       0\n",
      "RUTW 220630C1300000  102434       0\n",
      "RUTW 220630C1350000  102434       0\n",
      "RUTW 220630C1400000  102434       0\n",
      "RUTW 220630C1450000  102434       0\n",
      "RUTW 220630C1500000  102434       0\n",
      "RUTW 220630C1550000  102434       0\n",
      "RUTW 220630C1600000  102434       0\n",
      "RUTW 220630C1650000  102434       0\n",
      "RUTW 220630C1750000  102434       0\n",
      "RUTW 220630C2380000  102434       0\n",
      "RUTW 220630C1800000  102434       0\n",
      "RUTW 220630C1840000  102434       0\n",
      "RUTW 220630C1850000  102434       0\n",
      "RUTW 220630C1860000  102434       0\n",
      "RUTW 220630C1870000  102434       0\n",
      "RUTW 220630C1880000  102434       0\n",
      "RUTW 220630C1890000  102434       0\n",
      "RUTW 220630C1900000  102434       0\n",
      "RUTW 220630C1910000  102434       0\n",
      "RUTW 220630C1200000  102434       0\n",
      "RUTW 220630C1150000  102434       0\n",
      "RUTW 220630C1100000  102434       0\n",
      "RUTW 220531P3300000  102434       0\n",
      "RUTW 220531P2630000  102434       0\n",
      "RUTW 220531P2635000  102434       0\n",
      "RUTW 220531P2640000  102434       0\n",
      "RUTW 220531P2645000  102434       0\n",
      "RUTW 220531P2650000  102434       0\n",
      "RUTW 220531P2655000  102434       0\n",
      "RUTW 220531P2660000  102434       0\n",
      "RUTW 220531P2700000  102434       0\n",
      "RUTW 220531P2750000  102434       0\n",
      "RUTW 220531P2800000  102434       0\n",
      "RUTW 220531P2850000  102434       0\n",
      "RUTW 220531P2900000  102434       0\n",
      "RUTW 220531P2950000  102434       0\n",
      "RUTW 220531P3000000  102434       0\n",
      "RUTW 220531P3050000  102434       0\n",
      "RUTW 220531P3100000  102434       0\n",
      "RUTW 220531P3150000  102434       0\n",
      "RUTW 220531P3200000  102434       0\n",
      "RUTW 220531P3250000  102434       0\n",
      "RUTW 220630C1920000  102434       0\n",
      "RUTW 220630C1930000  102434       0\n",
      "RUTW 220630C1940000  102434       0\n",
      "RUTW 220630C2170000  102434       0\n",
      "RUTW 220630C2190000  102434       0\n",
      "RUTW 220630C2200000  102434       0\n",
      "RUTW 220630C2210000  102434       0\n",
      "RUTW 220630C2220000  102434       0\n",
      "RUTW 220630C2230000  102434       0\n",
      "RUTW 220630C2240000  102434       0\n",
      "RUTW 220630C2250000  102434       0\n",
      "RUTW 220630C2260000  102434       0\n",
      "RUTW 220630C2270000  102434       0\n",
      "RUTW 220630C2280000  102434       0\n",
      "RUTW 220630C2290000  102434       0\n",
      "RUTW 220630C2300000  102434       0\n",
      "RUTW 220630C2310000  102434       0\n",
      "RUTW 220630C2320000  102434       0\n",
      "RUTW 220630C2330000  102434       0\n",
      "RUTW 220630C2340000  102434       0\n",
      "RUTW 220630C2350000  102434       0\n",
      "RUTW 220630C2360000  102434       0\n",
      "RUTW 220630C2370000  102434       0\n",
      "RUTW 220630C2180000  102434       0\n",
      "RUTW 220630C2160000  102434       0\n",
      "RUTW 220630C1950000  102434       0\n",
      "RUTW 220630C2150000  102434       0\n",
      "RUTW 220630C1960000  102434       0\n",
      "RUTW 220630C1970000  102434       0\n",
      "RUTW 220630C1980000  102434       0\n",
      "RUTW 220630C1990000  102434       0\n",
      "RUTW 220630C2000000  102434       0\n",
      "RUTW 220630C2010000  102434       0\n",
      "RUTW 220630C2020000  102434       0\n",
      "RUTW 220630C2030000  102434       0\n",
      "RUTW 220630C2040000  102434       0\n",
      "RUTW 220630C2050000  102434       0\n",
      "RUTW 220630C2060000  102434       0\n",
      "RUTW 220630C2070000  102434       0\n",
      "RUTW 220630C2080000  102434       0\n",
      "RUTW 220630C2090000  102434       0\n",
      "RUTW 220630C2100000  102434       0\n",
      "RUTW 220630C2110000  102434       0\n",
      "RUTW 220630C2120000  102434       0\n",
      "RUTW 220630C2130000  102434       0\n",
      "RUTW 220630C2140000  102434       0\n",
      "RUTW 220630P2100000  102434       0\n",
      "RUTW 220630P2110000  102434       0\n",
      "RUTW 220630P2120000  102434       0\n",
      "RUTW 220930C2080000  102434       0\n",
      "RUTW 220930C1990000  102434       0\n",
      "RUTW 220930C2000000  102434       0\n",
      "RUTW 220930C2010000  102434       0\n",
      "RUTW 220930C2020000  102434       0\n",
      "RUTW 220930C2030000  102434       0\n",
      "RUTW 220930C2040000  102434       0\n",
      "RUTW 220930C2050000  102434       0\n",
      "RUTW 220930C2060000  102434       0\n",
      "RUTW 220930C2070000  102434       0\n",
      "RUTW 220930C2090000  102434       0\n",
      "RUTW 220930C1700000  102434       0\n",
      "RUTW 220930C2100000  102434       0\n",
      "RUTW 220930C2110000  102434       0\n",
      "RUTW 220930C2120000  102434       0\n",
      "RUTW 220930C2130000  102434       0\n",
      "RUTW 220930C2140000  102434       0\n",
      "RUTW 220930C2150000  102434       0\n",
      "RUTW 220930C2160000  102434       0\n",
      "RUTW 220930C2170000  102434       0\n",
      "RUTW 220930C2180000  102434       0\n",
      "RUTW 220930C1980000  102434       0\n",
      "RUTW 220930C1970000  102434       0\n",
      "RUTW 220930C1960000  102434       0\n",
      "RUTW 220930C1950000  102434       0\n",
      "RUTW 220930C1760000  102434       0\n",
      "RUTW 220930C1770000  102434       0\n",
      "RUTW 220930C1780000  102434       0\n",
      "RUTW 220930C1790000  102434       0\n",
      "RUTW 220930C1800000  102434       0\n",
      "RUTW 220930C1810000  102434       0\n",
      "RUTW 220930C1820000  102434       0\n",
      "RUTW 220930C1830000  102434       0\n",
      "RUTW 220930C1840000  102434       0\n",
      "RUTW 220930C1850000  102434       0\n",
      "RUTW 220930C1860000  102434       0\n",
      "RUTW 220930C1870000  102434       0\n",
      "RUTW 220930C1880000  102434       0\n",
      "RUTW 220930C1890000  102434       0\n",
      "RUTW 220930C1900000  102434       0\n",
      "RUTW 220930C1910000  102434       0\n",
      "RUTW 220930C1920000  102434       0\n",
      "RUTW 220930C1930000  102434       0\n",
      "RUTW 220930C1940000  102434       0\n",
      "RUTW 220930C2190000  102434       0\n",
      "RUTW 220930C2200000  102434       0\n",
      "RUTW 220930C2210000  102434       0\n",
      "RUTW 220930C2440000  102434       0\n",
      "RUTW 220930C2460000  102434       0\n",
      "RUTW 220930C2470000  102434       0\n",
      "RUTW 220930C2480000  102434       0\n",
      "RUTW 220930C2490000  102434       0\n",
      "RUTW 220930C2500000  102434       0\n",
      "RUTW 220930C2510000  102434       0\n",
      "RUTW 220930C2520000  102434       0\n",
      "RUTW 220930C2530000  102434       0\n",
      "RUTW 220930C2540000  102434       0\n",
      "RUTW 220930C2550000  102434       0\n",
      "RUTW 220930C2560000  102434       0\n",
      "RUTW 220930C2570000  102434       0\n",
      "RUTW 220930C2580000  102434       0\n",
      "RUTW 220930C2590000  102434       0\n",
      "RUTW 220930C2600000  102434       0\n",
      "RUTW 220930C2610000  102434       0\n",
      "RUTW 220930C2620000  102434       0\n",
      "RUTW 220930C2630000  102434       0\n",
      "RUTW 220930C2640000  102434       0\n",
      "RUTW 220930C2450000  102434       0\n",
      "RUTW 220930C2430000  102434       0\n",
      "RUTW 220930C2220000  102434       0\n",
      "RUTW 220930C2420000  102434       0\n",
      "RUTW 220930C2230000  102434       0\n",
      "RUTW 220930C2240000  102434       0\n",
      "RUTW 220930C2250000  102434       0\n",
      "RUTW 220930C2260000  102434       0\n",
      "RUTW 220930C2270000  102434       0\n",
      "RUTW 220930C2280000  102434       0\n",
      "RUTW 220930C2290000  102434       0\n",
      "RUTW 220930C2300000  102434       0\n",
      "RUTW 220930C2310000  102434       0\n",
      "RUTW 220930C2320000  102434       0\n",
      "RUTW 220930C2330000  102434       0\n",
      "RUTW 220930C2340000  102434       0\n",
      "RUTW 220930C2350000  102434       0\n",
      "RUTW 220930C2360000  102434       0\n",
      "RUTW 220930C2370000  102434       0\n",
      "RUTW 220930C2380000  102434       0\n",
      "RUTW 220930C2390000  102434       0\n",
      "RUTW 220930C2400000  102434       0\n",
      "RUTW 220930C2410000  102434       0\n",
      "RUTW 220930C1750000  102434       0\n",
      "RUTW 220930C1650000  102434       0\n",
      "RUTW 220630P2130000  102434       0\n",
      "RUTW 220630P2470000  102434       0\n",
      "RUTW 220630P2380000  102434       0\n",
      "RUTW 220630P2390000  102434       0\n",
      "RUTW 220630P2400000  102434       0\n",
      "RUTW 220630P2410000  102434       0\n",
      "RUTW 220630P2420000  102434       0\n",
      "RUTW 220630P2430000  102434       0\n",
      "RUTW 220630P2440000  102434       0\n",
      "RUTW 220630P2450000  102434       0\n",
      "RUTW 220630P2460000  102434       0\n",
      "RUTW 220630P2480000  102434       0\n",
      "RUTW 220930C1600000  102434       0\n",
      "RUTW 220630P2490000  102434       0\n",
      "RUTW 220630P2500000  102434       0\n",
      "RUTW 220630P2510000  102434       0\n",
      "RUTW 220630P2520000  102434       0\n",
      "RUTW 220630P2530000  102434       0\n",
      "RUTW 220630P2540000  102434       0\n",
      "RUTW 220630P2550000  102434       0\n",
      "RUTW 220630P2560000  102434       0\n",
      "RUTW 220630P2570000  102434       0\n",
      "RUTW 220630P2370000  102434       0\n",
      "RUTW 220630P2360000  102434       0\n",
      "RUTW 220630P2350000  102434       0\n",
      "RUTW 220630P2340000  102434       0\n",
      "RUTW 220630P2140000  102434       0\n",
      "RUTW 220630P2150000  102434       0\n",
      "RUTW 220630P2160000  102434       0\n",
      "RUTW 220630P2170000  102434       0\n",
      "RUTW 220630P2180000  102434       0\n",
      "RUTW 220630P2190000  102434       0\n",
      "RUTW 220630P2200000  102434       0\n",
      "RUTW 220630P2210000  102434       0\n",
      "RUTW 220630P2220000  102434       0\n",
      "RUTW 220630P2230000  102434       0\n",
      "RUTW 220630P2240000  102434       0\n",
      "RUTW 220630P2260000  102434       0\n",
      "RUTW 220630P2270000  102434       0\n",
      "RUTW 220630P2280000  102434       0\n",
      "RUTW 220630P2290000  102434       0\n",
      "RUTW 220630P2300000  102434       0\n",
      "RUTW 220630P2310000  102434       0\n",
      "RUTW 220630P2320000  102434       0\n",
      "RUTW 220630P2330000  102434       0\n",
      "RUTW 220630P2580000  102434       0\n",
      "RUTW 220630P2590000  102434       0\n",
      "RUTW 220630P2600000  102434       0\n",
      "RUTW 220630P3000000  102434       0\n",
      "RUTW 220630P3100000  102434       0\n",
      "RUTW 220630P3150000  102434       0\n",
      "RUTW 220630P3200000  102434       0\n",
      "RUTW 220630P3250000  102434       0\n",
      "RUTW 220630P3300000  102434       0\n",
      "RUTW 220630P3350000  102434       0\n",
      "RUTW 220630P3400000  102434       0\n",
      "RUTW 220630P3450000  102434       0\n",
      "RUTW 220630P3500000  102434       0\n",
      "RUTW 220930C1100000  102434       0\n",
      "RUTW 220930C1150000  102434       0\n",
      "RUTW 220930C1200000  102434       0\n",
      "RUTW 220930C1250000  102434       0\n",
      "RUTW 220930C1300000  102434       0\n",
      "RUTW 220930C1350000  102434       0\n",
      "RUTW 220930C1400000  102434       0\n",
      "RUTW 220930C1450000  102434       0\n",
      "RUTW 220930C1500000  102434       0\n",
      "RUTW 220930C1550000  102434       0\n",
      "RUTW 220630P3050000  102434       0\n",
      "RUTW 220630P2950000  102434       0\n",
      "RUTW 220630P2610000  102434       0\n",
      "RUTW 220630P2900000  102434       0\n",
      "RUTW 220630P2620000  102434       0\n",
      "RUTW 220630P2630000  102434       0\n",
      "RUTW 220630P2640000  102434       0\n",
      "RUTW 220630P2650000  102434       0\n",
      "RUTW 220630P2660000  102434       0\n",
      "RUTW 220630P2670000  102434       0\n",
      "RUTW 220630P2680000  102434       0\n",
      "RUTW 220630P2690000  102434       0\n",
      "RUTW 220630P2700000  102434       0\n",
      "RUTW 220630P2710000  102434       0\n",
      "RUTW 220630P2720000  102434       0\n",
      "RUTW 220630P2730000  102434       0\n",
      "RUTW 220630P2740000  102434       0\n",
      "RUTW 220630P2750000  102434       0\n",
      "RUTW 220630P2760000  102434       0\n",
      "RUTW 220630P2770000  102434       0\n",
      "RUTW 220630P2780000  102434       0\n",
      "RUTW 220630P2800000  102434       0\n",
      "RUTW 220630P2850000  102434       0\n",
      "RUTW 220331C2510000  102434       0\n",
      "RUTW 220331C2500000  102434       0\n",
      "RUTW 220331C2490000  102434       0\n",
      "RUTW 220204P1490000  102434       0\n",
      "RUTW 220204P1445000  102434       0\n",
      "RUTW 220204P1450000  102434       0\n",
      "RUTW 220204P1455000  102434       0\n",
      "RUTW 220204P1460000  102434       0\n",
      "RUTW 220204P1465000  102434       0\n",
      "RUTW 220204P1470000  102434       0\n",
      "RUTW 220204P1475000  102434       0\n",
      "RUTW 220204P1480000  102434       0\n",
      "RUTW 220204P1485000  102434       0\n",
      "RUTW 220204P1495000  102434       0\n",
      "RUTW 220204P1550000  102434       0\n",
      "RUTW 220204P1500000  102434       0\n",
      "RUTW 220204P1505000  102434       0\n",
      "RUTW 220204P1510000  102434       0\n",
      "RUTW 220204P1515000  102434       0\n",
      "RUTW 220204P1520000  102434       0\n",
      "RUTW 220204P1525000  102434       0\n",
      "RUTW 220204P1530000  102434       0\n",
      "RUTW 220204P1535000  102434       0\n",
      "RUTW 220204P1540000  102434       0\n",
      "RUTW 220204P1440000  102434       0\n",
      "RUTW 220204P1435000  102434       0\n",
      "RUTW 220204P1430000  102434       0\n",
      "RUTW 220204P1425000  102434       0\n",
      "RUTW 220204P1330000  102434       0\n",
      "RUTW 220204P1335000  102434       0\n",
      "RUTW 220204P1340000  102434       0\n",
      "RUTW 220204P1345000  102434       0\n",
      "RUTW 220204P1350000  102434       0\n",
      "RUTW 220204P1355000  102434       0\n",
      "RUTW 220204P1360000  102434       0\n",
      "RUTW 220204P1365000  102434       0\n",
      "RUTW 220204P1370000  102434       0\n",
      "RUTW 220204P1375000  102434       0\n",
      "RUTW 220204P1380000  102434       0\n",
      "RUTW 220204P1385000  102434       0\n",
      "RUTW 220204P1390000  102434       0\n",
      "RUTW 220204P1395000  102434       0\n",
      "RUTW 220204P1400000  102434       0\n",
      "RUTW 220204P1405000  102434       0\n",
      "RUTW 220204P1410000  102434       0\n",
      "RUTW 220204P1415000  102434       0\n",
      "RUTW 220204P1420000  102434       0\n",
      "RUTW 220204P1545000  102434       0\n",
      "RUTW 220204P1555000  102434       0\n",
      "RUTW 220204P1785000  102434       0\n",
      "RUTW 220204P1725000  102434       0\n",
      "RUTW 220204P1680000  102434       0\n",
      "RUTW 220204P1685000  102434       0\n",
      "RUTW 220204P1690000  102434       0\n",
      "RUTW 220204P1695000  102434       0\n",
      "RUTW 220204P1700000  102434       0\n",
      "RUTW 220204P1705000  102434       0\n",
      "RUTW 220204P1710000  102434       0\n",
      "RUTW 220204P1715000  102434       0\n",
      "RUTW 220204P1720000  102434       0\n",
      "RUTW 220204P1730000  102434       0\n",
      "RUTW 220204P1560000  102434       0\n",
      "RUTW 220204P1735000  102434       0\n",
      "RUTW 220204P1740000  102434       0\n",
      "RUTW 220204P1745000  102434       0\n",
      "RUTW 220204P1750000  102434       0\n",
      "RUTW 220204P1755000  102434       0\n",
      "RUTW 220204P1760000  102434       0\n",
      "RUTW 220204P1765000  102434       0\n",
      "RUTW 220204P1770000  102434       0\n",
      "RUTW 220204P1775000  102434       0\n",
      "RUTW 220204P1675000  102434       0\n",
      "RUTW 220204P1670000  102434       0\n",
      "RUTW 220204P1665000  102434       0\n",
      "RUTW 220204P1660000  102434       0\n",
      "RUTW 220204P1565000  102434       0\n",
      "RUTW 220204P1570000  102434       0\n",
      "RUTW 220204P1575000  102434       0\n",
      "RUTW 220204P1580000  102434       0\n",
      "RUTW 220204P1585000  102434       0\n",
      "RUTW 220204P1590000  102434       0\n",
      "RUTW 220204P1595000  102434       0\n",
      "RUTW 220204P1600000  102434       0\n",
      "RUTW 220204P1605000  102434       0\n",
      "RUTW 220204P1610000  102434       0\n",
      "RUTW 220204P1615000  102434       0\n",
      "RUTW 220204P1620000  102434       0\n",
      "RUTW 220204P1625000  102434       0\n",
      "RUTW 220204P1630000  102434       0\n",
      "RUTW 220204P1635000  102434       0\n",
      "RUTW 220204P1640000  102434       0\n",
      "RUTW 220204P1645000  102434       0\n",
      "RUTW 220204P1650000  102434       0\n",
      "RUTW 220204P1655000  102434       0\n",
      "RUTW 220204P1325000  102434       0\n",
      "RUTW 220204P1320000  102434       0\n",
      "RUTW 220204P1315000  102434       0\n",
      "RUTW 220204C2530000  102434       0\n",
      "RUTW 220204C2435000  102434       0\n",
      "RUTW 220204C2465000  102434       0\n",
      "RUTW 220204C2480000  102434       0\n",
      "RUTW 220204C2485000  102434       0\n",
      "RUTW 220204C2495000  102434       0\n",
      "RUTW 220204C2505000  102434       0\n",
      "RUTW 220204C2515000  102434       0\n",
      "RUTW 220204C2520000  102434       0\n",
      "RUTW 220204C2525000  102434       0\n",
      "RUTW 220204C2535000  102434       0\n",
      "RUTW 220204P1310000  102434       0\n",
      "RUTW 220204C2540000  102434       0\n",
      "RUTW 220204C2545000  102434       0\n",
      "RUTW 220204C2555000  102434       0\n",
      "RUTW 220204C2560000  102434       0\n",
      "RUTW 220204C2565000  102434       0\n",
      "RUTW 220204C2570000  102434       0\n",
      "RUTW 220204C2575000  102434       0\n",
      "RUTW 220204C2580000  102434       0\n",
      "RUTW 220204C2585000  102434       0\n",
      "RUTW 220204C2425000  102434       0\n",
      "RUTW 220204C2415000  102434       0\n",
      "RUTW 220204C2405000  102434       0\n",
      "RUTW 220204C2395000  102434       0\n",
      "RUTW 220204C2250000  102434       0\n",
      "RUTW 220204C2260000  102434       0\n",
      "RUTW 220204C2265000  102434       0\n",
      "RUTW 220204C2270000  102434       0\n",
      "RUTW 220204C2285000  102434       0\n",
      "RUTW 220204C2305000  102434       0\n",
      "RUTW 220204C2310000  102434       0\n",
      "RUTW 220204C2315000  102434       0\n",
      "RUTW 220204C2320000  102434       0\n",
      "RUTW 220204C2325000  102434       0\n",
      "RUTW 220204C2335000  102434       0\n",
      "RUTW 220204C2355000  102434       0\n",
      "RUTW 220204C2360000  102434       0\n",
      "RUTW 220204C2365000  102434       0\n",
      "RUTW 220204C2370000  102434       0\n",
      "RUTW 220204C2375000  102434       0\n",
      "RUTW 220204C2380000  102434       0\n",
      "RUTW 220204C2385000  102434       0\n",
      "RUTW 220204C2390000  102434       0\n",
      "RUTW 220204C2590000  102434       0\n",
      "RUTW 220204C2595000  102434       0\n",
      "RUTW 220204C2600000  102434       0\n",
      "RUTW 220204P1205000  102434       0\n",
      "RUTW 220204P1215000  102434       0\n",
      "RUTW 220204P1220000  102434       0\n",
      "RUTW 220204P1225000  102434       0\n",
      "RUTW 220204P1230000  102434       0\n",
      "RUTW 220204P1235000  102434       0\n",
      "RUTW 220204P1240000  102434       0\n",
      "RUTW 220204P1245000  102434       0\n",
      "RUTW 220204P1250000  102434       0\n",
      "RUTW 220204P1255000  102434       0\n",
      "RUTW 220204P1260000  102434       0\n",
      "RUTW 220204P1265000  102434       0\n",
      "RUTW 220204P1270000  102434       0\n",
      "RUTW 220204P1275000  102434       0\n",
      "RUTW 220204P1280000  102434       0\n",
      "RUTW 220204P1285000  102434       0\n",
      "RUTW 220204P1290000  102434       0\n",
      "RUTW 220204P1295000  102434       0\n",
      "RUTW 220204P1300000  102434       0\n",
      "RUTW 220204P1305000  102434       0\n",
      "RUTW 220204P1210000  102434       0\n",
      "RUTW 220204P1200000  102434       0\n",
      "RUTW 220204C2605000  102434       0\n",
      "RUTW 220204P1195000  102434       0\n",
      "RUTW 220204C2610000  102434       0\n",
      "RUTW 220204C2615000  102434       0\n",
      "RUTW 220204C2620000  102434       0\n",
      "RUTW 220204C2625000  102434       0\n",
      "RUTW 220204C2630000  102434       0\n",
      "RUTW 220204C2635000  102434       0\n",
      "RUTW 220204C2640000  102434       0\n",
      "RUTW 220204C2645000  102434       0\n",
      "RUTW 220204C2650000  102434       0\n",
      "RUTW 220204C2655000  102434       0\n",
      "RUTW 220204C2660000  102434       0\n",
      "RUTW 220204C2665000  102434       0\n",
      "RUTW 220204C2670000  102434       0\n",
      "RUTW 220204C2675000  102434       0\n",
      "RUTW 220204C2680000  102434       0\n",
      "RUTW 220204C2685000  102434       0\n",
      "RUTW 220204C2690000  102434       0\n",
      "RUTW 220204C2695000  102434       0\n",
      "RUTW 220204C2700000  102434       0\n",
      "RUTW 220204P1780000  102434       0\n",
      "RUTW 220204P1790000  102434       0\n",
      "RUTW 220211C1475000  102434       0\n",
      "RUTW 220204P2665000  102434       0\n",
      "RUTW 220204P2620000  102434       0\n",
      "RUTW 220204P2625000  102434       0\n",
      "RUTW 220204P2630000  102434       0\n",
      "RUTW 220204P2635000  102434       0\n",
      "RUTW 220204P2640000  102434       0\n",
      "RUTW 220204P2645000  102434       0\n",
      "RUTW 220204P2650000  102434       0\n",
      "RUTW 220204P2655000  102434       0\n",
      "RUTW 220204P2660000  102434       0\n",
      "RUTW 220204P2670000  102434       0\n",
      "RUTW 220211C1240000  102434       0\n",
      "RUTW 220204P2675000  102434       0\n",
      "RUTW 220204P2680000  102434       0\n",
      "RUTW 220204P2685000  102434       0\n",
      "RUTW 220204P2690000  102434       0\n",
      "RUTW 220204P2695000  102434       0\n",
      "RUTW 220204P2700000  102434       0\n",
      "RUTW 220211C1220000  102434       0\n",
      "RUTW 220211C1225000  102434       0\n",
      "RUTW 220211C1230000  102434       0\n",
      "RUTW 220204P2615000  102434       0\n",
      "RUTW 220204P2610000  102434       0\n",
      "RUTW 220204P2605000  102434       0\n",
      "RUTW 220204P2600000  102434       0\n",
      "RUTW 220204P2505000  102434       0\n",
      "RUTW 220204P2510000  102434       0\n",
      "RUTW 220204P2515000  102434       0\n",
      "RUTW 220204P2520000  102434       0\n",
      "RUTW 220204P2525000  102434       0\n",
      "RUTW 220204P2530000  102434       0\n",
      "RUTW 220204P2535000  102434       0\n",
      "RUTW 220204P2540000  102434       0\n",
      "RUTW 220204P2545000  102434       0\n",
      "RUTW 220204P2550000  102434       0\n",
      "RUTW 220204P2555000  102434       0\n",
      "RUTW 220204P2560000  102434       0\n",
      "RUTW 220204P2565000  102434       0\n",
      "RUTW 220204P2570000  102434       0\n",
      "RUTW 220204P2575000  102434       0\n",
      "RUTW 220204P2580000  102434       0\n",
      "RUTW 220204P2585000  102434       0\n",
      "RUTW 220204P2590000  102434       0\n",
      "RUTW 220204P2595000  102434       0\n",
      "RUTW 220211C1235000  102434       0\n",
      "RUTW 220211C1245000  102434       0\n",
      "RUTW 220204P1795000  102434       0\n",
      "RUTW 220211C1415000  102434       0\n",
      "RUTW 220211C1370000  102434       0\n",
      "RUTW 220211C1375000  102434       0\n",
      "RUTW 220211C1380000  102434       0\n",
      "RUTW 220211C1385000  102434       0\n",
      "RUTW 220211C1390000  102434       0\n",
      "RUTW 220211C1395000  102434       0\n",
      "RUTW 220211C1400000  102434       0\n",
      "RUTW 220211C1405000  102434       0\n",
      "RUTW 220211C1410000  102434       0\n",
      "RUTW 220211C1420000  102434       0\n",
      "RUTW 220211C1250000  102434       0\n",
      "RUTW 220211C1425000  102434       0\n",
      "RUTW 220211C1430000  102434       0\n",
      "RUTW 220211C1435000  102434       0\n",
      "RUTW 220211C1440000  102434       0\n",
      "RUTW 220211C1445000  102434       0\n",
      "RUTW 220211C1450000  102434       0\n",
      "RUTW 220211C1455000  102434       0\n",
      "RUTW 220211C1460000  102434       0\n",
      "RUTW 220211C1465000  102434       0\n",
      "RUTW 220211C1365000  102434       0\n",
      "RUTW 220211C1360000  102434       0\n",
      "RUTW 220211C1355000  102434       0\n",
      "RUTW 220211C1350000  102434       0\n",
      "RUTW 220211C1255000  102434       0\n",
      "RUTW 220211C1260000  102434       0\n",
      "RUTW 220211C1265000  102434       0\n",
      "RUTW 220211C1270000  102434       0\n",
      "RUTW 220211C1275000  102434       0\n",
      "RUTW 220211C1280000  102434       0\n",
      "RUTW 220211C1285000  102434       0\n",
      "RUTW 220211C1290000  102434       0\n",
      "RUTW 220211C1295000  102434       0\n",
      "RUTW 220211C1300000  102434       0\n",
      "RUTW 220211C1305000  102434       0\n",
      "RUTW 220211C1310000  102434       0\n",
      "RUTW 220211C1315000  102434       0\n",
      "RUTW 220211C1320000  102434       0\n",
      "RUTW 220211C1325000  102434       0\n",
      "RUTW 220211C1330000  102434       0\n",
      "RUTW 220211C1335000  102434       0\n",
      "RUTW 220211C1340000  102434       0\n",
      "RUTW 220211C1345000  102434       0\n",
      "RUTW 220204P2500000  102434       0\n",
      "RUTW 220204P2495000  102434       0\n",
      "RUTW 220204P2490000  102434       0\n",
      "RUTW 220204P2065000  102434       0\n",
      "RUTW 220204P1940000  102434       0\n",
      "RUTW 220204P1950000  102434       0\n",
      "RUTW 220204P1960000  102434       0\n",
      "RUTW 220204P1980000  102434       0\n",
      "RUTW 220204P2005000  102434       0\n",
      "RUTW 220204P2015000  102434       0\n",
      "RUTW 220204P2025000  102434       0\n",
      "RUTW 220204P2030000  102434       0\n",
      "RUTW 220204P2055000  102434       0\n",
      "RUTW 220204P2075000  102434       0\n",
      "RUTW 220204P2485000  102434       0\n",
      "RUTW 220204P2080000  102434       0\n",
      "RUTW 220204P2085000  102434       0\n",
      "RUTW 220204P2090000  102434       0\n",
      "RUTW 220204P2120000  102434       0\n",
      "RUTW 220204P2130000  102434       0\n",
      "RUTW 220204P2135000  102434       0\n",
      "RUTW 220204P2140000  102434       0\n",
      "RUTW 220204P2145000  102434       0\n",
      "RUTW 220204P2150000  102434       0\n",
      "RUTW 220204P1935000  102434       0\n",
      "RUTW 220204P1930000  102434       0\n",
      "RUTW 220204P1925000  102434       0\n",
      "RUTW 220204P1915000  102434       0\n",
      "RUTW 220204P1805000  102434       0\n",
      "RUTW 220204P1810000  102434       0\n",
      "RUTW 220204P1815000  102434       0\n",
      "RUTW 220204P1820000  102434       0\n",
      "RUTW 220204P1825000  102434       0\n",
      "RUTW 220204P1830000  102434       0\n",
      "RUTW 220204P1835000  102434       0\n",
      "RUTW 220204P1840000  102434       0\n",
      "RUTW 220204P1845000  102434       0\n",
      "RUTW 220204P1850000  102434       0\n",
      "RUTW 220204P1855000  102434       0\n",
      "RUTW 220204P1860000  102434       0\n",
      "RUTW 220204P1865000  102434       0\n",
      "RUTW 220204P1870000  102434       0\n",
      "RUTW 220204P1875000  102434       0\n",
      "RUTW 220204P1880000  102434       0\n",
      "RUTW 220204P1890000  102434       0\n",
      "RUTW 220204P1895000  102434       0\n",
      "RUTW 220204P1905000  102434       0\n",
      "RUTW 220204P2160000  102434       0\n",
      "RUTW 220204P2165000  102434       0\n",
      "RUTW 220204P2170000  102434       0\n",
      "RUTW 220204P2380000  102434       0\n",
      "RUTW 220204P2390000  102434       0\n",
      "RUTW 220204P2395000  102434       0\n",
      "RUTW 220204P2400000  102434       0\n",
      "RUTW 220204P2405000  102434       0\n",
      "RUTW 220204P2410000  102434       0\n",
      "RUTW 220204P2415000  102434       0\n",
      "RUTW 220204P2420000  102434       0\n",
      "RUTW 220204P2425000  102434       0\n",
      "RUTW 220204P2430000  102434       0\n",
      "RUTW 220204P2435000  102434       0\n",
      "RUTW 220204P2440000  102434       0\n",
      "RUTW 220204P2445000  102434       0\n",
      "RUTW 220204P2450000  102434       0\n",
      "RUTW 220204P2455000  102434       0\n",
      "RUTW 220204P2460000  102434       0\n",
      "RUTW 220204P2465000  102434       0\n",
      "RUTW 220204P2470000  102434       0\n",
      "RUTW 220204P2475000  102434       0\n",
      "RUTW 220204P2480000  102434       0\n",
      "RUTW 220204P2385000  102434       0\n",
      "RUTW 220204P2375000  102434       0\n",
      "RUTW 220204P2175000  102434       0\n",
      "RUTW 220204P2370000  102434       0\n",
      "RUTW 220204P2180000  102434       0\n",
      "RUTW 220204P2185000  102434       0\n",
      "RUTW 220204P2195000  102434       0\n",
      "RUTW 220204P2225000  102434       0\n",
      "RUTW 220204P2235000  102434       0\n",
      "RUTW 220204P2285000  102434       0\n",
      "RUTW 220204P2300000  102434       0\n",
      "RUTW 220204P2305000  102434       0\n",
      "RUTW 220204P2310000  102434       0\n",
      "RUTW 220204P2315000  102434       0\n",
      "RUTW 220204P2320000  102434       0\n",
      "RUTW 220204P2325000  102434       0\n",
      "RUTW 220204P2330000  102434       0\n",
      "RUTW 220204P2335000  102434       0\n",
      "RUTW 220204P2345000  102434       0\n",
      "RUTW 220204P2350000  102434       0\n",
      "RUTW 220204P2355000  102434       0\n",
      "RUTW 220204P2360000  102434       0\n",
      "RUTW 220204P2365000  102434       0\n",
      "RUTW 220204C2245000  102434       0\n",
      "RUTW 220204C2235000  102434       0\n",
      "RUTW 220204C2220000  102434       0\n",
      "RUTW 220131P2390000  102434       0\n",
      "RUTW 220131P2260000  102434       0\n",
      "RUTW 220131P2290000  102434       0\n",
      "RUTW 220131P2300000  102434       0\n",
      "RUTW 220131P2330000  102434       0\n",
      "RUTW 220131P2340000  102434       0\n",
      "RUTW 220131P2350000  102434       0\n",
      "RUTW 220131P2360000  102434       0\n",
      "RUTW 220131P2370000  102434       0\n",
      "RUTW 220131P2380000  102434       0\n",
      "RUTW 220131P2400000  102434       0\n",
      "RUTW 220131P2510000  102434       0\n",
      "RUTW 220131P2410000  102434       0\n",
      "RUTW 220131P2420000  102434       0\n",
      "RUTW 220131P2430000  102434       0\n",
      "RUTW 220131P2440000  102434       0\n",
      "RUTW 220131P2450000  102434       0\n",
      "RUTW 220131P2460000  102434       0\n",
      "RUTW 220131P2470000  102434       0\n",
      "RUTW 220131P2480000  102434       0\n",
      "RUTW 220131P2490000  102434       0\n",
      "RUTW 220131P2200000  102434       0\n",
      "RUTW 220131P2150000  102434       0\n",
      "RUTW 220131P1910000  102434       0\n",
      "RUTW 220131P1870000  102434       0\n",
      "RUTW 220131C3200000  102434       0\n",
      "RUTW 220131C3250000  102434       0\n",
      "RUTW 220131C3300000  102434       0\n",
      "RUTW 220131P1150000  102434       0\n",
      "RUTW 220131P1200000  102434       0\n",
      "RUTW 220131P1250000  102434       0\n",
      "RUTW 220131P1300000  102434       0\n",
      "RUTW 220131P1350000  102434       0\n",
      "RUTW 220131P1400000  102434       0\n",
      "RUTW 220131P1500000  102434       0\n",
      "RUTW 220131P1550000  102434       0\n",
      "RUTW 220131P1750000  102434       0\n",
      "RUTW 220131P1790000  102434       0\n",
      "RUTW 220131P1810000  102434       0\n",
      "RUTW 220131P1820000  102434       0\n",
      "RUTW 220131P1830000  102434       0\n",
      "RUTW 220131P1840000  102434       0\n",
      "RUTW 220131P1850000  102434       0\n",
      "RUTW 220131P1860000  102434       0\n",
      "RUTW 220131P2500000  102434       0\n",
      "RUTW 220131P2520000  102434       0\n",
      "RUTW 220204C2215000  102434       0\n",
      "RUTW 220204C1220000  102434       0\n",
      "RUTW 220131P3150000  102434       0\n",
      "RUTW 220131P3200000  102434       0\n",
      "RUTW 220131P3250000  102434       0\n",
      "RUTW 220131P3300000  102434       0\n",
      "RUTW 220204C1195000  102434       0\n",
      "RUTW 220204C1200000  102434       0\n",
      "RUTW 220204C1205000  102434       0\n",
      "RUTW 220204C1210000  102434       0\n",
      "RUTW 220204C1215000  102434       0\n",
      "RUTW 220204C1225000  102434       0\n",
      "RUTW 220131P2530000  102434       0\n",
      "RUTW 220204C1230000  102434       0\n",
      "RUTW 220204C1235000  102434       0\n",
      "RUTW 220204C1240000  102434       0\n",
      "RUTW 220204C1245000  102434       0\n",
      "RUTW 220204C1250000  102434       0\n",
      "RUTW 220204C1255000  102434       0\n",
      "RUTW 220204C1260000  102434       0\n",
      "RUTW 220204C1265000  102434       0\n",
      "RUTW 220204C1270000  102434       0\n",
      "RUTW 220131P3100000  102434       0\n",
      "RUTW 220131P3050000  102434       0\n",
      "RUTW 220131P3000000  102434       0\n",
      "RUTW 220131P2950000  102434       0\n",
      "RUTW 220131P2540000  102434       0\n",
      "RUTW 220131P2550000  102434       0\n",
      "RUTW 220131P2560000  102434       0\n",
      "RUTW 220131P2570000  102434       0\n",
      "RUTW 220131P2580000  102434       0\n",
      "RUTW 220131P2590000  102434       0\n",
      "RUTW 220131P2600000  102434       0\n",
      "RUTW 220131P2610000  102434       0\n",
      "RUTW 220131P2620000  102434       0\n",
      "RUTW 220131P2630000  102434       0\n",
      "RUTW 220131P2640000  102434       0\n",
      "RUTW 220131P2650000  102434       0\n",
      "RUTW 220131P2660000  102434       0\n",
      "RUTW 220131P2670000  102434       0\n",
      "RUTW 220131P2700000  102434       0\n",
      "RUTW 220131P2750000  102434       0\n",
      "RUTW 220131P2800000  102434       0\n",
      "RUTW 220131P2850000  102434       0\n",
      "RUTW 220131P2900000  102434       0\n",
      "RUTW 220131C3150000  102434       0\n",
      "RUTW 220131C3100000  102434       0\n",
      "RUTW 220131C3050000  102434       0\n",
      "RUTW 220131C1940000  102434       0\n",
      "RUTW 220131C1850000  102434       0\n",
      "RUTW 220131C1860000  102434       0\n",
      "RUTW 220131C1870000  102434       0\n",
      "RUTW 220131C1880000  102434       0\n",
      "RUTW 220131C1890000  102434       0\n",
      "RUTW 220131C1900000  102434       0\n",
      "RUTW 220131C1910000  102434       0\n",
      "RUTW 220131C1920000  102434       0\n",
      "RUTW 220131C1930000  102434       0\n",
      "RUTW 220131C1950000  102434       0\n",
      "RUTW 220131C3000000  102434       0\n",
      "RUTW 220131C1960000  102434       0\n",
      "RUTW 220131C1970000  102434       0\n",
      "RUTW 220131C1980000  102434       0\n",
      "RUTW 220131C1990000  102434       0\n",
      "RUTW 220131C2000000  102434       0\n",
      "RUTW 220131C2010000  102434       0\n",
      "RUTW 220131C2020000  102434       0\n",
      "RUTW 220131C2030000  102434       0\n",
      "RUTW 220131C2040000  102434       0\n",
      "RUTW 220131C1840000  102434       0\n",
      "RUTW 220131C1830000  102434       0\n",
      "RUTW 220131C1820000  102434       0\n",
      "RUTW 220131C1810000  102434       0\n",
      "RUTW 220128P2765000  102434       0\n",
      "RUTW 220128P2770000  102434       0\n",
      "RUTW 220128P2775000  102434       0\n",
      "RUTW 220128P2780000  102434       0\n",
      "RUTW 220131C1150000  102434       0\n",
      "RUTW 220131C1200000  102434       0\n",
      "RUTW 220131C1250000  102434       0\n",
      "RUTW 220131C1300000  102434       0\n",
      "RUTW 220131C1350000  102434       0\n",
      "RUTW 220131C1400000  102434       0\n",
      "RUTW 220131C1450000  102434       0\n",
      "RUTW 220131C1500000  102434       0\n",
      "RUTW 220131C1550000  102434       0\n",
      "RUTW 220131C1600000  102434       0\n",
      "RUTW 220131C1650000  102434       0\n",
      "RUTW 220131C1700000  102434       0\n",
      "RUTW 220131C1750000  102434       0\n",
      "RUTW 220131C1790000  102434       0\n",
      "RUTW 220131C1800000  102434       0\n",
      "RUTW 220131C2050000  102434       0\n",
      "RUTW 220131C2060000  102434       0\n",
      "RUTW 220131C2070000  102434       0\n",
      "RUTW 220131C2500000  102434       0\n",
      "RUTW 220131C2520000  102434       0\n",
      "RUTW 220131C2530000  102434       0\n",
      "RUTW 220131C2540000  102434       0\n",
      "RUTW 220131C2550000  102434       0\n",
      "RUTW 220131C2560000  102434       0\n",
      "RUTW 220131C2570000  102434       0\n",
      "RUTW 220131C2580000  102434       0\n",
      "RUTW 220131C2590000  102434       0\n",
      "RUTW 220131C2600000  102434       0\n",
      "RUTW 220131C2610000  102434       0\n",
      "RUTW 220131C2620000  102434       0\n",
      "RUTW 220131C2630000  102434       0\n",
      "RUTW 220131C2640000  102434       0\n",
      "RUTW 220131C2660000  102434       0\n",
      "RUTW 220107P1425000  102434       0\n",
      "RUTW 220131C2700000  102434       0\n",
      "RUTW 220131C2850000  102434       0\n",
      "RUTW 220131C2900000  102434       0\n",
      "RUTW 220131C2950000  102434       0\n",
      "RUTW 220131C2510000  102434       0\n",
      "RUTW 220131C2480000  102434       0\n",
      "RUTW 220131C2080000  102434       0\n",
      "RUTW 220131C2470000  102434       0\n",
      "RUTW 220131C2090000  102434       0\n",
      "RUTW 220131C2110000  102434       0\n",
      "RUTW 220131C2120000  102434       0\n",
      "RUTW 220131C2130000  102434       0\n",
      "RUTW 220131C2140000  102434       0\n",
      "RUTW 220131C2150000  102434       0\n",
      "RUTW 220131C2160000  102434       0\n",
      "RUTW 220131C2180000  102434       0\n",
      "RUTW 220131C2190000  102434       0\n",
      "RUTW 220131C2200000  102434       0\n",
      "RUTW 220131C2210000  102434       0\n",
      "RUTW 220131C2220000  102434       0\n",
      "RUTW 220131C2270000  102434       0\n",
      "RUTW 220131C2290000  102434       0\n",
      "RUTW 220131C2310000  102434       0\n",
      "RUTW 220131C2330000  102434       0\n",
      "RUTW 220131C2340000  102434       0\n",
      "RUTW 220131C2360000  102434       0\n",
      "RUTW 220131C2370000  102434       0\n",
      "RUTW 220204C1275000  102434       0\n",
      "RUTW 220204C1280000  102434       0\n",
      "RUTW 220204C1285000  102434       0\n",
      "RUTW 220204C1920000  102434       0\n",
      "RUTW 220204C1875000  102434       0\n",
      "RUTW 220204C1880000  102434       0\n",
      "RUTW 220204C1885000  102434       0\n",
      "RUTW 220204C1890000  102434       0\n",
      "RUTW 220204C1895000  102434       0\n",
      "RUTW 220204C1900000  102434       0\n",
      "RUTW 220204C1905000  102434       0\n",
      "RUTW 220204C1910000  102434       0\n",
      "RUTW 220204C1915000  102434       0\n",
      "RUTW 220204C1925000  102434       0\n",
      "RUTW 220204C1750000  102434       0\n",
      "RUTW 220204C1930000  102434       0\n",
      "RUTW 220204C1935000  102434       0\n",
      "RUTW 220204C1940000  102434       0\n",
      "RUTW 220204C1945000  102434       0\n",
      "RUTW 220204C1950000  102434       0\n",
      "RUTW 220204C1955000  102434       0\n",
      "RUTW 220204C1960000  102434       0\n",
      "RUTW 220204C1965000  102434       0\n",
      "RUTW 220204C1970000  102434       0\n",
      "RUTW 220204C1870000  102434       0\n",
      "RUTW 220204C1865000  102434       0\n",
      "RUTW 220204C1860000  102434       0\n",
      "RUTW 220204C1855000  102434       0\n",
      "RUTW 220204C1760000  102434       0\n",
      "RUTW 220204C1765000  102434       0\n",
      "RUTW 220204C1770000  102434       0\n",
      "RUTW 220204C1775000  102434       0\n",
      "RUTW 220204C1780000  102434       0\n",
      "RUTW 220204C1785000  102434       0\n",
      "RUTW 220204C1790000  102434       0\n",
      "RUTW 220204C1795000  102434       0\n",
      "RUTW 220204C1800000  102434       0\n",
      "RUTW 220204C1805000  102434       0\n",
      "RUTW 220204C1810000  102434       0\n",
      "RUTW 220204C1815000  102434       0\n",
      "RUTW 220204C1820000  102434       0\n",
      "RUTW 220204C1825000  102434       0\n",
      "RUTW 220204C1830000  102434       0\n",
      "RUTW 220204C1835000  102434       0\n",
      "RUTW 220204C1840000  102434       0\n",
      "RUTW 220204C1845000  102434       0\n",
      "RUTW 220204C1850000  102434       0\n",
      "RUTW 220204C1975000  102434       0\n",
      "RUTW 220204C1980000  102434       0\n",
      "RUTW 220204C1985000  102434       0\n",
      "RUTW 220204C2100000  102434       0\n",
      "RUTW 220204C2110000  102434       0\n",
      "RUTW 220204C2115000  102434       0\n",
      "RUTW 220204C2120000  102434       0\n",
      "RUTW 220204C2125000  102434       0\n",
      "RUTW 220204C2130000  102434       0\n",
      "RUTW 220204C2135000  102434       0\n",
      "RUTW 220204C2140000  102434       0\n",
      "RUTW 220204C2145000  102434       0\n",
      "RUTW 220204C2150000  102434       0\n",
      "RUTW 220204C2155000  102434       0\n",
      "RUTW 220204C2160000  102434       0\n",
      "RUTW 220204C2165000  102434       0\n",
      "RUTW 220204C2170000  102434       0\n",
      "RUTW 220204C2180000  102434       0\n",
      "RUTW 220204C2185000  102434       0\n",
      "RUTW 220204C2195000  102434       0\n",
      "RUTW 220204C2200000  102434       0\n",
      "RUTW 220204C2205000  102434       0\n",
      "RUTW 220204C2210000  102434       0\n",
      "RUTW 220204C2105000  102434       0\n",
      "RUTW 220204C2095000  102434       0\n",
      "RUTW 220204C1990000  102434       0\n",
      "RUTW 220204C2090000  102434       0\n",
      "RUTW 220204C1995000  102434       0\n",
      "RUTW 220204C2000000  102434       0\n",
      "RUTW 220204C2005000  102434       0\n",
      "RUTW 220204C2010000  102434       0\n",
      "RUTW 220204C2015000  102434       0\n",
      "RUTW 220204C2020000  102434       0\n",
      "RUTW 220204C2025000  102434       0\n",
      "RUTW 220204C2030000  102434       0\n",
      "RUTW 220204C2035000  102434       0\n",
      "RUTW 220204C2040000  102434       0\n",
      "RUTW 220204C2045000  102434       0\n",
      "RUTW 220204C2050000  102434       0\n",
      "RUTW 220204C2055000  102434       0\n",
      "RUTW 220204C2060000  102434       0\n",
      "RUTW 220204C2065000  102434       0\n",
      "RUTW 220204C2070000  102434       0\n",
      "RUTW 220204C2075000  102434       0\n",
      "RUTW 220204C2080000  102434       0\n",
      "RUTW 220204C2085000  102434       0\n",
      "RUTW 220204C1755000  102434       0\n",
      "RUTW 220204C1745000  102434       0\n",
      "RUTW 220204C1290000  102434       0\n",
      "RUTW 220204C1455000  102434       0\n",
      "RUTW 220204C1410000  102434       0\n",
      "RUTW 220204C1415000  102434       0\n",
      "RUTW 220204C1420000  102434       0\n",
      "RUTW 220204C1425000  102434       0\n",
      "RUTW 220204C1430000  102434       0\n",
      "RUTW 220204C1435000  102434       0\n",
      "RUTW 220204C1440000  102434       0\n",
      "RUTW 220204C1445000  102434       0\n",
      "RUTW 220204C1450000  102434       0\n",
      "RUTW 220204C1460000  102434       0\n",
      "RUTW 220204C1740000  102434       0\n",
      "RUTW 220204C1465000  102434       0\n",
      "RUTW 220204C1470000  102434       0\n",
      "RUTW 220204C1475000  102434       0\n",
      "RUTW 220204C1480000  102434       0\n",
      "RUTW 220204C1485000  102434       0\n",
      "RUTW 220204C1490000  102434       0\n",
      "RUTW 220204C1495000  102434       0\n",
      "RUTW 220204C1500000  102434       0\n",
      "RUTW 220204C1505000  102434       0\n",
      "RUTW 220204C1405000  102434       0\n",
      "RUTW 220204C1400000  102434       0\n",
      "RUTW 220204C1395000  102434       0\n",
      "RUTW 220204C1390000  102434       0\n",
      "RUTW 220204C1295000  102434       0\n",
      "RUTW 220204C1300000  102434       0\n",
      "RUTW 220204C1305000  102434       0\n",
      "RUTW 220204C1310000  102434       0\n",
      "RUTW 220204C1315000  102434       0\n",
      "RUTW 220204C1320000  102434       0\n",
      "RUTW 220204C1325000  102434       0\n",
      "RUTW 220204C1330000  102434       0\n",
      "RUTW 220204C1335000  102434       0\n",
      "RUTW 220204C1340000  102434       0\n",
      "RUTW 220204C1345000  102434       0\n",
      "RUTW 220204C1350000  102434       0\n",
      "RUTW 220204C1355000  102434       0\n",
      "RUTW 220204C1360000  102434       0\n",
      "RUTW 220204C1365000  102434       0\n",
      "RUTW 220204C1370000  102434       0\n",
      "RUTW 220204C1375000  102434       0\n",
      "RUTW 220204C1380000  102434       0\n",
      "RUTW 220204C1385000  102434       0\n",
      "RUTW 220204C1510000  102434       0\n",
      "RUTW 220204C1515000  102434       0\n",
      "RUTW 220204C1520000  102434       0\n",
      "RUTW 220204C1635000  102434       0\n",
      "RUTW 220204C1645000  102434       0\n",
      "RUTW 220204C1650000  102434       0\n",
      "RUTW 220204C1655000  102434       0\n",
      "RUTW 220204C1660000  102434       0\n",
      "RUTW 220204C1665000  102434       0\n",
      "RUTW 220204C1670000  102434       0\n",
      "RUTW 220204C1675000  102434       0\n",
      "RUTW 220204C1680000  102434       0\n",
      "RUTW 220204C1685000  102434       0\n",
      "RUTW 220204C1690000  102434       0\n",
      "RUTW 220204C1695000  102434       0\n",
      "RUTW 220204C1700000  102434       0\n",
      "RUTW 220204C1705000  102434       0\n",
      "RUTW 220204C1710000  102434       0\n",
      "RUTW 220204C1715000  102434       0\n",
      "RUTW 220204C1720000  102434       0\n",
      "RUTW 220204C1725000  102434       0\n",
      "RUTW 220204C1730000  102434       0\n",
      "RUTW 220204C1735000  102434       0\n",
      "RUTW 220204C1640000  102434       0\n",
      "RUTW 220204C1630000  102434       0\n",
      "RUTW 220204C1525000  102434       0\n",
      "RUTW 220204C1625000  102434       0\n",
      "RUTW 220204C1530000  102434       0\n",
      "RUTW 220204C1535000  102434       0\n",
      "RUTW 220204C1540000  102434       0\n",
      "RUTW 220204C1545000  102434       0\n",
      "RUTW 220204C1550000  102434       0\n",
      "RUTW 220204C1555000  102434       0\n",
      "RUTW 220204C1560000  102434       0\n",
      "RUTW 220204C1565000  102434       0\n",
      "RUTW 220204C1570000  102434       0\n",
      "RUTW 220204C1575000  102434       0\n",
      "RUTW 220204C1580000  102434       0\n",
      "RUTW 220204C1585000  102434       0\n",
      "RUTW 220204C1590000  102434       0\n",
      "RUTW 220204C1595000  102434       0\n",
      "RUTW 220204C1600000  102434       0\n",
      "RUTW 220204C1605000  102434       0\n",
      "RUTW 220204C1610000  102434       0\n",
      "RUTW 220204C1615000  102434       0\n",
      "RUTW 220204C1620000  102434       0\n",
      "RUTW 220211C1470000  102434       0\n",
      "RUTW 220211C1480000  102434       0\n",
      "RUTW 220331C2480000  102434       0\n",
      "RUTW 220228C1200000  102434       0\n",
      "RUTW 220211P2720000  102434       0\n",
      "RUTW 220211P2725000  102434       0\n",
      "RUTW 220211P2730000  102434       0\n",
      "RUTW 220211P2735000  102434       0\n",
      "RUTW 220211P2740000  102434       0\n",
      "RUTW 220211P2745000  102434       0\n",
      "RUTW 220211P2750000  102434       0\n",
      "RUTW 220211P2755000  102434       0\n",
      "RUTW 220228C1150000  102434       0\n",
      "RUTW 220228C1250000  102434       0\n",
      "RUTW 220228C1800000  102434       0\n",
      "RUTW 220228C1300000  102434       0\n",
      "RUTW 220228C1350000  102434       0\n",
      "RUTW 220228C1400000  102434       0\n",
      "RUTW 220228C1450000  102434       0\n",
      "RUTW 220228C1500000  102434       0\n",
      "RUTW 220228C1550000  102434       0\n",
      "RUTW 220228C1600000  102434       0\n",
      "RUTW 220228C1650000  102434       0\n",
      "RUTW 220228C1700000  102434       0\n",
      "RUTW 220211P2715000  102434       0\n",
      "RUTW 220211P2710000  102434       0\n",
      "RUTW 220211P2705000  102434       0\n",
      "RUTW 220211P2700000  102434       0\n",
      "RUTW 220211P2605000  102434       0\n",
      "RUTW 220211P2610000  102434       0\n",
      "RUTW 220211P2615000  102434       0\n",
      "RUTW 220211P2620000  102434       0\n",
      "RUTW 220211P2625000  102434       0\n",
      "RUTW 220211P2630000  102434       0\n",
      "RUTW 220211P2635000  102434       0\n",
      "RUTW 220211P2640000  102434       0\n",
      "RUTW 220211P2645000  102434       0\n",
      "RUTW 220211P2650000  102434       0\n",
      "RUTW 220211P2655000  102434       0\n",
      "RUTW 220211P2660000  102434       0\n",
      "RUTW 220211P2665000  102434       0\n",
      "RUTW 220211P2670000  102434       0\n",
      "RUTW 220211P2675000  102434       0\n",
      "RUTW 220211P2680000  102434       0\n",
      "RUTW 220211P2685000  102434       0\n",
      "RUTW 220211P2690000  102434       0\n",
      "RUTW 220211P2695000  102434       0\n",
      "RUTW 220228C1750000  102434       0\n",
      "RUTW 220228C1820000  102434       0\n",
      "RUTW 220228C2540000  102434       0\n",
      "RUTW 220228C2170000  102434       0\n",
      "RUTW 220228C2070000  102434       0\n",
      "RUTW 220228C2080000  102434       0\n",
      "RUTW 220228C2090000  102434       0\n",
      "RUTW 220228C2110000  102434       0\n",
      "RUTW 220228C2120000  102434       0\n",
      "RUTW 220228C2130000  102434       0\n",
      "RUTW 220228C2140000  102434       0\n",
      "RUTW 220228C2150000  102434       0\n",
      "RUTW 220228C2160000  102434       0\n",
      "RUTW 220228C2190000  102434       0\n",
      "RUTW 220228C1830000  102434       0\n",
      "RUTW 220228C2200000  102434       0\n",
      "RUTW 220228C2210000  102434       0\n",
      "RUTW 220228C2220000  102434       0\n",
      "RUTW 220228C2240000  102434       0\n",
      "RUTW 220228C2300000  102434       0\n",
      "RUTW 220228C2310000  102434       0\n",
      "RUTW 220228C2380000  102434       0\n",
      "RUTW 220228C2460000  102434       0\n",
      "RUTW 220228C2490000  102434       0\n",
      "RUTW 220228C2060000  102434       0\n",
      "RUTW 220228C2050000  102434       0\n",
      "RUTW 220228C2040000  102434       0\n",
      "RUTW 220228C2030000  102434       0\n",
      "RUTW 220228C1840000  102434       0\n",
      "RUTW 220228C1850000  102434       0\n",
      "RUTW 220228C1860000  102434       0\n",
      "RUTW 220228C1870000  102434       0\n",
      "RUTW 220228C1880000  102434       0\n",
      "RUTW 220228C1890000  102434       0\n",
      "RUTW 220228C1900000  102434       0\n",
      "RUTW 220228C1910000  102434       0\n",
      "RUTW 220228C1920000  102434       0\n",
      "RUTW 220228C1930000  102434       0\n",
      "RUTW 220228C1940000  102434       0\n",
      "RUTW 220228C1950000  102434       0\n",
      "RUTW 220228C1960000  102434       0\n",
      "RUTW 220228C1970000  102434       0\n",
      "RUTW 220228C1980000  102434       0\n",
      "RUTW 220228C1990000  102434       0\n",
      "RUTW 220228C2000000  102434       0\n",
      "RUTW 220228C2010000  102434       0\n",
      "RUTW 220228C2020000  102434       0\n",
      "RUTW 220211P2600000  102434       0\n",
      "RUTW 220211P2595000  102434       0\n",
      "RUTW 220211P2590000  102434       0\n",
      "RUTW 220211P2295000  102434       0\n",
      "RUTW 220211P2230000  102434       0\n",
      "RUTW 220211P2235000  102434       0\n",
      "RUTW 220211P2245000  102434       0\n",
      "RUTW 220211P2260000  102434       0\n",
      "RUTW 220211P2265000  102434       0\n",
      "RUTW 220211P2270000  102434       0\n",
      "RUTW 220211P2275000  102434       0\n",
      "RUTW 220211P2285000  102434       0\n",
      "RUTW 220211P2290000  102434       0\n",
      "RUTW 220211P2305000  102434       0\n",
      "RUTW 220211P2585000  102434       0\n",
      "RUTW 220211P2310000  102434       0\n",
      "RUTW 220211P2315000  102434       0\n",
      "RUTW 220211P2320000  102434       0\n",
      "RUTW 220211P2325000  102434       0\n",
      "RUTW 220211P2330000  102434       0\n",
      "RUTW 220211P2335000  102434       0\n",
      "RUTW 220211P2340000  102434       0\n",
      "RUTW 220211P2345000  102434       0\n",
      "RUTW 220211P2350000  102434       0\n",
      "RUTW 220211P2225000  102434       0\n",
      "RUTW 220211P2220000  102434       0\n",
      "RUTW 220211P2205000  102434       0\n",
      "RUTW 220211P2175000  102434       0\n",
      "RUTW 220211P2015000  102434       0\n",
      "RUTW 220211P2020000  102434       0\n",
      "RUTW 220211P2025000  102434       0\n",
      "RUTW 220211P2035000  102434       0\n",
      "RUTW 220211P2045000  102434       0\n",
      "RUTW 220211P2055000  102434       0\n",
      "RUTW 220211P2065000  102434       0\n",
      "RUTW 220211P2085000  102434       0\n",
      "RUTW 220211P2100000  102434       0\n",
      "RUTW 220211P2115000  102434       0\n",
      "RUTW 220211P2125000  102434       0\n",
      "RUTW 220211P2135000  102434       0\n",
      "RUTW 220211P2140000  102434       0\n",
      "RUTW 220211P2145000  102434       0\n",
      "RUTW 220211P2150000  102434       0\n",
      "RUTW 220211P2155000  102434       0\n",
      "RUTW 220211P2160000  102434       0\n",
      "RUTW 220211P2165000  102434       0\n",
      "RUTW 220211P2170000  102434       0\n",
      "RUTW 220211P2355000  102434       0\n",
      "RUTW 220211P2360000  102434       0\n",
      "RUTW 220211P2365000  102434       0\n",
      "RUTW 220211P2480000  102434       0\n",
      "RUTW 220211P2490000  102434       0\n",
      "RUTW 220211P2495000  102434       0\n",
      "RUTW 220211P2500000  102434       0\n",
      "RUTW 220211P2505000  102434       0\n",
      "RUTW 220211P2510000  102434       0\n",
      "RUTW 220211P2515000  102434       0\n",
      "RUTW 220211P2520000  102434       0\n",
      "RUTW 220211P2525000  102434       0\n",
      "RUTW 220211P2530000  102434       0\n",
      "RUTW 220211P2535000  102434       0\n",
      "RUTW 220211P2540000  102434       0\n",
      "RUTW 220211P2545000  102434       0\n",
      "RUTW 220211P2550000  102434       0\n",
      "RUTW 220211P2555000  102434       0\n",
      "RUTW 220211P2560000  102434       0\n",
      "RUTW 220211P2565000  102434       0\n",
      "RUTW 220211P2570000  102434       0\n",
      "RUTW 220211P2575000  102434       0\n",
      "RUTW 220211P2580000  102434       0\n",
      "RUTW 220211P2485000  102434       0\n",
      "RUTW 220211P2475000  102434       0\n",
      "RUTW 220211P2370000  102434       0\n",
      "RUTW 220211P2470000  102434       0\n",
      "RUTW 220211P2375000  102434       0\n",
      "RUTW 220211P2380000  102434       0\n",
      "RUTW 220211P2385000  102434       0\n",
      "RUTW 220211P2390000  102434       0\n",
      "RUTW 220211P2395000  102434       0\n",
      "RUTW 220211P2400000  102434       0\n",
      "RUTW 220211P2405000  102434       0\n",
      "RUTW 220211P2410000  102434       0\n",
      "RUTW 220211P2415000  102434       0\n",
      "RUTW 220211P2420000  102434       0\n",
      "RUTW 220211P2425000  102434       0\n",
      "RUTW 220211P2430000  102434       0\n",
      "RUTW 220211P2435000  102434       0\n",
      "RUTW 220211P2440000  102434       0\n",
      "RUTW 220211P2445000  102434       0\n",
      "RUTW 220211P2450000  102434       0\n",
      "RUTW 220211P2455000  102434       0\n",
      "RUTW 220211P2460000  102434       0\n",
      "RUTW 220211P2465000  102434       0\n",
      "RUTW 220228C2530000  102434       0\n",
      "RUTW 220228C2560000  102434       0\n",
      "RUTW 220211C1485000  102434       0\n",
      "RUTW 220331C1850000  102434       0\n",
      "RUTW 220331C1600000  102434       0\n",
      "RUTW 220331C1650000  102434       0\n",
      "RUTW 220331C1700000  102434       0\n",
      "RUTW 220331C1750000  102434       0\n",
      "RUTW 220331C1800000  102434       0\n",
      "RUTW 220331C1810000  102434       0\n",
      "RUTW 220331C1820000  102434       0\n",
      "RUTW 220331C1830000  102434       0\n",
      "RUTW 220331C1840000  102434       0\n",
      "RUTW 220331C1860000  102434       0\n",
      "RUTW 220331C1970000  102434       0\n",
      "RUTW 220331C1870000  102434       0\n",
      "RUTW 220331C1880000  102434       0\n",
      "RUTW 220331C1890000  102434       0\n",
      "RUTW 220331C1900000  102434       0\n",
      "RUTW 220331C1910000  102434       0\n",
      "RUTW 220331C1920000  102434       0\n",
      "RUTW 220331C1930000  102434       0\n",
      "RUTW 220331C1940000  102434       0\n",
      "RUTW 220331C1950000  102434       0\n",
      "RUTW 220331C1450000  102434       0\n",
      "RUTW 220331C1400000  102434       0\n",
      "RUTW 220331C1350000  102434       0\n",
      "RUTW 220331C1300000  102434       0\n",
      "RUTW 220228P2720000  102434       0\n",
      "RUTW 220228P2750000  102434       0\n",
      "RUTW 220228P2800000  102434       0\n",
      "RUTW 220228P2850000  102434       0\n",
      "RUTW 220228P2900000  102434       0\n",
      "RUTW 220228P2950000  102434       0\n",
      "RUTW 220228P3000000  102434       0\n",
      "RUTW 220228P3050000  102434       0\n",
      "RUTW 220228P3100000  102434       0\n",
      "RUTW 220228P3150000  102434       0\n",
      "RUTW 220228P3200000  102434       0\n",
      "RUTW 220228P3250000  102434       0\n",
      "RUTW 220228P3300000  102434       0\n",
      "RUTW 220228P3350000  102434       0\n",
      "RUTW 220228P3400000  102434       0\n",
      "RUTW 220331C1100000  102434       0\n",
      "RUTW 220331C1150000  102434       0\n",
      "RUTW 220331C1200000  102434       0\n",
      "RUTW 220331C1250000  102434       0\n",
      "RUTW 220331C1960000  102434       0\n",
      "RUTW 220331C1980000  102434       0\n",
      "RUTW 220228C2570000  102434       0\n",
      "RUTW 220331C2360000  102434       0\n",
      "RUTW 220331C2230000  102434       0\n",
      "RUTW 220331C2240000  102434       0\n",
      "RUTW 220331C2260000  102434       0\n",
      "RUTW 220331C2270000  102434       0\n",
      "RUTW 220331C2280000  102434       0\n",
      "RUTW 220331C2290000  102434       0\n",
      "RUTW 220331C2300000  102434       0\n",
      "RUTW 220331C2310000  102434       0\n",
      "RUTW 220331C2320000  102434       0\n",
      "RUTW 220331C2370000  102434       0\n",
      "RUTW 220331C1990000  102434       0\n",
      "RUTW 220331C2380000  102434       0\n",
      "RUTW 220331C2390000  102434       0\n",
      "RUTW 220331C2410000  102434       0\n",
      "RUTW 220331C2420000  102434       0\n",
      "RUTW 220331C2430000  102434       0\n",
      "RUTW 220331C2440000  102434       0\n",
      "RUTW 220331C2450000  102434       0\n",
      "RUTW 220331C2460000  102434       0\n",
      "RUTW 220331C2470000  102434       0\n",
      "RUTW 220331C2220000  102434       0\n",
      "RUTW 220331C2210000  102434       0\n",
      "RUTW 220331C2200000  102434       0\n",
      "RUTW 220331C2190000  102434       0\n",
      "RUTW 220331C2000000  102434       0\n",
      "RUTW 220331C2010000  102434       0\n",
      "RUTW 220331C2020000  102434       0\n",
      "RUTW 220331C2030000  102434       0\n",
      "RUTW 220331C2040000  102434       0\n",
      "RUTW 220331C2050000  102434       0\n",
      "RUTW 220331C2060000  102434       0\n",
      "RUTW 220331C2070000  102434       0\n",
      "RUTW 220331C2080000  102434       0\n",
      "RUTW 220331C2090000  102434       0\n",
      "RUTW 220331C2100000  102434       0\n",
      "RUTW 220331C2110000  102434       0\n",
      "RUTW 220331C2120000  102434       0\n",
      "RUTW 220331C2130000  102434       0\n",
      "RUTW 220331C2140000  102434       0\n",
      "RUTW 220331C2150000  102434       0\n",
      "RUTW 220331C2160000  102434       0\n",
      "RUTW 220331C2170000  102434       0\n",
      "RUTW 220331C2180000  102434       0\n",
      "RUTW 220228P2710000  102434       0\n",
      "RUTW 220228P2700000  102434       0\n",
      "RUTW 220228P2690000  102434       0\n",
      "RUTW 220228P1350000  102434       0\n",
      "RUTW 220228C3200000  102434       0\n",
      "RUTW 220228C3250000  102434       0\n",
      "RUTW 220228C3300000  102434       0\n",
      "RUTW 220228C3350000  102434       0\n",
      "RUTW 220228C3400000  102434       0\n",
      "RUTW 220228P1150000  102434       0\n",
      "RUTW 220228P1200000  102434       0\n",
      "RUTW 220228P1250000  102434       0\n",
      "RUTW 220228P1300000  102434       0\n",
      "RUTW 220228P1400000  102434       0\n",
      "RUTW 220228P2680000  102434       0\n",
      "RUTW 220228P1450000  102434       0\n",
      "RUTW 220228P1500000  102434       0\n",
      "RUTW 220228P1550000  102434       0\n",
      "RUTW 220228P1600000  102434       0\n",
      "RUTW 220228P1650000  102434       0\n",
      "RUTW 220228P1700000  102434       0\n",
      "RUTW 220228P1750000  102434       0\n",
      "RUTW 220228P1800000  102434       0\n",
      "RUTW 220228P1820000  102434       0\n",
      "RUTW 220228C3150000  102434       0\n",
      "RUTW 220228C3100000  102434       0\n",
      "RUTW 220228C3050000  102434       0\n",
      "RUTW 220228C3000000  102434       0\n",
      "RUTW 220228C2580000  102434       0\n",
      "RUTW 220228C2590000  102434       0\n",
      "RUTW 220228C2600000  102434       0\n",
      "RUTW 220228C2610000  102434       0\n",
      "RUTW 220228C2630000  102434       0\n",
      "RUTW 220228C2640000  102434       0\n",
      "RUTW 220228C2650000  102434       0\n",
      "RUTW 220228C2660000  102434       0\n",
      "RUTW 220228C2670000  102434       0\n",
      "RUTW 220228C2680000  102434       0\n",
      "RUTW 220228C2690000  102434       0\n",
      "RUTW 220228C2700000  102434       0\n",
      "RUTW 220228C2710000  102434       0\n",
      "RUTW 220228C2720000  102434       0\n",
      "RUTW 220228C2750000  102434       0\n",
      "RUTW 220228C2800000  102434       0\n",
      "RUTW 220228C2850000  102434       0\n",
      "RUTW 220228C2900000  102434       0\n",
      "RUTW 220228C2950000  102434       0\n",
      "RUTW 220228P1830000  102434       0\n",
      "RUTW 220228P1850000  102434       0\n",
      "RUTW 220228P1860000  102434       0\n",
      "RUTW 220228P2470000  102434       0\n",
      "RUTW 220228P2490000  102434       0\n",
      "RUTW 220228P2500000  102434       0\n",
      "RUTW 220228P2510000  102434       0\n",
      "RUTW 220228P2520000  102434       0\n",
      "RUTW 220228P2530000  102434       0\n",
      "RUTW 220228P2540000  102434       0\n",
      "RUTW 220228P2550000  102434       0\n",
      "RUTW 220228P2560000  102434       0\n",
      "RUTW 220228P2570000  102434       0\n",
      "RUTW 220228P2580000  102434       0\n",
      "RUTW 220228P2590000  102434       0\n",
      "RUTW 220228P2600000  102434       0\n",
      "RUTW 220228P2610000  102434       0\n",
      "RUTW 220228P2620000  102434       0\n",
      "RUTW 220228P2630000  102434       0\n",
      "RUTW 220228P2640000  102434       0\n",
      "RUTW 220228P2650000  102434       0\n",
      "RUTW 220228P2660000  102434       0\n",
      "RUTW 220228P2670000  102434       0\n",
      "RUTW 220228P2480000  102434       0\n",
      "RUTW 220228P2460000  102434       0\n",
      "RUTW 220228P1870000  102434       0\n",
      "RUTW 220228P2450000  102434       0\n",
      "RUTW 220228P1880000  102434       0\n",
      "RUTW 220228P1890000  102434       0\n",
      "RUTW 220228P1900000  102434       0\n",
      "RUTW 220228P1910000  102434       0\n",
      "RUTW 220228P1930000  102434       0\n",
      "RUTW 220228P1940000  102434       0\n",
      "RUTW 220228P1980000  102434       0\n",
      "RUTW 220228P2090000  102434       0\n",
      "RUTW 220228P2340000  102434       0\n",
      "RUTW 220228P2350000  102434       0\n",
      "RUTW 220228P2360000  102434       0\n",
      "RUTW 220228P2370000  102434       0\n",
      "RUTW 220228P2380000  102434       0\n",
      "RUTW 220228P2390000  102434       0\n",
      "RUTW 220228P2400000  102434       0\n",
      "RUTW 220228P2410000  102434       0\n",
      "RUTW 220228P2420000  102434       0\n",
      "RUTW 220228P2430000  102434       0\n",
      "RUTW 220228P2440000  102434       0\n",
      "RUTW 220211P2005000  102434       0\n",
      "RUTW 220211P1995000  102434       0\n",
      "RUTW 220211P1990000  102434       0\n",
      "RUTW 220211C2120000  102434       0\n",
      "RUTW 220211C2070000  102434       0\n",
      "RUTW 220211C2075000  102434       0\n",
      "RUTW 220211C2080000  102434       0\n",
      "RUTW 220211C2085000  102434       0\n",
      "RUTW 220211C2090000  102434       0\n",
      "RUTW 220211C2095000  102434       0\n",
      "RUTW 220211C2105000  102434       0\n",
      "RUTW 220211C2110000  102434       0\n",
      "RUTW 220211C2115000  102434       0\n",
      "RUTW 220211C2125000  102434       0\n",
      "RUTW 220211C2180000  102434       0\n",
      "RUTW 220211C2130000  102434       0\n",
      "RUTW 220211C2135000  102434       0\n",
      "RUTW 220211C2140000  102434       0\n",
      "RUTW 220211C2145000  102434       0\n",
      "RUTW 220211C2150000  102434       0\n",
      "RUTW 220211C2155000  102434       0\n",
      "RUTW 220211C2160000  102434       0\n",
      "RUTW 220211C2165000  102434       0\n",
      "RUTW 220211C2170000  102434       0\n",
      "RUTW 220211C2065000  102434       0\n",
      "RUTW 220211C2060000  102434       0\n",
      "RUTW 220211C2055000  102434       0\n",
      "RUTW 220211C2050000  102434       0\n",
      "RUTW 220211C1955000  102434       0\n",
      "RUTW 220211C1960000  102434       0\n",
      "RUTW 220211C1965000  102434       0\n",
      "RUTW 220211C1970000  102434       0\n",
      "RUTW 220211C1975000  102434       0\n",
      "RUTW 220211C1980000  102434       0\n",
      "RUTW 220211C1985000  102434       0\n",
      "RUTW 220211C1990000  102434       0\n",
      "RUTW 220211C1995000  102434       0\n",
      "RUTW 220211C2000000  102434       0\n",
      "RUTW 220211C2005000  102434       0\n",
      "RUTW 220211C2010000  102434       0\n",
      "RUTW 220211C2015000  102434       0\n",
      "RUTW 220211C2020000  102434       0\n",
      "RUTW 220211C2025000  102434       0\n",
      "RUTW 220211C2030000  102434       0\n",
      "RUTW 220211C2035000  102434       0\n",
      "RUTW 220211C2040000  102434       0\n",
      "RUTW 220211C2045000  102434       0\n",
      "RUTW 220211C2175000  102434       0\n",
      "RUTW 220211C2185000  102434       0\n",
      "RUTW 220211P1975000  102434       0\n",
      "RUTW 220211C2455000  102434       0\n",
      "RUTW 220211C2365000  102434       0\n",
      "RUTW 220211C2370000  102434       0\n",
      "RUTW 220211C2385000  102434       0\n",
      "RUTW 220211C2390000  102434       0\n",
      "RUTW 220211C2395000  102434       0\n",
      "RUTW 220211C2405000  102434       0\n",
      "RUTW 220211C2410000  102434       0\n",
      "RUTW 220211C2415000  102434       0\n",
      "RUTW 220211C2435000  102434       0\n",
      "RUTW 220211C2460000  102434       0\n",
      "RUTW 220211C2190000  102434       0\n",
      "RUTW 220211C2470000  102434       0\n",
      "RUTW 220211C2480000  102434       0\n",
      "RUTW 220211C2485000  102434       0\n",
      "RUTW 220211C2490000  102434       0\n",
      "RUTW 220211C2505000  102434       0\n",
      "RUTW 220211C2515000  102434       0\n",
      "RUTW 220211C2520000  102434       0\n",
      "RUTW 220211C2530000  102434       0\n",
      "RUTW 220211C2535000  102434       0\n",
      "RUTW 220211C2355000  102434       0\n",
      "RUTW 220211C2350000  102434       0\n",
      "RUTW 220211C2345000  102434       0\n",
      "RUTW 220211C2335000  102434       0\n",
      "RUTW 220211C2195000  102434       0\n",
      "RUTW 220211C2200000  102434       0\n",
      "RUTW 220211C2205000  102434       0\n",
      "RUTW 220211C2210000  102434       0\n",
      "RUTW 220211C2215000  102434       0\n",
      "RUTW 220211C2220000  102434       0\n",
      "RUTW 220211C2225000  102434       0\n",
      "RUTW 220211C2230000  102434       0\n",
      "RUTW 220211C2235000  102434       0\n",
      "RUTW 220211C2260000  102434       0\n",
      "RUTW 220211C2265000  102434       0\n",
      "RUTW 220211C2280000  102434       0\n",
      "RUTW 220211C2295000  102434       0\n",
      "RUTW 220211C2305000  102434       0\n",
      "RUTW 220211C2310000  102434       0\n",
      "RUTW 220211C2315000  102434       0\n",
      "RUTW 220211C2320000  102434       0\n",
      "RUTW 220211C2325000  102434       0\n",
      "RUTW 220211C2330000  102434       0\n",
      "RUTW 220211C1950000  102434       0\n",
      "RUTW 220211C1945000  102434       0\n",
      "RUTW 220211C1940000  102434       0\n",
      "RUTW 220211C1650000  102434       0\n",
      "RUTW 220211C1605000  102434       0\n",
      "RUTW 220211C1610000  102434       0\n",
      "RUTW 220211C1615000  102434       0\n",
      "RUTW 220211C1620000  102434       0\n",
      "RUTW 220211C1625000  102434       0\n",
      "RUTW 220211C1630000  102434       0\n",
      "RUTW 220211C1635000  102434       0\n",
      "RUTW 220211C1640000  102434       0\n",
      "RUTW 220211C1645000  102434       0\n",
      "RUTW 220211C1655000  102434       0\n",
      "RUTW 220211C1935000  102434       0\n",
      "RUTW 220211C1660000  102434       0\n",
      "RUTW 220211C1665000  102434       0\n",
      "RUTW 220211C1670000  102434       0\n",
      "RUTW 220211C1675000  102434       0\n",
      "RUTW 220211C1680000  102434       0\n",
      "RUTW 220211C1685000  102434       0\n",
      "RUTW 220211C1690000  102434       0\n",
      "RUTW 220211C1695000  102434       0\n",
      "RUTW 220211C1700000  102434       0\n",
      "RUTW 220211C1600000  102434       0\n",
      "RUTW 220211C1595000  102434       0\n",
      "RUTW 220211C1590000  102434       0\n",
      "RUTW 220211C1585000  102434       0\n",
      "RUTW 220211C1490000  102434       0\n",
      "RUTW 220211C1495000  102434       0\n",
      "RUTW 220211C1500000  102434       0\n",
      "RUTW 220211C1505000  102434       0\n",
      "RUTW 220211C1510000  102434       0\n",
      "RUTW 220211C1515000  102434       0\n",
      "RUTW 220211C1520000  102434       0\n",
      "RUTW 220211C1525000  102434       0\n",
      "RUTW 220211C1530000  102434       0\n",
      "RUTW 220211C1535000  102434       0\n",
      "RUTW 220211C1540000  102434       0\n",
      "RUTW 220211C1545000  102434       0\n",
      "RUTW 220211C1550000  102434       0\n",
      "RUTW 220211C1555000  102434       0\n",
      "RUTW 220211C1560000  102434       0\n",
      "RUTW 220211C1565000  102434       0\n",
      "RUTW 220211C1570000  102434       0\n",
      "RUTW 220211C1575000  102434       0\n",
      "RUTW 220211C1580000  102434       0\n",
      "RUTW 220211C1705000  102434       0\n",
      "RUTW 220211C1710000  102434       0\n",
      "RUTW 220211C1715000  102434       0\n",
      "RUTW 220211C1830000  102434       0\n",
      "RUTW 220211C1840000  102434       0\n",
      "RUTW 220211C1845000  102434       0\n",
      "RUTW 220211C1850000  102434       0\n",
      "RUTW 220211C1855000  102434       0\n",
      "RUTW 220211C1860000  102434       0\n",
      "RUTW 220211C1865000  102434       0\n",
      "RUTW 220211C1870000  102434       0\n",
      "RUTW 220211C1875000  102434       0\n",
      "RUTW 220211C1880000  102434       0\n",
      "RUTW 220211C1885000  102434       0\n",
      "RUTW 220211C1890000  102434       0\n",
      "RUTW 220211C1895000  102434       0\n",
      "RUTW 220211C1900000  102434       0\n",
      "RUTW 220211C1905000  102434       0\n",
      "RUTW 220211C1910000  102434       0\n",
      "RUTW 220211C1915000  102434       0\n",
      "RUTW 220211C1920000  102434       0\n",
      "RUTW 220211C1925000  102434       0\n",
      "RUTW 220211C1930000  102434       0\n",
      "RUTW 220211C1835000  102434       0\n",
      "RUTW 220211C1825000  102434       0\n",
      "RUTW 220211C1720000  102434       0\n",
      "RUTW 220211C1820000  102434       0\n",
      "RUTW 220211C1725000  102434       0\n",
      "RUTW 220211C1730000  102434       0\n",
      "RUTW 220211C1735000  102434       0\n",
      "RUTW 220211C1740000  102434       0\n",
      "RUTW 220211C1745000  102434       0\n",
      "RUTW 220211C1750000  102434       0\n",
      "RUTW 220211C1755000  102434       0\n",
      "RUTW 220211C1760000  102434       0\n",
      "RUTW 220211C1765000  102434       0\n",
      "RUTW 220211C1770000  102434       0\n",
      "RUTW 220211C1775000  102434       0\n",
      "RUTW 220211C1780000  102434       0\n",
      "RUTW 220211C1785000  102434       0\n",
      "RUTW 220211C1790000  102434       0\n",
      "RUTW 220211C1795000  102434       0\n",
      "RUTW 220211C1800000  102434       0\n",
      "RUTW 220211C1805000  102434       0\n",
      "RUTW 220211C1810000  102434       0\n",
      "RUTW 220211C1815000  102434       0\n",
      "RUTW 220211C2540000  102434       0\n",
      "RUTW 220211C2545000  102434       0\n",
      "RUTW 220211C2555000  102434       0\n",
      "RUTW 220211P1660000  102434       0\n",
      "RUTW 220211P1615000  102434       0\n",
      "RUTW 220211P1620000  102434       0\n",
      "RUTW 220211P1625000  102434       0\n",
      "RUTW 220211P1630000  102434       0\n",
      "RUTW 220211P1635000  102434       0\n",
      "RUTW 220211P1640000  102434       0\n",
      "RUTW 220211P1645000  102434       0\n",
      "RUTW 220211P1650000  102434       0\n",
      "RUTW 220211P1655000  102434       0\n",
      "RUTW 220211P1665000  102434       0\n",
      "RUTW 220211P1485000  102434       0\n",
      "RUTW 220211P1670000  102434       0\n",
      "RUTW 220211P1675000  102434       0\n",
      "RUTW 220211P1680000  102434       0\n",
      "RUTW 220211P1685000  102434       0\n",
      "RUTW 220211P1690000  102434       0\n",
      "RUTW 220211P1695000  102434       0\n",
      "RUTW 220211P1700000  102434       0\n",
      "RUTW 220211P1705000  102434       0\n",
      "RUTW 220211P1710000  102434       0\n",
      "RUTW 220211P1610000  102434       0\n",
      "RUTW 220211P1605000  102434       0\n",
      "RUTW 220211P1600000  102434       0\n",
      "RUTW 220211P1595000  102434       0\n",
      "RUTW 220211P1495000  102434       0\n",
      "RUTW 220211P1500000  102434       0\n",
      "RUTW 220211P1505000  102434       0\n",
      "RUTW 220211P1510000  102434       0\n",
      "RUTW 220211P1515000  102434       0\n",
      "RUTW 220211P1520000  102434       0\n",
      "RUTW 220211P1525000  102434       0\n",
      "RUTW 220211P1530000  102434       0\n",
      "RUTW 220211P1535000  102434       0\n",
      "RUTW 220211P1540000  102434       0\n",
      "RUTW 220211P1545000  102434       0\n",
      "RUTW 220211P1550000  102434       0\n",
      "RUTW 220211P1555000  102434       0\n",
      "RUTW 220211P1560000  102434       0\n",
      "RUTW 220211P1565000  102434       0\n",
      "RUTW 220211P1570000  102434       0\n",
      "RUTW 220211P1575000  102434       0\n",
      "RUTW 220211P1580000  102434       0\n",
      "RUTW 220211P1585000  102434       0\n",
      "RUTW 220211P1715000  102434       0\n",
      "RUTW 220211P1720000  102434       0\n",
      "RUTW 220211P1725000  102434       0\n",
      "RUTW 220211P1845000  102434       0\n",
      "RUTW 220211P1855000  102434       0\n",
      "RUTW 220211P1860000  102434       0\n",
      "RUTW 220211P1865000  102434       0\n",
      "RUTW 220211P1875000  102434       0\n",
      "RUTW 220211P1880000  102434       0\n",
      "RUTW 220211P1885000  102434       0\n",
      "RUTW 220211P1890000  102434       0\n",
      "RUTW 220211P1895000  102434       0\n",
      "RUTW 220211P1900000  102434       0\n",
      "RUTW 220211P1905000  102434       0\n",
      "RUTW 220211P1910000  102434       0\n",
      "RUTW 220211P1920000  102434       0\n",
      "RUTW 220211P1925000  102434       0\n",
      "RUTW 220211P1930000  102434       0\n",
      "RUTW 220211P1940000  102434       0\n",
      "RUTW 220211P1945000  102434       0\n",
      "RUTW 220211P1950000  102434       0\n",
      "RUTW 220211P1955000  102434       0\n",
      "RUTW 220211P1970000  102434       0\n",
      "RUTW 220211P1850000  102434       0\n",
      "RUTW 220211P1840000  102434       0\n",
      "RUTW 220211P1730000  102434       0\n",
      "RUTW 220211P1835000  102434       0\n",
      "RUTW 220211P1735000  102434       0\n",
      "RUTW 220211P1740000  102434       0\n",
      "RUTW 220211P1745000  102434       0\n",
      "RUTW 220211P1750000  102434       0\n",
      "RUTW 220211P1755000  102434       0\n",
      "RUTW 220211P1760000  102434       0\n",
      "RUTW 220211P1765000  102434       0\n",
      "RUTW 220211P1770000  102434       0\n",
      "RUTW 220211P1775000  102434       0\n",
      "RUTW 220211P1780000  102434       0\n",
      "RUTW 220211P1785000  102434       0\n",
      "RUTW 220211P1790000  102434       0\n",
      "RUTW 220211P1795000  102434       0\n",
      "RUTW 220211P1800000  102434       0\n",
      "RUTW 220211P1805000  102434       0\n",
      "RUTW 220211P1810000  102434       0\n",
      "RUTW 220211P1815000  102434       0\n",
      "RUTW 220211P1820000  102434       0\n",
      "RUTW 220211P1825000  102434       0\n",
      "RUTW 220211P1490000  102434       0\n",
      "RUTW 220211P1480000  102434       0\n",
      "RUTW 220211C2560000  102434       0\n",
      "RUTW 220211C2730000  102434       0\n",
      "RUTW 220211C2685000  102434       0\n",
      "RUTW 220211C2690000  102434       0\n",
      "RUTW 220211C2695000  102434       0\n",
      "RUTW 220211C2700000  102434       0\n",
      "RUTW 220211C2705000  102434       0\n",
      "RUTW 220211C2710000  102434       0\n",
      "RUTW 220211C2715000  102434       0\n",
      "RUTW 220211C2720000  102434       0\n",
      "RUTW 220211C2725000  102434       0\n",
      "RUTW 220211C2735000  102434       0\n",
      "RUTW 220211P1475000  102434       0\n",
      "RUTW 220211C2740000  102434       0\n",
      "RUTW 220211C2745000  102434       0\n",
      "RUTW 220211C2750000  102434       0\n",
      "RUTW 220211C2755000  102434       0\n",
      "RUTW 220211P1220000  102434       0\n",
      "RUTW 220211P1225000  102434       0\n",
      "RUTW 220211P1230000  102434       0\n",
      "RUTW 220211P1235000  102434       0\n",
      "RUTW 220211P1240000  102434       0\n",
      "RUTW 220211C2680000  102434       0\n",
      "RUTW 220211C2675000  102434       0\n",
      "RUTW 220211C2670000  102434       0\n",
      "RUTW 220211C2665000  102434       0\n",
      "RUTW 220211C2565000  102434       0\n",
      "RUTW 220211C2570000  102434       0\n",
      "RUTW 220211C2580000  102434       0\n",
      "RUTW 220211C2585000  102434       0\n",
      "RUTW 220211C2590000  102434       0\n",
      "RUTW 220211C2595000  102434       0\n",
      "RUTW 220211C2600000  102434       0\n",
      "RUTW 220211C2605000  102434       0\n",
      "RUTW 220211C2610000  102434       0\n",
      "RUTW 220211C2615000  102434       0\n",
      "RUTW 220211C2620000  102434       0\n",
      "RUTW 220211C2625000  102434       0\n",
      "RUTW 220211C2630000  102434       0\n",
      "RUTW 220211C2635000  102434       0\n",
      "RUTW 220211C2640000  102434       0\n",
      "RUTW 220211C2645000  102434       0\n",
      "RUTW 220211C2650000  102434       0\n",
      "RUTW 220211C2655000  102434       0\n",
      "RUTW 220211C2660000  102434       0\n",
      "RUTW 220211P1245000  102434       0\n",
      "RUTW 220211P1250000  102434       0\n",
      "RUTW 220211P1255000  102434       0\n",
      "RUTW 220211P1370000  102434       0\n",
      "RUTW 220211P1380000  102434       0\n",
      "RUTW 220211P1385000  102434       0\n",
      "RUTW 220211P1390000  102434       0\n",
      "RUTW 220211P1395000  102434       0\n",
      "RUTW 220211P1400000  102434       0\n",
      "RUTW 220211P1405000  102434       0\n",
      "RUTW 220211P1410000  102434       0\n",
      "RUTW 220211P1415000  102434       0\n",
      "RUTW 220211P1420000  102434       0\n",
      "RUTW 220211P1425000  102434       0\n",
      "RUTW 220211P1430000  102434       0\n",
      "RUTW 220211P1435000  102434       0\n",
      "RUTW 220211P1440000  102434       0\n",
      "RUTW 220211P1445000  102434       0\n",
      "RUTW 220211P1450000  102434       0\n",
      "RUTW 220211P1455000  102434       0\n",
      "RUTW 220211P1460000  102434       0\n",
      "RUTW 220211P1465000  102434       0\n",
      "RUTW 220211P1470000  102434       0\n",
      "RUTW 220211P1375000  102434       0\n",
      "RUTW 220211P1365000  102434       0\n",
      "RUTW 220211P1260000  102434       0\n",
      "RUTW 220211P1360000  102434       0\n",
      "RUTW 220211P1265000  102434       0\n",
      "RUTW 220211P1270000  102434       0\n",
      "RUTW 220211P1275000  102434       0\n",
      "RUTW 220211P1280000  102434       0\n",
      "RUTW 220211P1285000  102434       0\n",
      "RUTW 220211P1290000  102434       0\n",
      "RUTW 220211P1295000  102434       0\n",
      "RUTW 220211P1300000  102434       0\n",
      "RUTW 220211P1305000  102434       0\n",
      "RUTW 220211P1310000  102434       0\n",
      "RUTW 220211P1315000  102434       0\n",
      "RUTW 220211P1320000  102434       0\n",
      "RUTW 220211P1325000  102434       0\n",
      "RUTW 220211P1330000  102434       0\n",
      "RUTW 220211P1335000  102434       0\n",
      "RUTW 220211P1340000  102434       0\n",
      "RUTW 220211P1345000  102434       0\n",
      "RUTW 220211P1350000  102434       0\n",
      "RUTW 220211P1355000  102434       0\n",
      "RUTW 220107P1430000  102434       0\n",
      "RUTW 220107C1785000  102434       0\n",
      "RUTW 220107P1420000  102434       0\n",
      "RUI 220121P3100000   100219       0\n",
      "RUI 220121P2875000   100219       0\n",
      "RUI 220121P2900000   100219       0\n",
      "RUI 220121P2925000   100219       0\n",
      "RUI 220121P2950000   100219       0\n",
      "RUI 220121P2975000   100219       0\n",
      "RUI 220121P3000000   100219       0\n",
      "RUI 220121P3025000   100219       0\n",
      "RUI 220121P3050000   100219       0\n",
      "RUI 220121P3075000   100219       0\n",
      "RUI 220121P3125000   100219       0\n",
      "RUI 220218C2540000   100219       0\n",
      "RUI 220121P3150000   100219       0\n",
      "RUI 220121P3175000   100219       0\n",
      "RUI 220121P3200000   100219       0\n",
      "RUI 220121P3225000   100219       0\n",
      "RUI 220218C1850000   100219       0\n",
      "RUI 220218C1875000   100219       0\n",
      "RUI 220218C1900000   100219       0\n",
      "RUI 220218C1925000   100219       0\n",
      "RUI 220218C1950000   100219       0\n",
      "RUI 220121P2850000   100219       0\n",
      "RUI 220121P2840000   100219       0\n",
      "RUI 220121P2830000   100219       0\n",
      "RUI 220121P2825000   100219       0\n",
      "RUI 220121P2670000   100219       0\n",
      "RUI 220121P2675000   100219       0\n",
      "RUI 220121P2680000   100219       0\n",
      "RUI 220121P2690000   100219       0\n",
      "RUI 220121P2700000   100219       0\n",
      "RUI 220121P2710000   100219       0\n",
      "RUI 220121P2720000   100219       0\n",
      "RUI 220121P2725000   100219       0\n",
      "RUI 220121P2730000   100219       0\n",
      "RUI 220121P2740000   100219       0\n",
      "RUI 220121P2750000   100219       0\n",
      "RUI 220121P2760000   100219       0\n",
      "RUI 220121P2770000   100219       0\n",
      "RUI 220121P2775000   100219       0\n",
      "RUI 220121P2780000   100219       0\n",
      "RUI 220121P2790000   100219       0\n",
      "RUI 220121P2800000   100219       0\n",
      "RUI 220121P2810000   100219       0\n",
      "RUI 220121P2820000   100219       0\n",
      "RUI 220218C1975000   100219       0\n",
      "RUI 220218C2000000   100219       0\n",
      "RUI 220218C2025000   100219       0\n",
      "RUI 220218C2360000   100219       0\n",
      "RUI 220218C2375000   100219       0\n",
      "RUI 220218C2380000   100219       0\n",
      "RUI 220218C2390000   100219       0\n",
      "RUI 220218C2400000   100219       0\n",
      "RUI 220218C2410000   100219       0\n",
      "RUI 220218C2420000   100219       0\n",
      "RUI 220218C2425000   100219       0\n",
      "RUI 220218C2430000   100219       0\n",
      "RUI 220218C2440000   100219       0\n",
      "RUI 220218C2450000   100219       0\n",
      "RUI 220218C2460000   100219       0\n",
      "RUI 220218C2470000   100219       0\n",
      "RUI 220218C2475000   100219       0\n",
      "RUI 220218C2480000   100219       0\n",
      "RUI 220218C2490000   100219       0\n",
      "RUI 220218C2500000   100219       0\n",
      "RUI 220218C2510000   100219       0\n",
      "RUI 220218C2520000   100219       0\n",
      "RUI 220218C2525000   100219       0\n",
      "RUI 220218C2370000   100219       0\n",
      "RUI 220218C2350000   100219       0\n",
      "RUI 220218C2050000   100219       0\n",
      "RUI 220218C2340000   100219       0\n",
      "RUI 220218C2075000   100219       0\n",
      "RUI 220218C2100000   100219       0\n",
      "RUI 220218C2125000   100219       0\n",
      "RUI 220218C2150000   100219       0\n",
      "RUI 220218C2175000   100219       0\n",
      "RUI 220218C2200000   100219       0\n",
      "RUI 220218C2225000   100219       0\n",
      "RUI 220218C2240000   100219       0\n",
      "RUI 220218C2250000   100219       0\n",
      "RUI 220218C2260000   100219       0\n",
      "RUI 220218C2270000   100219       0\n",
      "RUI 220218C2275000   100219       0\n",
      "RUI 220218C2280000   100219       0\n",
      "RUI 220218C2290000   100219       0\n",
      "RUI 220218C2300000   100219       0\n",
      "RUI 220218C2310000   100219       0\n",
      "RUI 220218C2320000   100219       0\n",
      "RUI 220218C2325000   100219       0\n",
      "RUI 220218C2330000   100219       0\n",
      "RUI 220121P2660000   100219       0\n",
      "RUI 220121P2650000   100219       0\n",
      "RUI 220121P2640000   100219       0\n",
      "RUI 220121P2000000   100219       0\n",
      "RUI 220121P2050000   100219       0\n",
      "RUI 220121P2075000   100219       0\n",
      "RUI 220121P2100000   100219       0\n",
      "RUI 220121P2120000   100219       0\n",
      "RUI 220121P2125000   100219       0\n",
      "RUI 220121P2130000   100219       0\n",
      "RUI 220121P2140000   100219       0\n",
      "RUI 220121P2150000   100219       0\n",
      "RUI 220121P2160000   100219       0\n",
      "RUI 220121P2170000   100219       0\n",
      "RUI 220121P2175000   100219       0\n",
      "RUI 220121P2180000   100219       0\n",
      "RUI 220121P2190000   100219       0\n",
      "RUI 220121P2200000   100219       0\n",
      "RUI 220121P2210000   100219       0\n",
      "RUI 220121P2220000   100219       0\n",
      "RUI 220121P2225000   100219       0\n",
      "RUI 220121P2230000   100219       0\n",
      "RUI 220121P2240000   100219       0\n",
      "RUI 220121P2025000   100219       0\n",
      "RUI 220121P1975000   100219       0\n",
      "RUI 220121P2260000   100219       0\n",
      "RUI 220121P1950000   100219       0\n",
      "RUI 220121C2975000   100219       0\n",
      "RUI 220121C3000000   100219       0\n",
      "RUI 220121C3025000   100219       0\n",
      "RUI 220121C3050000   100219       0\n",
      "RUI 220121C3075000   100219       0\n",
      "RUI 220121C3100000   100219       0\n",
      "RUI 220121C3125000   100219       0\n",
      "RUI 220121C3150000   100219       0\n",
      "RUI 220121C3175000   100219       0\n",
      "RUI 220121C3200000   100219       0\n",
      "RUI 220121C3225000   100219       0\n",
      "RUI 220121P1750000   100219       0\n",
      "RUI 220121P1775000   100219       0\n",
      "RUI 220121P1800000   100219       0\n",
      "RUI 220121P1825000   100219       0\n",
      "RUI 220121P1850000   100219       0\n",
      "RUI 220121P1875000   100219       0\n",
      "RUI 220121P1900000   100219       0\n",
      "RUI 220121P1925000   100219       0\n",
      "RUI 220121P2250000   100219       0\n",
      "RUI 220121P2270000   100219       0\n",
      "RUI 220121P2630000   100219       0\n",
      "RUI 220121P2460000   100219       0\n",
      "RUI 220121P2475000   100219       0\n",
      "RUI 220121P2480000   100219       0\n",
      "RUI 220121P2490000   100219       0\n",
      "RUI 220121P2500000   100219       0\n",
      "RUI 220121P2510000   100219       0\n",
      "RUI 220121P2520000   100219       0\n",
      "RUI 220121P2525000   100219       0\n",
      "RUI 220121P2530000   100219       0\n",
      "RUI 220121P2540000   100219       0\n",
      "RUI 220121P2550000   100219       0\n",
      "RUI 220121P2560000   100219       0\n",
      "RUI 220121P2570000   100219       0\n",
      "RUI 220121P2575000   100219       0\n",
      "RUI 220121P2580000   100219       0\n",
      "RUI 220121P2590000   100219       0\n",
      "RUI 220121P2600000   100219       0\n",
      "RUI 220121P2610000   100219       0\n",
      "RUI 220121P2620000   100219       0\n",
      "RUI 220121P2625000   100219       0\n",
      "RUI 220121P2470000   100219       0\n",
      "RUI 220121P2450000   100219       0\n",
      "RUI 220121P2275000   100219       0\n",
      "RUI 220121P2440000   100219       0\n",
      "RUI 220121P2280000   100219       0\n",
      "RUI 220121P2290000   100219       0\n",
      "RUI 220121P2300000   100219       0\n",
      "RUI 220121P2310000   100219       0\n",
      "RUI 220121P2320000   100219       0\n",
      "RUI 220121P2325000   100219       0\n",
      "RUI 220121P2330000   100219       0\n",
      "RUI 220121P2340000   100219       0\n",
      "RUI 220121P2350000   100219       0\n",
      "RUI 220121P2360000   100219       0\n",
      "RUI 220121P2370000   100219       0\n",
      "RUI 220121P2375000   100219       0\n",
      "RUI 220121P2380000   100219       0\n",
      "RUI 220121P2390000   100219       0\n",
      "RUI 220121P2400000   100219       0\n",
      "RUI 220121P2410000   100219       0\n",
      "RUI 220121P2420000   100219       0\n",
      "RUI 220121P2425000   100219       0\n",
      "RUI 220121P2430000   100219       0\n",
      "RUI 220218C2530000   100219       0\n",
      "RUI 220218C2550000   100219       0\n",
      "RUI 220218P3050000   100219       0\n",
      "RUI 220218P2550000   100219       0\n",
      "RUI 220218P2475000   100219       0\n",
      "RUI 220218P2480000   100219       0\n",
      "RUI 220218P2490000   100219       0\n",
      "RUI 220218P2500000   100219       0\n",
      "RUI 220218P2510000   100219       0\n",
      "RUI 220218P2520000   100219       0\n",
      "RUI 220218P2525000   100219       0\n",
      "RUI 220218P2530000   100219       0\n",
      "RUI 220218P2540000   100219       0\n",
      "RUI 220218P2560000   100219       0\n",
      "RUI 220218C2560000   100219       0\n",
      "RUI 220218P2570000   100219       0\n",
      "RUI 220218P2575000   100219       0\n",
      "RUI 220218P2580000   100219       0\n",
      "RUI 220218P2590000   100219       0\n",
      "RUI 220218P2600000   100219       0\n",
      "RUI 220218P2610000   100219       0\n",
      "RUI 220218P2620000   100219       0\n",
      "RUI 220218P2625000   100219       0\n",
      "RUI 220218P2630000   100219       0\n",
      "RUI 220218P2470000   100219       0\n",
      "RUI 220218P2460000   100219       0\n",
      "RUI 220218P2450000   100219       0\n",
      "RUI 220218P2440000   100219       0\n",
      "RUI 220218P2280000   100219       0\n",
      "RUI 220218P2290000   100219       0\n",
      "RUI 220218P2300000   100219       0\n",
      "RUI 220218P2310000   100219       0\n",
      "RUI 220218P2320000   100219       0\n",
      "RUI 220218P2325000   100219       0\n",
      "RUI 220218P2330000   100219       0\n",
      "RUI 220218P2340000   100219       0\n",
      "RUI 220218P2350000   100219       0\n",
      "RUI 220218P2360000   100219       0\n",
      "RUI 220218P2370000   100219       0\n",
      "RUI 220218P2375000   100219       0\n",
      "RUI 220218P2380000   100219       0\n",
      "RUI 220218P2390000   100219       0\n",
      "RUI 220218P2400000   100219       0\n",
      "RUI 220218P2410000   100219       0\n",
      "RUI 220218P2420000   100219       0\n",
      "RUI 220218P2425000   100219       0\n",
      "RUI 220218P2430000   100219       0\n",
      "RUI 220218P2640000   100219       0\n",
      "RUI 220218P2650000   100219       0\n",
      "RUI 220218P2660000   100219       0\n",
      "RUI 220218P2850000   100219       0\n",
      "RUI 220218P2870000   100219       0\n",
      "RUI 220218P2875000   100219       0\n",
      "RUI 220218P2880000   100219       0\n",
      "RUI 220218P2890000   100219       0\n",
      "RUI 220218P2900000   100219       0\n",
      "RUI 220218P2910000   100219       0\n",
      "RUI 220218P2920000   100219       0\n",
      "RUI 220218P2925000   100219       0\n",
      "RUI 220218P2930000   100219       0\n",
      "RUI 220218P2940000   100219       0\n",
      "RUI 220218P2950000   100219       0\n",
      "RUI 220218P2960000   100219       0\n",
      "RUI 220218P2970000   100219       0\n",
      "RUI 220218P2975000   100219       0\n",
      "RUI 220218P2980000   100219       0\n",
      "RUI 220218P2990000   100219       0\n",
      "RUI 220218P3000000   100219       0\n",
      "RUI 220218P3010000   100219       0\n",
      "RUI 220218P3020000   100219       0\n",
      "RUI 220218P2860000   100219       0\n",
      "RUI 220218P2840000   100219       0\n",
      "RUI 220218P2670000   100219       0\n",
      "RUI 220218P2830000   100219       0\n",
      "RUI 220218P2675000   100219       0\n",
      "RUI 220218P2680000   100219       0\n",
      "RUI 220218P2690000   100219       0\n",
      "RUI 220218P2700000   100219       0\n",
      "RUI 220218P2710000   100219       0\n",
      "RUI 220218P2720000   100219       0\n",
      "RUI 220218P2725000   100219       0\n",
      "RUI 220218P2730000   100219       0\n",
      "RUI 220218P2740000   100219       0\n",
      "RUI 220218P2750000   100219       0\n",
      "RUI 220218P2760000   100219       0\n",
      "RUI 220218P2770000   100219       0\n",
      "RUI 220218P2775000   100219       0\n",
      "RUI 220218P2780000   100219       0\n",
      "RUI 220218P2790000   100219       0\n",
      "RUI 220218P2800000   100219       0\n",
      "RUI 220218P2810000   100219       0\n",
      "RUI 220218P2820000   100219       0\n",
      "RUI 220218P2825000   100219       0\n",
      "RUI 220218P2275000   100219       0\n",
      "RUI 220218P2270000   100219       0\n",
      "RUI 220218P2260000   100219       0\n",
      "RUI 220218C2740000   100219       0\n",
      "RUI 220218C2760000   100219       0\n",
      "RUI 220218C2770000   100219       0\n",
      "RUI 220218C2775000   100219       0\n",
      "RUI 220218C2780000   100219       0\n",
      "RUI 220218C2790000   100219       0\n",
      "RUI 220218C2800000   100219       0\n",
      "RUI 220218C2810000   100219       0\n",
      "RUI 220218C2820000   100219       0\n",
      "RUI 220218C2825000   100219       0\n",
      "RUI 220218C2830000   100219       0\n",
      "RUI 220218C2840000   100219       0\n",
      "RUI 220218C2850000   100219       0\n",
      "RUI 220218C2860000   100219       0\n",
      "RUI 220218C2870000   100219       0\n",
      "RUI 220218C2875000   100219       0\n",
      "RUI 220218C2880000   100219       0\n",
      "RUI 220218C2890000   100219       0\n",
      "RUI 220218C2900000   100219       0\n",
      "RUI 220218C2910000   100219       0\n",
      "RUI 220218C2750000   100219       0\n",
      "RUI 220218C2730000   100219       0\n",
      "RUI 220218C2925000   100219       0\n",
      "RUI 220218C2725000   100219       0\n",
      "RUI 220218C2570000   100219       0\n",
      "RUI 220218C2575000   100219       0\n",
      "RUI 220218C2580000   100219       0\n",
      "RUI 220218C2590000   100219       0\n",
      "RUI 220218C2600000   100219       0\n",
      "RUI 220218C2610000   100219       0\n",
      "RUI 220218C2620000   100219       0\n",
      "RUI 220218C2625000   100219       0\n",
      "RUI 220218C2630000   100219       0\n",
      "RUI 220218C2640000   100219       0\n",
      "RUI 220218C2650000   100219       0\n",
      "RUI 220218C2660000   100219       0\n",
      "RUI 220218C2670000   100219       0\n",
      "RUI 220218C2675000   100219       0\n",
      "RUI 220218C2680000   100219       0\n",
      "RUI 220218C2690000   100219       0\n",
      "RUI 220218C2700000   100219       0\n",
      "RUI 220218C2710000   100219       0\n",
      "RUI 220218C2720000   100219       0\n",
      "RUI 220218C2920000   100219       0\n",
      "RUI 220218C2930000   100219       0\n",
      "RUI 220218P2250000   100219       0\n",
      "RUI 220218C3325000   100219       0\n",
      "RUI 220218C3375000   100219       0\n",
      "RUI 220218C3400000   100219       0\n",
      "RUI 220218P1850000   100219       0\n",
      "RUI 220218P1875000   100219       0\n",
      "RUI 220218P1900000   100219       0\n",
      "RUI 220218P1925000   100219       0\n",
      "RUI 220218P1950000   100219       0\n",
      "RUI 220218P1975000   100219       0\n",
      "RUI 220218P2000000   100219       0\n",
      "RUI 220218P2025000   100219       0\n",
      "RUI 220218P2050000   100219       0\n",
      "RUI 220218P2075000   100219       0\n",
      "RUI 220218P2100000   100219       0\n",
      "RUI 220218P2125000   100219       0\n",
      "RUI 220218P2150000   100219       0\n",
      "RUI 220218P2175000   100219       0\n",
      "RUI 220218P2200000   100219       0\n",
      "RUI 220218P2225000   100219       0\n",
      "RUI 220218P2240000   100219       0\n",
      "RUI 220218C3350000   100219       0\n",
      "RUI 220218C3300000   100219       0\n",
      "RUI 220218C2940000   100219       0\n",
      "RUI 220218C3275000   100219       0\n",
      "RUI 220218C2950000   100219       0\n",
      "RUI 220218C2960000   100219       0\n",
      "RUI 220218C2970000   100219       0\n",
      "RUI 220218C2975000   100219       0\n",
      "RUI 220218C2980000   100219       0\n",
      "RUI 220218C2990000   100219       0\n",
      "RUI 220218C3000000   100219       0\n",
      "RUI 220218C3010000   100219       0\n",
      "RUI 220218C3020000   100219       0\n",
      "RUI 220218C3025000   100219       0\n",
      "RUI 220218C3050000   100219       0\n",
      "RUI 220218C3075000   100219       0\n",
      "RUI 220218C3100000   100219       0\n",
      "RUI 220218C3125000   100219       0\n",
      "RUI 220218C3150000   100219       0\n",
      "RUI 220218C3175000   100219       0\n",
      "RUI 220218C3200000   100219       0\n",
      "RUI 220218C3225000   100219       0\n",
      "RUI 220218C3250000   100219       0\n",
      "RUI 220121C2950000   100219       0\n",
      "RUI 220121C2925000   100219       0\n",
      "RUI 220121C2900000   100219       0\n",
      "RLV 220617C1440000   100221       0\n",
      "RLV 220617C1370000   100221       0\n",
      "RLV 220617C1375000   100221       0\n",
      "RLV 220617C1380000   100221       0\n",
      "RLV 220617C1390000   100221       0\n",
      "RLV 220617C1400000   100221       0\n",
      "RLV 220617C1410000   100221       0\n",
      "RLV 220617C1420000   100221       0\n",
      "RLV 220617C1425000   100221       0\n",
      "RLV 220617C1430000   100221       0\n",
      "RLV 220617C1450000   100221       0\n",
      "RUI 220121C2875000   100219       0\n",
      "RLV 220617C1460000   100221       0\n",
      "RLV 220617C1470000   100221       0\n",
      "RLV 220617C1475000   100221       0\n",
      "RLV 220617C1480000   100221       0\n",
      "RLV 220617C1490000   100221       0\n",
      "RLV 220617C1500000   100221       0\n",
      "RLV 220617C1510000   100221       0\n",
      "RLV 220617C1520000   100221       0\n",
      "RLV 220617C1525000   100221       0\n",
      "RLV 220617C1350000   100221       0\n",
      "RLV 220617C1325000   100221       0\n",
      "RLV 220617C1300000   100221       0\n",
      "RLV 220617C1275000   100221       0\n",
      "RLV 220318P1775000   100221       0\n",
      "RLV 220318P1780000   100221       0\n",
      "RLV 220318P1790000   100221       0\n",
      "RLV 220318P1800000   100221       0\n",
      "RLV 220318P1825000   100221       0\n",
      "RLV 220318P1850000   100221       0\n",
      "RLV 220318P1875000   100221       0\n",
      "RLV 220318P1900000   100221       0\n",
      "RLV 220318P1925000   100221       0\n",
      "RLV 220318P1950000   100221       0\n",
      "RLV 220318P1975000   100221       0\n",
      "RLV 220318P2000000   100221       0\n",
      "RLV 220318P2025000   100221       0\n",
      "RLV 220617C1125000   100221       0\n",
      "RLV 220617C1150000   100221       0\n",
      "RLV 220617C1175000   100221       0\n",
      "RLV 220617C1200000   100221       0\n",
      "RLV 220617C1225000   100221       0\n",
      "RLV 220617C1250000   100221       0\n",
      "RLV 220617C1530000   100221       0\n",
      "RLV 220617C1540000   100221       0\n",
      "RLV 220617C1550000   100221       0\n",
      "RLV 220617C1740000   100221       0\n",
      "RLV 220617C1760000   100221       0\n",
      "RLV 220617C1770000   100221       0\n",
      "RLV 220617C1775000   100221       0\n",
      "RLV 220617C1780000   100221       0\n",
      "RLV 220617C1790000   100221       0\n",
      "RLV 220617C1800000   100221       0\n",
      "RLV 220617C1810000   100221       0\n",
      "RLV 220617C1820000   100221       0\n",
      "RLV 220617C1825000   100221       0\n",
      "RLV 220617C1830000   100221       0\n",
      "RLV 220617C1840000   100221       0\n",
      "RLV 220617C1850000   100221       0\n",
      "RLV 220617C1875000   100221       0\n",
      "RLV 220617C1900000   100221       0\n",
      "RLV 220617C1925000   100221       0\n",
      "RLV 220617C1950000   100221       0\n",
      "RLV 220617C1975000   100221       0\n",
      "RLV 220617C2000000   100221       0\n",
      "RLV 220617C2025000   100221       0\n",
      "RLV 220617C1750000   100221       0\n",
      "RLV 220617C1730000   100221       0\n",
      "RLV 220617C1560000   100221       0\n",
      "RLV 220617C1725000   100221       0\n",
      "RLV 220617C1570000   100221       0\n",
      "RLV 220617C1575000   100221       0\n",
      "RLV 220617C1580000   100221       0\n",
      "RLV 220617C1590000   100221       0\n",
      "RLV 220617C1600000   100221       0\n",
      "RLV 220617C1610000   100221       0\n",
      "RLV 220617C1620000   100221       0\n",
      "RLV 220617C1625000   100221       0\n",
      "RLV 220617C1630000   100221       0\n",
      "RLV 220617C1640000   100221       0\n",
      "RLV 220617C1650000   100221       0\n",
      "RLV 220617C1660000   100221       0\n",
      "RLV 220617C1670000   100221       0\n",
      "RLV 220617C1675000   100221       0\n",
      "RLV 220617C1680000   100221       0\n",
      "RLV 220617C1690000   100221       0\n",
      "RLV 220617C1700000   100221       0\n",
      "RLV 220617C1710000   100221       0\n",
      "RLV 220617C1720000   100221       0\n",
      "RLV 220318P1770000   100221       0\n",
      "RLV 220318P1760000   100221       0\n",
      "RLV 220318P1750000   100221       0\n",
      "RLV 220318C1800000   100221       0\n",
      "RLV 220318C1850000   100221       0\n",
      "RLV 220318C1875000   100221       0\n",
      "RLV 220318C1900000   100221       0\n",
      "RLV 220318C1925000   100221       0\n",
      "RLV 220318C1950000   100221       0\n",
      "RLV 220318C1975000   100221       0\n",
      "RLV 220318C2000000   100221       0\n",
      "RLV 220318C2025000   100221       0\n",
      "RLV 220318P1125000   100221       0\n",
      "RLV 220318P1150000   100221       0\n",
      "RLV 220318P1175000   100221       0\n",
      "RLV 220318P1200000   100221       0\n",
      "RLV 220318P1225000   100221       0\n",
      "RLV 220318P1250000   100221       0\n",
      "RLV 220318P1275000   100221       0\n",
      "RLV 220318P1300000   100221       0\n",
      "RLV 220318P1325000   100221       0\n",
      "RLV 220318P1340000   100221       0\n",
      "RLV 220318P1350000   100221       0\n",
      "RLV 220318C1825000   100221       0\n",
      "RLV 220318C1790000   100221       0\n",
      "RLV 220318P1370000   100221       0\n",
      "RLV 220318C1780000   100221       0\n",
      "RLV 220318C1625000   100221       0\n",
      "RLV 220318C1630000   100221       0\n",
      "RLV 220318C1640000   100221       0\n",
      "RLV 220318C1650000   100221       0\n",
      "RLV 220318C1660000   100221       0\n",
      "RLV 220318C1670000   100221       0\n",
      "RLV 220318C1675000   100221       0\n",
      "RLV 220318C1680000   100221       0\n",
      "RLV 220318C1690000   100221       0\n",
      "RLV 220318C1700000   100221       0\n",
      "RLV 220318C1710000   100221       0\n",
      "RLV 220318C1720000   100221       0\n",
      "RLV 220318C1725000   100221       0\n",
      "RLV 220318C1730000   100221       0\n",
      "RLV 220318C1740000   100221       0\n",
      "RLV 220318C1750000   100221       0\n",
      "RLV 220318C1760000   100221       0\n",
      "RLV 220318C1770000   100221       0\n",
      "RLV 220318C1775000   100221       0\n",
      "RLV 220318P1360000   100221       0\n",
      "RLV 220318P1375000   100221       0\n",
      "RLV 220318P1740000   100221       0\n",
      "RLV 220318P1570000   100221       0\n",
      "RLV 220318P1580000   100221       0\n",
      "RLV 220318P1590000   100221       0\n",
      "RLV 220318P1600000   100221       0\n",
      "RLV 220318P1610000   100221       0\n",
      "RLV 220318P1620000   100221       0\n",
      "RLV 220318P1625000   100221       0\n",
      "RLV 220318P1630000   100221       0\n",
      "RLV 220318P1640000   100221       0\n",
      "RLV 220318P1650000   100221       0\n",
      "RLV 220318P1660000   100221       0\n",
      "RLV 220318P1670000   100221       0\n",
      "RLV 220318P1675000   100221       0\n",
      "RLV 220318P1680000   100221       0\n",
      "RLV 220318P1690000   100221       0\n",
      "RLV 220318P1700000   100221       0\n",
      "RLV 220318P1710000   100221       0\n",
      "RLV 220318P1720000   100221       0\n",
      "RLV 220318P1725000   100221       0\n",
      "RLV 220318P1730000   100221       0\n",
      "RLV 220318P1575000   100221       0\n",
      "RLV 220318P1560000   100221       0\n",
      "RLV 220318P1380000   100221       0\n",
      "RLV 220318P1550000   100221       0\n",
      "RLV 220318P1390000   100221       0\n",
      "RLV 220318P1400000   100221       0\n",
      "RLV 220318P1410000   100221       0\n",
      "RLV 220318P1420000   100221       0\n",
      "RLV 220318P1425000   100221       0\n",
      "RLV 220318P1430000   100221       0\n",
      "RLV 220318P1440000   100221       0\n",
      "RLV 220318P1450000   100221       0\n",
      "RLV 220318P1460000   100221       0\n",
      "RLV 220318P1470000   100221       0\n",
      "RLV 220318P1475000   100221       0\n",
      "RLV 220318P1480000   100221       0\n",
      "RLV 220318P1490000   100221       0\n",
      "RLV 220318P1500000   100221       0\n",
      "RLV 220318P1510000   100221       0\n",
      "RLV 220318P1520000   100221       0\n",
      "RLV 220318P1525000   100221       0\n",
      "RLV 220318P1530000   100221       0\n",
      "RLV 220318P1540000   100221       0\n",
      "RLV 220617C2050000   100221       0\n",
      "RLV 220617C2075000   100221       0\n",
      "RLV 220617P1125000   100221       0\n",
      "RUI 220121C2300000   100219       0\n",
      "RUI 220121C2320000   100219       0\n",
      "RUI 220121C2325000   100219       0\n",
      "RUI 220121C2330000   100219       0\n",
      "RUI 220121C2340000   100219       0\n",
      "RUI 220121C2350000   100219       0\n",
      "RUI 220121C2360000   100219       0\n",
      "RUI 220121C2370000   100219       0\n",
      "RUI 220121C2375000   100219       0\n",
      "RUI 220121C2380000   100219       0\n",
      "RUI 220121C2390000   100219       0\n",
      "RUI 220121C2400000   100219       0\n",
      "RUI 220121C2410000   100219       0\n",
      "RUI 220121C2420000   100219       0\n",
      "RUI 220121C2425000   100219       0\n",
      "RUI 220121C2430000   100219       0\n",
      "RUI 220121C2440000   100219       0\n",
      "RUI 220121C2450000   100219       0\n",
      "RUI 220121C2460000   100219       0\n",
      "RUI 220121C2470000   100219       0\n",
      "RUI 220121C2310000   100219       0\n",
      "RUI 220121C2290000   100219       0\n",
      "RUI 220121C2480000   100219       0\n",
      "RUI 220121C2280000   100219       0\n",
      "RUI 220121C2125000   100219       0\n",
      "RUI 220121C2130000   100219       0\n",
      "RUI 220121C2140000   100219       0\n",
      "RUI 220121C2150000   100219       0\n",
      "RUI 220121C2160000   100219       0\n",
      "RUI 220121C2170000   100219       0\n",
      "RUI 220121C2175000   100219       0\n",
      "RUI 220121C2180000   100219       0\n",
      "RUI 220121C2190000   100219       0\n",
      "RUI 220121C2200000   100219       0\n",
      "RUI 220121C2210000   100219       0\n",
      "RUI 220121C2220000   100219       0\n",
      "RUI 220121C2225000   100219       0\n",
      "RUI 220121C2230000   100219       0\n",
      "RUI 220121C2240000   100219       0\n",
      "RUI 220121C2250000   100219       0\n",
      "RUI 220121C2260000   100219       0\n",
      "RUI 220121C2270000   100219       0\n",
      "RUI 220121C2275000   100219       0\n",
      "RUI 220121C2475000   100219       0\n",
      "RUI 220121C2490000   100219       0\n",
      "RUI 220121C2100000   100219       0\n",
      "RUI 220121C2680000   100219       0\n",
      "RUI 220121C2700000   100219       0\n",
      "RUI 220121C2710000   100219       0\n",
      "RUI 220121C2720000   100219       0\n",
      "RUI 220121C2725000   100219       0\n",
      "RUI 220121C2730000   100219       0\n",
      "RUI 220121C2740000   100219       0\n",
      "RUI 220121C2750000   100219       0\n",
      "RUI 220121C2760000   100219       0\n",
      "RUI 220121C2770000   100219       0\n",
      "RUI 220121C2775000   100219       0\n",
      "RUI 220121C2780000   100219       0\n",
      "RUI 220121C2790000   100219       0\n",
      "RUI 220121C2800000   100219       0\n",
      "RUI 220121C2810000   100219       0\n",
      "RUI 220121C2820000   100219       0\n",
      "RUI 220121C2825000   100219       0\n",
      "RUI 220121C2830000   100219       0\n",
      "RUI 220121C2840000   100219       0\n",
      "RUI 220121C2850000   100219       0\n",
      "RUI 220121C2690000   100219       0\n",
      "RUI 220121C2675000   100219       0\n",
      "RUI 220121C2500000   100219       0\n",
      "RUI 220121C2670000   100219       0\n",
      "RUI 220121C2510000   100219       0\n",
      "RUI 220121C2520000   100219       0\n",
      "RUI 220121C2525000   100219       0\n",
      "RUI 220121C2530000   100219       0\n",
      "RUI 220121C2540000   100219       0\n",
      "RUI 220121C2550000   100219       0\n",
      "RUI 220121C2560000   100219       0\n",
      "RUI 220121C2570000   100219       0\n",
      "RUI 220121C2575000   100219       0\n",
      "RUI 220121C2580000   100219       0\n",
      "RUI 220121C2590000   100219       0\n",
      "RUI 220121C2600000   100219       0\n",
      "RUI 220121C2610000   100219       0\n",
      "RUI 220121C2620000   100219       0\n",
      "RUI 220121C2625000   100219       0\n",
      "RUI 220121C2630000   100219       0\n",
      "RUI 220121C2640000   100219       0\n",
      "RUI 220121C2650000   100219       0\n",
      "RUI 220121C2660000   100219       0\n",
      "RUI 220121C2120000   100219       0\n",
      "RUI 220121C2075000   100219       0\n",
      "RLV 220617P1150000   100221       0\n",
      "RLV 220617P1475000   100221       0\n",
      "RLV 220617P1490000   100221       0\n",
      "RLV 220617P1500000   100221       0\n",
      "RLV 220617P1510000   100221       0\n",
      "RLV 220617P1520000   100221       0\n",
      "RLV 220617P1525000   100221       0\n",
      "RLV 220617P1530000   100221       0\n",
      "RLV 220617P1540000   100221       0\n",
      "RLV 220617P1550000   100221       0\n",
      "RLV 220617P1560000   100221       0\n",
      "RLV 220617P1570000   100221       0\n",
      "RLV 220617P1575000   100221       0\n",
      "RLV 220617P1580000   100221       0\n",
      "RLV 220617P1590000   100221       0\n",
      "RLV 220617P1600000   100221       0\n",
      "RLV 220617P1610000   100221       0\n",
      "RLV 220617P1620000   100221       0\n",
      "RLV 220617P1625000   100221       0\n",
      "RLV 220617P1630000   100221       0\n",
      "RLV 220617P1640000   100221       0\n",
      "RLV 220617P1480000   100221       0\n",
      "RLV 220617P1470000   100221       0\n",
      "RLV 220617P1660000   100221       0\n",
      "RLV 220617P1460000   100221       0\n",
      "RLV 220617P1175000   100221       0\n",
      "RLV 220617P1200000   100221       0\n",
      "RLV 220617P1225000   100221       0\n",
      "RLV 220617P1250000   100221       0\n",
      "RLV 220617P1275000   100221       0\n",
      "RLV 220617P1300000   100221       0\n",
      "RLV 220617P1325000   100221       0\n",
      "RLV 220617P1350000   100221       0\n",
      "RLV 220617P1370000   100221       0\n",
      "RLV 220617P1375000   100221       0\n",
      "RLV 220617P1380000   100221       0\n",
      "RLV 220617P1390000   100221       0\n",
      "RLV 220617P1400000   100221       0\n",
      "RLV 220617P1410000   100221       0\n",
      "RLV 220617P1420000   100221       0\n",
      "RLV 220617P1425000   100221       0\n",
      "RLV 220617P1430000   100221       0\n",
      "RLV 220617P1440000   100221       0\n",
      "RLV 220617P1450000   100221       0\n",
      "RLV 220617P1650000   100221       0\n",
      "RLV 220617P1670000   100221       0\n",
      "RUI 220121C2050000   100219       0\n",
      "RLV 220617P1875000   100221       0\n",
      "RLV 220617P1925000   100221       0\n",
      "RLV 220617P1950000   100221       0\n",
      "RLV 220617P1975000   100221       0\n",
      "RLV 220617P2000000   100221       0\n",
      "RLV 220617P2025000   100221       0\n",
      "RLV 220617P2050000   100221       0\n",
      "RLV 220617P2075000   100221       0\n",
      "RUI 220121C1750000   100219       0\n",
      "RUI 220121C1775000   100219       0\n",
      "RUI 220121C1800000   100219       0\n",
      "RUI 220121C1825000   100219       0\n",
      "RUI 220121C1850000   100219       0\n",
      "RUI 220121C1875000   100219       0\n",
      "RUI 220121C1900000   100219       0\n",
      "RUI 220121C1925000   100219       0\n",
      "RUI 220121C1950000   100219       0\n",
      "RUI 220121C1975000   100219       0\n",
      "RUI 220121C2000000   100219       0\n",
      "RUI 220121C2025000   100219       0\n",
      "RLV 220617P1900000   100221       0\n",
      "RLV 220617P1850000   100221       0\n",
      "RLV 220617P1675000   100221       0\n",
      "RLV 220617P1840000   100221       0\n",
      "RLV 220617P1680000   100221       0\n",
      "RLV 220617P1690000   100221       0\n",
      "RLV 220617P1700000   100221       0\n",
      "RLV 220617P1710000   100221       0\n",
      "RLV 220617P1720000   100221       0\n",
      "RLV 220617P1725000   100221       0\n",
      "RLV 220617P1730000   100221       0\n",
      "RLV 220617P1740000   100221       0\n",
      "RLV 220617P1750000   100221       0\n",
      "RLV 220617P1760000   100221       0\n",
      "RLV 220617P1770000   100221       0\n",
      "RLV 220617P1775000   100221       0\n",
      "RLV 220617P1780000   100221       0\n",
      "RLV 220617P1790000   100221       0\n",
      "RLV 220617P1800000   100221       0\n",
      "RLV 220617P1810000   100221       0\n",
      "RLV 220617P1820000   100221       0\n",
      "RLV 220617P1825000   100221       0\n",
      "RLV 220617P1830000   100221       0\n",
      "RUI 220218P3025000   100219       0\n",
      "RUI 220218P3075000   100219       0\n",
      "RUTW 220107P1415000  102434       0\n",
      "RUI 220916C2330000   100219       0\n",
      "RUI 220916C2260000   100219       0\n",
      "RUI 220916C2270000   100219       0\n",
      "RUI 220916C2275000   100219       0\n",
      "RUI 220916C2280000   100219       0\n",
      "RUI 220916C2290000   100219       0\n",
      "RUI 220916C2300000   100219       0\n",
      "RUI 220916C2310000   100219       0\n",
      "RUI 220916C2320000   100219       0\n",
      "RUI 220916C2325000   100219       0\n",
      "RUI 220916C2340000   100219       0\n",
      "RUI 220916C2820000   100219       0\n",
      "RUI 220916C2350000   100219       0\n",
      "RUI 220916C2360000   100219       0\n",
      "RUI 220916C2370000   100219       0\n",
      "RUI 220916C2375000   100219       0\n",
      "RUI 220916C2380000   100219       0\n",
      "RUI 220916C2390000   100219       0\n",
      "RUI 220916C2400000   100219       0\n",
      "RUI 220916C2410000   100219       0\n",
      "RUI 220916C2420000   100219       0\n",
      "RUI 220916C2250000   100219       0\n",
      "RUI 220916C2240000   100219       0\n",
      "RUI 220916C2230000   100219       0\n",
      "RUI 220916C2225000   100219       0\n",
      "RUI 220916C1950000   100219       0\n",
      "RUI 220916C1975000   100219       0\n",
      "RUI 220916C2000000   100219       0\n",
      "RUI 220916C2025000   100219       0\n",
      "RUI 220916C2050000   100219       0\n",
      "RUI 220916C2075000   100219       0\n",
      "RUI 220916C2100000   100219       0\n",
      "RUI 220916C2125000   100219       0\n",
      "RUI 220916C2130000   100219       0\n",
      "RUI 220916C2140000   100219       0\n",
      "RUI 220916C2150000   100219       0\n",
      "RUI 220916C2160000   100219       0\n",
      "RUI 220916C2170000   100219       0\n",
      "RUI 220916C2175000   100219       0\n",
      "RUI 220916C2180000   100219       0\n",
      "RUI 220916C2190000   100219       0\n",
      "RUI 220916C2200000   100219       0\n",
      "RUI 220916C2210000   100219       0\n",
      "RUI 220916C2220000   100219       0\n",
      "RUI 220916C2425000   100219       0\n",
      "RUI 220916C2430000   100219       0\n",
      "RUI 220916C2440000   100219       0\n",
      "RUI 220916C2630000   100219       0\n",
      "RUI 220916C2650000   100219       0\n",
      "RUI 220916C2660000   100219       0\n",
      "RUI 220916C2670000   100219       0\n",
      "RUI 220916C2675000   100219       0\n",
      "RUI 220916C2680000   100219       0\n",
      "RUI 220916C2690000   100219       0\n",
      "RUI 220916C2700000   100219       0\n",
      "RUI 220916C2710000   100219       0\n",
      "RUI 220916C2720000   100219       0\n",
      "RUI 220916C2725000   100219       0\n",
      "RUI 220916C2730000   100219       0\n",
      "RUI 220916C2740000   100219       0\n",
      "RUI 220916C2750000   100219       0\n",
      "RUI 220916C2760000   100219       0\n",
      "RUI 220916C2770000   100219       0\n",
      "RUI 220916C2775000   100219       0\n",
      "RUI 220916C2780000   100219       0\n",
      "RUI 220916C2790000   100219       0\n",
      "RUI 220916C2800000   100219       0\n",
      "RUI 220916C2640000   100219       0\n",
      "RUI 220916C2625000   100219       0\n",
      "RUI 220916C2450000   100219       0\n",
      "RUI 220916C2620000   100219       0\n",
      "RUI 220916C2460000   100219       0\n",
      "RUI 220916C2470000   100219       0\n",
      "RUI 220916C2475000   100219       0\n",
      "RUI 220916C2480000   100219       0\n",
      "RUI 220916C2490000   100219       0\n",
      "RUI 220916C2500000   100219       0\n",
      "RUI 220916C2510000   100219       0\n",
      "RUI 220916C2520000   100219       0\n",
      "RUI 220916C2525000   100219       0\n",
      "RUI 220916C2530000   100219       0\n",
      "RUI 220916C2540000   100219       0\n",
      "RUI 220916C2550000   100219       0\n",
      "RUI 220916C2560000   100219       0\n",
      "RUI 220916C2570000   100219       0\n",
      "RUI 220916C2575000   100219       0\n",
      "RUI 220916C2580000   100219       0\n",
      "RUI 220916C2590000   100219       0\n",
      "RUI 220916C2600000   100219       0\n",
      "RUI 220916C2610000   100219       0\n",
      "RUI 220916C1925000   100219       0\n",
      "RUI 220916C1900000   100219       0\n",
      "RUI 220916C1875000   100219       0\n",
      "RUI 220617P2320000   100219       0\n",
      "RUI 220617P2330000   100219       0\n",
      "RUI 220617P2340000   100219       0\n",
      "RUI 220617P2350000   100219       0\n",
      "RUI 220617P2360000   100219       0\n",
      "RUI 220617P2370000   100219       0\n",
      "RUI 220617P2375000   100219       0\n",
      "RUI 220617P2380000   100219       0\n",
      "RUI 220617P2390000   100219       0\n",
      "RUI 220617P2400000   100219       0\n",
      "RUI 220617P2410000   100219       0\n",
      "RUI 220617P2420000   100219       0\n",
      "RUI 220617P2425000   100219       0\n",
      "RUI 220617P2430000   100219       0\n",
      "RUI 220617P2440000   100219       0\n",
      "RUI 220617P2450000   100219       0\n",
      "RUI 220617P2460000   100219       0\n",
      "RUI 220617P2470000   100219       0\n",
      "RUI 220617P2475000   100219       0\n",
      "RUI 220617P2480000   100219       0\n",
      "RUI 220617P2325000   100219       0\n",
      "RUI 220617P2310000   100219       0\n",
      "RUI 220617P2500000   100219       0\n",
      "RUI 220617P2300000   100219       0\n",
      "RUI 220617P2140000   100219       0\n",
      "RUI 220617P2150000   100219       0\n",
      "RUI 220617P2160000   100219       0\n",
      "RUI 220617P2170000   100219       0\n",
      "RUI 220617P2175000   100219       0\n",
      "RUI 220617P2180000   100219       0\n",
      "RUI 220617P2190000   100219       0\n",
      "RUI 220617P2200000   100219       0\n",
      "RUI 220617P2210000   100219       0\n",
      "RUI 220617P2220000   100219       0\n",
      "RUI 220617P2225000   100219       0\n",
      "RUI 220617P2230000   100219       0\n",
      "RUI 220617P2240000   100219       0\n",
      "RUI 220617P2250000   100219       0\n",
      "RUI 220617P2260000   100219       0\n",
      "RUI 220617P2270000   100219       0\n",
      "RUI 220617P2275000   100219       0\n",
      "RUI 220617P2280000   100219       0\n",
      "RUI 220617P2290000   100219       0\n",
      "RUI 220617P2490000   100219       0\n",
      "RUI 220617P2510000   100219       0\n",
      "RUI 220916C1850000   100219       0\n",
      "RUI 220617P2700000   100219       0\n",
      "RUI 220617P2720000   100219       0\n",
      "RUI 220617P2725000   100219       0\n",
      "RUI 220617P2750000   100219       0\n",
      "RUI 220617P2775000   100219       0\n",
      "RUI 220617P2800000   100219       0\n",
      "RUI 220617P2825000   100219       0\n",
      "RUI 220617P2850000   100219       0\n",
      "RUI 220617P2875000   100219       0\n",
      "RUI 220617P2900000   100219       0\n",
      "RUI 220617P2925000   100219       0\n",
      "RUI 220617P2950000   100219       0\n",
      "RUI 220617P2975000   100219       0\n",
      "RUI 220617P3000000   100219       0\n",
      "RUI 220617P3025000   100219       0\n",
      "RUI 220617P3050000   100219       0\n",
      "RUI 220617P3075000   100219       0\n",
      "RUI 220916C1775000   100219       0\n",
      "RUI 220916C1800000   100219       0\n",
      "RUI 220916C1825000   100219       0\n",
      "RUI 220617P2710000   100219       0\n",
      "RUI 220617P2690000   100219       0\n",
      "RUI 220617P2520000   100219       0\n",
      "RUI 220617P2680000   100219       0\n",
      "RUI 220617P2525000   100219       0\n",
      "RUI 220617P2530000   100219       0\n",
      "RUI 220617P2540000   100219       0\n",
      "RUI 220617P2550000   100219       0\n",
      "RUI 220617P2560000   100219       0\n",
      "RUI 220617P2570000   100219       0\n",
      "RUI 220617P2575000   100219       0\n",
      "RUI 220617P2580000   100219       0\n",
      "RUI 220617P2590000   100219       0\n",
      "RUI 220617P2600000   100219       0\n",
      "RUI 220617P2610000   100219       0\n",
      "RUI 220617P2620000   100219       0\n",
      "RUI 220617P2625000   100219       0\n",
      "RUI 220617P2630000   100219       0\n",
      "RUI 220617P2640000   100219       0\n",
      "RUI 220617P2650000   100219       0\n",
      "RUI 220617P2660000   100219       0\n",
      "RUI 220617P2670000   100219       0\n",
      "RUI 220617P2675000   100219       0\n",
      "RUI 220916C2810000   100219       0\n",
      "RUI 220916C2825000   100219       0\n",
      "RUI 220218P3100000   100219       0\n",
      "RUI 220916P2875000   100219       0\n",
      "RUI 220916P2800000   100219       0\n",
      "RUI 220916P2810000   100219       0\n",
      "RUI 220916P2820000   100219       0\n",
      "RUI 220916P2825000   100219       0\n",
      "RUI 220916P2830000   100219       0\n",
      "RUI 220916P2840000   100219       0\n",
      "RUI 220916P2850000   100219       0\n",
      "RUI 220916P2860000   100219       0\n",
      "RUI 220916P2870000   100219       0\n",
      "RUI 220916P2900000   100219       0\n",
      "RUI 220916C2830000   100219       0\n",
      "RUI 220916P2925000   100219       0\n",
      "RUI 220916P2950000   100219       0\n",
      "RUI 220916P2975000   100219       0\n",
      "RUI 220916P3000000   100219       0\n",
      "RUI 220916P3025000   100219       0\n",
      "RUI 220916P3050000   100219       0\n",
      "RUI 220916P3075000   100219       0\n",
      "RUI 220916P3100000   100219       0\n",
      "RUI 220916P3125000   100219       0\n",
      "RUI 220916P2790000   100219       0\n",
      "RUI 220916P2780000   100219       0\n",
      "RUI 220916P2775000   100219       0\n",
      "RUI 220916P2770000   100219       0\n",
      "RUI 220916P2610000   100219       0\n",
      "RUI 220916P2620000   100219       0\n",
      "RUI 220916P2625000   100219       0\n",
      "RUI 220916P2630000   100219       0\n",
      "RUI 220916P2640000   100219       0\n",
      "RUI 220916P2650000   100219       0\n",
      "RUI 220916P2660000   100219       0\n",
      "RUI 220916P2670000   100219       0\n",
      "RUI 220916P2675000   100219       0\n",
      "RUI 220916P2680000   100219       0\n",
      "RUI 220916P2690000   100219       0\n",
      "RUI 220916P2700000   100219       0\n",
      "RUI 220916P2710000   100219       0\n",
      "RUI 220916P2720000   100219       0\n",
      "RUI 220916P2725000   100219       0\n",
      "RUI 220916P2730000   100219       0\n",
      "RUI 220916P2740000   100219       0\n",
      "RUI 220916P2750000   100219       0\n",
      "RUI 220916P2760000   100219       0\n",
      "RUI 220916P3150000   100219       0\n",
      "RUI 220916P3175000   100219       0\n",
      "RUI 220916P3200000   100219       0\n",
      "RUI 221216C2270000   100219       0\n",
      "RUI 221216C2280000   100219       0\n",
      "RUI 221216C2290000   100219       0\n",
      "RUI 221216C2300000   100219       0\n",
      "RUI 221216C2310000   100219       0\n",
      "RUI 221216C2320000   100219       0\n",
      "RUI 221216C2325000   100219       0\n",
      "RUI 221216C2330000   100219       0\n",
      "RUI 221216C2340000   100219       0\n",
      "RUI 221216C2350000   100219       0\n",
      "RUI 221216C2360000   100219       0\n",
      "RUI 221216C2370000   100219       0\n",
      "RUI 221216C2375000   100219       0\n",
      "RUI 221216C2380000   100219       0\n",
      "RUI 221216C2390000   100219       0\n",
      "RUI 221216C2400000   100219       0\n",
      "RUI 221216C2410000   100219       0\n",
      "RUI 221216C2420000   100219       0\n",
      "RUI 221216C2425000   100219       0\n",
      "RUI 221216C2430000   100219       0\n",
      "RUI 221216C2275000   100219       0\n",
      "RUI 221216C2260000   100219       0\n",
      "RUI 220916P3225000   100219       0\n",
      "RUI 221216C2250000   100219       0\n",
      "RUI 220916P3250000   100219       0\n",
      "RUI 221216C1850000   100219       0\n",
      "RUI 221216C1875000   100219       0\n",
      "RUI 221216C1900000   100219       0\n",
      "RUI 221216C1925000   100219       0\n",
      "RUI 221216C1950000   100219       0\n",
      "RUI 221216C1975000   100219       0\n",
      "RUI 221216C2000000   100219       0\n",
      "RUI 221216C2025000   100219       0\n",
      "RUI 221216C2050000   100219       0\n",
      "RUI 221216C2075000   100219       0\n",
      "RUI 221216C2100000   100219       0\n",
      "RUI 221216C2125000   100219       0\n",
      "RUI 221216C2150000   100219       0\n",
      "RUI 221216C2175000   100219       0\n",
      "RUI 221216C2200000   100219       0\n",
      "RUI 221216C2225000   100219       0\n",
      "RUI 221216C2230000   100219       0\n",
      "RUI 221216C2240000   100219       0\n",
      "RUI 220916P2600000   100219       0\n",
      "RUI 220916P2590000   100219       0\n",
      "RUI 220916P2580000   100219       0\n",
      "RUI 220916P1800000   100219       0\n",
      "RUI 220916P1850000   100219       0\n",
      "RUI 220916P1875000   100219       0\n",
      "RUI 220916P1900000   100219       0\n",
      "RUI 220916P1925000   100219       0\n",
      "RUI 220916P1950000   100219       0\n",
      "RUI 220916P1975000   100219       0\n",
      "RUI 220916P2000000   100219       0\n",
      "RUI 220916P2025000   100219       0\n",
      "RUI 220916P2050000   100219       0\n",
      "RUI 220916P2075000   100219       0\n",
      "RUI 220916P2100000   100219       0\n",
      "RUI 220916P2125000   100219       0\n",
      "RUI 220916P2130000   100219       0\n",
      "RUI 220916P2140000   100219       0\n",
      "RUI 220916P2150000   100219       0\n",
      "RUI 220916P2160000   100219       0\n",
      "RUI 220916P2170000   100219       0\n",
      "RUI 220916P2175000   100219       0\n",
      "RUI 220916P2180000   100219       0\n",
      "RUI 220916P1825000   100219       0\n",
      "RUI 220916P1775000   100219       0\n",
      "RUI 220916P2200000   100219       0\n",
      "RUI 220916C3250000   100219       0\n",
      "RUI 220916C2840000   100219       0\n",
      "RUI 220916C2850000   100219       0\n",
      "RUI 220916C2860000   100219       0\n",
      "RUI 220916C2870000   100219       0\n",
      "RUI 220916C2875000   100219       0\n",
      "RUI 220916C2900000   100219       0\n",
      "RUI 220916C2925000   100219       0\n",
      "RUI 220916C2950000   100219       0\n",
      "RUI 220916C2975000   100219       0\n",
      "RUI 220916C3000000   100219       0\n",
      "RUI 220916C3025000   100219       0\n",
      "RUI 220916C3050000   100219       0\n",
      "RUI 220916C3075000   100219       0\n",
      "RUI 220916C3100000   100219       0\n",
      "RUI 220916C3125000   100219       0\n",
      "RUI 220916C3150000   100219       0\n",
      "RUI 220916C3175000   100219       0\n",
      "RUI 220916C3200000   100219       0\n",
      "RUI 220916C3225000   100219       0\n",
      "RUI 220916P2190000   100219       0\n",
      "RUI 220916P2210000   100219       0\n",
      "RUI 220916P2575000   100219       0\n",
      "RUI 220916P2400000   100219       0\n",
      "RUI 220916P2420000   100219       0\n",
      "RUI 220916P2425000   100219       0\n",
      "RUI 220916P2430000   100219       0\n",
      "RUI 220916P2440000   100219       0\n",
      "RUI 220916P2450000   100219       0\n",
      "RUI 220916P2460000   100219       0\n",
      "RUI 220916P2470000   100219       0\n",
      "RUI 220916P2475000   100219       0\n",
      "RUI 220916P2480000   100219       0\n",
      "RUI 220916P2490000   100219       0\n",
      "RUI 220916P2500000   100219       0\n",
      "RUI 220916P2510000   100219       0\n",
      "RUI 220916P2520000   100219       0\n",
      "RUI 220916P2525000   100219       0\n",
      "RUI 220916P2530000   100219       0\n",
      "RUI 220916P2540000   100219       0\n",
      "RUI 220916P2550000   100219       0\n",
      "RUI 220916P2560000   100219       0\n",
      "RUI 220916P2570000   100219       0\n",
      "RUI 220916P2410000   100219       0\n",
      "RUI 220916P2390000   100219       0\n",
      "RUI 220916P2220000   100219       0\n",
      "RUI 220916P2380000   100219       0\n",
      "RUI 220916P2225000   100219       0\n",
      "RUI 220916P2230000   100219       0\n",
      "RUI 220916P2240000   100219       0\n",
      "RUI 220916P2250000   100219       0\n",
      "RUI 220916P2260000   100219       0\n",
      "RUI 220916P2270000   100219       0\n",
      "RUI 220916P2275000   100219       0\n",
      "RUI 220916P2280000   100219       0\n",
      "RUI 220916P2290000   100219       0\n",
      "RUI 220916P2300000   100219       0\n",
      "RUI 220916P2310000   100219       0\n",
      "RUI 220916P2320000   100219       0\n",
      "RUI 220916P2325000   100219       0\n",
      "RUI 220916P2330000   100219       0\n",
      "RUI 220916P2340000   100219       0\n",
      "RUI 220916P2350000   100219       0\n",
      "RUI 220916P2360000   100219       0\n",
      "RUI 220916P2370000   100219       0\n",
      "RUI 220916P2375000   100219       0\n",
      "RUI 220617P2130000   100219       0\n",
      "RUI 220617P2125000   100219       0\n",
      "RUI 220617P2120000   100219       0\n",
      "RUI 220318P1700000   100219       0\n",
      "RUI 220318C2825000   100219       0\n",
      "RUI 220318C2850000   100219       0\n",
      "RUI 220318C2875000   100219       0\n",
      "RUI 220318C2900000   100219       0\n",
      "RUI 220318P1575000   100219       0\n",
      "RUI 220318P1600000   100219       0\n",
      "RUI 220318P1625000   100219       0\n",
      "RUI 220318P1650000   100219       0\n",
      "RUI 220318P1675000   100219       0\n",
      "RUI 220318P1725000   100219       0\n",
      "RUI 220617P2110000   100219       0\n",
      "RUI 220318P1750000   100219       0\n",
      "RUI 220318P1775000   100219       0\n",
      "RUI 220318P1800000   100219       0\n",
      "RUI 220318P1825000   100219       0\n",
      "RUI 220318P1850000   100219       0\n",
      "RUI 220318P1875000   100219       0\n",
      "RUI 220318P1900000   100219       0\n",
      "RUI 220318P1910000   100219       0\n",
      "RUI 220318P1920000   100219       0\n",
      "RUI 220318C2800000   100219       0\n",
      "RUI 220318C2775000   100219       0\n",
      "RUI 220318C2750000   100219       0\n",
      "RUI 220318C2725000   100219       0\n",
      "RUI 220318C2460000   100219       0\n",
      "RUI 220318C2470000   100219       0\n",
      "RUI 220318C2475000   100219       0\n",
      "RUI 220318C2480000   100219       0\n",
      "RUI 220318C2490000   100219       0\n",
      "RUI 220318C2500000   100219       0\n",
      "RUI 220318C2510000   100219       0\n",
      "RUI 220318C2520000   100219       0\n",
      "RUI 220318C2525000   100219       0\n",
      "RUI 220318C2530000   100219       0\n",
      "RUI 220318C2540000   100219       0\n",
      "RUI 220318C2550000   100219       0\n",
      "RUI 220318C2560000   100219       0\n",
      "RUI 220318C2575000   100219       0\n",
      "RUI 220318C2600000   100219       0\n",
      "RUI 220318C2625000   100219       0\n",
      "RUI 220318C2650000   100219       0\n",
      "RUI 220318C2675000   100219       0\n",
      "RUI 220318C2700000   100219       0\n",
      "RUI 220318P1925000   100219       0\n",
      "RUI 220318P1930000   100219       0\n",
      "RUI 220318P1940000   100219       0\n",
      "RUI 220318P2130000   100219       0\n",
      "RUI 220318P2150000   100219       0\n",
      "RUI 220318P2160000   100219       0\n",
      "RUI 220318P2170000   100219       0\n",
      "RUI 220318P2175000   100219       0\n",
      "RUI 220318P2180000   100219       0\n",
      "RUI 220318P2190000   100219       0\n",
      "RUI 220318P2200000   100219       0\n",
      "RUI 220318P2210000   100219       0\n",
      "RUI 220318P2220000   100219       0\n",
      "RUI 220318P2225000   100219       0\n",
      "RUI 220318P2230000   100219       0\n",
      "RUI 220318P2240000   100219       0\n",
      "RUI 220318P2250000   100219       0\n",
      "RUI 220318P2260000   100219       0\n",
      "RUI 220318P2270000   100219       0\n",
      "RUI 220318P2275000   100219       0\n",
      "RUI 220318P2280000   100219       0\n",
      "RUI 220318P2290000   100219       0\n",
      "RUI 220318P2300000   100219       0\n",
      "RUI 220318P2140000   100219       0\n",
      "RUI 220318P2125000   100219       0\n",
      "RUI 220318P1950000   100219       0\n",
      "RUI 220318P2120000   100219       0\n",
      "RUI 220318P1960000   100219       0\n",
      "RUI 220318P1970000   100219       0\n",
      "RUI 220318P1975000   100219       0\n",
      "RUI 220318P1980000   100219       0\n",
      "RUI 220318P1990000   100219       0\n",
      "RUI 220318P2000000   100219       0\n",
      "RUI 220318P2010000   100219       0\n",
      "RUI 220318P2020000   100219       0\n",
      "RUI 220318P2025000   100219       0\n",
      "RUI 220318P2030000   100219       0\n",
      "RUI 220318P2040000   100219       0\n",
      "RUI 220318P2050000   100219       0\n",
      "RUI 220318P2060000   100219       0\n",
      "RUI 220318P2070000   100219       0\n",
      "RUI 220318P2075000   100219       0\n",
      "RUI 220318P2080000   100219       0\n",
      "RUI 220318P2090000   100219       0\n",
      "RUI 220318P2100000   100219       0\n",
      "RUI 220318P2110000   100219       0\n",
      "RUI 220318C2450000   100219       0\n",
      "RUI 220318C2440000   100219       0\n",
      "RUI 220318C2430000   100219       0\n",
      "RUI 220318C1800000   100219       0\n",
      "RUI 220318C1850000   100219       0\n",
      "RUI 220318C1875000   100219       0\n",
      "RUI 220318C1900000   100219       0\n",
      "RUI 220318C1910000   100219       0\n",
      "RUI 220318C1920000   100219       0\n",
      "RUI 220318C1925000   100219       0\n",
      "RUI 220318C1930000   100219       0\n",
      "RUI 220318C1940000   100219       0\n",
      "RUI 220318C1950000   100219       0\n",
      "RUI 220318C1960000   100219       0\n",
      "RUI 220318C1970000   100219       0\n",
      "RUI 220318C1975000   100219       0\n",
      "RUI 220318C1980000   100219       0\n",
      "RUI 220318C1990000   100219       0\n",
      "RUI 220318C2000000   100219       0\n",
      "RUI 220318C2010000   100219       0\n",
      "RUI 220318C2020000   100219       0\n",
      "RUI 220318C2025000   100219       0\n",
      "RUI 220318C2030000   100219       0\n",
      "RUI 220318C1825000   100219       0\n",
      "RUI 220318C1775000   100219       0\n",
      "RUI 220318C2050000   100219       0\n",
      "RUI 220318C1750000   100219       0\n",
      "RUI 220218P3125000   100219       0\n",
      "RUI 220218P3150000   100219       0\n",
      "RUI 220218P3175000   100219       0\n",
      "RUI 220218P3200000   100219       0\n",
      "RUI 220218P3225000   100219       0\n",
      "RUI 220218P3250000   100219       0\n",
      "RUI 220218P3275000   100219       0\n",
      "RUI 220218P3300000   100219       0\n",
      "RUI 220218P3325000   100219       0\n",
      "RUI 220218P3350000   100219       0\n",
      "RUI 220218P3375000   100219       0\n",
      "RUI 220218P3400000   100219       0\n",
      "RUI 220318C1575000   100219       0\n",
      "RUI 220318C1600000   100219       0\n",
      "RUI 220318C1625000   100219       0\n",
      "RUI 220318C1650000   100219       0\n",
      "RUI 220318C1675000   100219       0\n",
      "RUI 220318C1700000   100219       0\n",
      "RUI 220318C1725000   100219       0\n",
      "RUI 220318C2040000   100219       0\n",
      "RUI 220318C2060000   100219       0\n",
      "RUI 220318C2425000   100219       0\n",
      "RUI 220318C2250000   100219       0\n",
      "RUI 220318C2270000   100219       0\n",
      "RUI 220318C2275000   100219       0\n",
      "RUI 220318C2280000   100219       0\n",
      "RUI 220318C2290000   100219       0\n",
      "RUI 220318C2300000   100219       0\n",
      "RUI 220318C2310000   100219       0\n",
      "RUI 220318C2320000   100219       0\n",
      "RUI 220318C2325000   100219       0\n",
      "RUI 220318C2330000   100219       0\n",
      "RUI 220318C2340000   100219       0\n",
      "RUI 220318C2350000   100219       0\n",
      "RUI 220318C2360000   100219       0\n",
      "RUI 220318C2370000   100219       0\n",
      "RUI 220318C2375000   100219       0\n",
      "RUI 220318C2380000   100219       0\n",
      "RUI 220318C2390000   100219       0\n",
      "RUI 220318C2400000   100219       0\n",
      "RUI 220318C2410000   100219       0\n",
      "RUI 220318C2420000   100219       0\n",
      "RUI 220318C2260000   100219       0\n",
      "RUI 220318C2240000   100219       0\n",
      "RUI 220318C2070000   100219       0\n",
      "RUI 220318C2230000   100219       0\n",
      "RUI 220318C2075000   100219       0\n",
      "RUI 220318C2080000   100219       0\n",
      "RUI 220318C2090000   100219       0\n",
      "RUI 220318C2100000   100219       0\n",
      "RUI 220318C2110000   100219       0\n",
      "RUI 220318C2120000   100219       0\n",
      "RUI 220318C2125000   100219       0\n",
      "RUI 220318C2130000   100219       0\n",
      "RUI 220318C2140000   100219       0\n",
      "RUI 220318C2150000   100219       0\n",
      "RUI 220318C2160000   100219       0\n",
      "RUI 220318C2170000   100219       0\n",
      "RUI 220318C2175000   100219       0\n",
      "RUI 220318C2180000   100219       0\n",
      "RUI 220318C2190000   100219       0\n",
      "RUI 220318C2200000   100219       0\n",
      "RUI 220318C2210000   100219       0\n",
      "RUI 220318C2220000   100219       0\n",
      "RUI 220318C2225000   100219       0\n",
      "RUI 220318P2310000   100219       0\n",
      "RUI 220318P2320000   100219       0\n",
      "RUI 220318P2325000   100219       0\n",
      "RUI 220617C2500000   100219       0\n",
      "RUI 220617C2520000   100219       0\n",
      "RUI 220617C2525000   100219       0\n",
      "RUI 220617C2530000   100219       0\n",
      "RUI 220617C2540000   100219       0\n",
      "RUI 220617C2550000   100219       0\n",
      "RUI 220617C2560000   100219       0\n",
      "RUI 220617C2570000   100219       0\n",
      "RUI 220617C2575000   100219       0\n",
      "RUI 220617C2580000   100219       0\n",
      "RUI 220617C2590000   100219       0\n",
      "RUI 220617C2600000   100219       0\n",
      "RUI 220617C2610000   100219       0\n",
      "RUI 220617C2620000   100219       0\n",
      "RUI 220617C2625000   100219       0\n",
      "RUI 220617C2630000   100219       0\n",
      "RUI 220617C2640000   100219       0\n",
      "RUI 220617C2650000   100219       0\n",
      "RUI 220617C2660000   100219       0\n",
      "RUI 220617C2670000   100219       0\n",
      "RUI 220617C2510000   100219       0\n",
      "RUI 220617C2490000   100219       0\n",
      "RUI 220617C2680000   100219       0\n",
      "RUI 220617C2480000   100219       0\n",
      "RUI 220617C2325000   100219       0\n",
      "RUI 220617C2330000   100219       0\n",
      "RUI 220617C2340000   100219       0\n",
      "RUI 220617C2350000   100219       0\n",
      "RUI 220617C2360000   100219       0\n",
      "RUI 220617C2370000   100219       0\n",
      "RUI 220617C2375000   100219       0\n",
      "RUI 220617C2380000   100219       0\n",
      "RUI 220617C2390000   100219       0\n",
      "RUI 220617C2400000   100219       0\n",
      "RUI 220617C2410000   100219       0\n",
      "RUI 220617C2420000   100219       0\n",
      "RUI 220617C2425000   100219       0\n",
      "RUI 220617C2430000   100219       0\n",
      "RUI 220617C2440000   100219       0\n",
      "RUI 220617C2450000   100219       0\n",
      "RUI 220617C2460000   100219       0\n",
      "RUI 220617C2470000   100219       0\n",
      "RUI 220617C2475000   100219       0\n",
      "RUI 220617C2675000   100219       0\n",
      "RUI 220617C2690000   100219       0\n",
      "RUI 220617C2310000   100219       0\n",
      "RUI 220617P1775000   100219       0\n",
      "RUI 220617P1825000   100219       0\n",
      "RUI 220617P1850000   100219       0\n",
      "RUI 220617P1875000   100219       0\n",
      "RUI 220617P1900000   100219       0\n",
      "RUI 220617P1925000   100219       0\n",
      "RUI 220617P1950000   100219       0\n",
      "RUI 220617P1975000   100219       0\n",
      "RUI 220617P2000000   100219       0\n",
      "RUI 220617P2020000   100219       0\n",
      "RUI 220617P2025000   100219       0\n",
      "RUI 220617P2030000   100219       0\n",
      "RUI 220617P2040000   100219       0\n",
      "RUI 220617P2050000   100219       0\n",
      "RUI 220617P2060000   100219       0\n",
      "RUI 220617P2070000   100219       0\n",
      "RUI 220617P2075000   100219       0\n",
      "RUI 220617P2080000   100219       0\n",
      "RUI 220617P2090000   100219       0\n",
      "RUI 220617P2100000   100219       0\n",
      "RUI 220617P1800000   100219       0\n",
      "RUI 220617P1750000   100219       0\n",
      "RUI 220617C2700000   100219       0\n",
      "RUI 220617P1725000   100219       0\n",
      "RUI 220617C2710000   100219       0\n",
      "RUI 220617C2720000   100219       0\n",
      "RUI 220617C2725000   100219       0\n",
      "RUI 220617C2750000   100219       0\n",
      "RUI 220617C2775000   100219       0\n",
      "RUI 220617C2800000   100219       0\n",
      "RUI 220617C2825000   100219       0\n",
      "RUI 220617C2850000   100219       0\n",
      "RUI 220617C2875000   100219       0\n",
      "RUI 220617C2900000   100219       0\n",
      "RUI 220617C2925000   100219       0\n",
      "RUI 220617C2950000   100219       0\n",
      "RUI 220617C2975000   100219       0\n",
      "RUI 220617C3000000   100219       0\n",
      "RUI 220617C3025000   100219       0\n",
      "RUI 220617C3050000   100219       0\n",
      "RUI 220617C3075000   100219       0\n",
      "RUI 220617P1675000   100219       0\n",
      "RUI 220617P1700000   100219       0\n",
      "RUI 220617C2320000   100219       0\n",
      "RUI 220617C2300000   100219       0\n",
      "RUI 220318P2330000   100219       0\n",
      "RUI 220318P2520000   100219       0\n",
      "RUI 220318P2530000   100219       0\n",
      "RUI 220318P2540000   100219       0\n",
      "RUI 220318P2550000   100219       0\n",
      "RUI 220318P2560000   100219       0\n",
      "RUI 220318P2575000   100219       0\n",
      "RUI 220318P2600000   100219       0\n",
      "RUI 220318P2625000   100219       0\n",
      "RUI 220318P2650000   100219       0\n",
      "RUI 220318P2675000   100219       0\n",
      "RUI 220318P2700000   100219       0\n",
      "RUI 220318P2725000   100219       0\n",
      "RUI 220318P2750000   100219       0\n",
      "RUI 220318P2775000   100219       0\n",
      "RUI 220318P2800000   100219       0\n",
      "RUI 220318P2825000   100219       0\n",
      "RUI 220318P2850000   100219       0\n",
      "RUI 220318P2875000   100219       0\n",
      "RUI 220318P2900000   100219       0\n",
      "RUI 220617C1675000   100219       0\n",
      "RUI 220318P2525000   100219       0\n",
      "RUI 220318P2510000   100219       0\n",
      "RUI 220617C1725000   100219       0\n",
      "RUI 220318P2500000   100219       0\n",
      "RUI 220318P2340000   100219       0\n",
      "RUI 220318P2350000   100219       0\n",
      "RUI 220318P2360000   100219       0\n",
      "RUI 220318P2370000   100219       0\n",
      "RUI 220318P2375000   100219       0\n",
      "RUI 220318P2380000   100219       0\n",
      "RUI 220318P2390000   100219       0\n",
      "RUI 220318P2400000   100219       0\n",
      "RUI 220318P2410000   100219       0\n",
      "RUI 220318P2420000   100219       0\n",
      "RUI 220318P2425000   100219       0\n",
      "RUI 220318P2430000   100219       0\n",
      "RUI 220318P2440000   100219       0\n",
      "RUI 220318P2450000   100219       0\n",
      "RUI 220318P2460000   100219       0\n",
      "RUI 220318P2470000   100219       0\n",
      "RUI 220318P2475000   100219       0\n",
      "RUI 220318P2480000   100219       0\n",
      "RUI 220318P2490000   100219       0\n",
      "RUI 220617C1700000   100219       0\n",
      "RUI 220617C1750000   100219       0\n",
      "RUI 220617C2290000   100219       0\n",
      "RUI 220617C2120000   100219       0\n",
      "RUI 220617C2130000   100219       0\n",
      "RUI 220617C2140000   100219       0\n",
      "RUI 220617C2150000   100219       0\n",
      "RUI 220617C2160000   100219       0\n",
      "RUI 220617C2170000   100219       0\n",
      "RUI 220617C2175000   100219       0\n",
      "RUI 220617C2180000   100219       0\n",
      "RUI 220617C2190000   100219       0\n",
      "RUI 220617C2200000   100219       0\n",
      "RUI 220617C2210000   100219       0\n",
      "RUI 220617C2220000   100219       0\n",
      "RUI 220617C2225000   100219       0\n",
      "RUI 220617C2230000   100219       0\n",
      "RUI 220617C2240000   100219       0\n",
      "RUI 220617C2250000   100219       0\n",
      "RUI 220617C2260000   100219       0\n",
      "RUI 220617C2270000   100219       0\n",
      "RUI 220617C2275000   100219       0\n",
      "RUI 220617C2280000   100219       0\n",
      "RUI 220617C2125000   100219       0\n",
      "RUI 220617C2110000   100219       0\n",
      "RUI 220617C1775000   100219       0\n",
      "RUI 220617C2100000   100219       0\n",
      "RUI 220617C1800000   100219       0\n",
      "RUI 220617C1825000   100219       0\n",
      "RUI 220617C1850000   100219       0\n",
      "RUI 220617C1875000   100219       0\n",
      "RUI 220617C1900000   100219       0\n",
      "RUI 220617C1925000   100219       0\n",
      "RUI 220617C1950000   100219       0\n",
      "RUI 220617C1975000   100219       0\n",
      "RUI 220617C2000000   100219       0\n",
      "RUI 220617C2020000   100219       0\n",
      "RUI 220617C2025000   100219       0\n",
      "RUI 220617C2030000   100219       0\n",
      "RUI 220617C2040000   100219       0\n",
      "RUI 220617C2050000   100219       0\n",
      "RUI 220617C2060000   100219       0\n",
      "RUI 220617C2070000   100219       0\n",
      "RUI 220617C2075000   100219       0\n",
      "RUI 220617C2080000   100219       0\n",
      "RUI 220617C2090000   100219       0\n",
      "RLV 220318C1620000   100221       0\n",
      "RLV 220318C1610000   100221       0\n",
      "RLV 220318C1600000   100221       0\n",
      "RLG 220218P3130000   100222       0\n",
      "RLG 220218P3060000   100222       0\n",
      "RLG 220218P3070000   100222       0\n",
      "RLG 220218P3075000   100222       0\n",
      "RLG 220218P3080000   100222       0\n",
      "RLG 220218P3090000   100222       0\n",
      "RLG 220218P3100000   100222       0\n",
      "RLG 220218P3110000   100222       0\n",
      "RLG 220218P3120000   100222       0\n",
      "RLG 220218P3125000   100222       0\n",
      "RLG 220218P3140000   100222       0\n",
      "RLG 220218P3775000   100222       0\n",
      "RLG 220218P3150000   100222       0\n",
      "RLG 220218P3160000   100222       0\n",
      "RLG 220218P3170000   100222       0\n",
      "RLG 220218P3175000   100222       0\n",
      "RLG 220218P3180000   100222       0\n",
      "RLG 220218P3190000   100222       0\n",
      "RLG 220218P3200000   100222       0\n",
      "RLG 220218P3210000   100222       0\n",
      "RLG 220218P3220000   100222       0\n",
      "RLG 220218P3050000   100222       0\n",
      "RLG 220218P3040000   100222       0\n",
      "RLG 220218P3030000   100222       0\n",
      "RLG 220218P3025000   100222       0\n",
      "RLG 220218P2870000   100222       0\n",
      "RLG 220218P2875000   100222       0\n",
      "RLG 220218P2880000   100222       0\n",
      "RLG 220218P2890000   100222       0\n",
      "RLG 220218P2900000   100222       0\n",
      "RLG 220218P2910000   100222       0\n",
      "RLG 220218P2920000   100222       0\n",
      "RLG 220218P2925000   100222       0\n",
      "RLG 220218P2930000   100222       0\n",
      "RLG 220218P2940000   100222       0\n",
      "RLG 220218P2950000   100222       0\n",
      "RLG 220218P2960000   100222       0\n",
      "RLG 220218P2970000   100222       0\n",
      "RLG 220218P2975000   100222       0\n",
      "RLG 220218P2980000   100222       0\n",
      "RLG 220218P2990000   100222       0\n",
      "RLG 220218P3000000   100222       0\n",
      "RLG 220218P3010000   100222       0\n",
      "RLG 220218P3020000   100222       0\n",
      "RLG 220218P3225000   100222       0\n",
      "RLG 220218P3230000   100222       0\n",
      "RLG 220218P3240000   100222       0\n",
      "RLG 220218P3430000   100222       0\n",
      "RLG 220218P3450000   100222       0\n",
      "RLG 220218P3460000   100222       0\n",
      "RLG 220218P3470000   100222       0\n",
      "RLG 220218P3475000   100222       0\n",
      "RLG 220218P3480000   100222       0\n",
      "RLG 220218P3490000   100222       0\n",
      "RLG 220218P3500000   100222       0\n",
      "RLG 220218P3510000   100222       0\n",
      "RLG 220218P3520000   100222       0\n",
      "RLG 220218P3525000   100222       0\n",
      "RLG 220218P3530000   100222       0\n",
      "RLG 220218P3550000   100222       0\n",
      "RLG 220218P3575000   100222       0\n",
      "RLG 220218P3600000   100222       0\n",
      "RLG 220218P3625000   100222       0\n",
      "RLG 220218P3650000   100222       0\n",
      "RLG 220218P3675000   100222       0\n",
      "RLG 220218P3700000   100222       0\n",
      "RLG 220218P3725000   100222       0\n",
      "RLG 220218P3440000   100222       0\n",
      "RLG 220218P3425000   100222       0\n",
      "RLG 220218P3250000   100222       0\n",
      "RLG 220218P3420000   100222       0\n",
      "RLG 220218P3260000   100222       0\n",
      "RLG 220218P3270000   100222       0\n",
      "RLG 220218P3275000   100222       0\n",
      "RLG 220218P3280000   100222       0\n",
      "RLG 220218P3290000   100222       0\n",
      "RLG 220218P3300000   100222       0\n",
      "RLG 220218P3310000   100222       0\n",
      "RLG 220218P3320000   100222       0\n",
      "RLG 220218P3325000   100222       0\n",
      "RLG 220218P3330000   100222       0\n",
      "RLG 220218P3340000   100222       0\n",
      "RLG 220218P3350000   100222       0\n",
      "RLG 220218P3360000   100222       0\n",
      "RLG 220218P3370000   100222       0\n",
      "RLG 220218P3375000   100222       0\n",
      "RLG 220218P3380000   100222       0\n",
      "RLG 220218P3390000   100222       0\n",
      "RLG 220218P3400000   100222       0\n",
      "RLG 220218P3410000   100222       0\n",
      "RLG 220218P2860000   100222       0\n",
      "RLG 220218P2850000   100222       0\n",
      "RLG 220218P2840000   100222       0\n",
      "RLG 220218C3500000   100222       0\n",
      "RLG 220218C3520000   100222       0\n",
      "RLG 220218C3525000   100222       0\n",
      "RLG 220218C3530000   100222       0\n",
      "RLG 220218C3550000   100222       0\n",
      "RLG 220218C3575000   100222       0\n",
      "RLG 220218C3600000   100222       0\n",
      "RLG 220218C3625000   100222       0\n",
      "RLG 220218C3650000   100222       0\n",
      "RLG 220218C3675000   100222       0\n",
      "RLG 220218C3700000   100222       0\n",
      "RLG 220218C3725000   100222       0\n",
      "RLG 220218C3750000   100222       0\n",
      "RLG 220218C3775000   100222       0\n",
      "RLG 220218C3800000   100222       0\n",
      "RLG 220218C3825000   100222       0\n",
      "RLG 220218C3850000   100222       0\n",
      "RLG 220218C3875000   100222       0\n",
      "RLG 220218C3900000   100222       0\n",
      "RLG 220218C3925000   100222       0\n",
      "RLG 220218C3510000   100222       0\n",
      "RLG 220218C3490000   100222       0\n",
      "RLG 220218C3975000   100222       0\n",
      "RLG 220218C3480000   100222       0\n",
      "RLG 220218C3325000   100222       0\n",
      "RLG 220218C3330000   100222       0\n",
      "RLG 220218C3340000   100222       0\n",
      "RLG 220218C3350000   100222       0\n",
      "RLG 220218C3360000   100222       0\n",
      "RLG 220218C3370000   100222       0\n",
      "RLG 220218C3375000   100222       0\n",
      "RLG 220218C3380000   100222       0\n",
      "RLG 220218C3390000   100222       0\n",
      "RLG 220218C3400000   100222       0\n",
      "RLG 220218C3410000   100222       0\n",
      "RLG 220218C3420000   100222       0\n",
      "RLG 220218C3425000   100222       0\n",
      "RLG 220218C3430000   100222       0\n",
      "RLG 220218C3440000   100222       0\n",
      "RLG 220218C3450000   100222       0\n",
      "RLG 220218C3460000   100222       0\n",
      "RLG 220218C3470000   100222       0\n",
      "RLG 220218C3475000   100222       0\n",
      "RLG 220218C3950000   100222       0\n",
      "RLG 220218P2175000   100222       0\n",
      "RLG 220218P2830000   100222       0\n",
      "RLG 220218P2660000   100222       0\n",
      "RLG 220218P2675000   100222       0\n",
      "RLG 220218P2680000   100222       0\n",
      "RLG 220218P2690000   100222       0\n",
      "RLG 220218P2700000   100222       0\n",
      "RLG 220218P2710000   100222       0\n",
      "RLG 220218P2720000   100222       0\n",
      "RLG 220218P2725000   100222       0\n",
      "RLG 220218P2730000   100222       0\n",
      "RLG 220218P2740000   100222       0\n",
      "RLG 220218P2750000   100222       0\n",
      "RLG 220218P2760000   100222       0\n",
      "RLG 220218P2770000   100222       0\n",
      "RLG 220218P2775000   100222       0\n",
      "RLG 220218P2780000   100222       0\n",
      "RLG 220218P2790000   100222       0\n",
      "RLG 220218P2800000   100222       0\n",
      "RLG 220218P2810000   100222       0\n",
      "RLG 220218P2820000   100222       0\n",
      "RLG 220218P2825000   100222       0\n",
      "RLG 220218P2670000   100222       0\n",
      "RLG 220218P2650000   100222       0\n",
      "RLG 220218P2200000   100222       0\n",
      "RLG 220218P2640000   100222       0\n",
      "RLG 220218P2225000   100222       0\n",
      "RLG 220218P2250000   100222       0\n",
      "RLG 220218P2275000   100222       0\n",
      "RLG 220218P2300000   100222       0\n",
      "RLG 220218P2325000   100222       0\n",
      "RLG 220218P2350000   100222       0\n",
      "RLG 220218P2375000   100222       0\n",
      "RLG 220218P2400000   100222       0\n",
      "RLG 220218P2425000   100222       0\n",
      "RLG 220218P2450000   100222       0\n",
      "RLG 220218P2475000   100222       0\n",
      "RLG 220218P2500000   100222       0\n",
      "RLG 220218P2525000   100222       0\n",
      "RLG 220218P2550000   100222       0\n",
      "RLG 220218P2575000   100222       0\n",
      "RLG 220218P2600000   100222       0\n",
      "RLG 220218P2620000   100222       0\n",
      "RLG 220218P2625000   100222       0\n",
      "RLG 220218P2630000   100222       0\n",
      "RLG 220218P3750000   100222       0\n",
      "RLG 220218P3800000   100222       0\n",
      "RLV 220318C1590000   100221       0\n",
      "RLG 220318C3325000   100222       0\n",
      "RLG 220318C3230000   100222       0\n",
      "RLG 220318C3240000   100222       0\n",
      "RLG 220318C3250000   100222       0\n",
      "RLG 220318C3260000   100222       0\n",
      "RLG 220318C3270000   100222       0\n",
      "RLG 220318C3275000   100222       0\n",
      "RLG 220318C3280000   100222       0\n",
      "RLG 220318C3290000   100222       0\n",
      "RLG 220318C3300000   100222       0\n",
      "RLG 220318C3350000   100222       0\n",
      "RLG 220218P3825000   100222       0\n",
      "RLG 220318C3375000   100222       0\n",
      "RLG 220318C3400000   100222       0\n",
      "RLG 220318C3425000   100222       0\n",
      "RLG 220318C3450000   100222       0\n",
      "RLG 220318C3475000   100222       0\n",
      "RLG 220318C3500000   100222       0\n",
      "RLG 220318C3525000   100222       0\n",
      "RLG 220318C3550000   100222       0\n",
      "RLG 220318C3575000   100222       0\n",
      "RLG 220318C3225000   100222       0\n",
      "RLG 220318C3220000   100222       0\n",
      "RLG 220318C3210000   100222       0\n",
      "RLG 220318C3200000   100222       0\n",
      "RLG 220318C3040000   100222       0\n",
      "RLG 220318C3050000   100222       0\n",
      "RLG 220318C3060000   100222       0\n",
      "RLG 220318C3070000   100222       0\n",
      "RLG 220318C3075000   100222       0\n",
      "RLG 220318C3080000   100222       0\n",
      "RLG 220318C3090000   100222       0\n",
      "RLG 220318C3100000   100222       0\n",
      "RLG 220318C3110000   100222       0\n",
      "RLG 220318C3120000   100222       0\n",
      "RLG 220318C3125000   100222       0\n",
      "RLG 220318C3130000   100222       0\n",
      "RLG 220318C3140000   100222       0\n",
      "RLG 220318C3150000   100222       0\n",
      "RLG 220318C3160000   100222       0\n",
      "RLG 220318C3170000   100222       0\n",
      "RLG 220318C3175000   100222       0\n",
      "RLG 220318C3180000   100222       0\n",
      "RLG 220318C3190000   100222       0\n",
      "RLG 220318C3600000   100222       0\n",
      "RLG 220318C3625000   100222       0\n",
      "RLG 220318C3650000   100222       0\n",
      "RLG 220318P2475000   100222       0\n",
      "RLG 220318P2490000   100222       0\n",
      "RLG 220318P2500000   100222       0\n",
      "RLG 220318P2510000   100222       0\n",
      "RLG 220318P2520000   100222       0\n",
      "RLG 220318P2525000   100222       0\n",
      "RLG 220318P2530000   100222       0\n",
      "RLG 220318P2540000   100222       0\n",
      "RLG 220318P2550000   100222       0\n",
      "RLG 220318P2560000   100222       0\n",
      "RLG 220318P2570000   100222       0\n",
      "RLG 220318P2575000   100222       0\n",
      "RLG 220318P2580000   100222       0\n",
      "RLG 220318P2590000   100222       0\n",
      "RLG 220318P2600000   100222       0\n",
      "RLG 220318P2610000   100222       0\n",
      "RLG 220318P2620000   100222       0\n",
      "RLG 220318P2625000   100222       0\n",
      "RLG 220318P2630000   100222       0\n",
      "RLG 220318P2640000   100222       0\n",
      "RLG 220318P2480000   100222       0\n",
      "RLG 220318P2470000   100222       0\n",
      "RLG 220318C3675000   100222       0\n",
      "RLG 220318P2450000   100222       0\n",
      "RLG 220318C3700000   100222       0\n",
      "RLG 220318C3725000   100222       0\n",
      "RLG 220318C3750000   100222       0\n",
      "RLG 220318P2050000   100222       0\n",
      "RLG 220318P2075000   100222       0\n",
      "RLG 220318P2100000   100222       0\n",
      "RLG 220318P2125000   100222       0\n",
      "RLG 220318P2150000   100222       0\n",
      "RLG 220318P2175000   100222       0\n",
      "RLG 220318P2200000   100222       0\n",
      "RLG 220318P2225000   100222       0\n",
      "RLG 220318P2250000   100222       0\n",
      "RLG 220318P2275000   100222       0\n",
      "RLG 220318P2300000   100222       0\n",
      "RLG 220318P2325000   100222       0\n",
      "RLG 220318P2350000   100222       0\n",
      "RLG 220318P2375000   100222       0\n",
      "RLG 220318P2400000   100222       0\n",
      "RLG 220318P2425000   100222       0\n",
      "RLG 220318C3030000   100222       0\n",
      "RLG 220318C3025000   100222       0\n",
      "RLG 220318C3020000   100222       0\n",
      "RLG 220318C2425000   100222       0\n",
      "RLG 220318C2470000   100222       0\n",
      "RLG 220318C2475000   100222       0\n",
      "RLG 220318C2480000   100222       0\n",
      "RLG 220318C2490000   100222       0\n",
      "RLG 220318C2500000   100222       0\n",
      "RLG 220318C2510000   100222       0\n",
      "RLG 220318C2520000   100222       0\n",
      "RLG 220318C2525000   100222       0\n",
      "RLG 220318C2530000   100222       0\n",
      "RLG 220318C2540000   100222       0\n",
      "RLG 220318C2550000   100222       0\n",
      "RLG 220318C2560000   100222       0\n",
      "RLG 220318C2570000   100222       0\n",
      "RLG 220318C2575000   100222       0\n",
      "RLG 220318C2580000   100222       0\n",
      "RLG 220318C2590000   100222       0\n",
      "RLG 220318C2600000   100222       0\n",
      "RLG 220318C2610000   100222       0\n",
      "RLG 220318C2620000   100222       0\n",
      "RLG 220318C2450000   100222       0\n",
      "RLG 220318C2400000   100222       0\n",
      "RLG 220318C2630000   100222       0\n",
      "RLG 220318C2375000   100222       0\n",
      "RLG 220218P3850000   100222       0\n",
      "RLG 220218P3875000   100222       0\n",
      "RLG 220218P3900000   100222       0\n",
      "RLG 220218P3925000   100222       0\n",
      "RLG 220218P3950000   100222       0\n",
      "RLG 220218P3975000   100222       0\n",
      "RLG 220318C2050000   100222       0\n",
      "RLG 220318C2075000   100222       0\n",
      "RLG 220318C2100000   100222       0\n",
      "RLG 220318C2125000   100222       0\n",
      "RLG 220318C2150000   100222       0\n",
      "RLG 220318C2175000   100222       0\n",
      "RLG 220318C2200000   100222       0\n",
      "RLG 220318C2225000   100222       0\n",
      "RLG 220318C2250000   100222       0\n",
      "RLG 220318C2275000   100222       0\n",
      "RLG 220318C2300000   100222       0\n",
      "RLG 220318C2325000   100222       0\n",
      "RLG 220318C2350000   100222       0\n",
      "RLG 220318C2625000   100222       0\n",
      "RLG 220318C2640000   100222       0\n",
      "RLG 220318C3010000   100222       0\n",
      "RLG 220318C2830000   100222       0\n",
      "RLG 220318C2850000   100222       0\n",
      "RLG 220318C2860000   100222       0\n",
      "RLG 220318C2870000   100222       0\n",
      "RLG 220318C2875000   100222       0\n",
      "RLG 220318C2880000   100222       0\n",
      "RLG 220318C2890000   100222       0\n",
      "RLG 220318C2900000   100222       0\n",
      "RLG 220318C2910000   100222       0\n",
      "RLG 220318C2920000   100222       0\n",
      "RLG 220318C2925000   100222       0\n",
      "RLG 220318C2930000   100222       0\n",
      "RLG 220318C2940000   100222       0\n",
      "RLG 220318C2950000   100222       0\n",
      "RLG 220318C2960000   100222       0\n",
      "RLG 220318C2970000   100222       0\n",
      "RLG 220318C2975000   100222       0\n",
      "RLG 220318C2980000   100222       0\n",
      "RLG 220318C2990000   100222       0\n",
      "RLG 220318C3000000   100222       0\n",
      "RLG 220318C2840000   100222       0\n",
      "RLG 220318C2825000   100222       0\n",
      "RLG 220318C2650000   100222       0\n",
      "RLG 220318C2820000   100222       0\n",
      "RLG 220318C2660000   100222       0\n",
      "RLG 220318C2670000   100222       0\n",
      "RLG 220318C2675000   100222       0\n",
      "RLG 220318C2680000   100222       0\n",
      "RLG 220318C2690000   100222       0\n",
      "RLG 220318C2700000   100222       0\n",
      "RLG 220318C2710000   100222       0\n",
      "RLG 220318C2720000   100222       0\n",
      "RLG 220318C2725000   100222       0\n",
      "RLG 220318C2730000   100222       0\n",
      "RLG 220318C2740000   100222       0\n",
      "RLG 220318C2750000   100222       0\n",
      "RLG 220318C2760000   100222       0\n",
      "RLG 220318C2770000   100222       0\n",
      "RLG 220318C2775000   100222       0\n",
      "RLG 220318C2780000   100222       0\n",
      "RLG 220318C2790000   100222       0\n",
      "RLG 220318C2800000   100222       0\n",
      "RLG 220318C2810000   100222       0\n",
      "RLG 220218C3320000   100222       0\n",
      "RLG 220218C3310000   100222       0\n",
      "RLG 220218C3300000   100222       0\n",
      "RLG 220121C3425000   100222       0\n",
      "RLG 220121C3200000   100222       0\n",
      "RLG 220121C3225000   100222       0\n",
      "RLG 220121C3250000   100222       0\n",
      "RLG 220121C3275000   100222       0\n",
      "RLG 220121C3300000   100222       0\n",
      "RLG 220121C3325000   100222       0\n",
      "RLG 220121C3350000   100222       0\n",
      "RLG 220121C3375000   100222       0\n",
      "RLG 220121C3400000   100222       0\n",
      "RLG 220121C3450000   100222       0\n",
      "RLG 220218C3290000   100222       0\n",
      "RLG 220121C3475000   100222       0\n",
      "RLG 220121C3500000   100222       0\n",
      "RLG 220121C3525000   100222       0\n",
      "RLG 220121C3550000   100222       0\n",
      "RLG 220121C3575000   100222       0\n",
      "RLG 220121C3600000   100222       0\n",
      "RLG 220121P1950000   100222       0\n",
      "RLG 220121P1975000   100222       0\n",
      "RLG 220121P2000000   100222       0\n",
      "RLG 220121C3190000   100222       0\n",
      "RLG 220121C3180000   100222       0\n",
      "RLG 220121C3175000   100222       0\n",
      "RLG 220121C3170000   100222       0\n",
      "RLG 220121C3010000   100222       0\n",
      "RLG 220121C3020000   100222       0\n",
      "RLG 220121C3025000   100222       0\n",
      "RLG 220121C3030000   100222       0\n",
      "RLG 220121C3040000   100222       0\n",
      "RLG 220121C3050000   100222       0\n",
      "RLG 220121C3060000   100222       0\n",
      "RLG 220121C3070000   100222       0\n",
      "RLG 220121C3075000   100222       0\n",
      "RLG 220121C3080000   100222       0\n",
      "RLG 220121C3090000   100222       0\n",
      "RLG 220121C3100000   100222       0\n",
      "RLG 220121C3110000   100222       0\n",
      "RLG 220121C3120000   100222       0\n",
      "RLG 220121C3125000   100222       0\n",
      "RLG 220121C3130000   100222       0\n",
      "RLG 220121C3140000   100222       0\n",
      "RLG 220121C3150000   100222       0\n",
      "RLG 220121C3160000   100222       0\n",
      "RLG 220121P2025000   100222       0\n",
      "RLG 220121P2050000   100222       0\n",
      "RLG 220121P2075000   100222       0\n",
      "RLG 220121P2460000   100222       0\n",
      "RLG 220121P2475000   100222       0\n",
      "RLG 220121P2480000   100222       0\n",
      "RLG 220121P2490000   100222       0\n",
      "RLG 220121P2500000   100222       0\n",
      "RLG 220121P2510000   100222       0\n",
      "RLG 220121P2520000   100222       0\n",
      "RLG 220121P2525000   100222       0\n",
      "RLG 220121P2530000   100222       0\n",
      "RLG 220121P2540000   100222       0\n",
      "RLG 220121P2550000   100222       0\n",
      "RLG 220121P2560000   100222       0\n",
      "RLG 220121P2570000   100222       0\n",
      "RLG 220121P2575000   100222       0\n",
      "RLG 220121P2580000   100222       0\n",
      "RLG 220121P2590000   100222       0\n",
      "RLG 220121P2600000   100222       0\n",
      "RLG 220121P2610000   100222       0\n",
      "RLG 220121P2620000   100222       0\n",
      "RLG 220121P2625000   100222       0\n",
      "RLG 220121P2470000   100222       0\n",
      "RLG 220121P2450000   100222       0\n",
      "RLG 220121P2100000   100222       0\n",
      "RLG 220121P2440000   100222       0\n",
      "RLG 220121P2125000   100222       0\n",
      "RLG 220121P2150000   100222       0\n",
      "RLG 220121P2175000   100222       0\n",
      "RLG 220121P2200000   100222       0\n",
      "RLG 220121P2225000   100222       0\n",
      "RLG 220121P2250000   100222       0\n",
      "RLG 220121P2275000   100222       0\n",
      "RLG 220121P2300000   100222       0\n",
      "RLG 220121P2325000   100222       0\n",
      "RLG 220121P2350000   100222       0\n",
      "RLG 220121P2370000   100222       0\n",
      "RLG 220121P2375000   100222       0\n",
      "RLG 220121P2380000   100222       0\n",
      "RLG 220121P2390000   100222       0\n",
      "RLG 220121P2400000   100222       0\n",
      "RLG 220121P2410000   100222       0\n",
      "RLG 220121P2420000   100222       0\n",
      "RLG 220121P2425000   100222       0\n",
      "RLG 220121P2430000   100222       0\n",
      "RLG 220121C3000000   100222       0\n",
      "RLG 220121C2990000   100222       0\n",
      "RLG 220121C2980000   100222       0\n",
      "RLG 220121C2420000   100222       0\n",
      "RLG 220121C2430000   100222       0\n",
      "RLG 220121C2440000   100222       0\n",
      "RLG 220121C2450000   100222       0\n",
      "RLG 220121C2460000   100222       0\n",
      "RLG 220121C2470000   100222       0\n",
      "RLG 220121C2475000   100222       0\n",
      "RLG 220121C2480000   100222       0\n",
      "RLG 220121C2490000   100222       0\n",
      "RLG 220121C2500000   100222       0\n",
      "RLG 220121C2510000   100222       0\n",
      "RLG 220121C2520000   100222       0\n",
      "RLG 220121C2525000   100222       0\n",
      "RLG 220121C2530000   100222       0\n",
      "RLG 220121C2540000   100222       0\n",
      "RLG 220121C2550000   100222       0\n",
      "RLG 220121C2560000   100222       0\n",
      "RLG 220121C2570000   100222       0\n",
      "RLG 220121C2575000   100222       0\n",
      "RLG 220121C2580000   100222       0\n",
      "RLG 220121C2425000   100222       0\n",
      "RLG 220121C2410000   100222       0\n",
      "RLG 220121C2600000   100222       0\n",
      "RLG 220121C2400000   100222       0\n",
      "RLG 220121C2000000   100222       0\n",
      "RLG 220121C2025000   100222       0\n",
      "RLG 220121C2050000   100222       0\n",
      "RLG 220121C2075000   100222       0\n",
      "RLG 220121C2100000   100222       0\n",
      "RLG 220121C2125000   100222       0\n",
      "RLG 220121C2150000   100222       0\n",
      "RLG 220121C2175000   100222       0\n",
      "RLG 220121C2200000   100222       0\n",
      "RLG 220121C2225000   100222       0\n",
      "RLG 220121C2250000   100222       0\n",
      "RLG 220121C2275000   100222       0\n",
      "RLG 220121C2300000   100222       0\n",
      "RLG 220121C2325000   100222       0\n",
      "RLG 220121C2350000   100222       0\n",
      "RLG 220121C2370000   100222       0\n",
      "RLG 220121C2375000   100222       0\n",
      "RLG 220121C2380000   100222       0\n",
      "RLG 220121C2390000   100222       0\n",
      "RLG 220121C2590000   100222       0\n",
      "RLG 220121C2610000   100222       0\n",
      "RLG 220121C2975000   100222       0\n",
      "RLG 220121C2800000   100222       0\n",
      "RLG 220121C2820000   100222       0\n",
      "RLG 220121C2825000   100222       0\n",
      "RLG 220121C2830000   100222       0\n",
      "RLG 220121C2840000   100222       0\n",
      "RLG 220121C2850000   100222       0\n",
      "RLG 220121C2860000   100222       0\n",
      "RLG 220121C2870000   100222       0\n",
      "RLG 220121C2875000   100222       0\n",
      "RLG 220121C2880000   100222       0\n",
      "RLG 220121C2890000   100222       0\n",
      "RLG 220121C2900000   100222       0\n",
      "RLG 220121C2910000   100222       0\n",
      "RLG 220121C2920000   100222       0\n",
      "RLG 220121C2925000   100222       0\n",
      "RLG 220121C2930000   100222       0\n",
      "RLG 220121C2940000   100222       0\n",
      "RLG 220121C2950000   100222       0\n",
      "RLG 220121C2960000   100222       0\n",
      "RLG 220121C2970000   100222       0\n",
      "RLG 220121C2810000   100222       0\n",
      "RLG 220121C2790000   100222       0\n",
      "RLG 220121C2620000   100222       0\n",
      "RLG 220121C2780000   100222       0\n",
      "RLG 220121C2625000   100222       0\n",
      "RLG 220121C2630000   100222       0\n",
      "RLG 220121C2640000   100222       0\n",
      "RLG 220121C2650000   100222       0\n",
      "RLG 220121C2660000   100222       0\n",
      "RLG 220121C2670000   100222       0\n",
      "RLG 220121C2675000   100222       0\n",
      "RLG 220121C2680000   100222       0\n",
      "RLG 220121C2690000   100222       0\n",
      "RLG 220121C2700000   100222       0\n",
      "RLG 220121C2710000   100222       0\n",
      "RLG 220121C2720000   100222       0\n",
      "RLG 220121C2725000   100222       0\n",
      "RLG 220121C2730000   100222       0\n",
      "RLG 220121C2740000   100222       0\n",
      "RLG 220121C2750000   100222       0\n",
      "RLG 220121C2760000   100222       0\n",
      "RLG 220121C2770000   100222       0\n",
      "RLG 220121C2775000   100222       0\n",
      "RLG 220121P2630000   100222       0\n",
      "RLG 220121P2640000   100222       0\n",
      "RLG 220121P2650000   100222       0\n",
      "RLG 220218C2730000   100222       0\n",
      "RLG 220218C2750000   100222       0\n",
      "RLG 220218C2760000   100222       0\n",
      "RLG 220218C2770000   100222       0\n",
      "RLG 220218C2775000   100222       0\n",
      "RLG 220218C2780000   100222       0\n",
      "RLG 220218C2790000   100222       0\n",
      "RLG 220218C2800000   100222       0\n",
      "RLG 220218C2810000   100222       0\n",
      "RLG 220218C2820000   100222       0\n",
      "RLG 220218C2825000   100222       0\n",
      "RLG 220218C2830000   100222       0\n",
      "RLG 220218C2840000   100222       0\n",
      "RLG 220218C2850000   100222       0\n",
      "RLG 220218C2860000   100222       0\n",
      "RLG 220218C2870000   100222       0\n",
      "RLG 220218C2875000   100222       0\n",
      "RLG 220218C2880000   100222       0\n",
      "RLG 220218C2890000   100222       0\n",
      "RLG 220218C2900000   100222       0\n",
      "RLG 220218C2740000   100222       0\n",
      "RLG 220218C2725000   100222       0\n",
      "RLG 220218C2920000   100222       0\n",
      "RLG 220218C2720000   100222       0\n",
      "RLG 220218C2450000   100222       0\n",
      "RLG 220218C2475000   100222       0\n",
      "RLG 220218C2500000   100222       0\n",
      "RLG 220218C2525000   100222       0\n",
      "RLG 220218C2550000   100222       0\n",
      "RLG 220218C2575000   100222       0\n",
      "RLG 220218C2600000   100222       0\n",
      "RLG 220218C2620000   100222       0\n",
      "RLG 220218C2625000   100222       0\n",
      "RLG 220218C2630000   100222       0\n",
      "RLG 220218C2640000   100222       0\n",
      "RLG 220218C2650000   100222       0\n",
      "RLG 220218C2660000   100222       0\n",
      "RLG 220218C2670000   100222       0\n",
      "RLG 220218C2675000   100222       0\n",
      "RLG 220218C2680000   100222       0\n",
      "RLG 220218C2690000   100222       0\n",
      "RLG 220218C2700000   100222       0\n",
      "RLG 220218C2710000   100222       0\n",
      "RLG 220218C2910000   100222       0\n",
      "RLG 220218C2925000   100222       0\n",
      "RLG 220218C2400000   100222       0\n",
      "RLG 220218C3120000   100222       0\n",
      "RLG 220218C3130000   100222       0\n",
      "RLG 220218C3140000   100222       0\n",
      "RLG 220218C3150000   100222       0\n",
      "RLG 220218C3160000   100222       0\n",
      "RLG 220218C3170000   100222       0\n",
      "RLG 220218C3175000   100222       0\n",
      "RLG 220218C3180000   100222       0\n",
      "RLG 220218C3190000   100222       0\n",
      "RLG 220218C3200000   100222       0\n",
      "RLG 220218C3210000   100222       0\n",
      "RLG 220218C3220000   100222       0\n",
      "RLG 220218C3225000   100222       0\n",
      "RLG 220218C3230000   100222       0\n",
      "RLG 220218C3240000   100222       0\n",
      "RLG 220218C3250000   100222       0\n",
      "RLG 220218C3260000   100222       0\n",
      "RLG 220218C3270000   100222       0\n",
      "RLG 220218C3275000   100222       0\n",
      "RLG 220218C3280000   100222       0\n",
      "RLG 220218C3125000   100222       0\n",
      "RLG 220218C3110000   100222       0\n",
      "RLG 220218C2930000   100222       0\n",
      "RLG 220218C3100000   100222       0\n",
      "RLG 220218C2940000   100222       0\n",
      "RLG 220218C2950000   100222       0\n",
      "RLG 220218C2960000   100222       0\n",
      "RLG 220218C2970000   100222       0\n",
      "RLG 220218C2975000   100222       0\n",
      "RLG 220218C2980000   100222       0\n",
      "RLG 220218C2990000   100222       0\n",
      "RLG 220218C3000000   100222       0\n",
      "RLG 220218C3010000   100222       0\n",
      "RLG 220218C3020000   100222       0\n",
      "RLG 220218C3025000   100222       0\n",
      "RLG 220218C3030000   100222       0\n",
      "RLG 220218C3040000   100222       0\n",
      "RLG 220218C3050000   100222       0\n",
      "RLG 220218C3060000   100222       0\n",
      "RLG 220218C3070000   100222       0\n",
      "RLG 220218C3075000   100222       0\n",
      "RLG 220218C3080000   100222       0\n",
      "RLG 220218C3090000   100222       0\n",
      "RLG 220218C2425000   100222       0\n",
      "RLG 220218C2375000   100222       0\n",
      "RLG 220121P2660000   100222       0\n",
      "RLG 220121P2840000   100222       0\n",
      "RLG 220121P2860000   100222       0\n",
      "RLG 220121P2870000   100222       0\n",
      "RLG 220121P2875000   100222       0\n",
      "RLG 220121P2880000   100222       0\n",
      "RLG 220121P2890000   100222       0\n",
      "RLG 220121P2900000   100222       0\n",
      "RLG 220121P2910000   100222       0\n",
      "RLG 220121P2920000   100222       0\n",
      "RLG 220121P2925000   100222       0\n",
      "RLG 220121P2930000   100222       0\n",
      "RLG 220121P2940000   100222       0\n",
      "RLG 220121P2950000   100222       0\n",
      "RLG 220121P2960000   100222       0\n",
      "RLG 220121P2970000   100222       0\n",
      "RLG 220121P2975000   100222       0\n",
      "RLG 220121P2980000   100222       0\n",
      "RLG 220121P2990000   100222       0\n",
      "RLG 220121P3000000   100222       0\n",
      "RLG 220121P3010000   100222       0\n",
      "RLG 220121P2850000   100222       0\n",
      "RLG 220121P2830000   100222       0\n",
      "RLG 220121P3025000   100222       0\n",
      "RLG 220121P2825000   100222       0\n",
      "RLG 220121P2670000   100222       0\n",
      "RLG 220121P2675000   100222       0\n",
      "RLG 220121P2680000   100222       0\n",
      "RLG 220121P2690000   100222       0\n",
      "RLG 220121P2700000   100222       0\n",
      "RLG 220121P2710000   100222       0\n",
      "RLG 220121P2720000   100222       0\n",
      "RLG 220121P2725000   100222       0\n",
      "RLG 220121P2730000   100222       0\n",
      "RLG 220121P2740000   100222       0\n",
      "RLG 220121P2750000   100222       0\n",
      "RLG 220121P2760000   100222       0\n",
      "RLG 220121P2770000   100222       0\n",
      "RLG 220121P2775000   100222       0\n",
      "RLG 220121P2780000   100222       0\n",
      "RLG 220121P2790000   100222       0\n",
      "RLG 220121P2800000   100222       0\n",
      "RLG 220121P2810000   100222       0\n",
      "RLG 220121P2820000   100222       0\n",
      "RLG 220121P3020000   100222       0\n",
      "RLG 220121P3030000   100222       0\n",
      "RLG 220218C2350000   100222       0\n",
      "RLG 220121P3275000   100222       0\n",
      "RLG 220121P3325000   100222       0\n",
      "RLG 220121P3350000   100222       0\n",
      "RLG 220121P3375000   100222       0\n",
      "RLG 220121P3400000   100222       0\n",
      "RLG 220121P3425000   100222       0\n",
      "RLG 220121P3450000   100222       0\n",
      "RLG 220121P3475000   100222       0\n",
      "RLG 220121P3500000   100222       0\n",
      "RLG 220121P3525000   100222       0\n",
      "RLG 220121P3550000   100222       0\n",
      "RLG 220121P3575000   100222       0\n",
      "RLG 220121P3600000   100222       0\n",
      "RLG 220218C2175000   100222       0\n",
      "RLG 220218C2200000   100222       0\n",
      "RLG 220218C2225000   100222       0\n",
      "RLG 220218C2250000   100222       0\n",
      "RLG 220218C2275000   100222       0\n",
      "RLG 220218C2300000   100222       0\n",
      "RLG 220218C2325000   100222       0\n",
      "RLG 220121P3300000   100222       0\n",
      "RLG 220121P3250000   100222       0\n",
      "RLG 220121P3040000   100222       0\n",
      "RLG 220121P3225000   100222       0\n",
      "RLG 220121P3050000   100222       0\n",
      "RLG 220121P3060000   100222       0\n",
      "RLG 220121P3070000   100222       0\n",
      "RLG 220121P3075000   100222       0\n",
      "RLG 220121P3080000   100222       0\n",
      "RLG 220121P3090000   100222       0\n",
      "RLG 220121P3100000   100222       0\n",
      "RLG 220121P3110000   100222       0\n",
      "RLG 220121P3120000   100222       0\n",
      "RLG 220121P3125000   100222       0\n",
      "RLG 220121P3130000   100222       0\n",
      "RLG 220121P3140000   100222       0\n",
      "RLG 220121P3150000   100222       0\n",
      "RLG 220121P3160000   100222       0\n",
      "RLG 220121P3170000   100222       0\n",
      "RLG 220121P3175000   100222       0\n",
      "RLG 220121P3180000   100222       0\n",
      "RLG 220121P3190000   100222       0\n",
      "RLG 220121P3200000   100222       0\n",
      "RLG 220318P2650000   100222       0\n",
      "RLG 220318P2660000   100222       0\n",
      "RLG 220318P2670000   100222       0\n",
      "RLV 220121P1520000   100221       0\n",
      "RLV 220121P1440000   100221       0\n",
      "RLV 220121P1450000   100221       0\n",
      "RLV 220121P1460000   100221       0\n",
      "RLV 220121P1470000   100221       0\n",
      "RLV 220121P1475000   100221       0\n",
      "RLV 220121P1480000   100221       0\n",
      "RLV 220121P1490000   100221       0\n",
      "RLV 220121P1500000   100221       0\n",
      "RLV 220121P1510000   100221       0\n",
      "RLV 220121P1525000   100221       0\n",
      "RLG 220617P3500000   100222       0\n",
      "RLV 220121P1530000   100221       0\n",
      "RLV 220121P1540000   100221       0\n",
      "RLV 220121P1550000   100221       0\n",
      "RLV 220121P1560000   100221       0\n",
      "RLV 220121P1570000   100221       0\n",
      "RLV 220121P1575000   100221       0\n",
      "RLV 220121P1580000   100221       0\n",
      "RLV 220121P1590000   100221       0\n",
      "RLV 220121P1600000   100221       0\n",
      "RLV 220121P1430000   100221       0\n",
      "RLV 220121P1425000   100221       0\n",
      "RLV 220121P1420000   100221       0\n",
      "RLV 220121P1410000   100221       0\n",
      "RLV 220121C2000000   100221       0\n",
      "RLV 220121C2025000   100221       0\n",
      "RLV 220121P1125000   100221       0\n",
      "RLV 220121P1150000   100221       0\n",
      "RLV 220121P1175000   100221       0\n",
      "RLV 220121P1200000   100221       0\n",
      "RLV 220121P1225000   100221       0\n",
      "RLV 220121P1250000   100221       0\n",
      "RLV 220121P1275000   100221       0\n",
      "RLV 220121P1300000   100221       0\n",
      "RLV 220121P1325000   100221       0\n",
      "RLV 220121P1340000   100221       0\n",
      "RLV 220121P1350000   100221       0\n",
      "RLV 220121P1360000   100221       0\n",
      "RLV 220121P1370000   100221       0\n",
      "RLV 220121P1375000   100221       0\n",
      "RLV 220121P1380000   100221       0\n",
      "RLV 220121P1390000   100221       0\n",
      "RLV 220121P1400000   100221       0\n",
      "RLV 220121P1610000   100221       0\n",
      "RLV 220121P1620000   100221       0\n",
      "RLV 220121P1625000   100221       0\n",
      "RLV 220121P1850000   100221       0\n",
      "RLV 220121P1900000   100221       0\n",
      "RLV 220121P1925000   100221       0\n",
      "RLV 220121P1950000   100221       0\n",
      "RLV 220121P1975000   100221       0\n",
      "RLV 220121P2000000   100221       0\n",
      "RLV 220121P2025000   100221       0\n",
      "RLV 220218C1150000   100221       0\n",
      "RLV 220218C1175000   100221       0\n",
      "RLV 220218C1200000   100221       0\n",
      "RLV 220218C1225000   100221       0\n",
      "RLV 220218C1250000   100221       0\n",
      "RLV 220218C1275000   100221       0\n",
      "RLV 220218C1300000   100221       0\n",
      "RLV 220218C1325000   100221       0\n",
      "RLV 220218C1350000   100221       0\n",
      "RLV 220218C1375000   100221       0\n",
      "RLV 220218C1400000   100221       0\n",
      "RLV 220218C1410000   100221       0\n",
      "RLV 220218C1420000   100221       0\n",
      "RLV 220121P1875000   100221       0\n",
      "RLV 220121P1825000   100221       0\n",
      "RLV 220121P1630000   100221       0\n",
      "RLV 220121P1800000   100221       0\n",
      "RLV 220121P1640000   100221       0\n",
      "RLV 220121P1650000   100221       0\n",
      "RLV 220121P1660000   100221       0\n",
      "RLV 220121P1670000   100221       0\n",
      "RLV 220121P1675000   100221       0\n",
      "RLV 220121P1680000   100221       0\n",
      "RLV 220121P1690000   100221       0\n",
      "RLV 220121P1700000   100221       0\n",
      "RLV 220121P1710000   100221       0\n",
      "RLV 220121P1720000   100221       0\n",
      "RLV 220121P1725000   100221       0\n",
      "RLV 220121P1730000   100221       0\n",
      "RLV 220121P1740000   100221       0\n",
      "RLV 220121P1750000   100221       0\n",
      "RLV 220121P1760000   100221       0\n",
      "RLV 220121P1770000   100221       0\n",
      "RLV 220121P1775000   100221       0\n",
      "RLV 220121P1780000   100221       0\n",
      "RLV 220121P1790000   100221       0\n",
      "RLV 220121C1975000   100221       0\n",
      "RLV 220121C1950000   100221       0\n",
      "RLV 220121C1925000   100221       0\n",
      "RLV 220121C1150000   100221       0\n",
      "RLV 220121C1200000   100221       0\n",
      "RLV 220121C1225000   100221       0\n",
      "RLV 220121C1250000   100221       0\n",
      "RLV 220121C1275000   100221       0\n",
      "RLV 220121C1300000   100221       0\n",
      "RLV 220121C1325000   100221       0\n",
      "RLV 220121C1340000   100221       0\n",
      "RLV 220121C1350000   100221       0\n",
      "RLV 220121C1360000   100221       0\n",
      "RLV 220121C1370000   100221       0\n",
      "RLV 220121C1375000   100221       0\n",
      "RLV 220121C1380000   100221       0\n",
      "RLV 220121C1390000   100221       0\n",
      "RLV 220121C1400000   100221       0\n",
      "RLV 220121C1410000   100221       0\n",
      "RLV 220121C1420000   100221       0\n",
      "RLV 220121C1425000   100221       0\n",
      "RLV 220121C1430000   100221       0\n",
      "RLV 220121C1440000   100221       0\n",
      "RLV 220121C1175000   100221       0\n",
      "RLV 220121C1125000   100221       0\n",
      "RLV 220121C1460000   100221       0\n",
      "RLG 220617P3975000   100222       0\n",
      "RLG 220617P3520000   100222       0\n",
      "RLG 220617P3525000   100222       0\n",
      "RLG 220617P3550000   100222       0\n",
      "RLG 220617P3575000   100222       0\n",
      "RLG 220617P3600000   100222       0\n",
      "RLG 220617P3625000   100222       0\n",
      "RLG 220617P3650000   100222       0\n",
      "RLG 220617P3675000   100222       0\n",
      "RLG 220617P3700000   100222       0\n",
      "RLG 220617P3725000   100222       0\n",
      "RLG 220617P3750000   100222       0\n",
      "RLG 220617P3775000   100222       0\n",
      "RLG 220617P3800000   100222       0\n",
      "RLG 220617P3825000   100222       0\n",
      "RLG 220617P3850000   100222       0\n",
      "RLG 220617P3875000   100222       0\n",
      "RLG 220617P3900000   100222       0\n",
      "RLG 220617P3925000   100222       0\n",
      "RLG 220617P3950000   100222       0\n",
      "RLV 220121C1450000   100221       0\n",
      "RLV 220121C1470000   100221       0\n",
      "RLV 220121C1900000   100221       0\n",
      "RLV 220121C1660000   100221       0\n",
      "RLV 220121C1675000   100221       0\n",
      "RLV 220121C1680000   100221       0\n",
      "RLV 220121C1690000   100221       0\n",
      "RLV 220121C1700000   100221       0\n",
      "RLV 220121C1710000   100221       0\n",
      "RLV 220121C1720000   100221       0\n",
      "RLV 220121C1725000   100221       0\n",
      "RLV 220121C1730000   100221       0\n",
      "RLV 220121C1740000   100221       0\n",
      "RLV 220121C1750000   100221       0\n",
      "RLV 220121C1760000   100221       0\n",
      "RLV 220121C1770000   100221       0\n",
      "RLV 220121C1775000   100221       0\n",
      "RLV 220121C1780000   100221       0\n",
      "RLV 220121C1790000   100221       0\n",
      "RLV 220121C1800000   100221       0\n",
      "RLV 220121C1825000   100221       0\n",
      "RLV 220121C1850000   100221       0\n",
      "RLV 220121C1875000   100221       0\n",
      "RLV 220121C1670000   100221       0\n",
      "RLV 220121C1650000   100221       0\n",
      "RLV 220121C1475000   100221       0\n",
      "RLV 220121C1640000   100221       0\n",
      "RLV 220121C1480000   100221       0\n",
      "RLV 220121C1490000   100221       0\n",
      "RLV 220121C1500000   100221       0\n",
      "RLV 220121C1510000   100221       0\n",
      "RLV 220121C1520000   100221       0\n",
      "RLV 220121C1525000   100221       0\n",
      "RLV 220121C1530000   100221       0\n",
      "RLV 220121C1540000   100221       0\n",
      "RLV 220121C1550000   100221       0\n",
      "RLV 220121C1560000   100221       0\n",
      "RLV 220121C1570000   100221       0\n",
      "RLV 220121C1575000   100221       0\n",
      "RLV 220121C1580000   100221       0\n",
      "RLV 220121C1590000   100221       0\n",
      "RLV 220121C1600000   100221       0\n",
      "RLV 220121C1610000   100221       0\n",
      "RLV 220121C1620000   100221       0\n",
      "RLV 220121C1625000   100221       0\n",
      "RLV 220121C1630000   100221       0\n",
      "RLV 220218C1425000   100221       0\n",
      "RLV 220218C1430000   100221       0\n",
      "RLV 220218C1440000   100221       0\n",
      "RLV 220218P1740000   100221       0\n",
      "RLV 220218P1760000   100221       0\n",
      "RLV 220218P1770000   100221       0\n",
      "RLV 220218P1775000   100221       0\n",
      "RLV 220218P1780000   100221       0\n",
      "RLV 220218P1790000   100221       0\n",
      "RLV 220218P1800000   100221       0\n",
      "RLV 220218P1810000   100221       0\n",
      "RLV 220218P1820000   100221       0\n",
      "RLV 220218P1825000   100221       0\n",
      "RLV 220218P1830000   100221       0\n",
      "RLV 220218P1840000   100221       0\n",
      "RLV 220218P1850000   100221       0\n",
      "RLV 220218P1860000   100221       0\n",
      "RLV 220218P1870000   100221       0\n",
      "RLV 220218P1875000   100221       0\n",
      "RLV 220218P1880000   100221       0\n",
      "RLV 220218P1900000   100221       0\n",
      "RLV 220218P1925000   100221       0\n",
      "RLV 220218P1950000   100221       0\n",
      "RLV 220218P1750000   100221       0\n",
      "RLV 220218P1730000   100221       0\n",
      "RLV 220218P2000000   100221       0\n",
      "RLV 220218P1725000   100221       0\n",
      "RLV 220218P1570000   100221       0\n",
      "RLV 220218P1575000   100221       0\n",
      "RLV 220218P1580000   100221       0\n",
      "RLV 220218P1590000   100221       0\n",
      "RLV 220218P1600000   100221       0\n",
      "RLV 220218P1610000   100221       0\n",
      "RLV 220218P1620000   100221       0\n",
      "RLV 220218P1625000   100221       0\n",
      "RLV 220218P1630000   100221       0\n",
      "RLV 220218P1640000   100221       0\n",
      "RLV 220218P1650000   100221       0\n",
      "RLV 220218P1660000   100221       0\n",
      "RLV 220218P1670000   100221       0\n",
      "RLV 220218P1675000   100221       0\n",
      "RLV 220218P1680000   100221       0\n",
      "RLV 220218P1690000   100221       0\n",
      "RLV 220218P1700000   100221       0\n",
      "RLV 220218P1710000   100221       0\n",
      "RLV 220218P1720000   100221       0\n",
      "RLV 220218P1975000   100221       0\n",
      "RLV 220218P2025000   100221       0\n",
      "RLV 220218P1550000   100221       0\n",
      "RLV 220318C1420000   100221       0\n",
      "RLV 220318C1430000   100221       0\n",
      "RLV 220318C1440000   100221       0\n",
      "RLV 220318C1450000   100221       0\n",
      "RLV 220318C1460000   100221       0\n",
      "RLV 220318C1470000   100221       0\n",
      "RLV 220318C1475000   100221       0\n",
      "RLV 220318C1480000   100221       0\n",
      "RLV 220318C1490000   100221       0\n",
      "RLV 220318C1500000   100221       0\n",
      "RLV 220318C1510000   100221       0\n",
      "RLV 220318C1520000   100221       0\n",
      "RLV 220318C1525000   100221       0\n",
      "RLV 220318C1530000   100221       0\n",
      "RLV 220318C1540000   100221       0\n",
      "RLV 220318C1550000   100221       0\n",
      "RLV 220318C1560000   100221       0\n",
      "RLV 220318C1570000   100221       0\n",
      "RLV 220318C1575000   100221       0\n",
      "RLV 220318C1580000   100221       0\n",
      "RLV 220318C1425000   100221       0\n",
      "RLV 220318C1410000   100221       0\n",
      "RLV 220218P2050000   100221       0\n",
      "RLV 220318C1400000   100221       0\n",
      "RLV 220218P2075000   100221       0\n",
      "RLV 220218P2100000   100221       0\n",
      "RLV 220218P2125000   100221       0\n",
      "RLV 220318C1125000   100221       0\n",
      "RLV 220318C1150000   100221       0\n",
      "RLV 220318C1175000   100221       0\n",
      "RLV 220318C1200000   100221       0\n",
      "RLV 220318C1225000   100221       0\n",
      "RLV 220318C1250000   100221       0\n",
      "RLV 220318C1275000   100221       0\n",
      "RLV 220318C1300000   100221       0\n",
      "RLV 220318C1325000   100221       0\n",
      "RLV 220318C1340000   100221       0\n",
      "RLV 220318C1350000   100221       0\n",
      "RLV 220318C1360000   100221       0\n",
      "RLV 220318C1370000   100221       0\n",
      "RLV 220318C1375000   100221       0\n",
      "RLV 220318C1380000   100221       0\n",
      "RLV 220318C1390000   100221       0\n",
      "RLV 220218P1560000   100221       0\n",
      "RLV 220218P1540000   100221       0\n",
      "RLV 220218C1450000   100221       0\n",
      "RLV 220218C1630000   100221       0\n",
      "RLV 220218C1650000   100221       0\n",
      "RLV 220218C1660000   100221       0\n",
      "RLV 220218C1670000   100221       0\n",
      "RLV 220218C1675000   100221       0\n",
      "RLV 220218C1680000   100221       0\n",
      "RLV 220218C1690000   100221       0\n",
      "RLV 220218C1700000   100221       0\n",
      "RLV 220218C1710000   100221       0\n",
      "RLV 220218C1720000   100221       0\n",
      "RLV 220218C1725000   100221       0\n",
      "RLV 220218C1730000   100221       0\n",
      "RLV 220218C1740000   100221       0\n",
      "RLV 220218C1750000   100221       0\n",
      "RLV 220218C1760000   100221       0\n",
      "RLV 220218C1770000   100221       0\n",
      "RLV 220218C1775000   100221       0\n",
      "RLV 220218C1780000   100221       0\n",
      "RLV 220218C1790000   100221       0\n",
      "RLV 220218C1800000   100221       0\n",
      "RLV 220218C1640000   100221       0\n",
      "RLV 220218C1625000   100221       0\n",
      "RLV 220218C1820000   100221       0\n",
      "RLV 220218C1620000   100221       0\n",
      "RLV 220218C1460000   100221       0\n",
      "RLV 220218C1470000   100221       0\n",
      "RLV 220218C1475000   100221       0\n",
      "RLV 220218C1480000   100221       0\n",
      "RLV 220218C1490000   100221       0\n",
      "RLV 220218C1500000   100221       0\n",
      "RLV 220218C1510000   100221       0\n",
      "RLV 220218C1520000   100221       0\n",
      "RLV 220218C1525000   100221       0\n",
      "RLV 220218C1530000   100221       0\n",
      "RLV 220218C1540000   100221       0\n",
      "RLV 220218C1550000   100221       0\n",
      "RLV 220218C1560000   100221       0\n",
      "RLV 220218C1570000   100221       0\n",
      "RLV 220218C1575000   100221       0\n",
      "RLV 220218C1580000   100221       0\n",
      "RLV 220218C1590000   100221       0\n",
      "RLV 220218C1600000   100221       0\n",
      "RLV 220218C1610000   100221       0\n",
      "RLV 220218C1810000   100221       0\n",
      "RLV 220218C1825000   100221       0\n",
      "RLV 220218P1530000   100221       0\n",
      "RLV 220218P1275000   100221       0\n",
      "RLV 220218P1325000   100221       0\n",
      "RLV 220218P1350000   100221       0\n",
      "RLV 220218P1375000   100221       0\n",
      "RLV 220218P1400000   100221       0\n",
      "RLV 220218P1410000   100221       0\n",
      "RLV 220218P1420000   100221       0\n",
      "RLV 220218P1425000   100221       0\n",
      "RLV 220218P1430000   100221       0\n",
      "RLV 220218P1440000   100221       0\n",
      "RLV 220218P1450000   100221       0\n",
      "RLV 220218P1460000   100221       0\n",
      "RLV 220218P1470000   100221       0\n",
      "RLV 220218P1475000   100221       0\n",
      "RLV 220218P1480000   100221       0\n",
      "RLV 220218P1490000   100221       0\n",
      "RLV 220218P1500000   100221       0\n",
      "RLV 220218P1510000   100221       0\n",
      "RLV 220218P1520000   100221       0\n",
      "RLV 220218P1525000   100221       0\n",
      "RLV 220218P1300000   100221       0\n",
      "RLV 220218P1250000   100221       0\n",
      "RLV 220218C1830000   100221       0\n",
      "RLV 220218P1225000   100221       0\n",
      "RLV 220218C1840000   100221       0\n",
      "RLV 220218C1850000   100221       0\n",
      "RLV 220218C1860000   100221       0\n",
      "RLV 220218C1870000   100221       0\n",
      "RLV 220218C1875000   100221       0\n",
      "RLV 220218C1880000   100221       0\n",
      "RLV 220218C1900000   100221       0\n",
      "RLV 220218C1925000   100221       0\n",
      "RLV 220218C1950000   100221       0\n",
      "RLV 220218C1975000   100221       0\n",
      "RLV 220218C2000000   100221       0\n",
      "RLV 220218C2025000   100221       0\n",
      "RLV 220218C2050000   100221       0\n",
      "RLV 220218C2075000   100221       0\n",
      "RLV 220218C2100000   100221       0\n",
      "RLV 220218C2125000   100221       0\n",
      "RLV 220218P1150000   100221       0\n",
      "RLV 220218P1175000   100221       0\n",
      "RLV 220218P1200000   100221       0\n",
      "RLG 220617P3510000   100222       0\n",
      "RLG 220617P3490000   100222       0\n",
      "RLG 220318P2675000   100222       0\n",
      "RLG 220617C2710000   100222       0\n",
      "RLG 220617C2630000   100222       0\n",
      "RLG 220617C2640000   100222       0\n",
      "RLG 220617C2650000   100222       0\n",
      "RLG 220617C2660000   100222       0\n",
      "RLG 220617C2670000   100222       0\n",
      "RLG 220617C2675000   100222       0\n",
      "RLG 220617C2680000   100222       0\n",
      "RLG 220617C2690000   100222       0\n",
      "RLG 220617C2700000   100222       0\n",
      "RLG 220617C2720000   100222       0\n",
      "RLG 220617P3480000   100222       0\n",
      "RLG 220617C2725000   100222       0\n",
      "RLG 220617C2730000   100222       0\n",
      "RLG 220617C2740000   100222       0\n",
      "RLG 220617C2750000   100222       0\n",
      "RLG 220617C2760000   100222       0\n",
      "RLG 220617C2770000   100222       0\n",
      "RLG 220617C2775000   100222       0\n",
      "RLG 220617C2780000   100222       0\n",
      "RLG 220617C2790000   100222       0\n",
      "RLG 220617C2625000   100222       0\n",
      "RLG 220617C2620000   100222       0\n",
      "RLG 220617C2610000   100222       0\n",
      "RLG 220617C2600000   100222       0\n",
      "RLG 220318P3750000   100222       0\n",
      "RLG 220617C2150000   100222       0\n",
      "RLG 220617C2175000   100222       0\n",
      "RLG 220617C2200000   100222       0\n",
      "RLG 220617C2225000   100222       0\n",
      "RLG 220617C2250000   100222       0\n",
      "RLG 220617C2275000   100222       0\n",
      "RLG 220617C2300000   100222       0\n",
      "RLG 220617C2325000   100222       0\n",
      "RLG 220617C2350000   100222       0\n",
      "RLG 220617C2375000   100222       0\n",
      "RLG 220617C2400000   100222       0\n",
      "RLG 220617C2425000   100222       0\n",
      "RLG 220617C2450000   100222       0\n",
      "RLG 220617C2475000   100222       0\n",
      "RLG 220617C2500000   100222       0\n",
      "RLG 220617C2525000   100222       0\n",
      "RLG 220617C2550000   100222       0\n",
      "RLG 220617C2575000   100222       0\n",
      "RLG 220617C2800000   100222       0\n",
      "RLG 220617C2810000   100222       0\n",
      "RLG 220617C2820000   100222       0\n",
      "RLG 220617C3010000   100222       0\n",
      "RLG 220617C3025000   100222       0\n",
      "RLG 220617C3030000   100222       0\n",
      "RLG 220617C3040000   100222       0\n",
      "RLG 220617C3050000   100222       0\n",
      "RLG 220617C3060000   100222       0\n",
      "RLG 220617C3070000   100222       0\n",
      "RLG 220617C3075000   100222       0\n",
      "RLG 220617C3080000   100222       0\n",
      "RLG 220617C3090000   100222       0\n",
      "RLG 220617C3100000   100222       0\n",
      "RLG 220617C3110000   100222       0\n",
      "RLG 220617C3120000   100222       0\n",
      "RLG 220617C3125000   100222       0\n",
      "RLG 220617C3130000   100222       0\n",
      "RLG 220617C3140000   100222       0\n",
      "RLG 220617C3150000   100222       0\n",
      "RLG 220617C3160000   100222       0\n",
      "RLG 220617C3170000   100222       0\n",
      "RLG 220617C3175000   100222       0\n",
      "RLG 220617C3020000   100222       0\n",
      "RLG 220617C3000000   100222       0\n",
      "RLG 220617C2825000   100222       0\n",
      "RLG 220617C2990000   100222       0\n",
      "RLG 220617C2830000   100222       0\n",
      "RLG 220617C2840000   100222       0\n",
      "RLG 220617C2850000   100222       0\n",
      "RLG 220617C2860000   100222       0\n",
      "RLG 220617C2870000   100222       0\n",
      "RLG 220617C2875000   100222       0\n",
      "RLG 220617C2880000   100222       0\n",
      "RLG 220617C2890000   100222       0\n",
      "RLG 220617C2900000   100222       0\n",
      "RLG 220617C2910000   100222       0\n",
      "RLG 220617C2920000   100222       0\n",
      "RLG 220617C2925000   100222       0\n",
      "RLG 220617C2930000   100222       0\n",
      "RLG 220617C2940000   100222       0\n",
      "RLG 220617C2950000   100222       0\n",
      "RLG 220617C2960000   100222       0\n",
      "RLG 220617C2970000   100222       0\n",
      "RLG 220617C2975000   100222       0\n",
      "RLG 220617C2980000   100222       0\n",
      "RLG 220318P3725000   100222       0\n",
      "RLG 220318P3700000   100222       0\n",
      "RLG 220318P3675000   100222       0\n",
      "RLG 220318P2860000   100222       0\n",
      "RLG 220318P2875000   100222       0\n",
      "RLG 220318P2880000   100222       0\n",
      "RLG 220318P2890000   100222       0\n",
      "RLG 220318P2900000   100222       0\n",
      "RLG 220318P2910000   100222       0\n",
      "RLG 220318P2920000   100222       0\n",
      "RLG 220318P2925000   100222       0\n",
      "RLG 220318P2930000   100222       0\n",
      "RLG 220318P2940000   100222       0\n",
      "RLG 220318P2950000   100222       0\n",
      "RLG 220318P2960000   100222       0\n",
      "RLG 220318P2970000   100222       0\n",
      "RLG 220318P2975000   100222       0\n",
      "RLG 220318P2980000   100222       0\n",
      "RLG 220318P2990000   100222       0\n",
      "RLG 220318P3000000   100222       0\n",
      "RLG 220318P3010000   100222       0\n",
      "RLG 220318P3020000   100222       0\n",
      "RLG 220318P3025000   100222       0\n",
      "RLG 220318P2870000   100222       0\n",
      "RLG 220318P2850000   100222       0\n",
      "RLG 220318P3040000   100222       0\n",
      "RLG 220318P2840000   100222       0\n",
      "RLG 220318P2680000   100222       0\n",
      "RLG 220318P2690000   100222       0\n",
      "RLG 220318P2700000   100222       0\n",
      "RLG 220318P2710000   100222       0\n",
      "RLG 220318P2720000   100222       0\n",
      "RLG 220318P2725000   100222       0\n",
      "RLG 220318P2730000   100222       0\n",
      "RLG 220318P2740000   100222       0\n",
      "RLG 220318P2750000   100222       0\n",
      "RLG 220318P2760000   100222       0\n",
      "RLG 220318P2770000   100222       0\n",
      "RLG 220318P2775000   100222       0\n",
      "RLG 220318P2780000   100222       0\n",
      "RLG 220318P2790000   100222       0\n",
      "RLG 220318P2800000   100222       0\n",
      "RLG 220318P2810000   100222       0\n",
      "RLG 220318P2820000   100222       0\n",
      "RLG 220318P2825000   100222       0\n",
      "RLG 220318P2830000   100222       0\n",
      "RLG 220318P3030000   100222       0\n",
      "RLG 220318P3050000   100222       0\n",
      "RLG 220318P3650000   100222       0\n",
      "RLG 220318P3240000   100222       0\n",
      "RLG 220318P3260000   100222       0\n",
      "RLG 220318P3270000   100222       0\n",
      "RLG 220318P3275000   100222       0\n",
      "RLG 220318P3280000   100222       0\n",
      "RLG 220318P3290000   100222       0\n",
      "RLG 220318P3300000   100222       0\n",
      "RLG 220318P3325000   100222       0\n",
      "RLG 220318P3350000   100222       0\n",
      "RLG 220318P3375000   100222       0\n",
      "RLG 220318P3400000   100222       0\n",
      "RLG 220318P3425000   100222       0\n",
      "RLG 220318P3450000   100222       0\n",
      "RLG 220318P3475000   100222       0\n",
      "RLG 220318P3500000   100222       0\n",
      "RLG 220318P3525000   100222       0\n",
      "RLG 220318P3550000   100222       0\n",
      "RLG 220318P3575000   100222       0\n",
      "RLG 220318P3600000   100222       0\n",
      "RLG 220318P3625000   100222       0\n",
      "RLG 220318P3250000   100222       0\n",
      "RLG 220318P3230000   100222       0\n",
      "RLG 220318P3060000   100222       0\n",
      "RLG 220318P3225000   100222       0\n",
      "RLG 220318P3070000   100222       0\n",
      "RLG 220318P3075000   100222       0\n",
      "RLG 220318P3080000   100222       0\n",
      "RLG 220318P3090000   100222       0\n",
      "RLG 220318P3100000   100222       0\n",
      "RLG 220318P3110000   100222       0\n",
      "RLG 220318P3120000   100222       0\n",
      "RLG 220318P3125000   100222       0\n",
      "RLG 220318P3130000   100222       0\n",
      "RLG 220318P3140000   100222       0\n",
      "RLG 220318P3150000   100222       0\n",
      "RLG 220318P3160000   100222       0\n",
      "RLG 220318P3170000   100222       0\n",
      "RLG 220318P3175000   100222       0\n",
      "RLG 220318P3180000   100222       0\n",
      "RLG 220318P3190000   100222       0\n",
      "RLG 220318P3200000   100222       0\n",
      "RLG 220318P3210000   100222       0\n",
      "RLG 220318P3220000   100222       0\n",
      "RLG 220617C3180000   100222       0\n",
      "RLG 220617C3190000   100222       0\n",
      "RLG 220617C3200000   100222       0\n",
      "RLG 220617P2925000   100222       0\n",
      "RLG 220617P2940000   100222       0\n",
      "RLG 220617P2950000   100222       0\n",
      "RLG 220617P2960000   100222       0\n",
      "RLG 220617P2970000   100222       0\n",
      "RLG 220617P2975000   100222       0\n",
      "RLG 220617P2980000   100222       0\n",
      "RLG 220617P2990000   100222       0\n",
      "RLG 220617P3000000   100222       0\n",
      "RLG 220617P3010000   100222       0\n",
      "RLG 220617P3020000   100222       0\n",
      "RLG 220617P3025000   100222       0\n",
      "RLG 220617P3030000   100222       0\n",
      "RLG 220617P3040000   100222       0\n",
      "RLG 220617P3050000   100222       0\n",
      "RLG 220617P3060000   100222       0\n",
      "RLG 220617P3070000   100222       0\n",
      "RLG 220617P3075000   100222       0\n",
      "RLG 220617P3080000   100222       0\n",
      "RLG 220617P3090000   100222       0\n",
      "RLG 220617P2930000   100222       0\n",
      "RLG 220617P2920000   100222       0\n",
      "RLG 220617P3110000   100222       0\n",
      "RLG 220617P2910000   100222       0\n",
      "RLG 220617P2750000   100222       0\n",
      "RLG 220617P2760000   100222       0\n",
      "RLG 220617P2770000   100222       0\n",
      "RLG 220617P2775000   100222       0\n",
      "RLG 220617P2780000   100222       0\n",
      "RLG 220617P2790000   100222       0\n",
      "RLG 220617P2800000   100222       0\n",
      "RLG 220617P2810000   100222       0\n",
      "RLG 220617P2820000   100222       0\n",
      "RLG 220617P2825000   100222       0\n",
      "RLG 220617P2830000   100222       0\n",
      "RLG 220617P2840000   100222       0\n",
      "RLG 220617P2850000   100222       0\n",
      "RLG 220617P2860000   100222       0\n",
      "RLG 220617P2870000   100222       0\n",
      "RLG 220617P2875000   100222       0\n",
      "RLG 220617P2880000   100222       0\n",
      "RLG 220617P2890000   100222       0\n",
      "RLG 220617P2900000   100222       0\n",
      "RLG 220617P3100000   100222       0\n",
      "RLG 220617P3120000   100222       0\n",
      "RLG 220617P2730000   100222       0\n",
      "RLG 220617P3310000   100222       0\n",
      "RLG 220617P3325000   100222       0\n",
      "RLG 220617P3330000   100222       0\n",
      "RLG 220617P3340000   100222       0\n",
      "RLG 220617P3350000   100222       0\n",
      "RLG 220617P3360000   100222       0\n",
      "RLG 220617P3370000   100222       0\n",
      "RLG 220617P3375000   100222       0\n",
      "RLG 220617P3380000   100222       0\n",
      "RLG 220617P3390000   100222       0\n",
      "RLG 220617P3400000   100222       0\n",
      "RLG 220617P3410000   100222       0\n",
      "RLG 220617P3420000   100222       0\n",
      "RLG 220617P3425000   100222       0\n",
      "RLG 220617P3430000   100222       0\n",
      "RLG 220617P3440000   100222       0\n",
      "RLG 220617P3450000   100222       0\n",
      "RLG 220617P3460000   100222       0\n",
      "RLG 220617P3470000   100222       0\n",
      "RLG 220617P3475000   100222       0\n",
      "RLG 220617P3320000   100222       0\n",
      "RLG 220617P3300000   100222       0\n",
      "RLG 220617P3125000   100222       0\n",
      "RLG 220617P3290000   100222       0\n",
      "RLG 220617P3130000   100222       0\n",
      "RLG 220617P3140000   100222       0\n",
      "RLG 220617P3150000   100222       0\n",
      "RLG 220617P3160000   100222       0\n",
      "RLG 220617P3170000   100222       0\n",
      "RLG 220617P3175000   100222       0\n",
      "RLG 220617P3180000   100222       0\n",
      "RLG 220617P3190000   100222       0\n",
      "RLG 220617P3200000   100222       0\n",
      "RLG 220617P3210000   100222       0\n",
      "RLG 220617P3220000   100222       0\n",
      "RLG 220617P3225000   100222       0\n",
      "RLG 220617P3230000   100222       0\n",
      "RLG 220617P3240000   100222       0\n",
      "RLG 220617P3250000   100222       0\n",
      "RLG 220617P3260000   100222       0\n",
      "RLG 220617P3270000   100222       0\n",
      "RLG 220617P3275000   100222       0\n",
      "RLG 220617P3280000   100222       0\n",
      "RLG 220617P2740000   100222       0\n",
      "RLG 220617P2725000   100222       0\n",
      "RLG 220617C3210000   100222       0\n",
      "RLG 220617C3390000   100222       0\n",
      "RLG 220617C3410000   100222       0\n",
      "RLG 220617C3420000   100222       0\n",
      "RLG 220617C3425000   100222       0\n",
      "RLG 220617C3430000   100222       0\n",
      "RLG 220617C3440000   100222       0\n",
      "RLG 220617C3450000   100222       0\n",
      "RLG 220617C3460000   100222       0\n",
      "RLG 220617C3470000   100222       0\n",
      "RLG 220617C3475000   100222       0\n",
      "RLG 220617C3480000   100222       0\n",
      "RLG 220617C3490000   100222       0\n",
      "RLG 220617C3500000   100222       0\n",
      "RLG 220617C3510000   100222       0\n",
      "RLG 220617C3520000   100222       0\n",
      "RLG 220617C3525000   100222       0\n",
      "RLG 220617C3550000   100222       0\n",
      "RLG 220617C3575000   100222       0\n",
      "RLG 220617C3600000   100222       0\n",
      "RLG 220617C3625000   100222       0\n",
      "RLG 220617C3400000   100222       0\n",
      "RLG 220617C3380000   100222       0\n",
      "RLG 220617C3675000   100222       0\n",
      "RLG 220617C3375000   100222       0\n",
      "RLG 220617C3220000   100222       0\n",
      "RLG 220617C3225000   100222       0\n",
      "RLG 220617C3230000   100222       0\n",
      "RLG 220617C3240000   100222       0\n",
      "RLG 220617C3250000   100222       0\n",
      "RLG 220617C3260000   100222       0\n",
      "RLG 220617C3270000   100222       0\n",
      "RLG 220617C3275000   100222       0\n",
      "RLG 220617C3280000   100222       0\n",
      "RLG 220617C3290000   100222       0\n",
      "RLG 220617C3300000   100222       0\n",
      "RLG 220617C3310000   100222       0\n",
      "RLG 220617C3320000   100222       0\n",
      "RLG 220617C3325000   100222       0\n",
      "RLG 220617C3330000   100222       0\n",
      "RLG 220617C3340000   100222       0\n",
      "RLG 220617C3350000   100222       0\n",
      "RLG 220617C3360000   100222       0\n",
      "RLG 220617C3370000   100222       0\n",
      "RLG 220617C3650000   100222       0\n",
      "RLG 220617C3700000   100222       0\n",
      "RLG 220617P2720000   100222       0\n",
      "RLG 220617P2425000   100222       0\n",
      "RLG 220617P2475000   100222       0\n",
      "RLG 220617P2500000   100222       0\n",
      "RLG 220617P2525000   100222       0\n",
      "RLG 220617P2550000   100222       0\n",
      "RLG 220617P2575000   100222       0\n",
      "RLG 220617P2600000   100222       0\n",
      "RLG 220617P2610000   100222       0\n",
      "RLG 220617P2620000   100222       0\n",
      "RLG 220617P2625000   100222       0\n",
      "RLG 220617P2630000   100222       0\n",
      "RLG 220617P2640000   100222       0\n",
      "RLG 220617P2650000   100222       0\n",
      "RLG 220617P2660000   100222       0\n",
      "RLG 220617P2670000   100222       0\n",
      "RLG 220617P2675000   100222       0\n",
      "RLG 220617P2680000   100222       0\n",
      "RLG 220617P2690000   100222       0\n",
      "RLG 220617P2700000   100222       0\n",
      "RLG 220617P2710000   100222       0\n",
      "RLG 220617P2450000   100222       0\n",
      "RLG 220617P2400000   100222       0\n",
      "RLG 220617C3725000   100222       0\n",
      "RLG 220617P2375000   100222       0\n",
      "RLG 220617C3750000   100222       0\n",
      "RLG 220617C3775000   100222       0\n",
      "RLG 220617C3800000   100222       0\n",
      "RLG 220617C3825000   100222       0\n",
      "RLG 220617C3850000   100222       0\n",
      "RLG 220617C3875000   100222       0\n",
      "RLG 220617C3900000   100222       0\n",
      "RLG 220617C3925000   100222       0\n",
      "RLG 220617C3950000   100222       0\n",
      "RLG 220617C3975000   100222       0\n",
      "RLG 220617P2150000   100222       0\n",
      "RLG 220617P2175000   100222       0\n",
      "RLG 220617P2200000   100222       0\n",
      "RLG 220617P2225000   100222       0\n",
      "RLG 220617P2250000   100222       0\n",
      "RLG 220617P2275000   100222       0\n",
      "RLG 220617P2300000   100222       0\n",
      "RLG 220617P2325000   100222       0\n",
      "RLG 220617P2350000   100222       0\n",
      "RUI 221216C2440000   100219       0\n",
      "RUI 221216C2450000   100219       0\n",
      "RUI 221216C2460000   100219       0\n",
      "RUT 231215P3350000   102434       0\n",
      "RUT 231215P2900000   102434       0\n",
      "RUT 231215P2950000   102434       0\n",
      "RUT 231215P3000000   102434       0\n",
      "RUT 231215P3050000   102434       0\n",
      "RUT 231215P3100000   102434       0\n",
      "RUT 231215P3150000   102434       0\n",
      "RUT 231215P3200000   102434       0\n",
      "RUT 231215P3250000   102434       0\n",
      "RUT 231215P3300000   102434       0\n",
      "RUT 231215P3400000   102434       0\n",
      "RUT 241220P1600000   102434       0\n",
      "RUT 231215P400000    102434       0\n",
      "RUT 231215P600000    102434       0\n",
      "RUT 231215P700000    102434       0\n",
      "RUT 231215P800000    102434       0\n",
      "RUT 231215P900000    102434       0\n",
      "RUT 241220C1100000   102434       0\n",
      "RUT 241220C1150000   102434       0\n",
      "RUT 241220C1200000   102434       0\n",
      "RUT 241220C1250000   102434       0\n",
      "RUT 231215P2850000   102434       0\n",
      "RUT 231215P2800000   102434       0\n",
      "RUT 231215P2750000   102434       0\n",
      "RUT 231215P2700000   102434       0\n",
      "RUT 231215P1750000   102434       0\n",
      "RUT 231215P1800000   102434       0\n",
      "RUT 231215P1850000   102434       0\n",
      "RUT 231215P1900000   102434       0\n",
      "RUT 231215P1950000   102434       0\n",
      "RUT 231215P2000000   102434       0\n",
      "RUT 231215P2050000   102434       0\n",
      "RUT 231215P2100000   102434       0\n",
      "RUT 231215P2150000   102434       0\n",
      "RUT 231215P2200000   102434       0\n",
      "RUT 231215P2250000   102434       0\n",
      "RUT 231215P2300000   102434       0\n",
      "RUT 231215P2350000   102434       0\n",
      "RUT 231215P2400000   102434       0\n",
      "RUT 231215P2450000   102434       0\n",
      "RUT 231215P2500000   102434       0\n",
      "RUT 231215P2550000   102434       0\n",
      "RUT 231215P2600000   102434       0\n",
      "RUT 231215P2650000   102434       0\n",
      "RUT 241220C1300000   102434       0\n",
      "RUT 241220C1350000   102434       0\n",
      "RUT 241220C1400000   102434       0\n",
      "RUT 241220C2550000   102434       0\n",
      "RUT 241220C2700000   102434       0\n",
      "RUT 241220C2750000   102434       0\n",
      "RUT 241220C2800000   102434       0\n",
      "RUT 241220C2850000   102434       0\n",
      "RUT 241220C2900000   102434       0\n",
      "RUT 241220C2950000   102434       0\n",
      "RUT 241220C3000000   102434       0\n",
      "RUT 241220C3050000   102434       0\n",
      "RUT 241220C3100000   102434       0\n",
      "RUT 241220C3150000   102434       0\n",
      "RUT 241220P1100000   102434       0\n",
      "RUT 241220P1150000   102434       0\n",
      "RUT 241220P1200000   102434       0\n",
      "RUT 241220P1250000   102434       0\n",
      "RUT 241220P1300000   102434       0\n",
      "RUT 241220P1350000   102434       0\n",
      "RUT 241220P1400000   102434       0\n",
      "RUT 241220P1450000   102434       0\n",
      "RUT 241220P1500000   102434       0\n",
      "RUT 241220C2650000   102434       0\n",
      "RUT 241220C2500000   102434       0\n",
      "RUT 241220C1450000   102434       0\n",
      "RUT 241220C2450000   102434       0\n",
      "RUT 241220C1500000   102434       0\n",
      "RUT 241220C1550000   102434       0\n",
      "RUT 241220C1600000   102434       0\n",
      "RUT 241220C1650000   102434       0\n",
      "RUT 241220C1700000   102434       0\n",
      "RUT 241220C1750000   102434       0\n",
      "RUT 241220C1800000   102434       0\n",
      "RUT 241220C1850000   102434       0\n",
      "RUT 241220C1900000   102434       0\n",
      "RUT 241220C1950000   102434       0\n",
      "RUT 241220C2000000   102434       0\n",
      "RUT 241220C2050000   102434       0\n",
      "RUT 241220C2100000   102434       0\n",
      "RUT 241220C2150000   102434       0\n",
      "RUT 241220C2200000   102434       0\n",
      "RUT 241220C2250000   102434       0\n",
      "RUT 241220C2300000   102434       0\n",
      "RUT 241220C2350000   102434       0\n",
      "RUT 241220C2400000   102434       0\n",
      "RUT 231215P1700000   102434       0\n",
      "RUT 231215P1650000   102434       0\n",
      "RUT 231215P1550000   102434       0\n",
      "RUT 230616P3300000   102434       0\n",
      "RUT 230616P3400000   102434       0\n",
      "RUT 230616P3450000   102434       0\n",
      "RUT 231215C1000000   102434       0\n",
      "RUT 231215C1050000   102434       0\n",
      "RUT 231215C1100000   102434       0\n",
      "RUT 231215C1150000   102434       0\n",
      "RUT 231215C1200000   102434       0\n",
      "RUT 231215C1250000   102434       0\n",
      "RUT 231215C1300000   102434       0\n",
      "RUT 231215C1350000   102434       0\n",
      "RUT 231215C1400000   102434       0\n",
      "RUT 231215C1450000   102434       0\n",
      "RUT 231215C1500000   102434       0\n",
      "RUT 231215C1550000   102434       0\n",
      "RUT 231215C1600000   102434       0\n",
      "RUT 231215C1650000   102434       0\n",
      "RUT 231215C1700000   102434       0\n",
      "RUT 231215C1750000   102434       0\n",
      "RUT 231215C1800000   102434       0\n",
      "RUT 230616P3350000   102434       0\n",
      "RUT 230616P3250000   102434       0\n",
      "RUT 231215C1900000   102434       0\n",
      "RUT 230616P3200000   102434       0\n",
      "RUT 230616P2680000   102434       0\n",
      "RUT 230616P2690000   102434       0\n",
      "RUT 230616P2700000   102434       0\n",
      "RUT 230616P2710000   102434       0\n",
      "RUT 230616P2720000   102434       0\n",
      "RUT 230616P2730000   102434       0\n",
      "RUT 230616P2740000   102434       0\n",
      "RUT 230616P2750000   102434       0\n",
      "RUT 230616P2760000   102434       0\n",
      "RUT 230616P2770000   102434       0\n",
      "RUT 230616P2780000   102434       0\n",
      "RUT 230616P2800000   102434       0\n",
      "RUT 230616P2850000   102434       0\n",
      "RUT 230616P2900000   102434       0\n",
      "RUT 230616P2950000   102434       0\n",
      "RUT 230616P3000000   102434       0\n",
      "RUT 230616P3050000   102434       0\n",
      "RUT 230616P3100000   102434       0\n",
      "RUT 230616P3150000   102434       0\n",
      "RUT 231215C1850000   102434       0\n",
      "RUT 231215C1950000   102434       0\n",
      "RUT 231215P1500000   102434       0\n",
      "RUT 231215C3100000   102434       0\n",
      "RUT 231215C3200000   102434       0\n",
      "RUT 231215C3250000   102434       0\n",
      "RUT 231215C3300000   102434       0\n",
      "RUT 231215C400000    102434       0\n",
      "RUT 231215C500000    102434       0\n",
      "RUT 231215C600000    102434       0\n",
      "RUT 231215C700000    102434       0\n",
      "RUT 231215C800000    102434       0\n",
      "RUT 231215C900000    102434       0\n",
      "RUT 231215P1000000   102434       0\n",
      "RUT 231215P1050000   102434       0\n",
      "RUT 231215P1100000   102434       0\n",
      "RUT 231215P1150000   102434       0\n",
      "RUT 231215P1200000   102434       0\n",
      "RUT 231215P1250000   102434       0\n",
      "RUT 231215P1300000   102434       0\n",
      "RUT 231215P1350000   102434       0\n",
      "RUT 231215P1400000   102434       0\n",
      "RUT 231215P1450000   102434       0\n",
      "RUT 231215C3150000   102434       0\n",
      "RUT 231215C3050000   102434       0\n",
      "RUT 231215C2000000   102434       0\n",
      "RUT 231215C3000000   102434       0\n",
      "RUT 231215C2050000   102434       0\n",
      "RUT 231215C2100000   102434       0\n",
      "RUT 231215C2150000   102434       0\n",
      "RUT 231215C2200000   102434       0\n",
      "RUT 231215C2250000   102434       0\n",
      "RUT 231215C2300000   102434       0\n",
      "RUT 231215C2350000   102434       0\n",
      "RUT 231215C2400000   102434       0\n",
      "RUT 231215C2450000   102434       0\n",
      "RUT 231215C2500000   102434       0\n",
      "RUT 231215C2550000   102434       0\n",
      "RUT 231215C2600000   102434       0\n",
      "RUT 231215C2650000   102434       0\n",
      "RUT 231215C2700000   102434       0\n",
      "RUT 231215C2750000   102434       0\n",
      "RUT 231215C2800000   102434       0\n",
      "RUT 231215C2850000   102434       0\n",
      "RUT 231215C2900000   102434       0\n",
      "RUT 231215C2950000   102434       0\n",
      "RUT 241220P1550000   102434       0\n",
      "RUT 241220P1650000   102434       0\n",
      "RUT 221216C2630000   102434       0\n",
      "RUTW 220103C2395000  102434       0\n",
      "RUTW 220103C2190000  102434       0\n",
      "RUTW 220103C2195000  102434       0\n",
      "RUTW 220103C2205000  102434       0\n",
      "RUTW 220103C2360000  102434       0\n",
      "RUTW 220103C2365000  102434       0\n",
      "RUTW 220103C2370000  102434       0\n",
      "RUTW 220103C2375000  102434       0\n",
      "RUTW 220103C2385000  102434       0\n",
      "RUTW 220103C2390000  102434       0\n",
      "RUTW 220103C2400000  102434       0\n",
      "RUT 241220P1700000   102434       0\n",
      "RUTW 220103C2405000  102434       0\n",
      "RUTW 220103C2410000  102434       0\n",
      "RUTW 220103C2415000  102434       0\n",
      "RUTW 220103C2420000  102434       0\n",
      "RUTW 220103C2425000  102434       0\n",
      "RUTW 220103C2430000  102434       0\n",
      "RUTW 220103C2435000  102434       0\n",
      "RUTW 220103C2440000  102434       0\n",
      "RUTW 220103C2445000  102434       0\n",
      "RUTW 220103C2185000  102434       0\n",
      "RUTW 220103C2180000  102434       0\n",
      "RUTW 220103C2175000  102434       0\n",
      "RUTW 220103C2160000  102434       0\n",
      "RUTW 220103C2065000  102434       0\n",
      "RUTW 220103C2070000  102434       0\n",
      "RUTW 220103C2075000  102434       0\n",
      "RUTW 220103C2080000  102434       0\n",
      "RUTW 220103C2085000  102434       0\n",
      "RUTW 220103C2090000  102434       0\n",
      "RUTW 220103C2095000  102434       0\n",
      "RUTW 220103C2100000  102434       0\n",
      "RUTW 220103C2105000  102434       0\n",
      "RUTW 220103C2110000  102434       0\n",
      "RUTW 220103C2115000  102434       0\n",
      "RUTW 220103C2120000  102434       0\n",
      "RUTW 220103C2125000  102434       0\n",
      "RUTW 220103C2130000  102434       0\n",
      "RUTW 220103C2135000  102434       0\n",
      "RUTW 220103C2140000  102434       0\n",
      "RUTW 220103C2145000  102434       0\n",
      "RUTW 220103C2150000  102434       0\n",
      "RUTW 220103C2155000  102434       0\n",
      "RUTW 220103C2450000  102434       0\n",
      "RUTW 220103C2455000  102434       0\n",
      "RUTW 220103C2460000  102434       0\n",
      "RUTW 220103C2575000  102434       0\n",
      "RUTW 220103C2585000  102434       0\n",
      "RUTW 220103C2590000  102434       0\n",
      "RUTW 220103C2595000  102434       0\n",
      "RUTW 220103C2600000  102434       0\n",
      "RUTW 220103C2605000  102434       0\n",
      "RUTW 220103C2610000  102434       0\n",
      "RUTW 220103C2615000  102434       0\n",
      "RUTW 220103C2620000  102434       0\n",
      "RUTW 220103C2625000  102434       0\n",
      "RUTW 220103C2630000  102434       0\n",
      "RUTW 220103C2635000  102434       0\n",
      "RUTW 220103P1755000  102434       0\n",
      "RUTW 220103P1760000  102434       0\n",
      "RUTW 220103P1765000  102434       0\n",
      "RUTW 220103P1770000  102434       0\n",
      "RUTW 220103P1775000  102434       0\n",
      "RUTW 220103P1780000  102434       0\n",
      "RUTW 220103P1785000  102434       0\n",
      "RUTW 220103P1790000  102434       0\n",
      "RUTW 220103C2580000  102434       0\n",
      "RUTW 220103C2570000  102434       0\n",
      "RUTW 220103C2465000  102434       0\n",
      "RUTW 220103C2565000  102434       0\n",
      "RUTW 220103C2470000  102434       0\n",
      "RUTW 220103C2475000  102434       0\n",
      "RUTW 220103C2480000  102434       0\n",
      "RUTW 220103C2485000  102434       0\n",
      "RUTW 220103C2490000  102434       0\n",
      "RUTW 220103C2495000  102434       0\n",
      "RUTW 220103C2500000  102434       0\n",
      "RUTW 220103C2505000  102434       0\n",
      "RUTW 220103C2510000  102434       0\n",
      "RUTW 220103C2515000  102434       0\n",
      "RUTW 220103C2520000  102434       0\n",
      "RUTW 220103C2525000  102434       0\n",
      "RUTW 220103C2530000  102434       0\n",
      "RUTW 220103C2535000  102434       0\n",
      "RUTW 220103C2540000  102434       0\n",
      "RUTW 220103C2545000  102434       0\n",
      "RUTW 220103C2550000  102434       0\n",
      "RUTW 220103C2555000  102434       0\n",
      "RUTW 220103C2560000  102434       0\n",
      "RUTW 220103C2060000  102434       0\n",
      "RUTW 220103C2055000  102434       0\n",
      "RUTW 220103C2050000  102434       0\n",
      "RUT 241220P2800000   102434       0\n",
      "RUT 241220P2900000   102434       0\n",
      "RUT 241220P2950000   102434       0\n",
      "RUT 241220P3000000   102434       0\n",
      "RUT 241220P3050000   102434       0\n",
      "RUT 241220P3100000   102434       0\n",
      "RUT 241220P3150000   102434       0\n",
      "RUT 241220P3200000   102434       0\n",
      "RUTW 220103C1755000  102434       0\n",
      "RUTW 220103C1760000  102434       0\n",
      "RUTW 220103C1765000  102434       0\n",
      "RUTW 220103C1770000  102434       0\n",
      "RUTW 220103C1775000  102434       0\n",
      "RUTW 220103C1780000  102434       0\n",
      "RUTW 220103C1785000  102434       0\n",
      "RUTW 220103C1790000  102434       0\n",
      "RUTW 220103C1795000  102434       0\n",
      "RUTW 220103C1800000  102434       0\n",
      "RUTW 220103C1805000  102434       0\n",
      "RUTW 220103C1810000  102434       0\n",
      "RUT 241220P2850000   102434       0\n",
      "RUT 241220P2750000   102434       0\n",
      "RUTW 220103C1820000  102434       0\n",
      "RUT 241220P2700000   102434       0\n",
      "RUT 241220P1750000   102434       0\n",
      "RUT 241220P1800000   102434       0\n",
      "RUT 241220P1850000   102434       0\n",
      "RUT 241220P1900000   102434       0\n",
      "RUT 241220P1950000   102434       0\n",
      "RUT 241220P2000000   102434       0\n",
      "RUT 241220P2050000   102434       0\n",
      "RUT 241220P2100000   102434       0\n",
      "RUT 241220P2150000   102434       0\n",
      "RUT 241220P2200000   102434       0\n",
      "RUT 241220P2250000   102434       0\n",
      "RUT 241220P2300000   102434       0\n",
      "RUT 241220P2350000   102434       0\n",
      "RUT 241220P2400000   102434       0\n",
      "RUT 241220P2450000   102434       0\n",
      "RUT 241220P2500000   102434       0\n",
      "RUT 241220P2550000   102434       0\n",
      "RUT 241220P2600000   102434       0\n",
      "RUT 241220P2650000   102434       0\n",
      "RUTW 220103C1815000  102434       0\n",
      "RUTW 220103C1825000  102434       0\n",
      "RUTW 220103C2045000  102434       0\n",
      "RUTW 220103C1940000  102434       0\n",
      "RUTW 220103C1950000  102434       0\n",
      "RUTW 220103C1955000  102434       0\n",
      "RUTW 220103C1960000  102434       0\n",
      "RUTW 220103C1965000  102434       0\n",
      "RUTW 220103C1970000  102434       0\n",
      "RUTW 220103C1975000  102434       0\n",
      "RUTW 220103C1980000  102434       0\n",
      "RUTW 220103C1985000  102434       0\n",
      "RUTW 220103C1990000  102434       0\n",
      "RUTW 220103C1995000  102434       0\n",
      "RUTW 220103C2000000  102434       0\n",
      "RUTW 220103C2005000  102434       0\n",
      "RUTW 220103C2010000  102434       0\n",
      "RUTW 220103C2015000  102434       0\n",
      "RUTW 220103C2020000  102434       0\n",
      "RUTW 220103C2025000  102434       0\n",
      "RUTW 220103C2030000  102434       0\n",
      "RUTW 220103C2035000  102434       0\n",
      "RUTW 220103C2040000  102434       0\n",
      "RUTW 220103C1945000  102434       0\n",
      "RUTW 220103C1935000  102434       0\n",
      "RUTW 220103C1830000  102434       0\n",
      "RUTW 220103C1930000  102434       0\n",
      "RUTW 220103C1835000  102434       0\n",
      "RUTW 220103C1840000  102434       0\n",
      "RUTW 220103C1845000  102434       0\n",
      "RUTW 220103C1850000  102434       0\n",
      "RUTW 220103C1855000  102434       0\n",
      "RUTW 220103C1860000  102434       0\n",
      "RUTW 220103C1865000  102434       0\n",
      "RUTW 220103C1870000  102434       0\n",
      "RUTW 220103C1875000  102434       0\n",
      "RUTW 220103C1880000  102434       0\n",
      "RUTW 220103C1885000  102434       0\n",
      "RUTW 220103C1890000  102434       0\n",
      "RUTW 220103C1895000  102434       0\n",
      "RUTW 220103C1900000  102434       0\n",
      "RUTW 220103C1905000  102434       0\n",
      "RUTW 220103C1910000  102434       0\n",
      "RUTW 220103C1915000  102434       0\n",
      "RUTW 220103C1920000  102434       0\n",
      "RUTW 220103C1925000  102434       0\n",
      "RUT 230616P2670000   102434       0\n",
      "RUT 230616P2660000   102434       0\n",
      "RUT 230616P2650000   102434       0\n",
      "RUT 221216P2600000   102434       0\n",
      "RUT 221216P2510000   102434       0\n",
      "RUT 221216P2520000   102434       0\n",
      "RUT 221216P2530000   102434       0\n",
      "RUT 221216P2540000   102434       0\n",
      "RUT 221216P2550000   102434       0\n",
      "RUT 221216P2560000   102434       0\n",
      "RUT 221216P2570000   102434       0\n",
      "RUT 221216P2580000   102434       0\n",
      "RUT 221216P2590000   102434       0\n",
      "RUT 221216P2610000   102434       0\n",
      "RUT 230616P2640000   102434       0\n",
      "RUT 221216P2620000   102434       0\n",
      "RUT 221216P2630000   102434       0\n",
      "RUT 221216P2640000   102434       0\n",
      "RUT 221216P2650000   102434       0\n",
      "RUT 221216P2660000   102434       0\n",
      "RUT 221216P2670000   102434       0\n",
      "RUT 221216P2680000   102434       0\n",
      "RUT 221216P2690000   102434       0\n",
      "RUT 221216P2700000   102434       0\n",
      "RUT 221216P2500000   102434       0\n",
      "RUT 221216P2490000   102434       0\n",
      "RUT 221216P2480000   102434       0\n",
      "RUT 221216P2470000   102434       0\n",
      "RUT 221216P2280000   102434       0\n",
      "RUT 221216P2290000   102434       0\n",
      "RUT 221216P2300000   102434       0\n",
      "RUT 221216P2310000   102434       0\n",
      "RUT 221216P2320000   102434       0\n",
      "RUT 221216P2330000   102434       0\n",
      "RUT 221216P2340000   102434       0\n",
      "RUT 221216P2350000   102434       0\n",
      "RUT 221216P2360000   102434       0\n",
      "RUT 221216P2370000   102434       0\n",
      "RUT 221216P2380000   102434       0\n",
      "RUT 221216P2390000   102434       0\n",
      "RUT 221216P2400000   102434       0\n",
      "RUT 221216P2410000   102434       0\n",
      "RUT 221216P2420000   102434       0\n",
      "RUT 221216P2430000   102434       0\n",
      "RUT 221216P2440000   102434       0\n",
      "RUT 221216P2450000   102434       0\n",
      "RUT 221216P2460000   102434       0\n",
      "RUT 221216P2750000   102434       0\n",
      "RUT 221216P2800000   102434       0\n",
      "RUT 221216P2850000   102434       0\n",
      "RUT 230616C1300000   102434       0\n",
      "RUT 230616C1400000   102434       0\n",
      "RUT 230616C1450000   102434       0\n",
      "RUT 230616C1500000   102434       0\n",
      "RUT 230616C1550000   102434       0\n",
      "RUT 230616C1600000   102434       0\n",
      "RUT 230616C1650000   102434       0\n",
      "RUT 230616C1700000   102434       0\n",
      "RUT 230616C1750000   102434       0\n",
      "RUT 230616C1800000   102434       0\n",
      "RUT 230616C1850000   102434       0\n",
      "RUT 230616C1860000   102434       0\n",
      "RUT 230616C1870000   102434       0\n",
      "RUT 230616C1880000   102434       0\n",
      "RUT 230616C1890000   102434       0\n",
      "RUT 230616C1900000   102434       0\n",
      "RUT 230616C1910000   102434       0\n",
      "RUT 230616C1920000   102434       0\n",
      "RUT 230616C1930000   102434       0\n",
      "RUT 230616C1940000   102434       0\n",
      "RUT 230616C1350000   102434       0\n",
      "RUT 230616C1250000   102434       0\n",
      "RUT 221216P2900000   102434       0\n",
      "RUT 230616C1200000   102434       0\n",
      "RUT 221216P2950000   102434       0\n",
      "RUT 221216P3000000   102434       0\n",
      "RUT 221216P3050000   102434       0\n",
      "RUT 221216P3100000   102434       0\n",
      "RUT 221216P3150000   102434       0\n",
      "RUT 221216P3200000   102434       0\n",
      "RUT 221216P3250000   102434       0\n",
      "RUT 221216P3300000   102434       0\n",
      "RUT 221216P3350000   102434       0\n",
      "RUT 221216P3400000   102434       0\n",
      "RUT 221216P400000    102434       0\n",
      "RUT 221216P500000    102434       0\n",
      "RUT 221216P600000    102434       0\n",
      "RUT 221216P700000    102434       0\n",
      "RUT 221216P750000    102434       0\n",
      "RUT 221216P800000    102434       0\n",
      "RUT 221216P850000    102434       0\n",
      "RUT 221216P900000    102434       0\n",
      "RUT 221216P950000    102434       0\n",
      "RUT 221216P2270000   102434       0\n",
      "RUT 221216P2260000   102434       0\n",
      "RUT 221216P2250000   102434       0\n",
      "RUT 221216C500000    102434       0\n",
      "RUT 221216C700000    102434       0\n",
      "RUT 221216C750000    102434       0\n",
      "RUT 221216C800000    102434       0\n",
      "RUT 221216C850000    102434       0\n",
      "RUT 221216C900000    102434       0\n",
      "RUT 221216C950000    102434       0\n",
      "RUT 221216P1000000   102434       0\n",
      "RUT 221216P1050000   102434       0\n",
      "RUT 221216P1100000   102434       0\n",
      "RUT 221216P1150000   102434       0\n",
      "RUT 221216P1200000   102434       0\n",
      "RUT 221216P1250000   102434       0\n",
      "RUT 221216P1300000   102434       0\n",
      "RUT 221216P1350000   102434       0\n",
      "RUT 221216P1400000   102434       0\n",
      "RUT 221216P1450000   102434       0\n",
      "RUT 221216P1500000   102434       0\n",
      "RUT 221216P1550000   102434       0\n",
      "RUT 221216P1600000   102434       0\n",
      "RUT 221216C600000    102434       0\n",
      "RUT 221216C400000    102434       0\n",
      "RUT 221216P1700000   102434       0\n",
      "RUT 221216C3400000   102434       0\n",
      "RUT 221216C2650000   102434       0\n",
      "RUT 221216C2660000   102434       0\n",
      "RUT 221216C2670000   102434       0\n",
      "RUT 221216C2680000   102434       0\n",
      "RUT 221216C2690000   102434       0\n",
      "RUT 221216C2700000   102434       0\n",
      "RUT 221216C2750000   102434       0\n",
      "RUT 221216C2800000   102434       0\n",
      "RUT 221216C2850000   102434       0\n",
      "RUT 221216C2900000   102434       0\n",
      "RUT 221216C2950000   102434       0\n",
      "RUT 221216C3000000   102434       0\n",
      "RUT 221216C3050000   102434       0\n",
      "RUT 221216C3100000   102434       0\n",
      "RUT 221216C3150000   102434       0\n",
      "RUT 221216C3200000   102434       0\n",
      "RUT 221216C3250000   102434       0\n",
      "RUT 221216C3300000   102434       0\n",
      "RUT 221216C3350000   102434       0\n",
      "RUT 221216P1650000   102434       0\n",
      "RUT 221216P1750000   102434       0\n",
      "RUT 221216P2240000   102434       0\n",
      "RUT 221216P2030000   102434       0\n",
      "RUT 221216P2050000   102434       0\n",
      "RUT 221216P2060000   102434       0\n",
      "RUT 221216P2070000   102434       0\n",
      "RUT 221216P2080000   102434       0\n",
      "RUT 221216P2090000   102434       0\n",
      "RUT 221216P2100000   102434       0\n",
      "RUT 221216P2110000   102434       0\n",
      "RUT 221216P2120000   102434       0\n",
      "RUT 221216P2130000   102434       0\n",
      "RUT 221216P2140000   102434       0\n",
      "RUT 221216P2150000   102434       0\n",
      "RUT 221216P2160000   102434       0\n",
      "RUT 221216P2170000   102434       0\n",
      "RUT 221216P2180000   102434       0\n",
      "RUT 221216P2190000   102434       0\n",
      "RUT 221216P2200000   102434       0\n",
      "RUT 221216P2210000   102434       0\n",
      "RUT 221216P2220000   102434       0\n",
      "RUT 221216P2230000   102434       0\n",
      "RUT 221216P2040000   102434       0\n",
      "RUT 221216P2020000   102434       0\n",
      "RUT 221216P1800000   102434       0\n",
      "RUT 221216P2010000   102434       0\n",
      "RUT 221216P1810000   102434       0\n",
      "RUT 221216P1820000   102434       0\n",
      "RUT 221216P1830000   102434       0\n",
      "RUT 221216P1840000   102434       0\n",
      "RUT 221216P1850000   102434       0\n",
      "RUT 221216P1860000   102434       0\n",
      "RUT 221216P1870000   102434       0\n",
      "RUT 221216P1880000   102434       0\n",
      "RUT 221216P1890000   102434       0\n",
      "RUT 221216P1900000   102434       0\n",
      "RUT 221216P1910000   102434       0\n",
      "RUT 221216P1920000   102434       0\n",
      "RUT 221216P1930000   102434       0\n",
      "RUT 221216P1940000   102434       0\n",
      "RUT 221216P1960000   102434       0\n",
      "RUT 221216P1970000   102434       0\n",
      "RUT 221216P1980000   102434       0\n",
      "RUT 221216P1990000   102434       0\n",
      "RUT 221216P2000000   102434       0\n",
      "RUT 230616C1950000   102434       0\n",
      "RUT 230616C1960000   102434       0\n",
      "RUT 230616C1970000   102434       0\n",
      "RUT 230616P1930000   102434       0\n",
      "RUT 230616P1970000   102434       0\n",
      "RUT 230616P1980000   102434       0\n",
      "RUT 230616P1990000   102434       0\n",
      "RUT 230616P2010000   102434       0\n",
      "RUT 230616P2030000   102434       0\n",
      "RUT 230616P2040000   102434       0\n",
      "RUT 230616P2050000   102434       0\n",
      "RUT 230616P2060000   102434       0\n",
      "RUT 230616P2070000   102434       0\n",
      "RUT 230616P2080000   102434       0\n",
      "RUT 230616P2090000   102434       0\n",
      "RUT 230616P2100000   102434       0\n",
      "RUT 230616P2110000   102434       0\n",
      "RUT 230616P2120000   102434       0\n",
      "RUT 230616P2130000   102434       0\n",
      "RUT 230616P2140000   102434       0\n",
      "RUT 230616P2150000   102434       0\n",
      "RUT 230616P2160000   102434       0\n",
      "RUT 230616P2170000   102434       0\n",
      "RUT 230616P1950000   102434       0\n",
      "RUT 230616P1920000   102434       0\n",
      "RUT 230616P2190000   102434       0\n",
      "RUT 230616P1910000   102434       0\n",
      "RUT 230616P1200000   102434       0\n",
      "RUT 230616P1250000   102434       0\n",
      "RUT 230616P1300000   102434       0\n",
      "RUT 230616P1350000   102434       0\n",
      "RUT 230616P1400000   102434       0\n",
      "RUT 230616P1450000   102434       0\n",
      "RUT 230616P1500000   102434       0\n",
      "RUT 230616P1550000   102434       0\n",
      "RUT 230616P1600000   102434       0\n",
      "RUT 230616P1650000   102434       0\n",
      "RUT 230616P1700000   102434       0\n",
      "RUT 230616P1750000   102434       0\n",
      "RUT 230616P1800000   102434       0\n",
      "RUT 230616P1850000   102434       0\n",
      "RUT 230616P1860000   102434       0\n",
      "RUT 230616P1870000   102434       0\n",
      "RUT 230616P1880000   102434       0\n",
      "RUT 230616P1890000   102434       0\n",
      "RUT 230616P1900000   102434       0\n",
      "RUT 230616P2180000   102434       0\n",
      "RUT 230616P2200000   102434       0\n",
      "RUT 230616C3400000   102434       0\n",
      "RUT 230616P2430000   102434       0\n",
      "RUT 230616P2450000   102434       0\n",
      "RUT 230616P2460000   102434       0\n",
      "RUT 230616P2470000   102434       0\n",
      "RUT 230616P2480000   102434       0\n",
      "RUT 230616P2490000   102434       0\n",
      "RUT 230616P2500000   102434       0\n",
      "RUT 230616P2510000   102434       0\n",
      "RUT 230616P2520000   102434       0\n",
      "RUT 230616P2530000   102434       0\n",
      "RUT 230616P2540000   102434       0\n",
      "RUT 230616P2550000   102434       0\n",
      "RUT 230616P2560000   102434       0\n",
      "RUT 230616P2570000   102434       0\n",
      "RUT 230616P2580000   102434       0\n",
      "RUT 230616P2590000   102434       0\n",
      "RUT 230616P2600000   102434       0\n",
      "RUT 230616P2610000   102434       0\n",
      "RUT 230616P2620000   102434       0\n",
      "RUT 230616P2630000   102434       0\n",
      "RUT 230616P2440000   102434       0\n",
      "RUT 230616P2420000   102434       0\n",
      "RUT 230616P2210000   102434       0\n",
      "RUT 230616P2410000   102434       0\n",
      "RUT 230616P2220000   102434       0\n",
      "RUT 230616P2230000   102434       0\n",
      "RUT 230616P2240000   102434       0\n",
      "RUT 230616P2250000   102434       0\n",
      "RUT 230616P2260000   102434       0\n",
      "RUT 230616P2270000   102434       0\n",
      "RUT 230616P2280000   102434       0\n",
      "RUT 230616P2290000   102434       0\n",
      "RUT 230616P2300000   102434       0\n",
      "RUT 230616P2310000   102434       0\n",
      "RUT 230616P2320000   102434       0\n",
      "RUT 230616P2330000   102434       0\n",
      "RUT 230616P2340000   102434       0\n",
      "RUT 230616P2350000   102434       0\n",
      "RUT 230616P2360000   102434       0\n",
      "RUT 230616P2370000   102434       0\n",
      "RUT 230616P2380000   102434       0\n",
      "RUT 230616P2390000   102434       0\n",
      "RUT 230616P2400000   102434       0\n",
      "RUT 230616C3450000   102434       0\n",
      "RUT 230616C3350000   102434       0\n",
      "RUT 230616C1980000   102434       0\n",
      "RUT 230616C2200000   102434       0\n",
      "RUT 230616C2220000   102434       0\n",
      "RUT 230616C2230000   102434       0\n",
      "RUT 230616C2240000   102434       0\n",
      "RUT 230616C2250000   102434       0\n",
      "RUT 230616C2260000   102434       0\n",
      "RUT 230616C2270000   102434       0\n",
      "RUT 230616C2280000   102434       0\n",
      "RUT 230616C2290000   102434       0\n",
      "RUT 230616C2300000   102434       0\n",
      "RUT 230616C2310000   102434       0\n",
      "RUT 230616C2320000   102434       0\n",
      "RUT 230616C2330000   102434       0\n",
      "RUT 230616C2340000   102434       0\n",
      "RUT 230616C2350000   102434       0\n",
      "RUT 230616C2360000   102434       0\n",
      "RUT 230616C2370000   102434       0\n",
      "RUT 230616C2380000   102434       0\n",
      "RUT 230616C2390000   102434       0\n",
      "RUT 230616C2400000   102434       0\n",
      "RUT 230616C2210000   102434       0\n",
      "RUT 230616C2190000   102434       0\n",
      "RUT 230616C2420000   102434       0\n",
      "RUT 230616C2180000   102434       0\n",
      "RUT 230616C1990000   102434       0\n",
      "RUT 230616C2000000   102434       0\n",
      "RUT 230616C2010000   102434       0\n",
      "RUT 230616C2020000   102434       0\n",
      "RUT 230616C2030000   102434       0\n",
      "RUT 230616C2040000   102434       0\n",
      "RUT 230616C2050000   102434       0\n",
      "RUT 230616C2060000   102434       0\n",
      "RUT 230616C2070000   102434       0\n",
      "RUT 230616C2080000   102434       0\n",
      "RUT 230616C2090000   102434       0\n",
      "RUT 230616C2100000   102434       0\n",
      "RUT 230616C2110000   102434       0\n",
      "RUT 230616C2120000   102434       0\n",
      "RUT 230616C2130000   102434       0\n",
      "RUT 230616C2140000   102434       0\n",
      "RUT 230616C2150000   102434       0\n",
      "RUT 230616C2160000   102434       0\n",
      "RUT 230616C2170000   102434       0\n",
      "RUT 230616C2410000   102434       0\n",
      "RUT 230616C2430000   102434       0\n",
      "RUT 230616C3300000   102434       0\n",
      "RUT 230616C2680000   102434       0\n",
      "RUT 230616C2700000   102434       0\n",
      "RUT 230616C2710000   102434       0\n",
      "RUT 230616C2720000   102434       0\n",
      "RUT 230616C2730000   102434       0\n",
      "RUT 230616C2740000   102434       0\n",
      "RUT 230616C2750000   102434       0\n",
      "RUT 230616C2760000   102434       0\n",
      "RUT 230616C2770000   102434       0\n",
      "RUT 230616C2780000   102434       0\n",
      "RUT 230616C2800000   102434       0\n",
      "RUT 230616C2850000   102434       0\n",
      "RUT 230616C2900000   102434       0\n",
      "RUT 230616C2950000   102434       0\n",
      "RUT 230616C3000000   102434       0\n",
      "RUT 230616C3050000   102434       0\n",
      "RUT 230616C3100000   102434       0\n",
      "RUT 230616C3150000   102434       0\n",
      "RUT 230616C3200000   102434       0\n",
      "RUT 230616C3250000   102434       0\n",
      "RUT 230616C2690000   102434       0\n",
      "RUT 230616C2670000   102434       0\n",
      "RUT 230616C2440000   102434       0\n",
      "RUT 230616C2660000   102434       0\n",
      "RUT 230616C2450000   102434       0\n",
      "RUT 230616C2460000   102434       0\n",
      "RUT 230616C2470000   102434       0\n",
      "RUT 230616C2480000   102434       0\n",
      "RUT 230616C2490000   102434       0\n",
      "RUT 230616C2500000   102434       0\n",
      "RUT 230616C2510000   102434       0\n",
      "RUT 230616C2520000   102434       0\n",
      "RUT 230616C2530000   102434       0\n",
      "RUT 230616C2540000   102434       0\n",
      "RUT 230616C2550000   102434       0\n",
      "RUT 230616C2560000   102434       0\n",
      "RUT 230616C2570000   102434       0\n",
      "RUT 230616C2580000   102434       0\n",
      "RUT 230616C2590000   102434       0\n",
      "RUT 230616C2600000   102434       0\n",
      "RUT 230616C2610000   102434       0\n",
      "RUT 230616C2620000   102434       0\n",
      "RUT 230616C2650000   102434       0\n",
      "RUTW 220103P1795000  102434       0\n",
      "RUTW 220103P1800000  102434       0\n",
      "RUTW 220103P1805000  102434       0\n",
      "RUTW 220107C1565000  102434       0\n",
      "RUTW 220107C1520000  102434       0\n",
      "RUTW 220107C1525000  102434       0\n",
      "RUTW 220107C1530000  102434       0\n",
      "RUTW 220107C1535000  102434       0\n",
      "RUTW 220107C1540000  102434       0\n",
      "RUTW 220107C1545000  102434       0\n",
      "RUTW 220107C1550000  102434       0\n",
      "RUTW 220107C1555000  102434       0\n",
      "RUTW 220107C1560000  102434       0\n",
      "RUTW 220107C1570000  102434       0\n",
      "RUTW 220105P2385000  102434       0\n",
      "RUTW 220107C1575000  102434       0\n",
      "RUTW 220107C1580000  102434       0\n",
      "RUTW 220107C1585000  102434       0\n",
      "RUTW 220107C1590000  102434       0\n",
      "RUTW 220107C1595000  102434       0\n",
      "RUTW 220107C1600000  102434       0\n",
      "RUTW 220107C1605000  102434       0\n",
      "RUTW 220107C1610000  102434       0\n",
      "RUTW 220107C1615000  102434       0\n",
      "RUTW 220107C1515000  102434       0\n",
      "RUTW 220107C1510000  102434       0\n",
      "RUTW 220107C1505000  102434       0\n",
      "RUTW 220107C1500000  102434       0\n",
      "RUTW 220107C1405000  102434       0\n",
      "RUTW 220107C1410000  102434       0\n",
      "RUTW 220107C1415000  102434       0\n",
      "RUTW 220107C1420000  102434       0\n",
      "RUTW 220107C1425000  102434       0\n",
      "RUTW 220107C1430000  102434       0\n",
      "RUTW 220107C1435000  102434       0\n",
      "RUTW 220107C1440000  102434       0\n",
      "RUTW 220107C1445000  102434       0\n",
      "RUTW 220107C1450000  102434       0\n",
      "RUTW 220107C1455000  102434       0\n",
      "RUTW 220107C1460000  102434       0\n",
      "RUTW 220107C1465000  102434       0\n",
      "RUTW 220107C1470000  102434       0\n",
      "RUTW 220107C1475000  102434       0\n",
      "RUTW 220107C1480000  102434       0\n",
      "RUTW 220107C1485000  102434       0\n",
      "RUTW 220107C1490000  102434       0\n",
      "RUTW 220107C1495000  102434       0\n",
      "RUTW 220107C1620000  102434       0\n",
      "RUTW 220107C1625000  102434       0\n",
      "RUTW 220107C1630000  102434       0\n",
      "RUTW 220107C1745000  102434       0\n",
      "RUTW 220107C1755000  102434       0\n",
      "RUTW 220107C1760000  102434       0\n",
      "RUTW 220107C1765000  102434       0\n",
      "RUTW 220107C1770000  102434       0\n",
      "RUTW 220107C1775000  102434       0\n",
      "RUTW 220107C1780000  102434       0\n",
      "RLG 220121C1975000   100222       0\n",
      "RUTW 220107C1790000  102434       0\n",
      "RUTW 220107C1795000  102434       0\n",
      "RUTW 220107C1800000  102434       0\n",
      "RUTW 220107C1805000  102434       0\n",
      "RUTW 220107C1810000  102434       0\n",
      "RUTW 220107C1815000  102434       0\n",
      "RUTW 220107C1820000  102434       0\n",
      "RUTW 220107C1825000  102434       0\n",
      "RUTW 220107C1830000  102434       0\n",
      "RUTW 220107C1835000  102434       0\n",
      "RUTW 220107C1840000  102434       0\n",
      "RUTW 220107C1845000  102434       0\n",
      "RUTW 220107C1750000  102434       0\n",
      "RUTW 220107C1740000  102434       0\n",
      "RUTW 220107C1635000  102434       0\n",
      "RUTW 220107C1735000  102434       0\n",
      "RUTW 220107C1640000  102434       0\n",
      "RUTW 220107C1645000  102434       0\n",
      "RUTW 220107C1650000  102434       0\n",
      "RUTW 220107C1655000  102434       0\n",
      "RUTW 220107C1660000  102434       0\n",
      "RUTW 220107C1665000  102434       0\n",
      "RUTW 220107C1670000  102434       0\n",
      "RUTW 220107C1675000  102434       0\n",
      "RUTW 220107C1680000  102434       0\n",
      "RUTW 220107C1685000  102434       0\n",
      "RUTW 220107C1690000  102434       0\n",
      "RUTW 220107C1695000  102434       0\n",
      "RUTW 220107C1700000  102434       0\n",
      "RUTW 220107C1705000  102434       0\n",
      "RUTW 220107C1710000  102434       0\n",
      "RUTW 220107C1715000  102434       0\n",
      "RUTW 220107C1720000  102434       0\n",
      "RUTW 220107C1725000  102434       0\n",
      "RUTW 220107C1730000  102434       0\n",
      "RUTW 220107C1400000  102434       0\n",
      "RUTW 220107C1395000  102434       0\n",
      "RUTW 220107C1390000  102434       0\n",
      "RUTW 220105P2500000  102434       0\n",
      "RUTW 220105P2510000  102434       0\n",
      "RUTW 220105P2515000  102434       0\n",
      "RUTW 220105P2520000  102434       0\n",
      "RUTW 220105P2525000  102434       0\n",
      "RUTW 220105P2530000  102434       0\n",
      "RUTW 220105P2535000  102434       0\n",
      "RUTW 220105P2540000  102434       0\n",
      "RUTW 220105P2545000  102434       0\n",
      "RUTW 220105P2550000  102434       0\n",
      "RUTW 220105P2555000  102434       0\n",
      "RUTW 220105P2560000  102434       0\n",
      "RUTW 220105P2565000  102434       0\n",
      "RUTW 220105P2570000  102434       0\n",
      "RUTW 220105P2575000  102434       0\n",
      "RUTW 220105P2580000  102434       0\n",
      "RUTW 220105P2585000  102434       0\n",
      "RUTW 220105P2590000  102434       0\n",
      "RUTW 220105P2595000  102434       0\n",
      "RUTW 220105P2600000  102434       0\n",
      "RUTW 220105P2505000  102434       0\n",
      "RUTW 220105P2495000  102434       0\n",
      "RUTW 220105P2610000  102434       0\n",
      "RUTW 220105P2490000  102434       0\n",
      "RUTW 220105P2395000  102434       0\n",
      "RUTW 220105P2400000  102434       0\n",
      "RUTW 220105P2405000  102434       0\n",
      "RUTW 220105P2410000  102434       0\n",
      "RUTW 220105P2415000  102434       0\n",
      "RUTW 220105P2420000  102434       0\n",
      "RUTW 220105P2425000  102434       0\n",
      "RUTW 220105P2430000  102434       0\n",
      "RUTW 220105P2435000  102434       0\n",
      "RUTW 220105P2440000  102434       0\n",
      "RUTW 220105P2445000  102434       0\n",
      "RUTW 220105P2450000  102434       0\n",
      "RUTW 220105P2455000  102434       0\n",
      "RUTW 220105P2460000  102434       0\n",
      "RUTW 220105P2465000  102434       0\n",
      "RUTW 220105P2470000  102434       0\n",
      "RUTW 220105P2475000  102434       0\n",
      "RUTW 220105P2480000  102434       0\n",
      "RUTW 220105P2485000  102434       0\n",
      "RUTW 220105P2605000  102434       0\n",
      "RUTW 220105P2615000  102434       0\n",
      "RUTW 220107C1385000  102434       0\n",
      "RUTW 220107C1280000  102434       0\n",
      "RUTW 220107C1290000  102434       0\n",
      "RUTW 220107C1295000  102434       0\n",
      "RUTW 220107C1300000  102434       0\n",
      "RUTW 220107C1305000  102434       0\n",
      "RUTW 220107C1310000  102434       0\n",
      "RUTW 220107C1315000  102434       0\n",
      "RUTW 220107C1320000  102434       0\n",
      "RUTW 220107C1325000  102434       0\n",
      "RUTW 220107C1330000  102434       0\n",
      "RUTW 220107C1335000  102434       0\n",
      "RUTW 220107C1340000  102434       0\n",
      "RUTW 220107C1345000  102434       0\n",
      "RUTW 220107C1350000  102434       0\n",
      "RUTW 220107C1355000  102434       0\n",
      "RUTW 220107C1360000  102434       0\n",
      "RUTW 220107C1365000  102434       0\n",
      "RUTW 220107C1370000  102434       0\n",
      "RUTW 220107C1375000  102434       0\n",
      "RUTW 220107C1380000  102434       0\n",
      "RUTW 220107C1285000  102434       0\n",
      "RUTW 220107C1275000  102434       0\n",
      "RUTW 220105P2620000  102434       0\n",
      "RUTW 220107C1270000  102434       0\n",
      "RUTW 220105P2625000  102434       0\n",
      "RUTW 220105P2630000  102434       0\n",
      "RUTW 220105P2635000  102434       0\n",
      "RUTW 220105P2640000  102434       0\n",
      "RUTW 220105P2645000  102434       0\n",
      "RUTW 220105P2650000  102434       0\n",
      "RUTW 220105P2655000  102434       0\n",
      "RUTW 220105P2660000  102434       0\n",
      "RUTW 220105P2665000  102434       0\n",
      "RUTW 220105P2670000  102434       0\n",
      "RUTW 220105P2675000  102434       0\n",
      "RUTW 220105P2680000  102434       0\n",
      "RUTW 220105P2685000  102434       0\n",
      "RUTW 220105P2690000  102434       0\n",
      "RUTW 220105P2695000  102434       0\n",
      "RUTW 220105P2700000  102434       0\n",
      "RUTW 220105P2705000  102434       0\n",
      "RUTW 220105P2710000  102434       0\n",
      "RUTW 220107C1265000  102434       0\n",
      "RUTW 220107C1850000  102434       0\n",
      "RUTW 220107C1855000  102434       0\n",
      "RUTW 220107C1860000  102434       0\n",
      "RUTW 220107C2665000  102434       0\n",
      "RUTW 220107C2675000  102434       0\n",
      "RUTW 220107C2680000  102434       0\n",
      "RUTW 220107C2685000  102434       0\n",
      "RUTW 220107C2690000  102434       0\n",
      "RUTW 220107C2695000  102434       0\n",
      "RUTW 220107C2700000  102434       0\n",
      "RUTW 220107C2705000  102434       0\n",
      "RUTW 220107C2710000  102434       0\n",
      "RUTW 220107C2715000  102434       0\n",
      "RUTW 220107C2720000  102434       0\n",
      "RUTW 220107C2725000  102434       0\n",
      "RUTW 220107C2730000  102434       0\n",
      "RUTW 220107C2735000  102434       0\n",
      "RUTW 220107C2740000  102434       0\n",
      "RUTW 220107C2745000  102434       0\n",
      "RUTW 220107C2750000  102434       0\n",
      "RUTW 220107C2755000  102434       0\n",
      "RUTW 220107C2760000  102434       0\n",
      "RUTW 220107C2765000  102434       0\n",
      "RUTW 220107C2670000  102434       0\n",
      "RUTW 220107C2660000  102434       0\n",
      "RUTW 220107C2775000  102434       0\n",
      "RUTW 220107C2655000  102434       0\n",
      "RUTW 220107C2560000  102434       0\n",
      "RUTW 220107C2565000  102434       0\n",
      "RUTW 220107C2570000  102434       0\n",
      "RUTW 220107C2575000  102434       0\n",
      "RUTW 220107C2580000  102434       0\n",
      "RUTW 220107C2585000  102434       0\n",
      "RUTW 220107C2590000  102434       0\n",
      "RUTW 220107C2595000  102434       0\n",
      "RUTW 220107C2600000  102434       0\n",
      "RUTW 220107C2605000  102434       0\n",
      "RUTW 220107C2610000  102434       0\n",
      "RUTW 220107C2615000  102434       0\n",
      "RUTW 220107C2620000  102434       0\n",
      "RUTW 220107C2625000  102434       0\n",
      "RUTW 220107C2630000  102434       0\n",
      "RUTW 220107C2635000  102434       0\n",
      "RUTW 220107C2640000  102434       0\n",
      "RUTW 220107C2645000  102434       0\n",
      "RUTW 220107C2650000  102434       0\n",
      "RUTW 220107C2770000  102434       0\n",
      "RUTW 220107C2780000  102434       0\n",
      "RUTW 220107C2550000  102434       0\n",
      "RUTW 220107P1310000  102434       0\n",
      "RUTW 220107P1320000  102434       0\n",
      "RUTW 220107P1325000  102434       0\n",
      "RUTW 220107P1330000  102434       0\n",
      "RUTW 220107P1335000  102434       0\n",
      "RUTW 220107P1340000  102434       0\n",
      "RUTW 220107P1345000  102434       0\n",
      "RUTW 220107P1350000  102434       0\n",
      "RUTW 220107P1355000  102434       0\n",
      "RUTW 220107P1360000  102434       0\n",
      "RUTW 220107P1365000  102434       0\n",
      "RUTW 220107P1370000  102434       0\n",
      "RUTW 220107P1375000  102434       0\n",
      "RUTW 220107P1380000  102434       0\n",
      "RUTW 220107P1385000  102434       0\n",
      "RUTW 220107P1390000  102434       0\n",
      "RUTW 220107P1395000  102434       0\n",
      "RUTW 220107P1400000  102434       0\n",
      "RUTW 220107P1405000  102434       0\n",
      "RUTW 220107P1410000  102434       0\n",
      "RUTW 220107P1315000  102434       0\n",
      "RUTW 220107P1305000  102434       0\n",
      "RUTW 220107C2785000  102434       0\n",
      "RUTW 220107P1300000  102434       0\n",
      "RUTW 220107C2790000  102434       0\n",
      "RUTW 220107C2795000  102434       0\n",
      "RUTW 220107C2800000  102434       0\n",
      "RUTW 220107C2805000  102434       0\n",
      "RUTW 220107C2810000  102434       0\n",
      "RUTW 220107C2815000  102434       0\n",
      "RUTW 220107C2820000  102434       0\n",
      "RUTW 220107C2825000  102434       0\n",
      "RUTW 220107C2830000  102434       0\n",
      "RUTW 220107C2835000  102434       0\n",
      "RUTW 220107C2840000  102434       0\n",
      "RUTW 220107C2845000  102434       0\n",
      "RUTW 220107C2850000  102434       0\n",
      "RUTW 220107C2855000  102434       0\n",
      "RUTW 220107P1265000  102434       0\n",
      "RUTW 220107P1280000  102434       0\n",
      "RUTW 220107P1285000  102434       0\n",
      "RUTW 220107P1290000  102434       0\n",
      "RUTW 220107P1295000  102434       0\n",
      "RUTW 220107C2555000  102434       0\n",
      "RUTW 220107C2545000  102434       0\n",
      "RUTW 220107C1865000  102434       0\n",
      "RUTW 220107C1975000  102434       0\n",
      "RUTW 220107C1985000  102434       0\n",
      "RUTW 220107C1990000  102434       0\n",
      "RUTW 220107C1995000  102434       0\n",
      "RUTW 220107C2000000  102434       0\n",
      "RUTW 220107C2005000  102434       0\n",
      "RUTW 220107C2010000  102434       0\n",
      "RUTW 220107C2015000  102434       0\n",
      "RUTW 220107C2020000  102434       0\n",
      "RUTW 220107C2025000  102434       0\n",
      "RUTW 220107C2030000  102434       0\n",
      "RUTW 220107C2035000  102434       0\n",
      "RUTW 220107C2040000  102434       0\n",
      "RUTW 220107C2045000  102434       0\n",
      "RUTW 220107C2050000  102434       0\n",
      "RUTW 220107C2055000  102434       0\n",
      "RUTW 220107C2060000  102434       0\n",
      "RUTW 220107C2075000  102434       0\n",
      "RUTW 220107C2080000  102434       0\n",
      "RUTW 220107C2085000  102434       0\n",
      "RUTW 220107C1980000  102434       0\n",
      "RUTW 220107C1970000  102434       0\n",
      "RUTW 220107C2095000  102434       0\n",
      "RUTW 220107C1965000  102434       0\n",
      "RUTW 220107C1870000  102434       0\n",
      "RUTW 220107C1875000  102434       0\n",
      "RUTW 220107C1880000  102434       0\n",
      "RUTW 220107C1885000  102434       0\n",
      "RUTW 220107C1890000  102434       0\n",
      "RUTW 220107C1895000  102434       0\n",
      "RUTW 220107C1900000  102434       0\n",
      "RUTW 220107C1905000  102434       0\n",
      "RUTW 220107C1910000  102434       0\n",
      "RUTW 220107C1915000  102434       0\n",
      "RUTW 220107C1920000  102434       0\n",
      "RUTW 220107C1925000  102434       0\n",
      "RUTW 220107C1930000  102434       0\n",
      "RUTW 220107C1935000  102434       0\n",
      "RUTW 220107C1940000  102434       0\n",
      "RUTW 220107C1945000  102434       0\n",
      "RUTW 220107C1950000  102434       0\n",
      "RUTW 220107C1955000  102434       0\n",
      "RUTW 220107C1960000  102434       0\n",
      "RUTW 220107C2090000  102434       0\n",
      "RUTW 220107C2100000  102434       0\n",
      "RUTW 220107C2540000  102434       0\n",
      "RUTW 220107C2425000  102434       0\n",
      "RUTW 220107C2445000  102434       0\n",
      "RUTW 220107C2450000  102434       0\n",
      "RUTW 220107C2455000  102434       0\n",
      "RUTW 220107C2460000  102434       0\n",
      "RUTW 220107C2465000  102434       0\n",
      "RUTW 220107C2470000  102434       0\n",
      "RUTW 220107C2475000  102434       0\n",
      "RUTW 220107C2480000  102434       0\n",
      "RUTW 220107C2485000  102434       0\n",
      "RUTW 220107C2490000  102434       0\n",
      "RUTW 220107C2495000  102434       0\n",
      "RUTW 220107C2500000  102434       0\n",
      "RUTW 220107C2505000  102434       0\n",
      "RUTW 220107C2510000  102434       0\n",
      "RUTW 220107C2515000  102434       0\n",
      "RUTW 220107C2520000  102434       0\n",
      "RUTW 220107C2525000  102434       0\n",
      "RUTW 220107C2530000  102434       0\n",
      "RUTW 220107C2535000  102434       0\n",
      "RUTW 220107C2440000  102434       0\n",
      "RUTW 220107C2415000  102434       0\n",
      "RUTW 220107C2105000  102434       0\n",
      "RUTW 220107C2395000  102434       0\n",
      "RUTW 220107C2110000  102434       0\n",
      "RUTW 220107C2115000  102434       0\n",
      "RUTW 220107C2120000  102434       0\n",
      "RUTW 220107C2125000  102434       0\n",
      "RUTW 220107C2135000  102434       0\n",
      "RUTW 220107C2140000  102434       0\n",
      "RUTW 220107C2145000  102434       0\n",
      "RUTW 220107C2155000  102434       0\n",
      "RUTW 220107C2160000  102434       0\n",
      "RUTW 220107C2165000  102434       0\n",
      "RUTW 220107C2170000  102434       0\n",
      "RUTW 220107C2185000  102434       0\n",
      "RUTW 220107C2190000  102434       0\n",
      "RUTW 220107C2195000  102434       0\n",
      "RUTW 220107C2205000  102434       0\n",
      "RUTW 220107C2215000  102434       0\n",
      "RUTW 220107C2220000  102434       0\n",
      "RUTW 220107C2225000  102434       0\n",
      "RUTW 220107C2240000  102434       0\n",
      "RUTW 220105P2390000  102434       0\n",
      "RUTW 220105P2380000  102434       0\n",
      "RUTW 220103P1810000  102434       0\n",
      "RUTW 220105C1730000  102434       0\n",
      "RUTW 220103P2615000  102434       0\n",
      "RUTW 220103P2620000  102434       0\n",
      "RUTW 220103P2625000  102434       0\n",
      "RUTW 220103P2630000  102434       0\n",
      "RUTW 220103P2635000  102434       0\n",
      "RUTW 220105C1710000  102434       0\n",
      "RUTW 220105C1715000  102434       0\n",
      "RUTW 220105C1720000  102434       0\n",
      "RUTW 220105C1725000  102434       0\n",
      "RUTW 220105C1735000  102434       0\n",
      "RUTW 220105P2375000  102434       0\n",
      "RUTW 220105C1740000  102434       0\n",
      "RUTW 220105C1745000  102434       0\n",
      "RUTW 220105C1750000  102434       0\n",
      "RUTW 220105C1755000  102434       0\n",
      "RUTW 220105C1760000  102434       0\n",
      "RUTW 220105C1765000  102434       0\n",
      "RUTW 220105C1770000  102434       0\n",
      "RUTW 220105C1775000  102434       0\n",
      "RUTW 220105C1780000  102434       0\n",
      "RUTW 220103P2610000  102434       0\n",
      "RUTW 220103P2605000  102434       0\n",
      "RUTW 220103P2600000  102434       0\n",
      "RUTW 220103P2595000  102434       0\n",
      "RUTW 220103P2500000  102434       0\n",
      "RUTW 220103P2505000  102434       0\n",
      "RUTW 220103P2510000  102434       0\n",
      "RUTW 220103P2515000  102434       0\n",
      "RUTW 220103P2520000  102434       0\n",
      "RUTW 220103P2525000  102434       0\n",
      "RUTW 220103P2530000  102434       0\n",
      "RUTW 220103P2535000  102434       0\n",
      "RUTW 220103P2540000  102434       0\n",
      "RUTW 220103P2545000  102434       0\n",
      "RUTW 220103P2550000  102434       0\n",
      "RUTW 220103P2555000  102434       0\n",
      "RUTW 220103P2560000  102434       0\n",
      "RUTW 220103P2565000  102434       0\n",
      "RUTW 220103P2570000  102434       0\n",
      "RUTW 220103P2575000  102434       0\n",
      "RUTW 220103P2580000  102434       0\n",
      "RUTW 220103P2585000  102434       0\n",
      "RUTW 220103P2590000  102434       0\n",
      "RUTW 220105C1785000  102434       0\n",
      "RUTW 220105C1790000  102434       0\n",
      "RUTW 220105C1795000  102434       0\n",
      "RUTW 220105C1910000  102434       0\n",
      "RUTW 220105C1920000  102434       0\n",
      "RUTW 220105C1925000  102434       0\n",
      "RUTW 220105C1930000  102434       0\n",
      "RUTW 220105C1935000  102434       0\n",
      "RUTW 220105C1940000  102434       0\n",
      "RUTW 220105C1945000  102434       0\n",
      "RUTW 220105C1950000  102434       0\n",
      "RUTW 220105C1955000  102434       0\n",
      "RUTW 220105C1960000  102434       0\n",
      "RUTW 220105C1965000  102434       0\n",
      "RUTW 220105C1970000  102434       0\n",
      "RUTW 220105C1975000  102434       0\n",
      "RUTW 220105C1980000  102434       0\n",
      "RUTW 220105C1985000  102434       0\n",
      "RUTW 220105C1990000  102434       0\n",
      "RUTW 220105C1995000  102434       0\n",
      "RUTW 220105C2000000  102434       0\n",
      "RUTW 220105C2005000  102434       0\n",
      "RUTW 220105C2010000  102434       0\n",
      "RUTW 220105C1915000  102434       0\n",
      "RUTW 220105C1905000  102434       0\n",
      "RUTW 220105C1800000  102434       0\n",
      "RUTW 220105C1900000  102434       0\n",
      "RUTW 220105C1805000  102434       0\n",
      "RUTW 220105C1810000  102434       0\n",
      "RUTW 220105C1815000  102434       0\n",
      "RUTW 220105C1820000  102434       0\n",
      "RUTW 220105C1825000  102434       0\n",
      "RUTW 220105C1830000  102434       0\n",
      "RUTW 220105C1835000  102434       0\n",
      "RUTW 220105C1840000  102434       0\n",
      "RUTW 220105C1845000  102434       0\n",
      "RUTW 220105C1850000  102434       0\n",
      "RUTW 220105C1855000  102434       0\n",
      "RUTW 220105C1860000  102434       0\n",
      "RUTW 220105C1865000  102434       0\n",
      "RUTW 220105C1870000  102434       0\n",
      "RUTW 220105C1875000  102434       0\n",
      "RUTW 220105C1880000  102434       0\n",
      "RUTW 220105C1885000  102434       0\n",
      "RUTW 220105C1890000  102434       0\n",
      "RUTW 220105C1895000  102434       0\n",
      "RUTW 220103P2495000  102434       0\n",
      "RUTW 220103P2490000  102434       0\n",
      "RUTW 220103P2485000  102434       0\n",
      "RUTW 220103P1920000  102434       0\n",
      "RUTW 220103P1930000  102434       0\n",
      "RUTW 220103P1935000  102434       0\n",
      "RUTW 220103P1940000  102434       0\n",
      "RUTW 220103P1945000  102434       0\n",
      "RUTW 220103P1950000  102434       0\n",
      "RUTW 220103P1955000  102434       0\n",
      "RUTW 220103P1960000  102434       0\n",
      "RUTW 220103P1965000  102434       0\n",
      "RUTW 220103P1970000  102434       0\n",
      "RUTW 220103P1975000  102434       0\n",
      "RUTW 220103P1980000  102434       0\n",
      "RUTW 220103P1985000  102434       0\n",
      "RUTW 220103P1990000  102434       0\n",
      "RUTW 220103P1995000  102434       0\n",
      "RUTW 220103P2000000  102434       0\n",
      "RUTW 220103P2005000  102434       0\n",
      "RUTW 220103P2010000  102434       0\n",
      "RUTW 220103P2015000  102434       0\n",
      "RUTW 220103P2020000  102434       0\n",
      "RUTW 220103P1925000  102434       0\n",
      "RUTW 220103P1915000  102434       0\n",
      "RUTW 220103P2030000  102434       0\n",
      "RUTW 220103P1910000  102434       0\n",
      "RUTW 220103P1815000  102434       0\n",
      "RUTW 220103P1820000  102434       0\n",
      "RUTW 220103P1825000  102434       0\n",
      "RUTW 220103P1830000  102434       0\n",
      "RUTW 220103P1835000  102434       0\n",
      "RUTW 220103P1840000  102434       0\n",
      "RUTW 220103P1845000  102434       0\n",
      "RUTW 220103P1850000  102434       0\n",
      "RUTW 220103P1855000  102434       0\n",
      "RUTW 220103P1860000  102434       0\n",
      "RUTW 220103P1865000  102434       0\n",
      "RUTW 220103P1870000  102434       0\n",
      "RUTW 220103P1875000  102434       0\n",
      "RUTW 220103P1880000  102434       0\n",
      "RUTW 220103P1885000  102434       0\n",
      "RUTW 220103P1890000  102434       0\n",
      "RUTW 220103P1895000  102434       0\n",
      "RUTW 220103P1900000  102434       0\n",
      "RUTW 220103P1905000  102434       0\n",
      "RUTW 220103P2025000  102434       0\n",
      "RUTW 220103P2035000  102434       0\n",
      "RUTW 220103P2480000  102434       0\n",
      "RUTW 220103P2375000  102434       0\n",
      "RUTW 220103P2385000  102434       0\n",
      "RUTW 220103P2390000  102434       0\n",
      "RUTW 220103P2395000  102434       0\n",
      "RUTW 220103P2400000  102434       0\n",
      "RUTW 220103P2405000  102434       0\n",
      "RUTW 220103P2410000  102434       0\n",
      "RUTW 220103P2415000  102434       0\n",
      "RUTW 220103P2420000  102434       0\n",
      "RUTW 220103P2425000  102434       0\n",
      "RUTW 220103P2430000  102434       0\n",
      "RUTW 220103P2435000  102434       0\n",
      "RUTW 220103P2440000  102434       0\n",
      "RUTW 220103P2445000  102434       0\n",
      "RUTW 220103P2450000  102434       0\n",
      "RUTW 220103P2455000  102434       0\n",
      "RUTW 220103P2460000  102434       0\n",
      "RUTW 220103P2465000  102434       0\n",
      "RUTW 220103P2470000  102434       0\n",
      "RUTW 220103P2475000  102434       0\n",
      "RUTW 220103P2380000  102434       0\n",
      "RUTW 220103P2370000  102434       0\n",
      "RUTW 220103P2040000  102434       0\n",
      "RUTW 220103P2365000  102434       0\n",
      "RUTW 220103P2045000  102434       0\n",
      "RUTW 220103P2050000  102434       0\n",
      "RUTW 220103P2055000  102434       0\n",
      "RUTW 220103P2060000  102434       0\n",
      "RUTW 220103P2065000  102434       0\n",
      "RUTW 220103P2070000  102434       0\n",
      "RUTW 220103P2085000  102434       0\n",
      "RUTW 220103P2090000  102434       0\n",
      "RUTW 220103P2100000  102434       0\n",
      "RUTW 220103P2105000  102434       0\n",
      "RUTW 220103P2110000  102434       0\n",
      "RUTW 220103P2115000  102434       0\n",
      "RUTW 220103P2120000  102434       0\n",
      "RUTW 220103P2125000  102434       0\n",
      "RUTW 220103P2155000  102434       0\n",
      "RUTW 220103P2330000  102434       0\n",
      "RUTW 220103P2335000  102434       0\n",
      "RUTW 220103P2345000  102434       0\n",
      "RUTW 220103P2355000  102434       0\n",
      "RUTW 220105C2015000  102434       0\n",
      "RUTW 220105C2020000  102434       0\n",
      "RUTW 220105C2025000  102434       0\n",
      "RUTW 220105P1800000  102434       0\n",
      "RUTW 220105P1810000  102434       0\n",
      "RUTW 220105P1815000  102434       0\n",
      "RUTW 220105P1820000  102434       0\n",
      "RUTW 220105P1825000  102434       0\n",
      "RUTW 220105P1830000  102434       0\n",
      "RUTW 220105P1835000  102434       0\n",
      "RUTW 220105P1840000  102434       0\n",
      "RUTW 220105P1845000  102434       0\n",
      "RUTW 220105P1850000  102434       0\n",
      "RUTW 220105P1855000  102434       0\n",
      "RUTW 220105P1860000  102434       0\n",
      "RUTW 220105P1865000  102434       0\n",
      "RUTW 220105P1870000  102434       0\n",
      "RUTW 220105P1875000  102434       0\n",
      "RUTW 220105P1880000  102434       0\n",
      "RUTW 220105P1885000  102434       0\n",
      "RUTW 220105P1890000  102434       0\n",
      "RUTW 220105P1895000  102434       0\n",
      "RUTW 220105P1900000  102434       0\n",
      "RUTW 220105P1805000  102434       0\n",
      "RUTW 220105P1795000  102434       0\n",
      "RUTW 220105P1910000  102434       0\n",
      "RUTW 220105P1790000  102434       0\n",
      "RUTW 220105C2700000  102434       0\n",
      "RUTW 220105C2705000  102434       0\n",
      "RUTW 220105C2710000  102434       0\n",
      "RUTW 220105P1710000  102434       0\n",
      "RUTW 220105P1715000  102434       0\n",
      "RUTW 220105P1720000  102434       0\n",
      "RUTW 220105P1725000  102434       0\n",
      "RUTW 220105P1730000  102434       0\n",
      "RUTW 220105P1735000  102434       0\n",
      "RUTW 220105P1740000  102434       0\n",
      "RUTW 220105P1745000  102434       0\n",
      "RUTW 220105P1750000  102434       0\n",
      "RUTW 220105P1755000  102434       0\n",
      "RUTW 220105P1760000  102434       0\n",
      "RUTW 220105P1765000  102434       0\n",
      "RUTW 220105P1770000  102434       0\n",
      "RUTW 220105P1775000  102434       0\n",
      "RUTW 220105P1780000  102434       0\n",
      "RUTW 220105P1785000  102434       0\n",
      "RUTW 220105P1905000  102434       0\n",
      "RUTW 220105P1915000  102434       0\n",
      "RUTW 220105C2690000  102434       0\n",
      "RUTW 220105P2045000  102434       0\n",
      "RUTW 220105P2055000  102434       0\n",
      "RUTW 220105P2060000  102434       0\n",
      "RUTW 220105P2065000  102434       0\n",
      "RUTW 220105P2070000  102434       0\n",
      "RUTW 220105P2075000  102434       0\n",
      "RUTW 220105P2085000  102434       0\n",
      "RUTW 220105P2090000  102434       0\n",
      "RUTW 220105P2110000  102434       0\n",
      "RUTW 220105P2120000  102434       0\n",
      "RUTW 220105P2130000  102434       0\n",
      "RUTW 220105P2155000  102434       0\n",
      "RUTW 220105P2305000  102434       0\n",
      "RUTW 220105P2310000  102434       0\n",
      "RUTW 220105P2330000  102434       0\n",
      "RUTW 220105P2335000  102434       0\n",
      "RUTW 220105P2345000  102434       0\n",
      "RUTW 220105P2355000  102434       0\n",
      "RUTW 220105P2365000  102434       0\n",
      "RUTW 220105P2370000  102434       0\n",
      "RUTW 220105P2050000  102434       0\n",
      "RUTW 220105P2040000  102434       0\n",
      "RUTW 220105P1925000  102434       0\n",
      "RUTW 220105P2025000  102434       0\n",
      "RUTW 220105P1930000  102434       0\n",
      "RUTW 220105P1935000  102434       0\n",
      "RUTW 220105P1940000  102434       0\n",
      "RUTW 220105P1945000  102434       0\n",
      "RUTW 220105P1950000  102434       0\n",
      "RUTW 220105P1955000  102434       0\n",
      "RUTW 220105P1960000  102434       0\n",
      "RUTW 220105P1965000  102434       0\n",
      "RUTW 220105P1970000  102434       0\n",
      "RUTW 220105P1975000  102434       0\n",
      "RUTW 220105P1980000  102434       0\n",
      "RUTW 220105P1985000  102434       0\n",
      "RUTW 220105P1990000  102434       0\n",
      "RUTW 220105P1995000  102434       0\n",
      "RUTW 220105P2000000  102434       0\n",
      "RUTW 220105P2005000  102434       0\n",
      "RUTW 220105P2010000  102434       0\n",
      "RUTW 220105P2015000  102434       0\n",
      "RUTW 220105P2020000  102434       0\n",
      "RUTW 220105C2695000  102434       0\n",
      "RUTW 220105C2685000  102434       0\n",
      "RUTW 220105C2030000  102434       0\n",
      "RUTW 220105C2140000  102434       0\n",
      "RUTW 220105C2150000  102434       0\n",
      "RUTW 220105C2155000  102434       0\n",
      "RUTW 220105C2160000  102434       0\n",
      "RUTW 220105C2165000  102434       0\n",
      "RUTW 220105C2170000  102434       0\n",
      "RUTW 220105C2175000  102434       0\n",
      "RUTW 220105C2180000  102434       0\n",
      "RUTW 220105C2185000  102434       0\n",
      "RUTW 220105C2190000  102434       0\n",
      "RUTW 220105C2205000  102434       0\n",
      "RUTW 220105C2380000  102434       0\n",
      "RUTW 220105C2385000  102434       0\n",
      "RUTW 220105C2405000  102434       0\n",
      "RUTW 220105C2410000  102434       0\n",
      "RUTW 220105C2415000  102434       0\n",
      "RUTW 220105C2420000  102434       0\n",
      "RUTW 220105C2435000  102434       0\n",
      "RUTW 220105C2440000  102434       0\n",
      "RUTW 220105C2445000  102434       0\n",
      "RUTW 220105C2145000  102434       0\n",
      "RUTW 220105C2135000  102434       0\n",
      "RUTW 220105C2455000  102434       0\n",
      "RUTW 220105C2130000  102434       0\n",
      "RUTW 220105C2035000  102434       0\n",
      "RUTW 220105C2040000  102434       0\n",
      "RUTW 220105C2045000  102434       0\n",
      "RUTW 220105C2050000  102434       0\n",
      "RUTW 220105C2055000  102434       0\n",
      "RUTW 220105C2060000  102434       0\n",
      "RUTW 220105C2065000  102434       0\n",
      "RUTW 220105C2070000  102434       0\n",
      "RUTW 220105C2075000  102434       0\n",
      "RUTW 220105C2080000  102434       0\n",
      "RUTW 220105C2085000  102434       0\n",
      "RUTW 220105C2090000  102434       0\n",
      "RUTW 220105C2095000  102434       0\n",
      "RUTW 220105C2100000  102434       0\n",
      "RUTW 220105C2105000  102434       0\n",
      "RUTW 220105C2110000  102434       0\n",
      "RUTW 220105C2115000  102434       0\n",
      "RUTW 220105C2120000  102434       0\n",
      "RUTW 220105C2125000  102434       0\n",
      "RUTW 220105C2450000  102434       0\n",
      "RUTW 220105C2460000  102434       0\n",
      "RUTW 220105C2680000  102434       0\n",
      "RUTW 220105C2575000  102434       0\n",
      "RUTW 220105C2585000  102434       0\n",
      "RUTW 220105C2590000  102434       0\n",
      "RUTW 220105C2595000  102434       0\n",
      "RUTW 220105C2600000  102434       0\n",
      "RUTW 220105C2605000  102434       0\n",
      "RUTW 220105C2610000  102434       0\n",
      "RUTW 220105C2615000  102434       0\n",
      "RUTW 220105C2620000  102434       0\n",
      "RUTW 220105C2625000  102434       0\n",
      "RUTW 220105C2630000  102434       0\n",
      "RUTW 220105C2635000  102434       0\n",
      "RUTW 220105C2640000  102434       0\n",
      "RUTW 220105C2645000  102434       0\n",
      "RUTW 220105C2650000  102434       0\n",
      "RUTW 220105C2655000  102434       0\n",
      "RUTW 220105C2660000  102434       0\n",
      "RUTW 220105C2665000  102434       0\n",
      "RUTW 220105C2670000  102434       0\n",
      "RUTW 220105C2675000  102434       0\n",
      "RUTW 220105C2580000  102434       0\n",
      "RUTW 220105C2570000  102434       0\n",
      "RUTW 220105C2465000  102434       0\n",
      "RUTW 220105C2565000  102434       0\n",
      "RUTW 220105C2470000  102434       0\n",
      "RUTW 220105C2475000  102434       0\n",
      "RUTW 220105C2480000  102434       0\n",
      "RUTW 220105C2485000  102434       0\n",
      "RUTW 220105C2490000  102434       0\n",
      "RUTW 220105C2495000  102434       0\n",
      "RUTW 220105C2500000  102434       0\n",
      "RUTW 220105C2505000  102434       0\n",
      "RUTW 220105C2510000  102434       0\n",
      "RUTW 220105C2515000  102434       0\n",
      "RUTW 220105C2520000  102434       0\n",
      "RUTW 220105C2525000  102434       0\n",
      "RUTW 220105C2530000  102434       0\n",
      "RUTW 220105C2535000  102434       0\n",
      "RUTW 220105C2540000  102434       0\n",
      "RUTW 220105C2545000  102434       0\n",
      "RUTW 220105C2550000  102434       0\n",
      "RUTW 220105C2555000  102434       0\n",
      "RUTW 220105C2560000  102434       0\n",
      "RUT 221216C2640000   102434       0\n",
      "RUT 221216C2620000   102434       0\n",
      "RUI 221216C2470000   100219       0\n",
      "RUT 220218P2390000   102434       0\n",
      "RUT 220218P1250000   102434       0\n",
      "RUT 220218P1300000   102434       0\n",
      "RUT 220218P1350000   102434       0\n",
      "RUT 220218P1400000   102434       0\n",
      "RUT 220218P1500000   102434       0\n",
      "RUT 220218P2320000   102434       0\n",
      "RUT 220218P2350000   102434       0\n",
      "RUT 220218P2360000   102434       0\n",
      "RUT 220218P2370000   102434       0\n",
      "RUT 220218P2400000   102434       0\n",
      "RUT 220218P3450000   102434       0\n",
      "RUT 220218P2410000   102434       0\n",
      "RUT 220218P2420000   102434       0\n",
      "RUT 220218P2430000   102434       0\n",
      "RUT 220218P2440000   102434       0\n",
      "RUT 220218P2450000   102434       0\n",
      "RUT 220218P2460000   102434       0\n",
      "RUT 220218P2470000   102434       0\n",
      "RUT 220218P2480000   102434       0\n",
      "RUT 220218P2490000   102434       0\n",
      "RUT 220218C3550000   102434       0\n",
      "RUT 220218C3500000   102434       0\n",
      "RUT 220218C3450000   102434       0\n",
      "RUT 220218C3400000   102434       0\n",
      "RUT 220218C2760000   102434       0\n",
      "RUT 220218C2770000   102434       0\n",
      "RUT 220218C2780000   102434       0\n",
      "RUT 220218C2790000   102434       0\n",
      "RUT 220218C2800000   102434       0\n",
      "RUT 220218C2810000   102434       0\n",
      "RUT 220218C2820000   102434       0\n",
      "RUT 220218C2830000   102434       0\n",
      "RUT 220218C2840000   102434       0\n",
      "RUT 220218C2900000   102434       0\n",
      "RUT 220218C2950000   102434       0\n",
      "RUT 220218C3000000   102434       0\n",
      "RUT 220218C3050000   102434       0\n",
      "RUT 220218C3100000   102434       0\n",
      "RUT 220218C3150000   102434       0\n",
      "RUT 220218C3200000   102434       0\n",
      "RUT 220218C3250000   102434       0\n",
      "RUT 220218C3300000   102434       0\n",
      "RUT 220218C3350000   102434       0\n",
      "RUT 220218P2500000   102434       0\n",
      "RUT 220218P2510000   102434       0\n",
      "RUT 220218P2520000   102434       0\n",
      "RUT 220218P2750000   102434       0\n",
      "RUT 220218P2770000   102434       0\n",
      "RUT 220218P2780000   102434       0\n",
      "RUT 220218P2790000   102434       0\n",
      "RUT 220218P2800000   102434       0\n",
      "RUT 220218P2810000   102434       0\n",
      "RUT 220218P2820000   102434       0\n",
      "RUT 220218P2830000   102434       0\n",
      "RUT 220218P2840000   102434       0\n",
      "RUT 220218P2850000   102434       0\n",
      "RUT 220218P2900000   102434       0\n",
      "RUT 220218P2950000   102434       0\n",
      "RUT 220218P3000000   102434       0\n",
      "RUT 220218P3050000   102434       0\n",
      "RUT 220218P3100000   102434       0\n",
      "RUT 220218P3150000   102434       0\n",
      "RUT 220218P3200000   102434       0\n",
      "RUT 220218P3250000   102434       0\n",
      "RUT 220218P3300000   102434       0\n",
      "RUT 220218P3350000   102434       0\n",
      "RUT 220218P2760000   102434       0\n",
      "RUT 220218P2740000   102434       0\n",
      "RUT 220218P2530000   102434       0\n",
      "RUT 220218P2730000   102434       0\n",
      "RUT 220218P2540000   102434       0\n",
      "RUT 220218P2550000   102434       0\n",
      "RUT 220218P2560000   102434       0\n",
      "RUT 220218P2570000   102434       0\n",
      "RUT 220218P2580000   102434       0\n",
      "RUT 220218P2590000   102434       0\n",
      "RUT 220218P2600000   102434       0\n",
      "RUT 220218P2610000   102434       0\n",
      "RUT 220218P2620000   102434       0\n",
      "RUT 220218P2630000   102434       0\n",
      "RUT 220218P2640000   102434       0\n",
      "RUT 220218P2650000   102434       0\n",
      "RUT 220218P2660000   102434       0\n",
      "RUT 220218P2670000   102434       0\n",
      "RUT 220218P2680000   102434       0\n",
      "RUT 220218P2690000   102434       0\n",
      "RUT 220218P2700000   102434       0\n",
      "RUT 220218P2710000   102434       0\n",
      "RUT 220218P2720000   102434       0\n",
      "RUT 220218C2740000   102434       0\n",
      "RUT 220218C2730000   102434       0\n",
      "RUT 220218C2720000   102434       0\n",
      "RUT 220121P3250000   102434       0\n",
      "RUT 220121P3350000   102434       0\n",
      "RUT 220121P3400000   102434       0\n",
      "RUT 220121P400000    102434       0\n",
      "RUT 220121P500000    102434       0\n",
      "RUT 220121P550000    102434       0\n",
      "RUT 220121P600000    102434       0\n",
      "RUT 220121P650000    102434       0\n",
      "RUT 220121P700000    102434       0\n",
      "RUT 220121P750000    102434       0\n",
      "RUT 220121P800000    102434       0\n",
      "RUT 220121P850000    102434       0\n",
      "RUT 220121P900000    102434       0\n",
      "RUT 220121P950000    102434       0\n",
      "RUT 220218C1200000   102434       0\n",
      "RUT 220218C1250000   102434       0\n",
      "RUT 220218C1300000   102434       0\n",
      "RUT 220218C1350000   102434       0\n",
      "RUT 220218C1400000   102434       0\n",
      "RUT 220218C1450000   102434       0\n",
      "RUT 220121P3300000   102434       0\n",
      "RUT 220121P3200000   102434       0\n",
      "RUT 220218C1550000   102434       0\n",
      "RUT 220121P3150000   102434       0\n",
      "RUT 220121P2590000   102434       0\n",
      "RUT 220121P2600000   102434       0\n",
      "RUT 220121P2610000   102434       0\n",
      "RUT 220121P2620000   102434       0\n",
      "RUT 220121P2630000   102434       0\n",
      "RUT 220121P2640000   102434       0\n",
      "RUT 220121P2650000   102434       0\n",
      "RUT 220121P2660000   102434       0\n",
      "RUT 220121P2670000   102434       0\n",
      "RUT 220121P2680000   102434       0\n",
      "RUT 220121P2700000   102434       0\n",
      "RUT 220121P2750000   102434       0\n",
      "RUT 220121P2800000   102434       0\n",
      "RUT 220121P2850000   102434       0\n",
      "RUT 220121P2900000   102434       0\n",
      "RUT 220121P2950000   102434       0\n",
      "RUT 220121P3000000   102434       0\n",
      "RUT 220121P3050000   102434       0\n",
      "RUT 220121P3100000   102434       0\n",
      "RUT 220218C1500000   102434       0\n",
      "RUT 220218C1600000   102434       0\n",
      "RUT 220218C2710000   102434       0\n",
      "RUT 220218C2070000   102434       0\n",
      "RUT 220218C2090000   102434       0\n",
      "RUT 220218C2100000   102434       0\n",
      "RUT 220218C2120000   102434       0\n",
      "RUT 220218C2150000   102434       0\n",
      "RUT 220218C2190000   102434       0\n",
      "RUT 220218C2210000   102434       0\n",
      "RUT 220218C2530000   102434       0\n",
      "RUT 220218C2570000   102434       0\n",
      "RUT 220218C2580000   102434       0\n",
      "RUT 220218C2590000   102434       0\n",
      "RUT 220218C2620000   102434       0\n",
      "RUT 220218C2630000   102434       0\n",
      "RUT 220218C2640000   102434       0\n",
      "RUT 220218C2650000   102434       0\n",
      "RUT 220218C2660000   102434       0\n",
      "RUT 220218C2670000   102434       0\n",
      "RUT 220218C2680000   102434       0\n",
      "RUT 220218C2690000   102434       0\n",
      "RUT 220218C2700000   102434       0\n",
      "RUT 220218C2080000   102434       0\n",
      "RUT 220218C2060000   102434       0\n",
      "RUT 220218C1650000   102434       0\n",
      "RUT 220218C2050000   102434       0\n",
      "RUT 220218C1700000   102434       0\n",
      "RUT 220218C1750000   102434       0\n",
      "RUT 220218C1800000   102434       0\n",
      "RUT 220218C1850000   102434       0\n",
      "RUT 220218C1900000   102434       0\n",
      "RUT 220218C1910000   102434       0\n",
      "RUT 220218C1920000   102434       0\n",
      "RUT 220218C1930000   102434       0\n",
      "RUT 220218C1940000   102434       0\n",
      "RUT 220218C1950000   102434       0\n",
      "RUT 220218C1960000   102434       0\n",
      "RUT 220218C1970000   102434       0\n",
      "RUT 220218C1980000   102434       0\n",
      "RUT 220218C1990000   102434       0\n",
      "RUT 220218C2000000   102434       0\n",
      "RUT 220218C2010000   102434       0\n",
      "RUT 220218C2020000   102434       0\n",
      "RUT 220218C2030000   102434       0\n",
      "RUT 220218C2040000   102434       0\n",
      "RUT 220218P3400000   102434       0\n",
      "RUT 220218P3500000   102434       0\n",
      "RUT 221216C2610000   102434       0\n",
      "RUT 220617C1700000   102434       0\n",
      "RUT 220617C1250000   102434       0\n",
      "RUT 220617C1300000   102434       0\n",
      "RUT 220617C1350000   102434       0\n",
      "RUT 220617C1400000   102434       0\n",
      "RUT 220617C1450000   102434       0\n",
      "RUT 220617C1500000   102434       0\n",
      "RUT 220617C1550000   102434       0\n",
      "RUT 220617C1600000   102434       0\n",
      "RUT 220617C1650000   102434       0\n",
      "RUT 220617C1750000   102434       0\n",
      "RUT 220218P3550000   102434       0\n",
      "RUT 220617C1800000   102434       0\n",
      "RUT 220617C1850000   102434       0\n",
      "RUT 220617C1860000   102434       0\n",
      "RUT 220617C1870000   102434       0\n",
      "RUT 220617C1880000   102434       0\n",
      "RUT 220617C1890000   102434       0\n",
      "RUT 220617C1900000   102434       0\n",
      "RUT 220617C1910000   102434       0\n",
      "RUT 220617C1920000   102434       0\n",
      "RUT 220617C1200000   102434       0\n",
      "RUT 220617C1150000   102434       0\n",
      "RUT 220617C1100000   102434       0\n",
      "RUT 220617C1050000   102434       0\n",
      "RUT 220318P2550000   102434       0\n",
      "RUT 220318P2600000   102434       0\n",
      "RUT 220318P2650000   102434       0\n",
      "RUT 220318P2700000   102434       0\n",
      "RUT 220318P2750000   102434       0\n",
      "RUT 220318P2800000   102434       0\n",
      "RUT 220318P2850000   102434       0\n",
      "RUT 220318P2900000   102434       0\n",
      "RUT 220318P2950000   102434       0\n",
      "RUT 220318P3000000   102434       0\n",
      "RUT 220318P3050000   102434       0\n",
      "RUT 220318P3100000   102434       0\n",
      "RUT 220318P3150000   102434       0\n",
      "RUT 220318P3200000   102434       0\n",
      "RUT 220318P3250000   102434       0\n",
      "RUT 220318P3300000   102434       0\n",
      "RUT 220318P3350000   102434       0\n",
      "RUT 220318P3400000   102434       0\n",
      "RUT 220617C1000000   102434       0\n",
      "RUT 220617C1930000   102434       0\n",
      "RUT 220617C1940000   102434       0\n",
      "RUT 220617C1950000   102434       0\n",
      "RUT 220617C2190000   102434       0\n",
      "RUT 220617C2210000   102434       0\n",
      "RUT 220617C2220000   102434       0\n",
      "RUT 220617C2230000   102434       0\n",
      "RUT 220617C2240000   102434       0\n",
      "RUT 220617C2250000   102434       0\n",
      "RUT 220617C2260000   102434       0\n",
      "RUT 220617C2270000   102434       0\n",
      "RUT 220617C2280000   102434       0\n",
      "RUT 220617C2290000   102434       0\n",
      "RUT 220617C2310000   102434       0\n",
      "RUT 220617C2320000   102434       0\n",
      "RUT 220617C2330000   102434       0\n",
      "RUT 220617C2350000   102434       0\n",
      "RUT 220617C2360000   102434       0\n",
      "RUT 220617C2370000   102434       0\n",
      "RUT 220617C2380000   102434       0\n",
      "RUT 220617C2390000   102434       0\n",
      "RUT 220617C2400000   102434       0\n",
      "RUT 220617C2410000   102434       0\n",
      "RUT 220617C2200000   102434       0\n",
      "RUT 220617C2180000   102434       0\n",
      "RUT 220617C1960000   102434       0\n",
      "RUT 220617C2170000   102434       0\n",
      "RUT 220617C1970000   102434       0\n",
      "RUT 220617C1980000   102434       0\n",
      "RUT 220617C1990000   102434       0\n",
      "RUT 220617C2000000   102434       0\n",
      "RUT 220617C2010000   102434       0\n",
      "RUT 220617C2020000   102434       0\n",
      "RUT 220617C2030000   102434       0\n",
      "RUT 220617C2040000   102434       0\n",
      "RUT 220617C2050000   102434       0\n",
      "RUT 220617C2060000   102434       0\n",
      "RUT 220617C2070000   102434       0\n",
      "RUT 220617C2080000   102434       0\n",
      "RUT 220617C2090000   102434       0\n",
      "RUT 220617C2110000   102434       0\n",
      "RUT 220617C2120000   102434       0\n",
      "RUT 220617C2130000   102434       0\n",
      "RUT 220617C2140000   102434       0\n",
      "RUT 220617C2150000   102434       0\n",
      "RUT 220617C2160000   102434       0\n",
      "RUT 220318P2500000   102434       0\n",
      "RUT 220318P2450000   102434       0\n",
      "RUT 220318P2440000   102434       0\n",
      "RUT 220318C2050000   102434       0\n",
      "RUT 220318C2110000   102434       0\n",
      "RUT 220318C2120000   102434       0\n",
      "RUT 220318C2130000   102434       0\n",
      "RUT 220318C2140000   102434       0\n",
      "RUT 220318C2150000   102434       0\n",
      "RUT 220318C2170000   102434       0\n",
      "RUT 220318C2190000   102434       0\n",
      "RUT 220318C2200000   102434       0\n",
      "RUT 220318C2210000   102434       0\n",
      "RUT 220318C2220000   102434       0\n",
      "RUT 220318C2230000   102434       0\n",
      "RUT 220318C2240000   102434       0\n",
      "RUT 220318C2290000   102434       0\n",
      "RUT 220318C2310000   102434       0\n",
      "RUT 220318C2330000   102434       0\n",
      "RUT 220318C2340000   102434       0\n",
      "RUT 220318C2370000   102434       0\n",
      "RUT 220318C2420000   102434       0\n",
      "RUT 220318C2430000   102434       0\n",
      "RUT 220318C2100000   102434       0\n",
      "RUT 220318C2000000   102434       0\n",
      "RUT 220318C2500000   102434       0\n",
      "RUT 220318C1950000   102434       0\n",
      "RUT 220318C1000000   102434       0\n",
      "RUT 220318C1050000   102434       0\n",
      "RUT 220318C1100000   102434       0\n",
      "RUT 220318C1150000   102434       0\n",
      "RUT 220318C1200000   102434       0\n",
      "RUT 220318C1250000   102434       0\n",
      "RUT 220318C1300000   102434       0\n",
      "RUT 220318C1350000   102434       0\n",
      "RUT 220318C1400000   102434       0\n",
      "RUT 220318C1450000   102434       0\n",
      "RUT 220318C1500000   102434       0\n",
      "RUT 220318C1550000   102434       0\n",
      "RUT 220318C1600000   102434       0\n",
      "RUT 220318C1650000   102434       0\n",
      "RUT 220318C1700000   102434       0\n",
      "RUT 220318C1750000   102434       0\n",
      "RUT 220318C1800000   102434       0\n",
      "RUT 220318C1850000   102434       0\n",
      "RUT 220318C1900000   102434       0\n",
      "RUT 220318C2440000   102434       0\n",
      "RUT 220318C2650000   102434       0\n",
      "RUT 220318P2430000   102434       0\n",
      "RUT 220318P1600000   102434       0\n",
      "RUT 220318P1750000   102434       0\n",
      "RUT 220318P2110000   102434       0\n",
      "RUT 220318P2120000   102434       0\n",
      "RUT 220318P2130000   102434       0\n",
      "RUT 220318P2140000   102434       0\n",
      "RUT 220318P2290000   102434       0\n",
      "RUT 220318P2300000   102434       0\n",
      "RUT 220318P2310000   102434       0\n",
      "RUT 220318P2320000   102434       0\n",
      "RUT 220318P2330000   102434       0\n",
      "RUT 220318P2340000   102434       0\n",
      "RUT 220318P2350000   102434       0\n",
      "RUT 220318P2360000   102434       0\n",
      "RUT 220318P2370000   102434       0\n",
      "RUT 220318P2380000   102434       0\n",
      "RUT 220318P2390000   102434       0\n",
      "RUT 220318P2400000   102434       0\n",
      "RUT 220318P2410000   102434       0\n",
      "RUT 220318P2420000   102434       0\n",
      "RUT 220318P1650000   102434       0\n",
      "RUT 220318P1550000   102434       0\n",
      "RUT 220318C2800000   102434       0\n",
      "RUT 220318P1450000   102434       0\n",
      "RUT 220318C2850000   102434       0\n",
      "RUT 220318C2900000   102434       0\n",
      "RUT 220318C2950000   102434       0\n",
      "RUT 220318C3000000   102434       0\n",
      "RUT 220318C3050000   102434       0\n",
      "RUT 220318C3100000   102434       0\n",
      "RUT 220318C3150000   102434       0\n",
      "RUT 220318C3200000   102434       0\n",
      "RUT 220318C3250000   102434       0\n",
      "RUT 220318C3300000   102434       0\n",
      "RUT 220318C3350000   102434       0\n",
      "RUT 220318C3400000   102434       0\n",
      "RUT 220318P1000000   102434       0\n",
      "RUT 220318P1050000   102434       0\n",
      "RUT 220318P1100000   102434       0\n",
      "RUT 220318P1150000   102434       0\n",
      "RUT 220318P1250000   102434       0\n",
      "RUT 220318P1300000   102434       0\n",
      "RUT 220318P1350000   102434       0\n",
      "RUT 220121P2580000   102434       0\n",
      "RUT 220121P2570000   102434       0\n",
      "RUT 220121P2560000   102434       0\n",
      "RUI 221216P2460000   100219       0\n",
      "RUI 221216P2380000   100219       0\n",
      "RUI 221216P2390000   100219       0\n",
      "RUI 221216P2400000   100219       0\n",
      "RUI 221216P2410000   100219       0\n",
      "RUI 221216P2420000   100219       0\n",
      "RUI 221216P2425000   100219       0\n",
      "RUI 221216P2430000   100219       0\n",
      "RUI 221216P2440000   100219       0\n",
      "RUI 221216P2450000   100219       0\n",
      "RUI 221216P2470000   100219       0\n",
      "RUT 220121P2550000   102434       0\n",
      "RUI 221216P2475000   100219       0\n",
      "RUI 221216P2480000   100219       0\n",
      "RUI 221216P2490000   100219       0\n",
      "RUI 221216P2500000   100219       0\n",
      "RUI 221216P2510000   100219       0\n",
      "RUI 221216P2520000   100219       0\n",
      "RUI 221216P2525000   100219       0\n",
      "RUI 221216P2530000   100219       0\n",
      "RUI 221216P2540000   100219       0\n",
      "RUI 221216P2375000   100219       0\n",
      "RUI 221216P2370000   100219       0\n",
      "RUI 221216P2360000   100219       0\n",
      "RUI 221216P2350000   100219       0\n",
      "RUI 221216P2125000   100219       0\n",
      "RUI 221216P2150000   100219       0\n",
      "RUI 221216P2175000   100219       0\n",
      "RUI 221216P2200000   100219       0\n",
      "RUI 221216P2225000   100219       0\n",
      "RUI 221216P2230000   100219       0\n",
      "RUI 221216P2240000   100219       0\n",
      "RUI 221216P2250000   100219       0\n",
      "RUI 221216P2260000   100219       0\n",
      "RUI 221216P2270000   100219       0\n",
      "RUI 221216P2275000   100219       0\n",
      "RUI 221216P2280000   100219       0\n",
      "RUI 221216P2290000   100219       0\n",
      "RUI 221216P2300000   100219       0\n",
      "RUI 221216P2310000   100219       0\n",
      "RUI 221216P2320000   100219       0\n",
      "RUI 221216P2325000   100219       0\n",
      "RUI 221216P2330000   100219       0\n",
      "RUI 221216P2340000   100219       0\n",
      "RUI 221216P2550000   100219       0\n",
      "RUI 221216P2560000   100219       0\n",
      "RUI 221216P2570000   100219       0\n",
      "RUI 221216P2760000   100219       0\n",
      "RUI 221216P2775000   100219       0\n",
      "RUI 221216P2780000   100219       0\n",
      "RUI 221216P2790000   100219       0\n",
      "RUI 221216P2800000   100219       0\n",
      "RUI 221216P2810000   100219       0\n",
      "RUI 221216P2820000   100219       0\n",
      "RUI 221216P2825000   100219       0\n",
      "RUI 221216P2830000   100219       0\n",
      "RUI 221216P2840000   100219       0\n",
      "RUI 221216P2850000   100219       0\n",
      "RUI 221216P2860000   100219       0\n",
      "RUI 221216P2870000   100219       0\n",
      "RUI 221216P2875000   100219       0\n",
      "RUI 221216P2880000   100219       0\n",
      "RUI 221216P2890000   100219       0\n",
      "RUI 221216P2900000   100219       0\n",
      "RUI 221216P2910000   100219       0\n",
      "RUI 221216P2920000   100219       0\n",
      "RUI 221216P2925000   100219       0\n",
      "RUI 221216P2770000   100219       0\n",
      "RUI 221216P2750000   100219       0\n",
      "RUI 221216P2575000   100219       0\n",
      "RUI 221216P2740000   100219       0\n",
      "RUI 221216P2580000   100219       0\n",
      "RUI 221216P2590000   100219       0\n",
      "RUI 221216P2600000   100219       0\n",
      "RUI 221216P2610000   100219       0\n",
      "RUI 221216P2620000   100219       0\n",
      "RUI 221216P2625000   100219       0\n",
      "RUI 221216P2630000   100219       0\n",
      "RUI 221216P2640000   100219       0\n",
      "RUI 221216P2650000   100219       0\n",
      "RUI 221216P2660000   100219       0\n",
      "RUI 221216P2670000   100219       0\n",
      "RUI 221216P2675000   100219       0\n",
      "RUI 221216P2680000   100219       0\n",
      "RUI 221216P2690000   100219       0\n",
      "RUI 221216P2700000   100219       0\n",
      "RUI 221216P2710000   100219       0\n",
      "RUI 221216P2720000   100219       0\n",
      "RUI 221216P2725000   100219       0\n",
      "RUI 221216P2730000   100219       0\n",
      "RUI 221216P2100000   100219       0\n",
      "RUI 221216P2075000   100219       0\n",
      "RUI 221216P2050000   100219       0\n",
      "RUI 221216C2650000   100219       0\n",
      "RUI 221216C2670000   100219       0\n",
      "RUI 221216C2675000   100219       0\n",
      "RUI 221216C2680000   100219       0\n",
      "RUI 221216C2690000   100219       0\n",
      "RUI 221216C2700000   100219       0\n",
      "RUI 221216C2710000   100219       0\n",
      "RUI 221216C2720000   100219       0\n",
      "RUI 221216C2725000   100219       0\n",
      "RUI 221216C2730000   100219       0\n",
      "RUI 221216C2740000   100219       0\n",
      "RUI 221216C2750000   100219       0\n",
      "RUI 221216C2760000   100219       0\n",
      "RUI 221216C2770000   100219       0\n",
      "RUI 221216C2775000   100219       0\n",
      "RUI 221216C2780000   100219       0\n",
      "RUI 221216C2790000   100219       0\n",
      "RUI 221216C2800000   100219       0\n",
      "RUI 221216C2810000   100219       0\n",
      "RUI 221216C2820000   100219       0\n",
      "RUI 221216C2660000   100219       0\n",
      "RUI 221216C2640000   100219       0\n",
      "RUI 221216C2830000   100219       0\n",
      "RUI 221216C2630000   100219       0\n",
      "RUI 221216C2475000   100219       0\n",
      "RUI 221216C2480000   100219       0\n",
      "RUI 221216C2490000   100219       0\n",
      "RUI 221216C2500000   100219       0\n",
      "RUI 221216C2510000   100219       0\n",
      "RUI 221216C2520000   100219       0\n",
      "RUI 221216C2525000   100219       0\n",
      "RUI 221216C2530000   100219       0\n",
      "RUI 221216C2540000   100219       0\n",
      "RUI 221216C2550000   100219       0\n",
      "RUI 221216C2560000   100219       0\n",
      "RUI 221216C2570000   100219       0\n",
      "RUI 221216C2575000   100219       0\n",
      "RUI 221216C2580000   100219       0\n",
      "RUI 221216C2590000   100219       0\n",
      "RUI 221216C2600000   100219       0\n",
      "RUI 221216C2610000   100219       0\n",
      "RUI 221216C2620000   100219       0\n",
      "RUI 221216C2625000   100219       0\n",
      "RUI 221216C2825000   100219       0\n",
      "RUI 221216C2840000   100219       0\n",
      "RUI 221216P2025000   100219       0\n",
      "RUI 221216C3075000   100219       0\n",
      "RUI 221216C3125000   100219       0\n",
      "RUI 221216C3150000   100219       0\n",
      "RUI 221216C3175000   100219       0\n",
      "RUI 221216C3200000   100219       0\n",
      "RUI 221216C3225000   100219       0\n",
      "RUI 221216C3250000   100219       0\n",
      "RUI 221216C3275000   100219       0\n",
      "RUI 221216C3300000   100219       0\n",
      "RUI 221216C3325000   100219       0\n",
      "RUI 221216C3350000   100219       0\n",
      "RUI 221216C3375000   100219       0\n",
      "RUI 221216C3400000   100219       0\n",
      "RUI 221216P1850000   100219       0\n",
      "RUI 221216P1875000   100219       0\n",
      "RUI 221216P1900000   100219       0\n",
      "RUI 221216P1925000   100219       0\n",
      "RUI 221216P1950000   100219       0\n",
      "RUI 221216P1975000   100219       0\n",
      "RUI 221216P2000000   100219       0\n",
      "RUI 221216C3100000   100219       0\n",
      "RUI 221216C3050000   100219       0\n",
      "RUI 221216C2850000   100219       0\n",
      "RUI 221216C3025000   100219       0\n",
      "RUI 221216C2860000   100219       0\n",
      "RUI 221216C2870000   100219       0\n",
      "RUI 221216C2875000   100219       0\n",
      "RUI 221216C2880000   100219       0\n",
      "RUI 221216C2890000   100219       0\n",
      "RUI 221216C2900000   100219       0\n",
      "RUI 221216C2910000   100219       0\n",
      "RUI 221216C2920000   100219       0\n",
      "RUI 221216C2925000   100219       0\n",
      "RUI 221216C2930000   100219       0\n",
      "RUI 221216C2940000   100219       0\n",
      "RUI 221216C2950000   100219       0\n",
      "RUI 221216C2960000   100219       0\n",
      "RUI 221216C2970000   100219       0\n",
      "RUI 221216C2975000   100219       0\n",
      "RUI 221216C2980000   100219       0\n",
      "RUI 221216C2990000   100219       0\n",
      "RUI 221216C3000000   100219       0\n",
      "RUI 221216C3010000   100219       0\n",
      "RUI 221216P2930000   100219       0\n",
      "RUI 221216P2940000   100219       0\n",
      "RUI 221216P2950000   100219       0\n",
      "RUT 220121C2950000   102434       0\n",
      "RUT 220121C3050000   102434       0\n",
      "RUT 220121C3100000   102434       0\n",
      "RUT 220121C3150000   102434       0\n",
      "RUT 220121C3200000   102434       0\n",
      "RUT 220121C3250000   102434       0\n",
      "RUT 220121C3300000   102434       0\n",
      "RUT 220121C3350000   102434       0\n",
      "RUT 220121C3400000   102434       0\n",
      "RUT 220121C400000    102434       0\n",
      "RUT 220121C500000    102434       0\n",
      "RUT 220121C550000    102434       0\n",
      "RUT 220121C600000    102434       0\n",
      "RUT 220121C650000    102434       0\n",
      "RUT 220121C700000    102434       0\n",
      "RUT 220121C750000    102434       0\n",
      "RUT 220121C800000    102434       0\n",
      "RUT 220121C850000    102434       0\n",
      "RUT 220121C900000    102434       0\n",
      "RUT 220121C950000    102434       0\n",
      "RUT 220121C3000000   102434       0\n",
      "RUT 220121C2900000   102434       0\n",
      "RUT 220121P1050000   102434       0\n",
      "RUT 220121C2850000   102434       0\n",
      "RUT 220121C2180000   102434       0\n",
      "RUT 220121C2440000   102434       0\n",
      "RUT 220121C2530000   102434       0\n",
      "RUT 220121C2540000   102434       0\n",
      "RUT 220121C2560000   102434       0\n",
      "RUT 220121C2570000   102434       0\n",
      "RUT 220121C2580000   102434       0\n",
      "RUT 220121C2590000   102434       0\n",
      "RUT 220121C2610000   102434       0\n",
      "RUT 220121C2620000   102434       0\n",
      "RUT 220121C2630000   102434       0\n",
      "RUT 220121C2640000   102434       0\n",
      "RUT 220121C2650000   102434       0\n",
      "RUT 220121C2660000   102434       0\n",
      "RUT 220121C2670000   102434       0\n",
      "RUT 220121C2680000   102434       0\n",
      "RUT 220121C2700000   102434       0\n",
      "RUT 220121C2750000   102434       0\n",
      "RUT 220121C2800000   102434       0\n",
      "RUT 220121P1000000   102434       0\n",
      "RUT 220121P1100000   102434       0\n",
      "RUT 220121C2120000   102434       0\n",
      "RUT 220121P1700000   102434       0\n",
      "RUT 220121P1810000   102434       0\n",
      "RUT 220121P1820000   102434       0\n",
      "RUT 220121P1850000   102434       0\n",
      "RUT 220121P2380000   102434       0\n",
      "RUT 220121P2390000   102434       0\n",
      "RUT 220121P2410000   102434       0\n",
      "RUT 220121P2420000   102434       0\n",
      "RUT 220121P2430000   102434       0\n",
      "RUT 220121P2440000   102434       0\n",
      "RUT 220121P2450000   102434       0\n",
      "RUT 220121P2460000   102434       0\n",
      "RUT 220121P2470000   102434       0\n",
      "RUT 220121P2480000   102434       0\n",
      "RUT 220121P2490000   102434       0\n",
      "RUT 220121P2500000   102434       0\n",
      "RUT 220121P2510000   102434       0\n",
      "RUT 220121P2520000   102434       0\n",
      "RUT 220121P2530000   102434       0\n",
      "RUT 220121P2540000   102434       0\n",
      "RUT 220121P1710000   102434       0\n",
      "RUT 220121P1690000   102434       0\n",
      "RUT 220121P1200000   102434       0\n",
      "RUT 220121P1685000   102434       0\n",
      "RUT 220121P1250000   102434       0\n",
      "RUT 220121P1300000   102434       0\n",
      "RUT 220121P1350000   102434       0\n",
      "RUT 220121P1400000   102434       0\n",
      "RUT 220121P1450000   102434       0\n",
      "RUT 220121P1500000   102434       0\n",
      "RUT 220121P1550000   102434       0\n",
      "RUT 220121P1560000   102434       0\n",
      "RUT 220121P1570000   102434       0\n",
      "RUT 220121P1590000   102434       0\n",
      "RUT 220121P1600000   102434       0\n",
      "RUT 220121P1610000   102434       0\n",
      "RUT 220121P1620000   102434       0\n",
      "RUT 220121P1630000   102434       0\n",
      "RUT 220121P1640000   102434       0\n",
      "RUT 220121P1650000   102434       0\n",
      "RUT 220121P1660000   102434       0\n",
      "RUT 220121P1670000   102434       0\n",
      "RUT 220121P1680000   102434       0\n",
      "RUT 220121C2130000   102434       0\n",
      "RUT 220121C2110000   102434       0\n",
      "RUI 221216P2960000   100219       0\n",
      "RUI 221216P3400000   100219       0\n",
      "RUT 220121C1050000   102434       0\n",
      "RUT 220121C1100000   102434       0\n",
      "RUT 220121C1150000   102434       0\n",
      "RUT 220121C1200000   102434       0\n",
      "RUT 220121C1250000   102434       0\n",
      "RUT 220121C1300000   102434       0\n",
      "RUT 220121C1350000   102434       0\n",
      "RUT 220121C1400000   102434       0\n",
      "RUT 220121C1450000   102434       0\n",
      "RUT 220121C1500000   102434       0\n",
      "RUT 220121C1550000   102434       0\n",
      "RUT 220121C1560000   102434       0\n",
      "RUT 220121C1570000   102434       0\n",
      "RUT 220121C1580000   102434       0\n",
      "RUT 220121C1590000   102434       0\n",
      "RUT 220121C1600000   102434       0\n",
      "RUT 220121C1610000   102434       0\n",
      "RUT 220121C1620000   102434       0\n",
      "RUT 220121C1630000   102434       0\n",
      "RUT 220121C1000000   102434       0\n",
      "RUI 221216P3375000   100219       0\n",
      "RUT 220121C1650000   102434       0\n",
      "RUI 221216P3350000   100219       0\n",
      "RUI 221216P2970000   100219       0\n",
      "RUI 221216P2975000   100219       0\n",
      "RUI 221216P2980000   100219       0\n",
      "RUI 221216P2990000   100219       0\n",
      "RUI 221216P3000000   100219       0\n",
      "RUI 221216P3010000   100219       0\n",
      "RUI 221216P3025000   100219       0\n",
      "RUI 221216P3050000   100219       0\n",
      "RUI 221216P3075000   100219       0\n",
      "RUI 221216P3100000   100219       0\n",
      "RUI 221216P3125000   100219       0\n",
      "RUI 221216P3150000   100219       0\n",
      "RUI 221216P3175000   100219       0\n",
      "RUI 221216P3200000   100219       0\n",
      "RUI 221216P3225000   100219       0\n",
      "RUI 221216P3250000   100219       0\n",
      "RUI 221216P3275000   100219       0\n",
      "RUI 221216P3300000   100219       0\n",
      "RUI 221216P3325000   100219       0\n",
      "RUT 220121C1640000   102434       0\n",
      "RUT 220121C1660000   102434       0\n",
      "RUT 220121C2090000   102434       0\n",
      "RUT 220121C1880000   102434       0\n",
      "RUT 220121C1900000   102434       0\n",
      "RUT 220121C1910000   102434       0\n",
      "RUT 220121C1920000   102434       0\n",
      "RUT 220121C1930000   102434       0\n",
      "RUT 220121C1940000   102434       0\n",
      "RUT 220121C1950000   102434       0\n",
      "RUT 220121C1960000   102434       0\n",
      "RUT 220121C1970000   102434       0\n",
      "RUT 220121C1980000   102434       0\n",
      "RUT 220121C1990000   102434       0\n",
      "RUT 220121C2000000   102434       0\n",
      "RUT 220121C2010000   102434       0\n",
      "RUT 220121C2020000   102434       0\n",
      "RUT 220121C2030000   102434       0\n",
      "RUT 220121C2040000   102434       0\n",
      "RUT 220121C2050000   102434       0\n",
      "RUT 220121C2060000   102434       0\n",
      "RUT 220121C2070000   102434       0\n",
      "RUT 220121C2080000   102434       0\n",
      "RUT 220121C1890000   102434       0\n",
      "RUT 220121C1870000   102434       0\n",
      "RUT 220121C1670000   102434       0\n",
      "RUT 220121C1860000   102434       0\n",
      "RUT 220121C1680000   102434       0\n",
      "RUT 220121C1685000   102434       0\n",
      "RUT 220121C1690000   102434       0\n",
      "RUT 220121C1700000   102434       0\n",
      "RUT 220121C1710000   102434       0\n",
      "RUT 220121C1720000   102434       0\n",
      "RUT 220121C1730000   102434       0\n",
      "RUT 220121C1740000   102434       0\n",
      "RUT 220121C1750000   102434       0\n",
      "RUT 220121C1760000   102434       0\n",
      "RUT 220121C1770000   102434       0\n",
      "RUT 220121C1780000   102434       0\n",
      "RUT 220121C1790000   102434       0\n",
      "RUT 220121C1800000   102434       0\n",
      "RUT 220121C1810000   102434       0\n",
      "RUT 220121C1820000   102434       0\n",
      "RUT 220121C1830000   102434       0\n",
      "RUT 220121C1840000   102434       0\n",
      "RUT 220121C1850000   102434       0\n",
      "RUT 220617C2420000   102434       0\n",
      "RUT 220617C2430000   102434       0\n",
      "RUT 220617C2440000   102434       0\n",
      "RUT 220916C2490000   102434       0\n",
      "RUT 220916C2380000   102434       0\n",
      "RUT 220916C2390000   102434       0\n",
      "RUT 220916C2410000   102434       0\n",
      "RUT 220916C2420000   102434       0\n",
      "RUT 220916C2430000   102434       0\n",
      "RUT 220916C2440000   102434       0\n",
      "RUT 220916C2450000   102434       0\n",
      "RUT 220916C2460000   102434       0\n",
      "RUT 220916C2480000   102434       0\n",
      "RUT 220916C2500000   102434       0\n",
      "RUT 220715P2460000   102434       0\n",
      "RUT 220916C2510000   102434       0\n",
      "RUT 220916C2520000   102434       0\n",
      "RUT 220916C2530000   102434       0\n",
      "RUT 220916C2540000   102434       0\n",
      "RUT 220916C2550000   102434       0\n",
      "RUT 220916C2560000   102434       0\n",
      "RUT 220916C2570000   102434       0\n",
      "RUT 220916C2580000   102434       0\n",
      "RUT 220916C2590000   102434       0\n",
      "RUT 220916C2370000   102434       0\n",
      "RUT 220916C2360000   102434       0\n",
      "RUT 220916C2350000   102434       0\n",
      "RUT 220916C2340000   102434       0\n",
      "RUT 220916C2140000   102434       0\n",
      "RUT 220916C2150000   102434       0\n",
      "RUT 220916C2160000   102434       0\n",
      "RUT 220916C2170000   102434       0\n",
      "RUT 220916C2180000   102434       0\n",
      "RUT 220916C2190000   102434       0\n",
      "RUT 220916C2200000   102434       0\n",
      "RUT 220916C2210000   102434       0\n",
      "RUT 220916C2220000   102434       0\n",
      "RUT 220916C2240000   102434       0\n",
      "RUT 220916C2250000   102434       0\n",
      "RUT 220916C2260000   102434       0\n",
      "RUT 220916C2270000   102434       0\n",
      "RUT 220916C2280000   102434       0\n",
      "RUT 220916C2290000   102434       0\n",
      "RUT 220916C2300000   102434       0\n",
      "RUT 220916C2310000   102434       0\n",
      "RUT 220916C2320000   102434       0\n",
      "RUT 220916C2330000   102434       0\n",
      "RUT 220916C2600000   102434       0\n",
      "RUT 220916C2610000   102434       0\n",
      "RUT 220916C2620000   102434       0\n",
      "RUT 220916P1350000   102434       0\n",
      "RUT 220916P1450000   102434       0\n",
      "RUT 220916P1500000   102434       0\n",
      "RUT 220916P1550000   102434       0\n",
      "RUT 220916P1600000   102434       0\n",
      "RUT 220916P1650000   102434       0\n",
      "RUT 220916P1700000   102434       0\n",
      "RUT 220916P1750000   102434       0\n",
      "RUT 220916P1790000   102434       0\n",
      "RUT 220916P1800000   102434       0\n",
      "RUT 220916P1810000   102434       0\n",
      "RUT 220916P1820000   102434       0\n",
      "RUT 220916P1830000   102434       0\n",
      "RUT 220916P1840000   102434       0\n",
      "RUT 220916P1850000   102434       0\n",
      "RUT 220916P1860000   102434       0\n",
      "RUT 220916P1870000   102434       0\n",
      "RUT 220916P1880000   102434       0\n",
      "RUT 220916P1890000   102434       0\n",
      "RUT 220916P1900000   102434       0\n",
      "RUT 220916P1400000   102434       0\n",
      "RUT 220916P1300000   102434       0\n",
      "RUT 220916C2630000   102434       0\n",
      "RUT 220916P1250000   102434       0\n",
      "RUT 220916C2640000   102434       0\n",
      "RUT 220916C2650000   102434       0\n",
      "RUT 220916C2660000   102434       0\n",
      "RUT 220916C2670000   102434       0\n",
      "RUT 220916C2700000   102434       0\n",
      "RUT 220916C2750000   102434       0\n",
      "RUT 220916C2800000   102434       0\n",
      "RUT 220916C2850000   102434       0\n",
      "RUT 220916C2900000   102434       0\n",
      "RUT 220916C2950000   102434       0\n",
      "RUT 220916C3000000   102434       0\n",
      "RUT 220916C3050000   102434       0\n",
      "RUT 220916C3100000   102434       0\n",
      "RUT 220916C3150000   102434       0\n",
      "RUT 220916C3200000   102434       0\n",
      "RUT 220916C3250000   102434       0\n",
      "RUT 220916C3300000   102434       0\n",
      "RUT 220916P1150000   102434       0\n",
      "RUT 220916P1200000   102434       0\n",
      "RUT 220916C2130000   102434       0\n",
      "RUT 220916C2120000   102434       0\n",
      "RUT 220916C2110000   102434       0\n",
      "RUT 220715P2690000   102434       0\n",
      "RUT 220715P2710000   102434       0\n",
      "RUT 220715P2720000   102434       0\n",
      "RUT 220715P2730000   102434       0\n",
      "RUT 220715P2740000   102434       0\n",
      "RUT 220715P2750000   102434       0\n",
      "RUT 220715P2760000   102434       0\n",
      "RUT 220715P2770000   102434       0\n",
      "RUT 220715P2800000   102434       0\n",
      "RUT 220715P2850000   102434       0\n",
      "RUT 220715P2900000   102434       0\n",
      "RUT 220715P2950000   102434       0\n",
      "RUT 220715P3000000   102434       0\n",
      "RUT 220715P3050000   102434       0\n",
      "RUT 220715P3100000   102434       0\n",
      "RUT 220715P3150000   102434       0\n",
      "RUT 220715P3200000   102434       0\n",
      "RUT 220715P3250000   102434       0\n",
      "RUT 220715P3300000   102434       0\n",
      "RUT 220715P3350000   102434       0\n",
      "RUT 220715P2700000   102434       0\n",
      "RUT 220715P2680000   102434       0\n",
      "RUT 220715P3450000   102434       0\n",
      "RUT 220715P2670000   102434       0\n",
      "RUT 220715P2480000   102434       0\n",
      "RUT 220715P2490000   102434       0\n",
      "RUT 220715P2500000   102434       0\n",
      "RUT 220715P2510000   102434       0\n",
      "RUT 220715P2520000   102434       0\n",
      "RUT 220715P2530000   102434       0\n",
      "RUT 220715P2540000   102434       0\n",
      "RUT 220715P2550000   102434       0\n",
      "RUT 220715P2560000   102434       0\n",
      "RUT 220715P2570000   102434       0\n",
      "RUT 220715P2580000   102434       0\n",
      "RUT 220715P2590000   102434       0\n",
      "RUT 220715P2600000   102434       0\n",
      "RUT 220715P2610000   102434       0\n",
      "RUT 220715P2620000   102434       0\n",
      "RUT 220715P2630000   102434       0\n",
      "RUT 220715P2640000   102434       0\n",
      "RUT 220715P2650000   102434       0\n",
      "RUT 220715P2660000   102434       0\n",
      "RUT 220715P3400000   102434       0\n",
      "RUT 220916C1150000   102434       0\n",
      "RUT 220916C2100000   102434       0\n",
      "RUT 220916C1890000   102434       0\n",
      "RUT 220916C1910000   102434       0\n",
      "RUT 220916C1920000   102434       0\n",
      "RUT 220916C1930000   102434       0\n",
      "RUT 220916C1940000   102434       0\n",
      "RUT 220916C1950000   102434       0\n",
      "RUT 220916C1960000   102434       0\n",
      "RUT 220916C1970000   102434       0\n",
      "RUT 220916C1980000   102434       0\n",
      "RUT 220916C1990000   102434       0\n",
      "RUT 220916C2000000   102434       0\n",
      "RUT 220916C2010000   102434       0\n",
      "RUT 220916C2020000   102434       0\n",
      "RUT 220916C2030000   102434       0\n",
      "RUT 220916C2040000   102434       0\n",
      "RUT 220916C2050000   102434       0\n",
      "RUT 220916C2060000   102434       0\n",
      "RUT 220916C2070000   102434       0\n",
      "RUT 220916C2080000   102434       0\n",
      "RUT 220916C2090000   102434       0\n",
      "RUT 220916C1900000   102434       0\n",
      "RUT 220916C1880000   102434       0\n",
      "RUT 220916C1200000   102434       0\n",
      "RUT 220916C1870000   102434       0\n",
      "RUT 220916C1250000   102434       0\n",
      "RUT 220916C1300000   102434       0\n",
      "RUT 220916C1350000   102434       0\n",
      "RUT 220916C1400000   102434       0\n",
      "RUT 220916C1450000   102434       0\n",
      "RUT 220916C1500000   102434       0\n",
      "RUT 220916C1550000   102434       0\n",
      "RUT 220916C1600000   102434       0\n",
      "RUT 220916C1650000   102434       0\n",
      "RUT 220916C1700000   102434       0\n",
      "RUT 220916C1750000   102434       0\n",
      "RUT 220916C1790000   102434       0\n",
      "RUT 220916C1800000   102434       0\n",
      "RUT 220916C1810000   102434       0\n",
      "RUT 220916C1820000   102434       0\n",
      "RUT 220916C1830000   102434       0\n",
      "RUT 220916C1840000   102434       0\n",
      "RUT 220916C1850000   102434       0\n",
      "RUT 220916C1860000   102434       0\n",
      "RUT 220916P1910000   102434       0\n",
      "RUT 220916P1920000   102434       0\n",
      "RUT 220916P1930000   102434       0\n",
      "RUT 221216C1920000   102434       0\n",
      "RUT 221216C1940000   102434       0\n",
      "RUT 221216C1950000   102434       0\n",
      "RUT 221216C1960000   102434       0\n",
      "RUT 221216C1970000   102434       0\n",
      "RUT 221216C1980000   102434       0\n",
      "RUT 221216C1990000   102434       0\n",
      "RUT 221216C2000000   102434       0\n",
      "RUT 221216C2010000   102434       0\n",
      "RUT 221216C2020000   102434       0\n",
      "RUT 221216C2030000   102434       0\n",
      "RUT 221216C2040000   102434       0\n",
      "RUT 221216C2050000   102434       0\n",
      "RUT 221216C2060000   102434       0\n",
      "RUT 221216C2070000   102434       0\n",
      "RUT 221216C2080000   102434       0\n",
      "RUT 221216C2090000   102434       0\n",
      "RUT 221216C2100000   102434       0\n",
      "RUT 221216C2110000   102434       0\n",
      "RUT 221216C2120000   102434       0\n",
      "RUT 221216C1930000   102434       0\n",
      "RUT 221216C1910000   102434       0\n",
      "RUT 221216C2140000   102434       0\n",
      "RUT 221216C1900000   102434       0\n",
      "RUT 221216C1350000   102434       0\n",
      "RUT 221216C1400000   102434       0\n",
      "RUT 221216C1450000   102434       0\n",
      "RUT 221216C1500000   102434       0\n",
      "RUT 221216C1550000   102434       0\n",
      "RUT 221216C1600000   102434       0\n",
      "RUT 221216C1650000   102434       0\n",
      "RUT 221216C1700000   102434       0\n",
      "RUT 221216C1750000   102434       0\n",
      "RUT 221216C1800000   102434       0\n",
      "RUT 221216C1810000   102434       0\n",
      "RUT 221216C1820000   102434       0\n",
      "RUT 221216C1830000   102434       0\n",
      "RUT 221216C1840000   102434       0\n",
      "RUT 221216C1850000   102434       0\n",
      "RUT 221216C1860000   102434       0\n",
      "RUT 221216C1870000   102434       0\n",
      "RUT 221216C1880000   102434       0\n",
      "RUT 221216C1890000   102434       0\n",
      "RUT 221216C2130000   102434       0\n",
      "RUT 221216C2150000   102434       0\n",
      "RUT 221216C1250000   102434       0\n",
      "RUT 221216C2380000   102434       0\n",
      "RUT 221216C2400000   102434       0\n",
      "RUT 221216C2410000   102434       0\n",
      "RUT 221216C2420000   102434       0\n",
      "RUT 221216C2430000   102434       0\n",
      "RUT 221216C2440000   102434       0\n",
      "RUT 221216C2460000   102434       0\n",
      "RUT 221216C2470000   102434       0\n",
      "RUT 221216C2480000   102434       0\n",
      "RUT 221216C2490000   102434       0\n",
      "RUT 221216C2510000   102434       0\n",
      "RUT 221216C2520000   102434       0\n",
      "RUT 221216C2530000   102434       0\n",
      "RUT 221216C2540000   102434       0\n",
      "RUT 221216C2550000   102434       0\n",
      "RUT 221216C2560000   102434       0\n",
      "RUT 221216C2570000   102434       0\n",
      "RUT 221216C2580000   102434       0\n",
      "RUT 221216C2590000   102434       0\n",
      "RUT 221216C2600000   102434       0\n",
      "RUT 221216C2390000   102434       0\n",
      "RUT 221216C2370000   102434       0\n",
      "RUT 221216C2160000   102434       0\n",
      "RUT 221216C2360000   102434       0\n",
      "RUT 221216C2170000   102434       0\n",
      "RUT 221216C2180000   102434       0\n",
      "RUT 221216C2190000   102434       0\n",
      "RUT 221216C2200000   102434       0\n",
      "RUT 221216C2210000   102434       0\n",
      "RUT 221216C2220000   102434       0\n",
      "RUT 221216C2230000   102434       0\n",
      "RUT 221216C2240000   102434       0\n",
      "RUT 221216C2250000   102434       0\n",
      "RUT 221216C2260000   102434       0\n",
      "RUT 221216C2270000   102434       0\n",
      "RUT 221216C2280000   102434       0\n",
      "RUT 221216C2290000   102434       0\n",
      "RUT 221216C2300000   102434       0\n",
      "RUT 221216C2310000   102434       0\n",
      "RUT 221216C2320000   102434       0\n",
      "RUT 221216C2330000   102434       0\n",
      "RUT 221216C2340000   102434       0\n",
      "RUT 221216C2350000   102434       0\n",
      "RUT 221216C1300000   102434       0\n",
      "RUT 221216C1200000   102434       0\n",
      "RUT 220916P1940000   102434       0\n",
      "RUT 220916P2160000   102434       0\n",
      "RUT 220916P2190000   102434       0\n",
      "RUT 220916P2200000   102434       0\n",
      "RUT 220916P2210000   102434       0\n",
      "RUT 220916P2220000   102434       0\n",
      "RUT 220916P2230000   102434       0\n",
      "RUT 220916P2240000   102434       0\n",
      "RUT 220916P2250000   102434       0\n",
      "RUT 220916P2260000   102434       0\n",
      "RUT 220916P2270000   102434       0\n",
      "RUT 220916P2280000   102434       0\n",
      "RUT 220916P2290000   102434       0\n",
      "RUT 220916P2300000   102434       0\n",
      "RUT 220916P2310000   102434       0\n",
      "RUT 220916P2320000   102434       0\n",
      "RUT 220916P2330000   102434       0\n",
      "RUT 220916P2340000   102434       0\n",
      "RUT 220916P2350000   102434       0\n",
      "RUT 220916P2360000   102434       0\n",
      "RUT 220916P2370000   102434       0\n",
      "RUT 220916P2170000   102434       0\n",
      "RUT 220916P2150000   102434       0\n",
      "RUT 220916P2390000   102434       0\n",
      "RUT 220916P2140000   102434       0\n",
      "RUT 220916P1950000   102434       0\n",
      "RUT 220916P1960000   102434       0\n",
      "RUT 220916P1970000   102434       0\n",
      "RUT 220916P1980000   102434       0\n",
      "RUT 220916P1990000   102434       0\n",
      "RUT 220916P2000000   102434       0\n",
      "RUT 220916P2010000   102434       0\n",
      "RUT 220916P2020000   102434       0\n",
      "RUT 220916P2030000   102434       0\n",
      "RUT 220916P2040000   102434       0\n",
      "RUT 220916P2050000   102434       0\n",
      "RUT 220916P2060000   102434       0\n",
      "RUT 220916P2070000   102434       0\n",
      "RUT 220916P2080000   102434       0\n",
      "RUT 220916P2090000   102434       0\n",
      "RUT 220916P2100000   102434       0\n",
      "RUT 220916P2110000   102434       0\n",
      "RUT 220916P2120000   102434       0\n",
      "RUT 220916P2130000   102434       0\n",
      "RUT 220916P2380000   102434       0\n",
      "RUT 220916P2400000   102434       0\n",
      "RUT 221216C1150000   102434       0\n",
      "RUT 220916P2630000   102434       0\n",
      "RUT 220916P2650000   102434       0\n",
      "RUT 220916P2660000   102434       0\n",
      "RUT 220916P2670000   102434       0\n",
      "RUT 220916P2700000   102434       0\n",
      "RUT 220916P2750000   102434       0\n",
      "RUT 220916P2800000   102434       0\n",
      "RUT 220916P2850000   102434       0\n",
      "RUT 220916P2900000   102434       0\n",
      "RUT 220916P2950000   102434       0\n",
      "RUT 220916P3000000   102434       0\n",
      "RUT 220916P3050000   102434       0\n",
      "RUT 220916P3100000   102434       0\n",
      "RUT 220916P3150000   102434       0\n",
      "RUT 220916P3200000   102434       0\n",
      "RUT 220916P3250000   102434       0\n",
      "RUT 220916P3300000   102434       0\n",
      "RUT 221216C1000000   102434       0\n",
      "RUT 221216C1050000   102434       0\n",
      "RUT 221216C1100000   102434       0\n",
      "RUT 220916P2640000   102434       0\n",
      "RUT 220916P2620000   102434       0\n",
      "RUT 220916P2410000   102434       0\n",
      "RUT 220916P2610000   102434       0\n",
      "RUT 220916P2420000   102434       0\n",
      "RUT 220916P2430000   102434       0\n",
      "RUT 220916P2440000   102434       0\n",
      "RUT 220916P2450000   102434       0\n",
      "RUT 220916P2460000   102434       0\n",
      "RUT 220916P2470000   102434       0\n",
      "RUT 220916P2480000   102434       0\n",
      "RUT 220916P2490000   102434       0\n",
      "RUT 220916P2500000   102434       0\n",
      "RUT 220916P2510000   102434       0\n",
      "RUT 220916P2520000   102434       0\n",
      "RUT 220916P2530000   102434       0\n",
      "RUT 220916P2540000   102434       0\n",
      "RUT 220916P2550000   102434       0\n",
      "RUT 220916P2560000   102434       0\n",
      "RUT 220916P2570000   102434       0\n",
      "RUT 220916P2580000   102434       0\n",
      "RUT 220916P2590000   102434       0\n",
      "RUT 220916P2600000   102434       0\n",
      "RUT 220715P2470000   102434       0\n",
      "RUT 220715P2450000   102434       0\n",
      "RUT 220617C2450000   102434       0\n",
      "RUT 220617P2460000   102434       0\n",
      "RUT 220617P2370000   102434       0\n",
      "RUT 220617P2380000   102434       0\n",
      "RUT 220617P2390000   102434       0\n",
      "RUT 220617P2400000   102434       0\n",
      "RUT 220617P2410000   102434       0\n",
      "RUT 220617P2420000   102434       0\n",
      "RUT 220617P2430000   102434       0\n",
      "RUT 220617P2440000   102434       0\n",
      "RUT 220617P2450000   102434       0\n",
      "RUT 220617P2470000   102434       0\n",
      "RUT 220715P2440000   102434       0\n",
      "RUT 220617P2480000   102434       0\n",
      "RUT 220617P2490000   102434       0\n",
      "RUT 220617P2500000   102434       0\n",
      "RUT 220617P2510000   102434       0\n",
      "RUT 220617P2520000   102434       0\n",
      "RUT 220617P2530000   102434       0\n",
      "RUT 220617P2540000   102434       0\n",
      "RUT 220617P2550000   102434       0\n",
      "RUT 220617P2560000   102434       0\n",
      "RUT 220617P2360000   102434       0\n",
      "RUT 220617P2350000   102434       0\n",
      "RUT 220617P2340000   102434       0\n",
      "RUT 220617P2330000   102434       0\n",
      "RUT 220617P2120000   102434       0\n",
      "RUT 220617P2130000   102434       0\n",
      "RUT 220617P2140000   102434       0\n",
      "RUT 220617P2150000   102434       0\n",
      "RUT 220617P2160000   102434       0\n",
      "RUT 220617P2170000   102434       0\n",
      "RUT 220617P2180000   102434       0\n",
      "RUT 220617P2190000   102434       0\n",
      "RUT 220617P2210000   102434       0\n",
      "RUT 220617P2220000   102434       0\n",
      "RUT 220617P2230000   102434       0\n",
      "RUT 220617P2240000   102434       0\n",
      "RUT 220617P2250000   102434       0\n",
      "RUT 220617P2270000   102434       0\n",
      "RUT 220617P2280000   102434       0\n",
      "RUT 220617P2290000   102434       0\n",
      "RUT 220617P2300000   102434       0\n",
      "RUT 220617P2310000   102434       0\n",
      "RUT 220617P2320000   102434       0\n",
      "RUT 220617P2570000   102434       0\n",
      "RUT 220617P2580000   102434       0\n",
      "RUT 220617P2590000   102434       0\n",
      "RUT 220617P2950000   102434       0\n",
      "RUT 220617P3050000   102434       0\n",
      "RUT 220617P3100000   102434       0\n",
      "RUT 220617P3150000   102434       0\n",
      "RUT 220617P3200000   102434       0\n",
      "RUT 220617P3250000   102434       0\n",
      "RUT 220617P3300000   102434       0\n",
      "RUT 220617P3350000   102434       0\n",
      "RUT 220617P3400000   102434       0\n",
      "RUT 220617P750000    102434       0\n",
      "RUT 220617P800000    102434       0\n",
      "RUT 220617P850000    102434       0\n",
      "RUT 220617P900000    102434       0\n",
      "RUT 220617P950000    102434       0\n",
      "RUT 220715C1200000   102434       0\n",
      "RUT 220715C1250000   102434       0\n",
      "RUT 220715C1300000   102434       0\n",
      "RUT 220715C1350000   102434       0\n",
      "RUT 220715C1400000   102434       0\n",
      "RUT 220715C1450000   102434       0\n",
      "RUT 220617P3000000   102434       0\n",
      "RUT 220617P2900000   102434       0\n",
      "RUT 220617P2600000   102434       0\n",
      "RUT 220617P2850000   102434       0\n",
      "RUT 220617P2610000   102434       0\n",
      "RUT 220617P2620000   102434       0\n",
      "RUT 220617P2630000   102434       0\n",
      "RUT 220617P2640000   102434       0\n",
      "RUT 220617P2650000   102434       0\n",
      "RUT 220617P2660000   102434       0\n",
      "RUT 220617P2670000   102434       0\n",
      "RUT 220617P2680000   102434       0\n",
      "RUT 220617P2690000   102434       0\n",
      "RUT 220617P2700000   102434       0\n",
      "RUT 220617P2710000   102434       0\n",
      "RUT 220617P2720000   102434       0\n",
      "RUT 220617P2730000   102434       0\n",
      "RUT 220617P2740000   102434       0\n",
      "RUT 220617P2750000   102434       0\n",
      "RUT 220617P2760000   102434       0\n",
      "RUT 220617P2770000   102434       0\n",
      "RUT 220617P2780000   102434       0\n",
      "RUT 220617P2800000   102434       0\n",
      "RUT 220617P2110000   102434       0\n",
      "RUT 220617P2100000   102434       0\n",
      "RUT 220617P2090000   102434       0\n",
      "RUT 220617C2680000   102434       0\n",
      "RUT 220617C2700000   102434       0\n",
      "RUT 220617C2710000   102434       0\n",
      "RUT 220617C2720000   102434       0\n",
      "RUT 220617C2730000   102434       0\n",
      "RUT 220617C2740000   102434       0\n",
      "RUT 220617C2750000   102434       0\n",
      "RUT 220617C2760000   102434       0\n",
      "RUT 220617C2770000   102434       0\n",
      "RUT 220617C2780000   102434       0\n",
      "RUT 220617C2800000   102434       0\n",
      "RUT 220617C2850000   102434       0\n",
      "RUT 220617C2900000   102434       0\n",
      "RUT 220617C2950000   102434       0\n",
      "RUT 220617C3000000   102434       0\n",
      "RUT 220617C3050000   102434       0\n",
      "RUT 220617C3100000   102434       0\n",
      "RUT 220617C3150000   102434       0\n",
      "RUT 220617C3200000   102434       0\n",
      "RUT 220617C3250000   102434       0\n",
      "RUT 220617C2690000   102434       0\n",
      "RUT 220617C2670000   102434       0\n",
      "RUT 220617C3350000   102434       0\n",
      "RUT 220617C2660000   102434       0\n",
      "RUT 220617C2460000   102434       0\n",
      "RUT 220617C2470000   102434       0\n",
      "RUT 220617C2480000   102434       0\n",
      "RUT 220617C2490000   102434       0\n",
      "RUT 220617C2500000   102434       0\n",
      "RUT 220617C2510000   102434       0\n",
      "RUT 220617C2520000   102434       0\n",
      "RUT 220617C2530000   102434       0\n",
      "RUT 220617C2540000   102434       0\n",
      "RUT 220617C2550000   102434       0\n",
      "RUT 220617C2560000   102434       0\n",
      "RUT 220617C2570000   102434       0\n",
      "RUT 220617C2590000   102434       0\n",
      "RUT 220617C2600000   102434       0\n",
      "RUT 220617C2610000   102434       0\n",
      "RUT 220617C2620000   102434       0\n",
      "RUT 220617C2630000   102434       0\n",
      "RUT 220617C2640000   102434       0\n",
      "RUT 220617C2650000   102434       0\n",
      "RUT 220617C3300000   102434       0\n",
      "RUT 220617C3400000   102434       0\n",
      "RUT 220617P2080000   102434       0\n",
      "RUT 220617P1860000   102434       0\n",
      "RUT 220617P1880000   102434       0\n",
      "RUT 220617P1890000   102434       0\n",
      "RUT 220617P1900000   102434       0\n",
      "RUT 220617P1910000   102434       0\n",
      "RUT 220617P1930000   102434       0\n",
      "RUT 220617P1940000   102434       0\n",
      "RUT 220617P1950000   102434       0\n",
      "RUT 220617P1960000   102434       0\n",
      "RUT 220617P1970000   102434       0\n",
      "RUT 220617P1980000   102434       0\n",
      "RUT 220617P1990000   102434       0\n",
      "RUT 220617P2000000   102434       0\n",
      "RUT 220617P2010000   102434       0\n",
      "RUT 220617P2020000   102434       0\n",
      "RUT 220617P2030000   102434       0\n",
      "RUT 220617P2040000   102434       0\n",
      "RUT 220617P2050000   102434       0\n",
      "RUT 220617P2060000   102434       0\n",
      "RUT 220617P2070000   102434       0\n",
      "RUT 220617P1870000   102434       0\n",
      "RUT 220617P1850000   102434       0\n",
      "RUT 220617C750000    102434       0\n",
      "RUT 220617P1800000   102434       0\n",
      "RUT 220617C800000    102434       0\n",
      "RUT 220617C850000    102434       0\n",
      "RUT 220617C900000    102434       0\n",
      "RUT 220617C950000    102434       0\n",
      "RUT 220617P1000000   102434       0\n",
      "RUT 220617P1050000   102434       0\n",
      "RUT 220617P1100000   102434       0\n",
      "RUT 220617P1150000   102434       0\n",
      "RUT 220617P1200000   102434       0\n",
      "RUT 220617P1250000   102434       0\n",
      "RUT 220617P1300000   102434       0\n",
      "RUT 220617P1350000   102434       0\n",
      "RUT 220617P1400000   102434       0\n",
      "RUT 220617P1450000   102434       0\n",
      "RUT 220617P1550000   102434       0\n",
      "RUT 220617P1600000   102434       0\n",
      "RUT 220617P1650000   102434       0\n",
      "RUT 220617P1700000   102434       0\n",
      "RUT 220617P1750000   102434       0\n",
      "RUT 220715C1500000   102434       0\n",
      "RUT 220715C1550000   102434       0\n",
      "RUT 220715C1600000   102434       0\n",
      "RUT 220715P1400000   102434       0\n",
      "RUT 220715P1500000   102434       0\n",
      "RUT 220715P1550000   102434       0\n",
      "RUT 220715P1600000   102434       0\n",
      "RUT 220715P1650000   102434       0\n",
      "RUT 220715P1700000   102434       0\n",
      "RUT 220715P1750000   102434       0\n",
      "RUT 220715P1800000   102434       0\n",
      "RUT 220715P1850000   102434       0\n",
      "RUT 220715P1860000   102434       0\n",
      "RUT 220715P1870000   102434       0\n",
      "RUT 220715P1880000   102434       0\n",
      "RUT 220715P1890000   102434       0\n",
      "RUT 220715P1900000   102434       0\n",
      "RUT 220715P1910000   102434       0\n",
      "RUT 220715P1920000   102434       0\n",
      "RUT 220715P1930000   102434       0\n",
      "RUT 220715P1940000   102434       0\n",
      "RUT 220715P1950000   102434       0\n",
      "RUT 220715P1960000   102434       0\n",
      "RUT 220715P1450000   102434       0\n",
      "RUT 220715P1350000   102434       0\n",
      "RUT 220715P1980000   102434       0\n",
      "RUT 220715P1300000   102434       0\n",
      "RUT 220715C2750000   102434       0\n",
      "RUT 220715C2760000   102434       0\n",
      "RUT 220715C2770000   102434       0\n",
      "RUT 220715C2800000   102434       0\n",
      "RUT 220715C2850000   102434       0\n",
      "RUT 220715C2900000   102434       0\n",
      "RUT 220715C2950000   102434       0\n",
      "RUT 220715C3000000   102434       0\n",
      "RUT 220715C3050000   102434       0\n",
      "RUT 220715C3100000   102434       0\n",
      "RUT 220715C3150000   102434       0\n",
      "RUT 220715C3200000   102434       0\n",
      "RUT 220715C3250000   102434       0\n",
      "RUT 220715C3300000   102434       0\n",
      "RUT 220715C3350000   102434       0\n",
      "RUT 220715C3400000   102434       0\n",
      "RUT 220715C3450000   102434       0\n",
      "RUT 220715P1200000   102434       0\n",
      "RUT 220715P1250000   102434       0\n",
      "RUT 220715P1970000   102434       0\n",
      "RUT 220715P1990000   102434       0\n",
      "RUT 220715C2730000   102434       0\n",
      "RUT 220715P2230000   102434       0\n",
      "RUT 220715P2250000   102434       0\n",
      "RUT 220715P2260000   102434       0\n",
      "RUT 220715P2270000   102434       0\n",
      "RUT 220715P2280000   102434       0\n",
      "RUT 220715P2290000   102434       0\n",
      "RUT 220715P2300000   102434       0\n",
      "RUT 220715P2310000   102434       0\n",
      "RUT 220715P2320000   102434       0\n",
      "RUT 220715P2330000   102434       0\n",
      "RUT 220715P2340000   102434       0\n",
      "RUT 220715P2350000   102434       0\n",
      "RUT 220715P2360000   102434       0\n",
      "RUT 220715P2370000   102434       0\n",
      "RUT 220715P2380000   102434       0\n",
      "RUT 220715P2390000   102434       0\n",
      "RUT 220715P2400000   102434       0\n",
      "RUT 220715P2410000   102434       0\n",
      "RUT 220715P2420000   102434       0\n",
      "RUT 220715P2430000   102434       0\n",
      "RUT 220715P2240000   102434       0\n",
      "RUT 220715P2220000   102434       0\n",
      "RUT 220715P2000000   102434       0\n",
      "RUT 220715P2210000   102434       0\n",
      "RUT 220715P2010000   102434       0\n",
      "RUT 220715P2020000   102434       0\n",
      "RUT 220715P2030000   102434       0\n",
      "RUT 220715P2040000   102434       0\n",
      "RUT 220715P2050000   102434       0\n",
      "RUT 220715P2060000   102434       0\n",
      "RUT 220715P2070000   102434       0\n",
      "RUT 220715P2080000   102434       0\n",
      "RUT 220715P2090000   102434       0\n",
      "RUT 220715P2100000   102434       0\n",
      "RUT 220715P2110000   102434       0\n",
      "RUT 220715P2120000   102434       0\n",
      "RUT 220715P2130000   102434       0\n",
      "RUT 220715P2140000   102434       0\n",
      "RUT 220715P2160000   102434       0\n",
      "RUT 220715P2170000   102434       0\n",
      "RUT 220715P2180000   102434       0\n",
      "RUT 220715P2190000   102434       0\n",
      "RUT 220715P2200000   102434       0\n",
      "RUT 220715C2740000   102434       0\n",
      "RUT 220715C2720000   102434       0\n",
      "RUT 220715C1650000   102434       0\n",
      "RUT 220715C2030000   102434       0\n",
      "RUT 220715C2050000   102434       0\n",
      "RUT 220715C2060000   102434       0\n",
      "RUT 220715C2070000   102434       0\n",
      "RUT 220715C2080000   102434       0\n",
      "RUT 220715C2090000   102434       0\n",
      "RUT 220715C2100000   102434       0\n",
      "RUT 220715C2110000   102434       0\n",
      "RUT 220715C2120000   102434       0\n",
      "RUT 220715C2130000   102434       0\n",
      "RUT 220715C2140000   102434       0\n",
      "RUT 220715C2150000   102434       0\n",
      "RUT 220715C2160000   102434       0\n",
      "RUT 220715C2170000   102434       0\n",
      "RUT 220715C2180000   102434       0\n",
      "RUT 220715C2190000   102434       0\n",
      "RUT 220715C2200000   102434       0\n",
      "RUT 220715C2210000   102434       0\n",
      "RUT 220715C2220000   102434       0\n",
      "RUT 220715C2230000   102434       0\n",
      "RUT 220715C2040000   102434       0\n",
      "RUT 220715C2020000   102434       0\n",
      "RUT 220715C2250000   102434       0\n",
      "RUT 220715C2010000   102434       0\n",
      "RUT 220715C1700000   102434       0\n",
      "RUT 220715C1750000   102434       0\n",
      "RUT 220715C1800000   102434       0\n",
      "RUT 220715C1850000   102434       0\n",
      "RUT 220715C1860000   102434       0\n",
      "RUT 220715C1870000   102434       0\n",
      "RUT 220715C1880000   102434       0\n",
      "RUT 220715C1890000   102434       0\n",
      "RUT 220715C1900000   102434       0\n",
      "RUT 220715C1910000   102434       0\n",
      "RUT 220715C1920000   102434       0\n",
      "RUT 220715C1930000   102434       0\n",
      "RUT 220715C1940000   102434       0\n",
      "RUT 220715C1950000   102434       0\n",
      "RUT 220715C1960000   102434       0\n",
      "RUT 220715C1970000   102434       0\n",
      "RUT 220715C1980000   102434       0\n",
      "RUT 220715C1990000   102434       0\n",
      "RUT 220715C2000000   102434       0\n",
      "RUT 220715C2240000   102434       0\n",
      "RUT 220715C2260000   102434       0\n",
      "RUT 220715C2710000   102434       0\n",
      "RUT 220715C2490000   102434       0\n",
      "RUT 220715C2510000   102434       0\n",
      "RUT 220715C2520000   102434       0\n",
      "RUT 220715C2530000   102434       0\n",
      "RUT 220715C2540000   102434       0\n",
      "RUT 220715C2550000   102434       0\n",
      "RUT 220715C2560000   102434       0\n",
      "RUT 220715C2580000   102434       0\n",
      "RUT 220715C2590000   102434       0\n",
      "RUT 220715C2600000   102434       0\n",
      "RUT 220715C2610000   102434       0\n",
      "RUT 220715C2620000   102434       0\n",
      "RUT 220715C2630000   102434       0\n",
      "RUT 220715C2640000   102434       0\n",
      "RUT 220715C2650000   102434       0\n",
      "RUT 220715C2660000   102434       0\n",
      "RUT 220715C2670000   102434       0\n",
      "RUT 220715C2680000   102434       0\n",
      "RUT 220715C2690000   102434       0\n",
      "RUT 220715C2700000   102434       0\n",
      "RUT 220715C2500000   102434       0\n",
      "RUT 220715C2480000   102434       0\n",
      "RUT 220715C2270000   102434       0\n",
      "RUT 220715C2470000   102434       0\n",
      "RUT 220715C2280000   102434       0\n",
      "RUT 220715C2290000   102434       0\n",
      "RUT 220715C2300000   102434       0\n",
      "RUT 220715C2310000   102434       0\n",
      "RUT 220715C2320000   102434       0\n",
      "RUT 220715C2330000   102434       0\n",
      "RUT 220715C2340000   102434       0\n",
      "RUT 220715C2350000   102434       0\n",
      "RUT 220715C2360000   102434       0\n",
      "RUT 220715C2370000   102434       0\n",
      "RUT 220715C2380000   102434       0\n",
      "RUT 220715C2390000   102434       0\n",
      "RUT 220715C2400000   102434       0\n",
      "RUT 220715C2410000   102434       0\n",
      "RUT 220715C2420000   102434       0\n",
      "RUT 220715C2430000   102434       0\n",
      "RUT 220715C2440000   102434       0\n",
      "RUT 220715C2450000   102434       0\n",
      "RUT 220715C2460000   102434       0\n",
      "RUTW 221230P3400000  102434       0\n"
     ]
    }
   ],
   "source": [
    "with pd.option_context('display.max_rows', None, 'display.max_columns', None):  # more options can be specified also\n",
    "    print(data[data['date'] == '2022-01-03'].groupby('symbol').sum('volume')[['secid','volume']].sort_values('volume',ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    secid        date              symbol      exdate last_date cp_flag  \\\n",
      "0  100219  2022-01-03  RUI 220121C1750000  2022-01-21       NaN       C   \n",
      "1  100219  2022-01-03  RUI 220121C1775000  2022-01-21       NaN       C   \n",
      "2  100219  2022-01-03  RUI 220121C1800000  2022-01-21       NaN       C   \n",
      "3  100219  2022-01-03  RUI 220121C1825000  2022-01-21       NaN       C   \n",
      "4  100219  2022-01-03  RUI 220121C1850000  2022-01-21       NaN       C   \n",
      "\n",
      "   strike_price  best_bid  best_offer  volume  open_interest  impl_volatility  \\\n",
      "0       1750000     895.5       919.5       0              0              NaN   \n",
      "1       1775000     870.5       894.5       0              0              NaN   \n",
      "2       1800000     845.5       869.5       0              0              NaN   \n",
      "3       1825000     820.5       844.5       0              0              NaN   \n",
      "4       1850000     795.5       819.5       0              0              NaN   \n",
      "\n",
      "    optionid  contract_size  forward_price expiry_indicator  index_flag  \\\n",
      "0  143176231            100            NaN              NaN           1   \n",
      "1  143176232            100            NaN              NaN           1   \n",
      "2  143176233            100            NaN              NaN           1   \n",
      "3  143176234            100            NaN              NaN           1   \n",
      "4  143176235            100            NaN              NaN           1   \n",
      "\n",
      "               issuer exercise_style  \n",
      "0  RUSSELL 1000 INDEX              E  \n",
      "1  RUSSELL 1000 INDEX              E  \n",
      "2  RUSSELL 1000 INDEX              E  \n",
      "3  RUSSELL 1000 INDEX              E  \n",
      "4  RUSSELL 1000 INDEX              E  \n"
     ]
    }
   ],
   "source": [
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = data[(data['secid']==102434) & (data['date']=='2022-01-03') & (data['exdate'] =='2022-05-31') & (data['cp_flag']=='C')]\n",
    "\n",
    "nums  = data[(data['secid']==102434) & (data['date']=='2022-01-03') & (data['cp_flag']=='C')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nums.groupby('exdate').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "expiry_indicator  exdate    \n",
      "m                 2022-01-31    115\n",
      "                  2022-02-28    119\n",
      "                  2022-03-31    121\n",
      "                  2022-04-29    119\n",
      "                  2022-05-31    203\n",
      "                  2022-06-30    125\n",
      "                  2022-09-30    119\n",
      "                  2022-12-30    120\n",
      "w                 2022-01-03    177\n",
      "                  2022-01-05    201\n",
      "                  2022-01-07    319\n",
      "                  2022-01-10    177\n",
      "                  2022-01-12    181\n",
      "                  2022-01-14    309\n",
      "                  2022-01-18    182\n",
      "                  2022-01-28    311\n",
      "                  2022-02-04    302\n",
      "                  2022-02-11    308\n",
      "Name: volume, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "with pd.option_context('display.max_rows', None, 'display.max_columns', None):  # more options can be specified also\n",
    "    print(nums.groupby(['expiry_indicator', 'exdate'])['volume'].count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample2 = data[(data['secid']==102434) & (data['date']=='2022-01-03') & (data['exdate'] =='2022-01-07') & (data['cp_flag']=='C')]\n",
    "sample3 = data[(data['secid']==100219) & (data['date']=='2022-01-03') & (data['exdate'] =='2022-03-18') & (data['cp_flag']=='C')]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         secid        date               symbol      exdate   last_date  \\\n",
      "707627  102434  2022-01-03  RUTW 220107C1265000  2022-01-07         NaN   \n",
      "707628  102434  2022-01-03  RUTW 220107C1270000  2022-01-07         NaN   \n",
      "707629  102434  2022-01-03  RUTW 220107C1275000  2022-01-07         NaN   \n",
      "707630  102434  2022-01-03  RUTW 220107C1280000  2022-01-07         NaN   \n",
      "707631  102434  2022-01-03  RUTW 220107C1285000  2022-01-07         NaN   \n",
      "...        ...         ...                  ...         ...         ...   \n",
      "707941  102434  2022-01-03  RUTW 220107C2835000  2022-01-07         NaN   \n",
      "707942  102434  2022-01-03  RUTW 220107C2840000  2022-01-07         NaN   \n",
      "707943  102434  2022-01-03  RUTW 220107C2845000  2022-01-07         NaN   \n",
      "707944  102434  2022-01-03  RUTW 220107C2850000  2022-01-07  2021-11-30   \n",
      "707945  102434  2022-01-03  RUTW 220107C2855000  2022-01-07         NaN   \n",
      "\n",
      "       cp_flag  strike_price  best_bid  best_offer  volume  open_interest  \\\n",
      "707627       C       1265000    1002.8     1005.90       0              0   \n",
      "707628       C       1270000     997.8     1000.90       0              0   \n",
      "707629       C       1275000     992.8      995.90       0              0   \n",
      "707630       C       1280000     987.8      990.90       0              0   \n",
      "707631       C       1285000     982.8      985.90       0              0   \n",
      "...        ...           ...       ...         ...     ...            ...   \n",
      "707941       C       2835000       0.0        0.10       0              0   \n",
      "707942       C       2840000       0.0        0.10       0              0   \n",
      "707943       C       2845000       0.0        0.05       0              0   \n",
      "707944       C       2850000       0.0        0.05       0             40   \n",
      "707945       C       2855000       0.0        0.05       0              0   \n",
      "\n",
      "        impl_volatility   optionid  contract_size  forward_price  \\\n",
      "707627              NaN  143883527            100            NaN   \n",
      "707628              NaN  143883528            100            NaN   \n",
      "707629              NaN  143883529            100            NaN   \n",
      "707630              NaN  143883530            100            NaN   \n",
      "707631              NaN  143883531            100            NaN   \n",
      "...                 ...        ...            ...            ...   \n",
      "707941         0.683514  143883841            100            NaN   \n",
      "707942         0.688460  143883842            100            NaN   \n",
      "707943         0.656711  143883843            100            NaN   \n",
      "707944         0.661412  143883844            100            NaN   \n",
      "707945         0.666103  143883845            100            NaN   \n",
      "\n",
      "       expiry_indicator  index_flag              issuer exercise_style  \n",
      "707627                w           1  RUSSELL 2000 INDEX              E  \n",
      "707628                w           1  RUSSELL 2000 INDEX              E  \n",
      "707629                w           1  RUSSELL 2000 INDEX              E  \n",
      "707630                w           1  RUSSELL 2000 INDEX              E  \n",
      "707631                w           1  RUSSELL 2000 INDEX              E  \n",
      "...                 ...         ...                 ...            ...  \n",
      "707941                w           1  RUSSELL 2000 INDEX              E  \n",
      "707942                w           1  RUSSELL 2000 INDEX              E  \n",
      "707943                w           1  RUSSELL 2000 INDEX              E  \n",
      "707944                w           1  RUSSELL 2000 INDEX              E  \n",
      "707945                w           1  RUSSELL 2000 INDEX              E  \n",
      "\n",
      "[319 rows x 19 columns]\n"
     ]
    }
   ],
   "source": [
    "sample3 = sample2\n",
    "print(sample2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "forwards = pd.read_csv('./OptionMetrics/forwards2223.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>secid</th>\n",
       "      <th>date</th>\n",
       "      <th>expiration</th>\n",
       "      <th>ForwardPrice</th>\n",
       "      <th>ticker</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>371825</th>\n",
       "      <td>102434</td>\n",
       "      <td>2022-01-03</td>\n",
       "      <td>2022-01-03</td>\n",
       "      <td>2272.557100</td>\n",
       "      <td>RUT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>371826</th>\n",
       "      <td>102434</td>\n",
       "      <td>2022-01-03</td>\n",
       "      <td>2022-01-05</td>\n",
       "      <td>2272.466713</td>\n",
       "      <td>RUT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>371827</th>\n",
       "      <td>102434</td>\n",
       "      <td>2022-01-03</td>\n",
       "      <td>2022-01-07</td>\n",
       "      <td>2272.376330</td>\n",
       "      <td>RUT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>371828</th>\n",
       "      <td>102434</td>\n",
       "      <td>2022-01-03</td>\n",
       "      <td>2022-01-10</td>\n",
       "      <td>2272.240762</td>\n",
       "      <td>RUT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>371829</th>\n",
       "      <td>102434</td>\n",
       "      <td>2022-01-03</td>\n",
       "      <td>2022-01-12</td>\n",
       "      <td>2272.150388</td>\n",
       "      <td>RUT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>371830</th>\n",
       "      <td>102434</td>\n",
       "      <td>2022-01-03</td>\n",
       "      <td>2022-01-14</td>\n",
       "      <td>2272.060219</td>\n",
       "      <td>RUT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>371831</th>\n",
       "      <td>102434</td>\n",
       "      <td>2022-01-03</td>\n",
       "      <td>2022-01-18</td>\n",
       "      <td>2271.880662</td>\n",
       "      <td>RUT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>371832</th>\n",
       "      <td>102434</td>\n",
       "      <td>2022-01-03</td>\n",
       "      <td>2022-01-21</td>\n",
       "      <td>2271.791108</td>\n",
       "      <td>RUT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>371833</th>\n",
       "      <td>102434</td>\n",
       "      <td>2022-01-03</td>\n",
       "      <td>2022-01-28</td>\n",
       "      <td>2271.434394</td>\n",
       "      <td>RUT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>371834</th>\n",
       "      <td>102434</td>\n",
       "      <td>2022-01-03</td>\n",
       "      <td>2022-01-31</td>\n",
       "      <td>2271.301245</td>\n",
       "      <td>RUT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>371835</th>\n",
       "      <td>102434</td>\n",
       "      <td>2022-01-03</td>\n",
       "      <td>2022-02-04</td>\n",
       "      <td>2271.124372</td>\n",
       "      <td>RUT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>371836</th>\n",
       "      <td>102434</td>\n",
       "      <td>2022-01-03</td>\n",
       "      <td>2022-02-11</td>\n",
       "      <td>2270.816649</td>\n",
       "      <td>RUT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>371837</th>\n",
       "      <td>102434</td>\n",
       "      <td>2022-01-03</td>\n",
       "      <td>2022-02-18</td>\n",
       "      <td>2270.554509</td>\n",
       "      <td>RUT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>371838</th>\n",
       "      <td>102434</td>\n",
       "      <td>2022-01-03</td>\n",
       "      <td>2022-02-28</td>\n",
       "      <td>2270.077811</td>\n",
       "      <td>RUT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>371839</th>\n",
       "      <td>102434</td>\n",
       "      <td>2022-01-03</td>\n",
       "      <td>2022-03-18</td>\n",
       "      <td>2269.353331</td>\n",
       "      <td>RUT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>371840</th>\n",
       "      <td>102434</td>\n",
       "      <td>2022-01-03</td>\n",
       "      <td>2022-03-31</td>\n",
       "      <td>2268.767241</td>\n",
       "      <td>RUT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>371841</th>\n",
       "      <td>102434</td>\n",
       "      <td>2022-01-03</td>\n",
       "      <td>2022-04-29</td>\n",
       "      <td>2267.589195</td>\n",
       "      <td>RUT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>371842</th>\n",
       "      <td>102434</td>\n",
       "      <td>2022-01-03</td>\n",
       "      <td>2022-05-31</td>\n",
       "      <td>2266.349134</td>\n",
       "      <td>RUT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>371843</th>\n",
       "      <td>102434</td>\n",
       "      <td>2022-01-03</td>\n",
       "      <td>2022-06-17</td>\n",
       "      <td>2265.755686</td>\n",
       "      <td>RUT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>371844</th>\n",
       "      <td>102434</td>\n",
       "      <td>2022-01-03</td>\n",
       "      <td>2022-06-30</td>\n",
       "      <td>2265.250194</td>\n",
       "      <td>RUT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>371845</th>\n",
       "      <td>102434</td>\n",
       "      <td>2022-01-03</td>\n",
       "      <td>2022-07-15</td>\n",
       "      <td>2264.764602</td>\n",
       "      <td>RUT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>371846</th>\n",
       "      <td>102434</td>\n",
       "      <td>2022-01-03</td>\n",
       "      <td>2022-09-16</td>\n",
       "      <td>2262.758997</td>\n",
       "      <td>RUT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>371847</th>\n",
       "      <td>102434</td>\n",
       "      <td>2022-01-03</td>\n",
       "      <td>2022-09-30</td>\n",
       "      <td>2262.321458</td>\n",
       "      <td>RUT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>371848</th>\n",
       "      <td>102434</td>\n",
       "      <td>2022-01-03</td>\n",
       "      <td>2022-12-16</td>\n",
       "      <td>2260.468362</td>\n",
       "      <td>RUT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>371849</th>\n",
       "      <td>102434</td>\n",
       "      <td>2022-01-03</td>\n",
       "      <td>2022-12-16</td>\n",
       "      <td>2260.489330</td>\n",
       "      <td>RUT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>371850</th>\n",
       "      <td>102434</td>\n",
       "      <td>2022-01-03</td>\n",
       "      <td>2022-12-30</td>\n",
       "      <td>2260.183187</td>\n",
       "      <td>RUT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>371851</th>\n",
       "      <td>102434</td>\n",
       "      <td>2022-01-03</td>\n",
       "      <td>2023-06-16</td>\n",
       "      <td>2258.636050</td>\n",
       "      <td>RUT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>371852</th>\n",
       "      <td>102434</td>\n",
       "      <td>2022-01-03</td>\n",
       "      <td>2023-12-15</td>\n",
       "      <td>2260.913672</td>\n",
       "      <td>RUT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>371853</th>\n",
       "      <td>102434</td>\n",
       "      <td>2022-01-03</td>\n",
       "      <td>2023-12-15</td>\n",
       "      <td>2260.890711</td>\n",
       "      <td>RUT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>371854</th>\n",
       "      <td>102434</td>\n",
       "      <td>2022-01-03</td>\n",
       "      <td>2024-12-20</td>\n",
       "      <td>2256.012131</td>\n",
       "      <td>RUT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         secid        date  expiration  ForwardPrice ticker\n",
       "371825  102434  2022-01-03  2022-01-03   2272.557100    RUT\n",
       "371826  102434  2022-01-03  2022-01-05   2272.466713    RUT\n",
       "371827  102434  2022-01-03  2022-01-07   2272.376330    RUT\n",
       "371828  102434  2022-01-03  2022-01-10   2272.240762    RUT\n",
       "371829  102434  2022-01-03  2022-01-12   2272.150388    RUT\n",
       "371830  102434  2022-01-03  2022-01-14   2272.060219    RUT\n",
       "371831  102434  2022-01-03  2022-01-18   2271.880662    RUT\n",
       "371832  102434  2022-01-03  2022-01-21   2271.791108    RUT\n",
       "371833  102434  2022-01-03  2022-01-28   2271.434394    RUT\n",
       "371834  102434  2022-01-03  2022-01-31   2271.301245    RUT\n",
       "371835  102434  2022-01-03  2022-02-04   2271.124372    RUT\n",
       "371836  102434  2022-01-03  2022-02-11   2270.816649    RUT\n",
       "371837  102434  2022-01-03  2022-02-18   2270.554509    RUT\n",
       "371838  102434  2022-01-03  2022-02-28   2270.077811    RUT\n",
       "371839  102434  2022-01-03  2022-03-18   2269.353331    RUT\n",
       "371840  102434  2022-01-03  2022-03-31   2268.767241    RUT\n",
       "371841  102434  2022-01-03  2022-04-29   2267.589195    RUT\n",
       "371842  102434  2022-01-03  2022-05-31   2266.349134    RUT\n",
       "371843  102434  2022-01-03  2022-06-17   2265.755686    RUT\n",
       "371844  102434  2022-01-03  2022-06-30   2265.250194    RUT\n",
       "371845  102434  2022-01-03  2022-07-15   2264.764602    RUT\n",
       "371846  102434  2022-01-03  2022-09-16   2262.758997    RUT\n",
       "371847  102434  2022-01-03  2022-09-30   2262.321458    RUT\n",
       "371848  102434  2022-01-03  2022-12-16   2260.468362    RUT\n",
       "371849  102434  2022-01-03  2022-12-16   2260.489330    RUT\n",
       "371850  102434  2022-01-03  2022-12-30   2260.183187    RUT\n",
       "371851  102434  2022-01-03  2023-06-16   2258.636050    RUT\n",
       "371852  102434  2022-01-03  2023-12-15   2260.913672    RUT\n",
       "371853  102434  2022-01-03  2023-12-15   2260.890711    RUT\n",
       "371854  102434  2022-01-03  2024-12-20   2256.012131    RUT"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forwards[(forwards['secid']==102434) & (forwards['date']=='2022-01-03')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>secid</th>\n",
       "      <th>date</th>\n",
       "      <th>expiration</th>\n",
       "      <th>ForwardPrice</th>\n",
       "      <th>ticker</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>371842</th>\n",
       "      <td>102434</td>\n",
       "      <td>2022-01-03</td>\n",
       "      <td>2022-05-31</td>\n",
       "      <td>2266.349134</td>\n",
       "      <td>RUT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         secid        date  expiration  ForwardPrice ticker\n",
       "371842  102434  2022-01-03  2022-05-31   2266.349134    RUT"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forwards[(forwards['secid']==102434) & (forwards['date']=='2022-01-03') & (forwards['expiration'] == '2022-05-31')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>secid</th>\n",
       "      <th>date</th>\n",
       "      <th>expiration</th>\n",
       "      <th>ForwardPrice</th>\n",
       "      <th>ticker</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>371850</th>\n",
       "      <td>102434</td>\n",
       "      <td>2022-01-03</td>\n",
       "      <td>2022-12-30</td>\n",
       "      <td>2260.183187</td>\n",
       "      <td>RUT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         secid        date  expiration  ForwardPrice ticker\n",
       "371850  102434  2022-01-03  2022-12-30   2260.183187    RUT"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#f2\n",
    "forwards[(forwards['secid']==102434) & (forwards['date']=='2022-01-03') & (forwards['expiration'] == '2022-12-30')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "securities = pd.read_csv('./OptionMetrics/securities2223.csv', nrows=10_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>secid</th>\n",
       "      <th>date</th>\n",
       "      <th>ticker</th>\n",
       "      <th>sic</th>\n",
       "      <th>index_flag</th>\n",
       "      <th>exchange_d</th>\n",
       "      <th>low</th>\n",
       "      <th>high</th>\n",
       "      <th>open</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6953</th>\n",
       "      <td>100219</td>\n",
       "      <td>2022-01-03</td>\n",
       "      <td>RUI</td>\n",
       "      <td>9999.0</td>\n",
       "      <td>1</td>\n",
       "      <td>32768</td>\n",
       "      <td>2640.25</td>\n",
       "      <td>2660.95</td>\n",
       "      <td>2645.68</td>\n",
       "      <td>2660.78</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       secid        date ticker     sic  index_flag  exchange_d      low  \\\n",
       "6953  100219  2022-01-03    RUI  9999.0           1       32768  2640.25   \n",
       "\n",
       "         high     open    close  volume  \n",
       "6953  2660.95  2645.68  2660.78       0  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "securities[(securities['secid']==100219) & (securities['date']=='2022-01-03')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "rates = pd.read_csv('./OptionMetrics/rates2223.csv', nrows=10_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>days</th>\n",
       "      <th>rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-01-03</td>\n",
       "      <td>10</td>\n",
       "      <td>0.518382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-01-03</td>\n",
       "      <td>30</td>\n",
       "      <td>0.524269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-01-03</td>\n",
       "      <td>60</td>\n",
       "      <td>0.534101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-01-03</td>\n",
       "      <td>91</td>\n",
       "      <td>0.545490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-01-03</td>\n",
       "      <td>122</td>\n",
       "      <td>0.558093</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date  days      rate\n",
       "0  2022-01-03    10  0.518382\n",
       "1  2022-01-03    30  0.524269\n",
       "2  2022-01-03    60  0.534101\n",
       "3  2022-01-03    91  0.545490\n",
       "4  2022-01-03   122  0.558093"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rates.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "rates[(rates['date'] == '2022-01-03') & (rates['days']==30)]['rate'] / 100\n",
    "r = (rates[(rates['date'] == '2022-01-03') & (rates['days']==30)]['rate'] / 100).iloc[0]\n",
    "r2 = 0.0053\n",
    "r3 = 0.0056"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2660.8358027802246\n",
      "2446.580858701599\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "print(2662.556214 * np.exp(-r * 45 / 365))\n",
    "print(2445 * np.exp(r * 45/365.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            exdate  strike_price  impl_volatility  best_bid  best_offer\n",
      "713647  2022-12-30       1100000         0.395676    1112.3      1208.3\n",
      "713648  2022-12-30       1150000         0.386990    1064.3      1160.3\n",
      "713649  2022-12-30       1200000         0.380048    1016.8      1112.8\n",
      "713650  2022-12-30       1250000         0.379388     970.8      1066.8\n",
      "713651  2022-12-30       1300000         0.364597     922.5      1018.5\n",
      "713652  2022-12-30       1350000         0.367316     878.4       974.4\n",
      "713653  2022-12-30       1400000         0.350645     830.0       926.0\n",
      "713654  2022-12-30       1450000         0.352011     787.0       883.0\n",
      "713655  2022-12-30       1500000         0.338588     740.0       836.0\n",
      "713656  2022-12-30       1550000         0.333593     696.3       792.3\n",
      "713657  2022-12-30       1600000         0.324176     651.5       747.5\n",
      "713658  2022-12-30       1650000         0.311079     605.5       701.5\n",
      "713659  2022-12-30       1700000         0.308132     564.7       660.7\n",
      "713660  2022-12-30       1750000         0.283415     513.5       609.5\n",
      "713661  2022-12-30       1800000         0.292471     480.8       576.8\n",
      "713662  2022-12-30       1810000         0.290769     472.5       568.5\n",
      "713663  2022-12-30       1820000         0.289519     464.5       560.5\n",
      "713664  2022-12-30       1830000         0.287873     456.3       552.3\n",
      "713665  2022-12-30       1840000         0.286500     448.3       544.3\n",
      "713666  2022-12-30       1850000         0.285066     440.3       536.3\n",
      "713667  2022-12-30       1860000         0.283413     432.2       528.2\n",
      "713668  2022-12-30       1870000         0.282019     424.3       520.3\n",
      "713669  2022-12-30       1880000         0.280409     416.3       512.3\n",
      "713670  2022-12-30       1890000         0.278896     408.4       504.4\n",
      "713671  2022-12-30       1900000         0.277474     400.6       496.6\n",
      "713672  2022-12-30       1910000         0.275992     392.8       488.8\n",
      "713673  2022-12-30       1920000         0.274449     385.0       481.0\n",
      "713674  2022-12-30       1930000         0.272992     377.3       473.3\n",
      "713675  2022-12-30       1940000         0.271762     369.8       465.8\n",
      "713676  2022-12-30       1950000         0.270039     362.0       458.0\n",
      "713677  2022-12-30       1960000         0.268540     354.4       450.4\n",
      "713678  2022-12-30       1970000         0.267119     346.9       442.9\n",
      "713679  2022-12-30       1980000         0.265634     339.4       435.4\n",
      "713680  2022-12-30       1990000         0.264087     331.9       427.9\n",
      "713681  2022-12-30       2000000         0.262748     324.6       420.6\n",
      "713682  2022-12-30       2010000         0.261209     317.2       413.2\n",
      "713683  2022-12-30       2020000         0.259870     310.0       406.0\n",
      "713684  2022-12-30       2030000         0.259507     303.6       399.6\n",
      "713685  2022-12-30       2040000         0.256993     295.6       391.6\n",
      "713686  2022-12-30       2050000         0.255585     288.5       384.5\n",
      "713687  2022-12-30       2060000         0.254109     281.4       377.4\n",
      "713688  2022-12-30       2070000         0.252819     274.5       370.5\n",
      "713689  2022-12-30       2080000         0.251334     267.5       363.5\n",
      "713690  2022-12-30       2090000         0.250029     260.7       356.7\n",
      "713691  2022-12-30       2100000         0.248654     253.9       349.9\n",
      "713692  2022-12-30       2110000         0.247330     247.2       343.2\n",
      "713693  2022-12-30       2120000         0.245210     239.9       335.9\n",
      "713694  2022-12-30       2130000         0.243990     233.4       329.4\n",
      "713695  2022-12-30       2140000         0.243411     227.5       323.5\n",
      "713696  2022-12-30       2150000         0.242039     221.0       317.0\n",
      "713697  2022-12-30       2160000         0.240358     214.3       310.3\n",
      "713698  2022-12-30       2170000         0.239311     208.2       304.2\n",
      "713699  2022-12-30       2180000         0.238185     202.1       298.1\n",
      "713700  2022-12-30       2190000         0.247645     205.2       301.2\n",
      "713701  2022-12-30       2200000         0.251393     203.5       299.5\n",
      "713702  2022-12-30       2210000         0.234233     199.7       263.7\n",
      "713703  2022-12-30       2220000         0.233029     193.8       257.8\n",
      "713704  2022-12-30       2230000         0.231747     187.9       251.9\n",
      "713705  2022-12-30       2240000         0.230613     182.2       246.2\n",
      "713706  2022-12-30       2250000         0.229286     176.4       240.4\n",
      "713707  2022-12-30       2260000         0.228217     170.9       234.9\n",
      "713708  2022-12-30       2270000         0.227067     165.4       229.4\n",
      "713709  2022-12-30       2280000         0.225835     159.9       223.9\n",
      "713710  2022-12-30       2290000         0.224746     154.6       218.6\n",
      "713711  2022-12-30       2300000         0.223685     149.4       213.4\n",
      "713712  2022-12-30       2310000         0.222428     144.1       208.1\n",
      "713713  2022-12-30       2320000         0.221199     138.9       202.9\n",
      "713714  2022-12-30       2330000         0.220109     133.9       197.9\n",
      "713715  2022-12-30       2340000         0.219158     129.1       193.1\n",
      "713716  2022-12-30       2350000         0.218008     124.2       188.2\n",
      "713717  2022-12-30       2360000         0.216997     119.5       183.5\n",
      "713718  2022-12-30       2370000         0.216010     114.9       178.9\n",
      "713719  2022-12-30       2380000         0.215049     110.4       174.4\n",
      "713720  2022-12-30       2390000         0.214113     106.0       170.0\n",
      "713721  2022-12-30       2400000         0.213201     101.7       165.7\n",
      "713722  2022-12-30       2410000         0.215291     100.1       164.1\n",
      "713723  2022-12-30       2420000         0.219149     100.1       164.1\n",
      "713724  2022-12-30       2430000         0.222952     100.1       164.1\n",
      "713725  2022-12-30       2440000         0.209696      97.4       137.4\n",
      "713726  2022-12-30       2450000         0.208913      93.6       133.6\n",
      "713727  2022-12-30       2460000         0.208158      89.9       129.9\n",
      "713728  2022-12-30       2470000         0.207431      86.3       126.3\n",
      "713729  2022-12-30       2480000         0.206733      82.8       122.8\n",
      "713730  2022-12-30       2490000         0.206065      79.4       119.4\n",
      "713731  2022-12-30       2500000         0.205428      76.1       116.1\n",
      "713732  2022-12-30       2510000         0.204701      72.8       112.8\n",
      "713733  2022-12-30       2520000         0.204130      69.7       109.7\n",
      "713734  2022-12-30       2530000         0.203469      66.6       106.6\n",
      "713735  2022-12-30       2540000         0.202844      63.6       103.6\n",
      "713736  2022-12-30       2550000         0.202001      60.5       100.5\n",
      "713737  2022-12-30       2560000         0.201576      57.8        97.8\n",
      "713738  2022-12-30       2570000         0.200935      55.0        95.0\n",
      "713739  2022-12-30       2580000         0.200335      52.3        92.3\n",
      "713740  2022-12-30       2590000         0.199776      49.7        89.7\n",
      "713741  2022-12-30       2600000         0.198992      47.0        87.0\n",
      "713742  2022-12-30       2610000         0.198660      44.7        84.7\n",
      "713743  2022-12-30       2620000         0.198105      42.3        82.3\n",
      "713744  2022-12-30       2630000         0.197600      40.0        80.0\n",
      "713745  2022-12-30       2640000         0.197006      37.7        77.7\n",
      "713746  2022-12-30       2650000         0.196465      35.5        75.5\n",
      "713747  2022-12-30       2660000         0.195833      33.3        73.3\n",
      "713748  2022-12-30       2670000         0.195407      31.3        71.3\n",
      "713749  2022-12-30       2680000         0.194894      29.3        69.3\n",
      "713750  2022-12-30       2690000         0.194601      27.5        67.5\n",
      "713751  2022-12-30       2700000         0.194226      25.7        65.7\n",
      "713752  2022-12-30       2710000         0.193925      24.0        64.0\n",
      "713753  2022-12-30       2750000         0.192385      17.5        57.5\n",
      "713754  2022-12-30       2800000         0.191113      10.8        50.8\n",
      "713755  2022-12-30       2850000         0.190230       5.3        45.3\n",
      "713756  2022-12-30       2900000         0.199283       5.0        45.0\n",
      "713757  2022-12-30       2950000         0.208672       5.0        45.0\n",
      "713758  2022-12-30       3000000         0.217781       5.0        45.0\n",
      "713759  2022-12-30       3050000         0.226628       5.0        45.0\n",
      "713760  2022-12-30       3100000         0.235231       5.0        45.0\n",
      "713761  2022-12-30       3150000         0.194166       4.1        13.7\n",
      "713762  2022-12-30       3200000         0.194526       2.6        12.2\n",
      "713763  2022-12-30       3250000         0.195718       1.5        11.1\n",
      "713764  2022-12-30       3300000              NaN       0.5        10.1\n",
      "713765  2022-12-30       3350000              NaN       0.0         9.6\n",
      "713766  2022-12-30       3400000              NaN       0.0         9.6\n"
     ]
    }
   ],
   "source": [
    "with pd.option_context('display.max_rows', None, 'display.max_columns', None):  # more options can be specified also\n",
    "    print(sample3[['exdate','strike_price','impl_volatility', 'best_bid', 'best_offer']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1f6b0989eb0>]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(sample3['strike_price'],sample3['best_offer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample=sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   secid        date ticker     sic  index_flag  exchange_d     low     high  \\\n",
      "0   5139  2022-12-27    CAE  3690.0           0          17  18.930  19.1600   \n",
      "1   5139  2022-12-30    CAE  3690.0           0          17  19.170  19.6400   \n",
      "2   5139  2022-12-29    CAE  3690.0           0          17  18.810  19.4515   \n",
      "3   5139  2022-12-28    CAE  3690.0           0          17  18.735  19.2600   \n",
      "4   5139  2022-12-23    CAE  3690.0           0          17  18.900  19.1500   \n",
      "\n",
      "    open  close  volume  \n",
      "0  19.10  19.15   85882  \n",
      "1  19.17  19.34  285651  \n",
      "2  18.93  19.37  165575  \n",
      "3  18.95  18.78  159200  \n",
      "4  19.10  19.10  115037  \n"
     ]
    }
   ],
   "source": [
    "print(securities.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        strike_price  best_bid        date      exdate\n",
      "712753       1150000   1114.90  2022-01-03  2022-05-31\n",
      "712754       1200000   1065.70  2022-01-03  2022-05-31\n",
      "712755       1250000   1016.60  2022-01-03  2022-05-31\n",
      "712756       1300000    967.60  2022-01-03  2022-05-31\n",
      "712757       1350000    918.70  2022-01-03  2022-05-31\n",
      "712758       1400000    870.00  2022-01-03  2022-05-31\n",
      "712759       1450000    821.50  2022-01-03  2022-05-31\n",
      "712760       1500000    773.10  2022-01-03  2022-05-31\n",
      "712761       1550000    725.00  2022-01-03  2022-05-31\n",
      "712762       1600000    677.20  2022-01-03  2022-05-31\n",
      "712763       1650000    629.70  2022-01-03  2022-05-31\n",
      "712764       1700000    582.70  2022-01-03  2022-05-31\n",
      "712765       1750000    536.10  2022-01-03  2022-05-31\n",
      "712766       1780000    508.50  2022-01-03  2022-05-31\n",
      "712767       1785000    503.90  2022-01-03  2022-05-31\n",
      "712768       1790000    499.30  2022-01-03  2022-05-31\n",
      "712769       1795000    494.70  2022-01-03  2022-05-31\n",
      "712770       1800000    490.20  2022-01-03  2022-05-31\n",
      "712771       1805000    485.60  2022-01-03  2022-05-31\n",
      "712772       1810000    481.10  2022-01-03  2022-05-31\n",
      "712773       1815000    476.50  2022-01-03  2022-05-31\n",
      "712774       1820000    472.00  2022-01-03  2022-05-31\n",
      "712775       1825000    467.50  2022-01-03  2022-05-31\n",
      "712776       1830000    462.90  2022-01-03  2022-05-31\n",
      "712777       1835000    458.40  2022-01-03  2022-05-31\n",
      "712778       1840000    453.90  2022-01-03  2022-05-31\n",
      "712779       1845000    449.40  2022-01-03  2022-05-31\n",
      "712780       1850000    444.90  2022-01-03  2022-05-31\n",
      "712781       1855000    440.50  2022-01-03  2022-05-31\n",
      "712782       1860000    436.00  2022-01-03  2022-05-31\n",
      "712783       1865000    431.50  2022-01-03  2022-05-31\n",
      "712784       1870000    427.10  2022-01-03  2022-05-31\n",
      "712785       1875000    422.60  2022-01-03  2022-05-31\n",
      "712786       1880000    418.20  2022-01-03  2022-05-31\n",
      "712787       1885000    413.80  2022-01-03  2022-05-31\n",
      "712788       1890000    409.40  2022-01-03  2022-05-31\n",
      "712789       1895000    405.00  2022-01-03  2022-05-31\n",
      "712790       1900000    400.60  2022-01-03  2022-05-31\n",
      "712791       1905000    396.20  2022-01-03  2022-05-31\n",
      "712792       1910000    391.80  2022-01-03  2022-05-31\n",
      "712793       1915000    387.50  2022-01-03  2022-05-31\n",
      "712794       1920000    383.10  2022-01-03  2022-05-31\n",
      "712795       1925000    378.80  2022-01-03  2022-05-31\n",
      "712796       1930000    374.40  2022-01-03  2022-05-31\n",
      "712797       1935000    370.10  2022-01-03  2022-05-31\n",
      "712798       1940000    365.80  2022-01-03  2022-05-31\n",
      "712799       1945000    361.50  2022-01-03  2022-05-31\n",
      "712800       1950000    357.20  2022-01-03  2022-05-31\n",
      "712801       1955000    353.00  2022-01-03  2022-05-31\n",
      "712802       1960000    348.70  2022-01-03  2022-05-31\n",
      "712803       1965000    344.50  2022-01-03  2022-05-31\n",
      "712804       1970000    340.20  2022-01-03  2022-05-31\n",
      "712805       1975000    336.00  2022-01-03  2022-05-31\n",
      "712806       1980000    331.80  2022-01-03  2022-05-31\n",
      "712807       1985000    327.60  2022-01-03  2022-05-31\n",
      "712808       1990000    323.40  2022-01-03  2022-05-31\n",
      "712809       1995000    319.30  2022-01-03  2022-05-31\n",
      "712810       2000000    315.10  2022-01-03  2022-05-31\n",
      "712811       2005000    311.00  2022-01-03  2022-05-31\n",
      "712812       2010000    306.90  2022-01-03  2022-05-31\n",
      "712813       2015000    302.80  2022-01-03  2022-05-31\n",
      "712814       2020000    298.70  2022-01-03  2022-05-31\n",
      "712815       2025000    294.60  2022-01-03  2022-05-31\n",
      "712816       2030000    290.60  2022-01-03  2022-05-31\n",
      "712817       2035000    286.50  2022-01-03  2022-05-31\n",
      "712818       2040000    282.50  2022-01-03  2022-05-31\n",
      "712819       2045000    278.50  2022-01-03  2022-05-31\n",
      "712820       2050000    274.50  2022-01-03  2022-05-31\n",
      "712821       2055000    270.50  2022-01-03  2022-05-31\n",
      "712822       2060000    266.60  2022-01-03  2022-05-31\n",
      "712823       2065000    262.60  2022-01-03  2022-05-31\n",
      "712824       2070000    258.70  2022-01-03  2022-05-31\n",
      "712825       2075000    254.80  2022-01-03  2022-05-31\n",
      "712826       2080000    250.90  2022-01-03  2022-05-31\n",
      "712827       2085000    247.10  2022-01-03  2022-05-31\n",
      "712828       2090000    243.20  2022-01-03  2022-05-31\n",
      "712829       2095000    239.40  2022-01-03  2022-05-31\n",
      "712830       2100000    235.60  2022-01-03  2022-05-31\n",
      "712831       2105000    231.90  2022-01-03  2022-05-31\n",
      "712832       2110000    228.10  2022-01-03  2022-05-31\n",
      "712833       2115000    224.40  2022-01-03  2022-05-31\n",
      "712834       2120000    220.70  2022-01-03  2022-05-31\n",
      "712835       2125000    217.00  2022-01-03  2022-05-31\n",
      "712836       2130000    213.30  2022-01-03  2022-05-31\n",
      "712837       2135000    209.70  2022-01-03  2022-05-31\n",
      "712838       2140000    206.00  2022-01-03  2022-05-31\n",
      "712839       2145000    202.40  2022-01-03  2022-05-31\n",
      "712840       2150000    198.90  2022-01-03  2022-05-31\n",
      "712841       2155000    195.30  2022-01-03  2022-05-31\n",
      "712842       2160000    191.80  2022-01-03  2022-05-31\n",
      "712843       2165000    188.30  2022-01-03  2022-05-31\n",
      "712844       2170000    184.90  2022-01-03  2022-05-31\n",
      "712845       2175000    181.40  2022-01-03  2022-05-31\n",
      "712846       2180000    178.00  2022-01-03  2022-05-31\n",
      "712847       2185000    174.60  2022-01-03  2022-05-31\n",
      "712848       2190000    171.30  2022-01-03  2022-05-31\n",
      "712849       2195000    167.90  2022-01-03  2022-05-31\n",
      "712850       2200000    164.60  2022-01-03  2022-05-31\n",
      "712851       2205000    161.40  2022-01-03  2022-05-31\n",
      "712852       2210000    158.10  2022-01-03  2022-05-31\n",
      "712853       2215000    154.90  2022-01-03  2022-05-31\n",
      "712854       2220000    151.70  2022-01-03  2022-05-31\n",
      "712855       2225000    148.60  2022-01-03  2022-05-31\n",
      "712856       2230000    145.50  2022-01-03  2022-05-31\n",
      "712857       2235000    142.40  2022-01-03  2022-05-31\n",
      "712858       2240000    139.30  2022-01-03  2022-05-31\n",
      "712859       2245000    136.30  2022-01-03  2022-05-31\n",
      "712860       2250000    133.30  2022-01-03  2022-05-31\n",
      "712861       2255000    130.40  2022-01-03  2022-05-31\n",
      "712862       2260000    127.50  2022-01-03  2022-05-31\n",
      "712863       2265000    124.60  2022-01-03  2022-05-31\n",
      "712864       2270000    121.70  2022-01-03  2022-05-31\n",
      "712865       2275000    118.90  2022-01-03  2022-05-31\n",
      "712866       2280000    116.20  2022-01-03  2022-05-31\n",
      "712867       2285000    113.40  2022-01-03  2022-05-31\n",
      "712868       2290000    110.70  2022-01-03  2022-05-31\n",
      "712869       2295000    108.00  2022-01-03  2022-05-31\n",
      "712870       2300000    105.40  2022-01-03  2022-05-31\n",
      "712871       2305000    102.80  2022-01-03  2022-05-31\n",
      "712872       2310000    100.30  2022-01-03  2022-05-31\n",
      "712873       2315000     97.80  2022-01-03  2022-05-31\n",
      "712874       2320000     95.30  2022-01-03  2022-05-31\n",
      "712875       2325000     92.80  2022-01-03  2022-05-31\n",
      "712876       2330000     90.40  2022-01-03  2022-05-31\n",
      "712877       2335000     88.10  2022-01-03  2022-05-31\n",
      "712878       2340000     85.80  2022-01-03  2022-05-31\n",
      "712879       2345000     83.50  2022-01-03  2022-05-31\n",
      "712880       2350000     81.20  2022-01-03  2022-05-31\n",
      "712881       2355000     79.00  2022-01-03  2022-05-31\n",
      "712882       2360000     76.90  2022-01-03  2022-05-31\n",
      "712883       2365000     74.70  2022-01-03  2022-05-31\n",
      "712884       2370000     72.60  2022-01-03  2022-05-31\n",
      "712885       2375000     70.60  2022-01-03  2022-05-31\n",
      "712886       2380000     68.60  2022-01-03  2022-05-31\n",
      "712887       2385000     66.60  2022-01-03  2022-05-31\n",
      "712888       2390000     64.70  2022-01-03  2022-05-31\n",
      "712889       2395000     62.80  2022-01-03  2022-05-31\n",
      "712890       2400000     61.00  2022-01-03  2022-05-31\n",
      "712891       2405000     59.20  2022-01-03  2022-05-31\n",
      "712892       2410000     57.40  2022-01-03  2022-05-31\n",
      "712893       2415000     55.70  2022-01-03  2022-05-31\n",
      "712894       2420000     54.00  2022-01-03  2022-05-31\n",
      "712895       2425000     52.30  2022-01-03  2022-05-31\n",
      "712896       2430000     50.70  2022-01-03  2022-05-31\n",
      "712897       2435000     49.10  2022-01-03  2022-05-31\n",
      "712898       2440000     47.60  2022-01-03  2022-05-31\n",
      "712899       2445000     46.10  2022-01-03  2022-05-31\n",
      "712900       2450000     44.70  2022-01-03  2022-05-31\n",
      "712901       2455000     43.20  2022-01-03  2022-05-31\n",
      "712902       2460000     41.80  2022-01-03  2022-05-31\n",
      "712903       2465000     40.50  2022-01-03  2022-05-31\n",
      "712904       2470000     39.20  2022-01-03  2022-05-31\n",
      "712905       2475000     37.80  2022-01-03  2022-05-31\n",
      "712906       2480000     36.60  2022-01-03  2022-05-31\n",
      "712907       2485000     35.40  2022-01-03  2022-05-31\n",
      "712908       2490000     34.30  2022-01-03  2022-05-31\n",
      "712909       2495000     33.10  2022-01-03  2022-05-31\n",
      "712910       2500000     32.00  2022-01-03  2022-05-31\n",
      "712911       2505000     30.90  2022-01-03  2022-05-31\n",
      "712912       2510000     29.90  2022-01-03  2022-05-31\n",
      "712913       2515000     28.90  2022-01-03  2022-05-31\n",
      "712914       2520000     27.90  2022-01-03  2022-05-31\n",
      "712915       2525000     26.90  2022-01-03  2022-05-31\n",
      "712916       2530000     26.00  2022-01-03  2022-05-31\n",
      "712917       2535000     25.10  2022-01-03  2022-05-31\n",
      "712918       2540000     24.30  2022-01-03  2022-05-31\n",
      "712919       2545000     23.40  2022-01-03  2022-05-31\n",
      "712920       2550000     22.60  2022-01-03  2022-05-31\n",
      "712921       2555000     21.80  2022-01-03  2022-05-31\n",
      "712922       2560000     21.10  2022-01-03  2022-05-31\n",
      "712923       2565000     20.40  2022-01-03  2022-05-31\n",
      "712924       2570000     19.70  2022-01-03  2022-05-31\n",
      "712925       2575000     19.00  2022-01-03  2022-05-31\n",
      "712926       2580000     18.30  2022-01-03  2022-05-31\n",
      "712927       2585000     17.70  2022-01-03  2022-05-31\n",
      "712928       2590000     17.10  2022-01-03  2022-05-31\n",
      "712929       2595000     16.50  2022-01-03  2022-05-31\n",
      "712930       2600000     15.90  2022-01-03  2022-05-31\n",
      "712931       2605000     15.30  2022-01-03  2022-05-31\n",
      "712932       2610000     14.80  2022-01-03  2022-05-31\n",
      "712933       2615000     14.30  2022-01-03  2022-05-31\n",
      "712934       2620000     13.80  2022-01-03  2022-05-31\n",
      "712935       2625000     13.30  2022-01-03  2022-05-31\n",
      "712936       2630000     12.90  2022-01-03  2022-05-31\n",
      "712937       2635000     12.40  2022-01-03  2022-05-31\n",
      "712938       2640000     12.00  2022-01-03  2022-05-31\n",
      "712939       2645000     11.60  2022-01-03  2022-05-31\n",
      "712940       2650000     11.20  2022-01-03  2022-05-31\n",
      "712941       2655000     10.80  2022-01-03  2022-05-31\n",
      "712942       2660000     10.40  2022-01-03  2022-05-31\n",
      "712943       2700000      7.90  2022-01-03  2022-05-31\n",
      "712944       2750000      5.60  2022-01-03  2022-05-31\n",
      "712945       2800000      4.00  2022-01-03  2022-05-31\n",
      "712946       2850000      2.95  2022-01-03  2022-05-31\n",
      "712947       2900000      2.20  2022-01-03  2022-05-31\n",
      "712948       2950000      1.65  2022-01-03  2022-05-31\n",
      "712949       3000000      1.20  2022-01-03  2022-05-31\n",
      "712950       3050000      0.90  2022-01-03  2022-05-31\n",
      "712951       3100000      0.70  2022-01-03  2022-05-31\n",
      "712952       3150000      0.50  2022-01-03  2022-05-31\n",
      "712953       3200000      0.40  2022-01-03  2022-05-31\n",
      "712954       3250000      0.30  2022-01-03  2022-05-31\n",
      "712955       3300000      0.25  2022-01-03  2022-05-31\n"
     ]
    }
   ],
   "source": [
    "with pd.option_context('display.max_rows', None, 'display.max_columns', None):  # more options can be specified also\n",
    "    print(sample[['strike_price', 'best_bid','date','exdate']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_14608\\3208580283.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  processed['strike_price'] = processed['strike_price'] / 1000\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_14608\\3208580283.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  processed['vol_high'] = processed.apply(lambda x: implied_vol_catch(x['best_offer'], S, x['strike_price'], T, R), axis=1)\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_14608\\3208580283.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  processed['vol_low'] = processed.apply(lambda x: implied_vol_catch(x['best_bid'], S, x['strike_price'], T, R), axis=1)\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_14608\\3208580283.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  processed['vol_mid'] = (processed['vol_high'] + processed['vol_low']) / 2\n"
     ]
    }
   ],
   "source": [
    "import pipeline\n",
    "import importlib\n",
    "from py_vollib.black_scholes.implied_volatility import implied_volatility\n",
    "\n",
    "importlib.reload(pipeline)\n",
    "R = r2\n",
    "S = 2640.25 # We take low price to avoid impl vol calc issues\n",
    "S = 2640.25\n",
    "R = 0.0056 # Rate for > 122 day\n",
    "F = 2266.349134 # for ID 102434, Exp date 05/31/2022\n",
    "T = 5 * 31 / 365\n",
    "S = F * np.exp(-R * T)\n",
    "def implied_vol_catch(P, S, k, T, r):\n",
    "    try:\n",
    "        vol = implied_volatility(P, S, k, T, r, 'c')\n",
    "    except:\n",
    "        return 0\n",
    "    return vol\n",
    "processed = sample[['strike_price', 'best_bid', 'best_offer', 'impl_volatility']]\n",
    "processed['strike_price'] = processed['strike_price'] / 1000\n",
    "processed['vol_high'] = processed.apply(lambda x: implied_vol_catch(x['best_offer'], S, x['strike_price'], T, R), axis=1)\n",
    "processed['vol_low'] = processed.apply(lambda x: implied_vol_catch(x['best_bid'], S, x['strike_price'], T, R), axis=1)\n",
    "processed['vol_mid'] = (processed['vol_high'] + processed['vol_low']) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_14608\\1751140811.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  processed2['strike_price'] = processed2['strike_price'] / 1000\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_14608\\1751140811.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  processed2['vol_high'] = processed2.apply(lambda x: implied_vol_catch(x['best_offer'], S, x['strike_price'], T, R), axis=1)\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_14608\\1751140811.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  processed2['vol_low'] = processed2.apply(lambda x: implied_vol_catch(x['best_bid'], S, x['strike_price'], T, R), axis=1)\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_14608\\1751140811.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  processed2['vol_mid'] = (processed2['vol_high'] + processed2['vol_low']) / 2\n"
     ]
    }
   ],
   "source": [
    "import pipeline\n",
    "import importlib\n",
    "from py_vollib.black_scholes.implied_volatility import implied_volatility\n",
    "\n",
    "importlib.reload(pipeline)\n",
    "R = 0.00518\n",
    "F = 2272.376330 # for ID 102434, Exp date 07/01/2022\n",
    "T = 4 / 365.0\n",
    "S = F * np.exp(-R * T)\n",
    "def implied_vol_catch(P, S, k, T, r):\n",
    "    try:\n",
    "        vol = implied_volatility(P, S, k, T, r, 'c')\n",
    "    except:\n",
    "        return 0\n",
    "    return vol\n",
    "processed2 = sample2[['strike_price', 'best_bid', 'best_offer', 'impl_volatility']]\n",
    "processed2['strike_price'] = processed2['strike_price'] / 1000\n",
    "processed2['vol_high'] = processed2.apply(lambda x: implied_vol_catch(x['best_offer'], S, x['strike_price'], T, R), axis=1)\n",
    "processed2['vol_low'] = processed2.apply(lambda x: implied_vol_catch(x['best_bid'], S, x['strike_price'], T, R), axis=1)\n",
    "processed2['vol_mid'] = (processed2['vol_high'] + processed2['vol_low']) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>strike_price</th>\n",
       "      <th>best_bid</th>\n",
       "      <th>best_offer</th>\n",
       "      <th>impl_volatility</th>\n",
       "      <th>vol_high</th>\n",
       "      <th>vol_low</th>\n",
       "      <th>vol_mid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>712753</th>\n",
       "      <td>1150.0</td>\n",
       "      <td>1114.90</td>\n",
       "      <td>1118.50</td>\n",
       "      <td>0.497858</td>\n",
       "      <td>0.524338</td>\n",
       "      <td>0.432651</td>\n",
       "      <td>0.478494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712754</th>\n",
       "      <td>1200.0</td>\n",
       "      <td>1065.70</td>\n",
       "      <td>1069.30</td>\n",
       "      <td>0.484312</td>\n",
       "      <td>0.505587</td>\n",
       "      <td>0.431583</td>\n",
       "      <td>0.468585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712755</th>\n",
       "      <td>1250.0</td>\n",
       "      <td>1016.60</td>\n",
       "      <td>1020.20</td>\n",
       "      <td>0.470510</td>\n",
       "      <td>0.487543</td>\n",
       "      <td>0.426303</td>\n",
       "      <td>0.456923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712756</th>\n",
       "      <td>1300.0</td>\n",
       "      <td>967.60</td>\n",
       "      <td>971.20</td>\n",
       "      <td>0.456367</td>\n",
       "      <td>0.469955</td>\n",
       "      <td>0.418380</td>\n",
       "      <td>0.444168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712757</th>\n",
       "      <td>1350.0</td>\n",
       "      <td>918.70</td>\n",
       "      <td>922.30</td>\n",
       "      <td>0.441848</td>\n",
       "      <td>0.452639</td>\n",
       "      <td>0.408614</td>\n",
       "      <td>0.430626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712758</th>\n",
       "      <td>1400.0</td>\n",
       "      <td>870.00</td>\n",
       "      <td>873.60</td>\n",
       "      <td>0.428009</td>\n",
       "      <td>0.436380</td>\n",
       "      <td>0.398690</td>\n",
       "      <td>0.417535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712759</th>\n",
       "      <td>1450.0</td>\n",
       "      <td>821.50</td>\n",
       "      <td>825.00</td>\n",
       "      <td>0.413965</td>\n",
       "      <td>0.419950</td>\n",
       "      <td>0.388319</td>\n",
       "      <td>0.404134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712760</th>\n",
       "      <td>1500.0</td>\n",
       "      <td>773.10</td>\n",
       "      <td>776.60</td>\n",
       "      <td>0.399613</td>\n",
       "      <td>0.404034</td>\n",
       "      <td>0.376498</td>\n",
       "      <td>0.390266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712761</th>\n",
       "      <td>1550.0</td>\n",
       "      <td>725.00</td>\n",
       "      <td>728.50</td>\n",
       "      <td>0.385942</td>\n",
       "      <td>0.389007</td>\n",
       "      <td>0.365020</td>\n",
       "      <td>0.377014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712762</th>\n",
       "      <td>1600.0</td>\n",
       "      <td>677.20</td>\n",
       "      <td>680.60</td>\n",
       "      <td>0.372217</td>\n",
       "      <td>0.373887</td>\n",
       "      <td>0.353486</td>\n",
       "      <td>0.363686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712763</th>\n",
       "      <td>1650.0</td>\n",
       "      <td>629.70</td>\n",
       "      <td>633.10</td>\n",
       "      <td>0.358785</td>\n",
       "      <td>0.359554</td>\n",
       "      <td>0.341641</td>\n",
       "      <td>0.350597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712764</th>\n",
       "      <td>1700.0</td>\n",
       "      <td>582.70</td>\n",
       "      <td>586.00</td>\n",
       "      <td>0.345795</td>\n",
       "      <td>0.345585</td>\n",
       "      <td>0.330286</td>\n",
       "      <td>0.337936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712765</th>\n",
       "      <td>1750.0</td>\n",
       "      <td>536.10</td>\n",
       "      <td>539.40</td>\n",
       "      <td>0.332848</td>\n",
       "      <td>0.332053</td>\n",
       "      <td>0.318532</td>\n",
       "      <td>0.325292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712766</th>\n",
       "      <td>1780.0</td>\n",
       "      <td>508.50</td>\n",
       "      <td>511.70</td>\n",
       "      <td>0.325341</td>\n",
       "      <td>0.324057</td>\n",
       "      <td>0.311871</td>\n",
       "      <td>0.317964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712767</th>\n",
       "      <td>1785.0</td>\n",
       "      <td>503.90</td>\n",
       "      <td>507.10</td>\n",
       "      <td>0.324044</td>\n",
       "      <td>0.322718</td>\n",
       "      <td>0.310674</td>\n",
       "      <td>0.316696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712768</th>\n",
       "      <td>1790.0</td>\n",
       "      <td>499.30</td>\n",
       "      <td>502.50</td>\n",
       "      <td>0.322725</td>\n",
       "      <td>0.321359</td>\n",
       "      <td>0.309455</td>\n",
       "      <td>0.315407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712769</th>\n",
       "      <td>1795.0</td>\n",
       "      <td>494.70</td>\n",
       "      <td>498.00</td>\n",
       "      <td>0.321572</td>\n",
       "      <td>0.320339</td>\n",
       "      <td>0.308213</td>\n",
       "      <td>0.314276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712770</th>\n",
       "      <td>1800.0</td>\n",
       "      <td>490.20</td>\n",
       "      <td>493.40</td>\n",
       "      <td>0.320394</td>\n",
       "      <td>0.318938</td>\n",
       "      <td>0.307321</td>\n",
       "      <td>0.313129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712771</th>\n",
       "      <td>1805.0</td>\n",
       "      <td>485.60</td>\n",
       "      <td>488.80</td>\n",
       "      <td>0.319007</td>\n",
       "      <td>0.317517</td>\n",
       "      <td>0.306031</td>\n",
       "      <td>0.311774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712772</th>\n",
       "      <td>1810.0</td>\n",
       "      <td>481.10</td>\n",
       "      <td>484.30</td>\n",
       "      <td>0.317962</td>\n",
       "      <td>0.316425</td>\n",
       "      <td>0.305082</td>\n",
       "      <td>0.310753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712773</th>\n",
       "      <td>1815.0</td>\n",
       "      <td>476.50</td>\n",
       "      <td>479.70</td>\n",
       "      <td>0.316531</td>\n",
       "      <td>0.314964</td>\n",
       "      <td>0.303745</td>\n",
       "      <td>0.309354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712774</th>\n",
       "      <td>1820.0</td>\n",
       "      <td>472.00</td>\n",
       "      <td>475.20</td>\n",
       "      <td>0.315435</td>\n",
       "      <td>0.313824</td>\n",
       "      <td>0.302742</td>\n",
       "      <td>0.308283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712775</th>\n",
       "      <td>1825.0</td>\n",
       "      <td>467.50</td>\n",
       "      <td>470.60</td>\n",
       "      <td>0.314136</td>\n",
       "      <td>0.312324</td>\n",
       "      <td>0.301710</td>\n",
       "      <td>0.307017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712776</th>\n",
       "      <td>1830.0</td>\n",
       "      <td>462.90</td>\n",
       "      <td>466.10</td>\n",
       "      <td>0.312814</td>\n",
       "      <td>0.311138</td>\n",
       "      <td>0.300305</td>\n",
       "      <td>0.305721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712777</th>\n",
       "      <td>1835.0</td>\n",
       "      <td>458.40</td>\n",
       "      <td>461.60</td>\n",
       "      <td>0.311641</td>\n",
       "      <td>0.309928</td>\n",
       "      <td>0.299222</td>\n",
       "      <td>0.304575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712778</th>\n",
       "      <td>1840.0</td>\n",
       "      <td>453.90</td>\n",
       "      <td>457.10</td>\n",
       "      <td>0.310442</td>\n",
       "      <td>0.308695</td>\n",
       "      <td>0.298112</td>\n",
       "      <td>0.303403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712779</th>\n",
       "      <td>1845.0</td>\n",
       "      <td>449.40</td>\n",
       "      <td>452.60</td>\n",
       "      <td>0.309218</td>\n",
       "      <td>0.307438</td>\n",
       "      <td>0.296975</td>\n",
       "      <td>0.302206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712780</th>\n",
       "      <td>1850.0</td>\n",
       "      <td>444.90</td>\n",
       "      <td>448.10</td>\n",
       "      <td>0.307968</td>\n",
       "      <td>0.306157</td>\n",
       "      <td>0.295813</td>\n",
       "      <td>0.300985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712781</th>\n",
       "      <td>1855.0</td>\n",
       "      <td>440.50</td>\n",
       "      <td>443.60</td>\n",
       "      <td>0.306858</td>\n",
       "      <td>0.304855</td>\n",
       "      <td>0.294951</td>\n",
       "      <td>0.299903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712782</th>\n",
       "      <td>1860.0</td>\n",
       "      <td>436.00</td>\n",
       "      <td>439.10</td>\n",
       "      <td>0.305558</td>\n",
       "      <td>0.303530</td>\n",
       "      <td>0.293734</td>\n",
       "      <td>0.298632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712783</th>\n",
       "      <td>1865.0</td>\n",
       "      <td>431.50</td>\n",
       "      <td>434.60</td>\n",
       "      <td>0.304234</td>\n",
       "      <td>0.302182</td>\n",
       "      <td>0.292494</td>\n",
       "      <td>0.297338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712784</th>\n",
       "      <td>1870.0</td>\n",
       "      <td>427.10</td>\n",
       "      <td>430.20</td>\n",
       "      <td>0.303204</td>\n",
       "      <td>0.301118</td>\n",
       "      <td>0.291543</td>\n",
       "      <td>0.296330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712785</th>\n",
       "      <td>1875.0</td>\n",
       "      <td>422.60</td>\n",
       "      <td>425.70</td>\n",
       "      <td>0.301830</td>\n",
       "      <td>0.299724</td>\n",
       "      <td>0.290251</td>\n",
       "      <td>0.294988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712786</th>\n",
       "      <td>1880.0</td>\n",
       "      <td>418.20</td>\n",
       "      <td>421.30</td>\n",
       "      <td>0.300743</td>\n",
       "      <td>0.298608</td>\n",
       "      <td>0.289243</td>\n",
       "      <td>0.293925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712787</th>\n",
       "      <td>1885.0</td>\n",
       "      <td>413.80</td>\n",
       "      <td>416.80</td>\n",
       "      <td>0.299475</td>\n",
       "      <td>0.297170</td>\n",
       "      <td>0.288205</td>\n",
       "      <td>0.292687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712788</th>\n",
       "      <td>1890.0</td>\n",
       "      <td>409.40</td>\n",
       "      <td>412.40</td>\n",
       "      <td>0.298332</td>\n",
       "      <td>0.296003</td>\n",
       "      <td>0.287138</td>\n",
       "      <td>0.291570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712789</th>\n",
       "      <td>1895.0</td>\n",
       "      <td>405.00</td>\n",
       "      <td>408.00</td>\n",
       "      <td>0.297162</td>\n",
       "      <td>0.294809</td>\n",
       "      <td>0.286042</td>\n",
       "      <td>0.290426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712790</th>\n",
       "      <td>1900.0</td>\n",
       "      <td>400.60</td>\n",
       "      <td>403.60</td>\n",
       "      <td>0.295963</td>\n",
       "      <td>0.293590</td>\n",
       "      <td>0.284918</td>\n",
       "      <td>0.289254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712791</th>\n",
       "      <td>1905.0</td>\n",
       "      <td>396.20</td>\n",
       "      <td>399.20</td>\n",
       "      <td>0.294738</td>\n",
       "      <td>0.292346</td>\n",
       "      <td>0.283766</td>\n",
       "      <td>0.288056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712792</th>\n",
       "      <td>1910.0</td>\n",
       "      <td>391.80</td>\n",
       "      <td>394.80</td>\n",
       "      <td>0.293486</td>\n",
       "      <td>0.291077</td>\n",
       "      <td>0.282588</td>\n",
       "      <td>0.286832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712793</th>\n",
       "      <td>1915.0</td>\n",
       "      <td>387.50</td>\n",
       "      <td>390.50</td>\n",
       "      <td>0.292494</td>\n",
       "      <td>0.290059</td>\n",
       "      <td>0.281665</td>\n",
       "      <td>0.285862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712794</th>\n",
       "      <td>1920.0</td>\n",
       "      <td>383.10</td>\n",
       "      <td>386.10</td>\n",
       "      <td>0.291186</td>\n",
       "      <td>0.288738</td>\n",
       "      <td>0.280430</td>\n",
       "      <td>0.284584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712795</th>\n",
       "      <td>1925.0</td>\n",
       "      <td>378.80</td>\n",
       "      <td>381.70</td>\n",
       "      <td>0.289994</td>\n",
       "      <td>0.287392</td>\n",
       "      <td>0.279446</td>\n",
       "      <td>0.283419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712796</th>\n",
       "      <td>1930.0</td>\n",
       "      <td>374.40</td>\n",
       "      <td>377.40</td>\n",
       "      <td>0.288773</td>\n",
       "      <td>0.286291</td>\n",
       "      <td>0.278157</td>\n",
       "      <td>0.282224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712797</th>\n",
       "      <td>1935.0</td>\n",
       "      <td>370.10</td>\n",
       "      <td>373.10</td>\n",
       "      <td>0.287661</td>\n",
       "      <td>0.285162</td>\n",
       "      <td>0.277114</td>\n",
       "      <td>0.281138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712798</th>\n",
       "      <td>1940.0</td>\n",
       "      <td>365.80</td>\n",
       "      <td>368.80</td>\n",
       "      <td>0.286520</td>\n",
       "      <td>0.284004</td>\n",
       "      <td>0.276040</td>\n",
       "      <td>0.280022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712799</th>\n",
       "      <td>1945.0</td>\n",
       "      <td>361.50</td>\n",
       "      <td>364.40</td>\n",
       "      <td>0.285214</td>\n",
       "      <td>0.282558</td>\n",
       "      <td>0.274936</td>\n",
       "      <td>0.278747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712800</th>\n",
       "      <td>1950.0</td>\n",
       "      <td>357.20</td>\n",
       "      <td>360.20</td>\n",
       "      <td>0.284148</td>\n",
       "      <td>0.281604</td>\n",
       "      <td>0.273802</td>\n",
       "      <td>0.277703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712801</th>\n",
       "      <td>1955.0</td>\n",
       "      <td>353.00</td>\n",
       "      <td>355.90</td>\n",
       "      <td>0.283051</td>\n",
       "      <td>0.280363</td>\n",
       "      <td>0.272899</td>\n",
       "      <td>0.276631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712802</th>\n",
       "      <td>1960.0</td>\n",
       "      <td>348.70</td>\n",
       "      <td>351.60</td>\n",
       "      <td>0.281792</td>\n",
       "      <td>0.279095</td>\n",
       "      <td>0.271705</td>\n",
       "      <td>0.275400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712803</th>\n",
       "      <td>1965.0</td>\n",
       "      <td>344.50</td>\n",
       "      <td>347.30</td>\n",
       "      <td>0.280634</td>\n",
       "      <td>0.277801</td>\n",
       "      <td>0.270737</td>\n",
       "      <td>0.274269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712804</th>\n",
       "      <td>1970.0</td>\n",
       "      <td>340.20</td>\n",
       "      <td>343.10</td>\n",
       "      <td>0.279445</td>\n",
       "      <td>0.276728</td>\n",
       "      <td>0.269484</td>\n",
       "      <td>0.273106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712805</th>\n",
       "      <td>1975.0</td>\n",
       "      <td>336.00</td>\n",
       "      <td>338.90</td>\n",
       "      <td>0.278353</td>\n",
       "      <td>0.275624</td>\n",
       "      <td>0.268452</td>\n",
       "      <td>0.272038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712806</th>\n",
       "      <td>1980.0</td>\n",
       "      <td>331.80</td>\n",
       "      <td>334.70</td>\n",
       "      <td>0.277229</td>\n",
       "      <td>0.274490</td>\n",
       "      <td>0.267389</td>\n",
       "      <td>0.270939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712807</th>\n",
       "      <td>1985.0</td>\n",
       "      <td>327.60</td>\n",
       "      <td>330.50</td>\n",
       "      <td>0.276074</td>\n",
       "      <td>0.273326</td>\n",
       "      <td>0.266294</td>\n",
       "      <td>0.269810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712808</th>\n",
       "      <td>1990.0</td>\n",
       "      <td>323.40</td>\n",
       "      <td>326.30</td>\n",
       "      <td>0.274887</td>\n",
       "      <td>0.272132</td>\n",
       "      <td>0.265167</td>\n",
       "      <td>0.268649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712809</th>\n",
       "      <td>1995.0</td>\n",
       "      <td>319.30</td>\n",
       "      <td>322.10</td>\n",
       "      <td>0.273791</td>\n",
       "      <td>0.270908</td>\n",
       "      <td>0.264249</td>\n",
       "      <td>0.267579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712810</th>\n",
       "      <td>2000.0</td>\n",
       "      <td>315.10</td>\n",
       "      <td>317.90</td>\n",
       "      <td>0.272542</td>\n",
       "      <td>0.269656</td>\n",
       "      <td>0.263059</td>\n",
       "      <td>0.266357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712811</th>\n",
       "      <td>2005.0</td>\n",
       "      <td>311.00</td>\n",
       "      <td>313.80</td>\n",
       "      <td>0.271502</td>\n",
       "      <td>0.268607</td>\n",
       "      <td>0.262073</td>\n",
       "      <td>0.265340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712812</th>\n",
       "      <td>2010.0</td>\n",
       "      <td>306.90</td>\n",
       "      <td>309.60</td>\n",
       "      <td>0.270309</td>\n",
       "      <td>0.267296</td>\n",
       "      <td>0.261053</td>\n",
       "      <td>0.264174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712813</th>\n",
       "      <td>2015.0</td>\n",
       "      <td>302.80</td>\n",
       "      <td>305.50</td>\n",
       "      <td>0.269201</td>\n",
       "      <td>0.266184</td>\n",
       "      <td>0.259999</td>\n",
       "      <td>0.263091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712814</th>\n",
       "      <td>2020.0</td>\n",
       "      <td>298.70</td>\n",
       "      <td>301.40</td>\n",
       "      <td>0.268060</td>\n",
       "      <td>0.265040</td>\n",
       "      <td>0.258911</td>\n",
       "      <td>0.261976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712815</th>\n",
       "      <td>2025.0</td>\n",
       "      <td>294.60</td>\n",
       "      <td>297.30</td>\n",
       "      <td>0.266886</td>\n",
       "      <td>0.263865</td>\n",
       "      <td>0.257791</td>\n",
       "      <td>0.260828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712816</th>\n",
       "      <td>2030.0</td>\n",
       "      <td>290.60</td>\n",
       "      <td>293.30</td>\n",
       "      <td>0.265908</td>\n",
       "      <td>0.262880</td>\n",
       "      <td>0.256862</td>\n",
       "      <td>0.259871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712817</th>\n",
       "      <td>2035.0</td>\n",
       "      <td>286.50</td>\n",
       "      <td>289.20</td>\n",
       "      <td>0.264666</td>\n",
       "      <td>0.261640</td>\n",
       "      <td>0.255674</td>\n",
       "      <td>0.258657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712818</th>\n",
       "      <td>2040.0</td>\n",
       "      <td>282.50</td>\n",
       "      <td>285.20</td>\n",
       "      <td>0.263617</td>\n",
       "      <td>0.260588</td>\n",
       "      <td>0.254675</td>\n",
       "      <td>0.257632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712819</th>\n",
       "      <td>2045.0</td>\n",
       "      <td>278.50</td>\n",
       "      <td>281.10</td>\n",
       "      <td>0.262421</td>\n",
       "      <td>0.259285</td>\n",
       "      <td>0.253640</td>\n",
       "      <td>0.256463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712820</th>\n",
       "      <td>2050.0</td>\n",
       "      <td>274.50</td>\n",
       "      <td>277.10</td>\n",
       "      <td>0.261302</td>\n",
       "      <td>0.258167</td>\n",
       "      <td>0.252569</td>\n",
       "      <td>0.255368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712821</th>\n",
       "      <td>2055.0</td>\n",
       "      <td>270.50</td>\n",
       "      <td>273.20</td>\n",
       "      <td>0.260256</td>\n",
       "      <td>0.257227</td>\n",
       "      <td>0.251464</td>\n",
       "      <td>0.254346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712822</th>\n",
       "      <td>2060.0</td>\n",
       "      <td>266.60</td>\n",
       "      <td>269.20</td>\n",
       "      <td>0.259175</td>\n",
       "      <td>0.256040</td>\n",
       "      <td>0.250537</td>\n",
       "      <td>0.253289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712823</th>\n",
       "      <td>2065.0</td>\n",
       "      <td>262.60</td>\n",
       "      <td>265.20</td>\n",
       "      <td>0.257949</td>\n",
       "      <td>0.254820</td>\n",
       "      <td>0.249361</td>\n",
       "      <td>0.252090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712824</th>\n",
       "      <td>2070.0</td>\n",
       "      <td>258.70</td>\n",
       "      <td>261.30</td>\n",
       "      <td>0.256903</td>\n",
       "      <td>0.253774</td>\n",
       "      <td>0.248360</td>\n",
       "      <td>0.251067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712825</th>\n",
       "      <td>2075.0</td>\n",
       "      <td>254.80</td>\n",
       "      <td>257.40</td>\n",
       "      <td>0.255819</td>\n",
       "      <td>0.252693</td>\n",
       "      <td>0.247323</td>\n",
       "      <td>0.250008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712826</th>\n",
       "      <td>2080.0</td>\n",
       "      <td>250.90</td>\n",
       "      <td>253.50</td>\n",
       "      <td>0.254698</td>\n",
       "      <td>0.251576</td>\n",
       "      <td>0.246248</td>\n",
       "      <td>0.248912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712827</th>\n",
       "      <td>2085.0</td>\n",
       "      <td>247.10</td>\n",
       "      <td>249.60</td>\n",
       "      <td>0.253645</td>\n",
       "      <td>0.250424</td>\n",
       "      <td>0.245341</td>\n",
       "      <td>0.247882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712828</th>\n",
       "      <td>2090.0</td>\n",
       "      <td>243.20</td>\n",
       "      <td>245.80</td>\n",
       "      <td>0.252553</td>\n",
       "      <td>0.249438</td>\n",
       "      <td>0.244192</td>\n",
       "      <td>0.246815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712829</th>\n",
       "      <td>2095.0</td>\n",
       "      <td>239.40</td>\n",
       "      <td>241.90</td>\n",
       "      <td>0.251424</td>\n",
       "      <td>0.248214</td>\n",
       "      <td>0.243208</td>\n",
       "      <td>0.245711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712830</th>\n",
       "      <td>2100.0</td>\n",
       "      <td>235.60</td>\n",
       "      <td>238.10</td>\n",
       "      <td>0.250358</td>\n",
       "      <td>0.247154</td>\n",
       "      <td>0.242185</td>\n",
       "      <td>0.244669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712831</th>\n",
       "      <td>2105.0</td>\n",
       "      <td>231.90</td>\n",
       "      <td>234.30</td>\n",
       "      <td>0.249355</td>\n",
       "      <td>0.246056</td>\n",
       "      <td>0.241321</td>\n",
       "      <td>0.243689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712832</th>\n",
       "      <td>2110.0</td>\n",
       "      <td>228.10</td>\n",
       "      <td>230.50</td>\n",
       "      <td>0.248212</td>\n",
       "      <td>0.244922</td>\n",
       "      <td>0.240220</td>\n",
       "      <td>0.242571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712833</th>\n",
       "      <td>2115.0</td>\n",
       "      <td>224.40</td>\n",
       "      <td>226.80</td>\n",
       "      <td>0.247229</td>\n",
       "      <td>0.243945</td>\n",
       "      <td>0.239276</td>\n",
       "      <td>0.241610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712834</th>\n",
       "      <td>2120.0</td>\n",
       "      <td>220.70</td>\n",
       "      <td>223.10</td>\n",
       "      <td>0.246206</td>\n",
       "      <td>0.242928</td>\n",
       "      <td>0.238291</td>\n",
       "      <td>0.240609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712835</th>\n",
       "      <td>2125.0</td>\n",
       "      <td>217.00</td>\n",
       "      <td>219.40</td>\n",
       "      <td>0.245142</td>\n",
       "      <td>0.241872</td>\n",
       "      <td>0.237266</td>\n",
       "      <td>0.239569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712836</th>\n",
       "      <td>2130.0</td>\n",
       "      <td>213.30</td>\n",
       "      <td>215.70</td>\n",
       "      <td>0.244037</td>\n",
       "      <td>0.240777</td>\n",
       "      <td>0.236202</td>\n",
       "      <td>0.238489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712837</th>\n",
       "      <td>2135.0</td>\n",
       "      <td>209.70</td>\n",
       "      <td>212.00</td>\n",
       "      <td>0.242989</td>\n",
       "      <td>0.239643</td>\n",
       "      <td>0.235287</td>\n",
       "      <td>0.237465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712838</th>\n",
       "      <td>2140.0</td>\n",
       "      <td>206.00</td>\n",
       "      <td>208.40</td>\n",
       "      <td>0.241900</td>\n",
       "      <td>0.238658</td>\n",
       "      <td>0.234141</td>\n",
       "      <td>0.236399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712839</th>\n",
       "      <td>2145.0</td>\n",
       "      <td>202.40</td>\n",
       "      <td>204.80</td>\n",
       "      <td>0.240865</td>\n",
       "      <td>0.237632</td>\n",
       "      <td>0.233143</td>\n",
       "      <td>0.235388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712840</th>\n",
       "      <td>2150.0</td>\n",
       "      <td>198.90</td>\n",
       "      <td>201.20</td>\n",
       "      <td>0.239883</td>\n",
       "      <td>0.236566</td>\n",
       "      <td>0.232290</td>\n",
       "      <td>0.234428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712841</th>\n",
       "      <td>2155.0</td>\n",
       "      <td>195.30</td>\n",
       "      <td>197.60</td>\n",
       "      <td>0.238763</td>\n",
       "      <td>0.235459</td>\n",
       "      <td>0.231207</td>\n",
       "      <td>0.233333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712842</th>\n",
       "      <td>2160.0</td>\n",
       "      <td>191.80</td>\n",
       "      <td>194.10</td>\n",
       "      <td>0.237789</td>\n",
       "      <td>0.234495</td>\n",
       "      <td>0.230268</td>\n",
       "      <td>0.232381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712843</th>\n",
       "      <td>2165.0</td>\n",
       "      <td>188.30</td>\n",
       "      <td>190.60</td>\n",
       "      <td>0.236772</td>\n",
       "      <td>0.233488</td>\n",
       "      <td>0.229284</td>\n",
       "      <td>0.231386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712844</th>\n",
       "      <td>2170.0</td>\n",
       "      <td>184.90</td>\n",
       "      <td>187.10</td>\n",
       "      <td>0.235803</td>\n",
       "      <td>0.232439</td>\n",
       "      <td>0.228440</td>\n",
       "      <td>0.230440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712845</th>\n",
       "      <td>2175.0</td>\n",
       "      <td>181.40</td>\n",
       "      <td>183.60</td>\n",
       "      <td>0.234697</td>\n",
       "      <td>0.231348</td>\n",
       "      <td>0.227369</td>\n",
       "      <td>0.229358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712846</th>\n",
       "      <td>2180.0</td>\n",
       "      <td>178.00</td>\n",
       "      <td>180.20</td>\n",
       "      <td>0.233732</td>\n",
       "      <td>0.230394</td>\n",
       "      <td>0.226435</td>\n",
       "      <td>0.228415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712847</th>\n",
       "      <td>2185.0</td>\n",
       "      <td>174.60</td>\n",
       "      <td>176.80</td>\n",
       "      <td>0.232721</td>\n",
       "      <td>0.229396</td>\n",
       "      <td>0.225456</td>\n",
       "      <td>0.227426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712848</th>\n",
       "      <td>2190.0</td>\n",
       "      <td>171.30</td>\n",
       "      <td>173.40</td>\n",
       "      <td>0.231756</td>\n",
       "      <td>0.228355</td>\n",
       "      <td>0.224611</td>\n",
       "      <td>0.226483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712849</th>\n",
       "      <td>2195.0</td>\n",
       "      <td>167.90</td>\n",
       "      <td>170.10</td>\n",
       "      <td>0.230744</td>\n",
       "      <td>0.227446</td>\n",
       "      <td>0.223541</td>\n",
       "      <td>0.225494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712850</th>\n",
       "      <td>2200.0</td>\n",
       "      <td>164.60</td>\n",
       "      <td>166.80</td>\n",
       "      <td>0.229777</td>\n",
       "      <td>0.226492</td>\n",
       "      <td>0.222604</td>\n",
       "      <td>0.224548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712851</th>\n",
       "      <td>2205.0</td>\n",
       "      <td>161.40</td>\n",
       "      <td>163.50</td>\n",
       "      <td>0.228852</td>\n",
       "      <td>0.225492</td>\n",
       "      <td>0.221796</td>\n",
       "      <td>0.223644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712852</th>\n",
       "      <td>2210.0</td>\n",
       "      <td>158.10</td>\n",
       "      <td>160.20</td>\n",
       "      <td>0.227790</td>\n",
       "      <td>0.224447</td>\n",
       "      <td>0.220765</td>\n",
       "      <td>0.222606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712853</th>\n",
       "      <td>2215.0</td>\n",
       "      <td>154.90</td>\n",
       "      <td>157.00</td>\n",
       "      <td>0.226859</td>\n",
       "      <td>0.223531</td>\n",
       "      <td>0.219862</td>\n",
       "      <td>0.221696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712854</th>\n",
       "      <td>2220.0</td>\n",
       "      <td>151.70</td>\n",
       "      <td>153.80</td>\n",
       "      <td>0.225880</td>\n",
       "      <td>0.222567</td>\n",
       "      <td>0.218911</td>\n",
       "      <td>0.220739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712855</th>\n",
       "      <td>2225.0</td>\n",
       "      <td>148.60</td>\n",
       "      <td>150.60</td>\n",
       "      <td>0.224941</td>\n",
       "      <td>0.221557</td>\n",
       "      <td>0.218085</td>\n",
       "      <td>0.219821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712856</th>\n",
       "      <td>2230.0</td>\n",
       "      <td>145.50</td>\n",
       "      <td>147.50</td>\n",
       "      <td>0.224042</td>\n",
       "      <td>0.220672</td>\n",
       "      <td>0.217211</td>\n",
       "      <td>0.218942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712857</th>\n",
       "      <td>2235.0</td>\n",
       "      <td>142.40</td>\n",
       "      <td>144.40</td>\n",
       "      <td>0.223092</td>\n",
       "      <td>0.219739</td>\n",
       "      <td>0.216287</td>\n",
       "      <td>0.218013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712858</th>\n",
       "      <td>2240.0</td>\n",
       "      <td>139.30</td>\n",
       "      <td>141.30</td>\n",
       "      <td>0.222092</td>\n",
       "      <td>0.218757</td>\n",
       "      <td>0.215314</td>\n",
       "      <td>0.217036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712859</th>\n",
       "      <td>2245.0</td>\n",
       "      <td>136.30</td>\n",
       "      <td>138.30</td>\n",
       "      <td>0.221217</td>\n",
       "      <td>0.217898</td>\n",
       "      <td>0.214463</td>\n",
       "      <td>0.216181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712860</th>\n",
       "      <td>2250.0</td>\n",
       "      <td>133.30</td>\n",
       "      <td>135.30</td>\n",
       "      <td>0.220292</td>\n",
       "      <td>0.216989</td>\n",
       "      <td>0.213561</td>\n",
       "      <td>0.215275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712861</th>\n",
       "      <td>2255.0</td>\n",
       "      <td>130.40</td>\n",
       "      <td>132.30</td>\n",
       "      <td>0.219401</td>\n",
       "      <td>0.216031</td>\n",
       "      <td>0.212780</td>\n",
       "      <td>0.214405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712862</th>\n",
       "      <td>2260.0</td>\n",
       "      <td>127.50</td>\n",
       "      <td>129.40</td>\n",
       "      <td>0.218547</td>\n",
       "      <td>0.215192</td>\n",
       "      <td>0.211947</td>\n",
       "      <td>0.213570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712863</th>\n",
       "      <td>2265.0</td>\n",
       "      <td>124.60</td>\n",
       "      <td>126.50</td>\n",
       "      <td>0.217639</td>\n",
       "      <td>0.214303</td>\n",
       "      <td>0.211062</td>\n",
       "      <td>0.212683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712864</th>\n",
       "      <td>2270.0</td>\n",
       "      <td>121.70</td>\n",
       "      <td>123.40</td>\n",
       "      <td>0.216504</td>\n",
       "      <td>0.213022</td>\n",
       "      <td>0.210125</td>\n",
       "      <td>0.211573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712865</th>\n",
       "      <td>2275.0</td>\n",
       "      <td>118.90</td>\n",
       "      <td>120.60</td>\n",
       "      <td>0.215665</td>\n",
       "      <td>0.212200</td>\n",
       "      <td>0.209305</td>\n",
       "      <td>0.210752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712866</th>\n",
       "      <td>2280.0</td>\n",
       "      <td>116.20</td>\n",
       "      <td>117.80</td>\n",
       "      <td>0.214858</td>\n",
       "      <td>0.211325</td>\n",
       "      <td>0.208603</td>\n",
       "      <td>0.209964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712867</th>\n",
       "      <td>2285.0</td>\n",
       "      <td>113.40</td>\n",
       "      <td>115.10</td>\n",
       "      <td>0.213997</td>\n",
       "      <td>0.210568</td>\n",
       "      <td>0.207676</td>\n",
       "      <td>0.209122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712868</th>\n",
       "      <td>2290.0</td>\n",
       "      <td>110.70</td>\n",
       "      <td>112.40</td>\n",
       "      <td>0.213168</td>\n",
       "      <td>0.209758</td>\n",
       "      <td>0.206866</td>\n",
       "      <td>0.208312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712869</th>\n",
       "      <td>2295.0</td>\n",
       "      <td>108.00</td>\n",
       "      <td>109.70</td>\n",
       "      <td>0.212284</td>\n",
       "      <td>0.208894</td>\n",
       "      <td>0.206001</td>\n",
       "      <td>0.207447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712870</th>\n",
       "      <td>2300.0</td>\n",
       "      <td>105.40</td>\n",
       "      <td>107.10</td>\n",
       "      <td>0.211517</td>\n",
       "      <td>0.208146</td>\n",
       "      <td>0.205251</td>\n",
       "      <td>0.206698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712871</th>\n",
       "      <td>2305.0</td>\n",
       "      <td>102.80</td>\n",
       "      <td>104.50</td>\n",
       "      <td>0.210695</td>\n",
       "      <td>0.207343</td>\n",
       "      <td>0.204446</td>\n",
       "      <td>0.205894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712872</th>\n",
       "      <td>2310.0</td>\n",
       "      <td>100.30</td>\n",
       "      <td>101.90</td>\n",
       "      <td>0.209903</td>\n",
       "      <td>0.206485</td>\n",
       "      <td>0.203756</td>\n",
       "      <td>0.205121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712873</th>\n",
       "      <td>2315.0</td>\n",
       "      <td>97.80</td>\n",
       "      <td>99.40</td>\n",
       "      <td>0.209142</td>\n",
       "      <td>0.205743</td>\n",
       "      <td>0.203009</td>\n",
       "      <td>0.204376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712874</th>\n",
       "      <td>2320.0</td>\n",
       "      <td>95.30</td>\n",
       "      <td>96.90</td>\n",
       "      <td>0.208323</td>\n",
       "      <td>0.204945</td>\n",
       "      <td>0.202206</td>\n",
       "      <td>0.203576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712875</th>\n",
       "      <td>2325.0</td>\n",
       "      <td>92.80</td>\n",
       "      <td>94.50</td>\n",
       "      <td>0.207534</td>\n",
       "      <td>0.204262</td>\n",
       "      <td>0.201346</td>\n",
       "      <td>0.202804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712876</th>\n",
       "      <td>2330.0</td>\n",
       "      <td>90.40</td>\n",
       "      <td>92.10</td>\n",
       "      <td>0.206774</td>\n",
       "      <td>0.203523</td>\n",
       "      <td>0.200600</td>\n",
       "      <td>0.202061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712877</th>\n",
       "      <td>2335.0</td>\n",
       "      <td>88.10</td>\n",
       "      <td>89.70</td>\n",
       "      <td>0.206043</td>\n",
       "      <td>0.202726</td>\n",
       "      <td>0.199968</td>\n",
       "      <td>0.201347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712878</th>\n",
       "      <td>2340.0</td>\n",
       "      <td>85.80</td>\n",
       "      <td>87.40</td>\n",
       "      <td>0.205343</td>\n",
       "      <td>0.202045</td>\n",
       "      <td>0.199279</td>\n",
       "      <td>0.200662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712879</th>\n",
       "      <td>2345.0</td>\n",
       "      <td>83.50</td>\n",
       "      <td>85.10</td>\n",
       "      <td>0.204582</td>\n",
       "      <td>0.201307</td>\n",
       "      <td>0.198531</td>\n",
       "      <td>0.199919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712880</th>\n",
       "      <td>2350.0</td>\n",
       "      <td>81.20</td>\n",
       "      <td>82.80</td>\n",
       "      <td>0.203762</td>\n",
       "      <td>0.200510</td>\n",
       "      <td>0.197725</td>\n",
       "      <td>0.199117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712881</th>\n",
       "      <td>2355.0</td>\n",
       "      <td>79.00</td>\n",
       "      <td>80.60</td>\n",
       "      <td>0.203060</td>\n",
       "      <td>0.199829</td>\n",
       "      <td>0.197032</td>\n",
       "      <td>0.198431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712882</th>\n",
       "      <td>2360.0</td>\n",
       "      <td>76.90</td>\n",
       "      <td>78.40</td>\n",
       "      <td>0.202386</td>\n",
       "      <td>0.199089</td>\n",
       "      <td>0.196456</td>\n",
       "      <td>0.197772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712883</th>\n",
       "      <td>2365.0</td>\n",
       "      <td>74.70</td>\n",
       "      <td>76.20</td>\n",
       "      <td>0.201562</td>\n",
       "      <td>0.198289</td>\n",
       "      <td>0.195644</td>\n",
       "      <td>0.196967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712884</th>\n",
       "      <td>2370.0</td>\n",
       "      <td>72.60</td>\n",
       "      <td>74.10</td>\n",
       "      <td>0.200857</td>\n",
       "      <td>0.197606</td>\n",
       "      <td>0.194948</td>\n",
       "      <td>0.196277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712885</th>\n",
       "      <td>2375.0</td>\n",
       "      <td>70.60</td>\n",
       "      <td>72.10</td>\n",
       "      <td>0.200272</td>\n",
       "      <td>0.197041</td>\n",
       "      <td>0.194369</td>\n",
       "      <td>0.195705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712886</th>\n",
       "      <td>2380.0</td>\n",
       "      <td>68.60</td>\n",
       "      <td>70.10</td>\n",
       "      <td>0.199626</td>\n",
       "      <td>0.196417</td>\n",
       "      <td>0.193730</td>\n",
       "      <td>0.195074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712887</th>\n",
       "      <td>2385.0</td>\n",
       "      <td>66.60</td>\n",
       "      <td>68.10</td>\n",
       "      <td>0.198917</td>\n",
       "      <td>0.195733</td>\n",
       "      <td>0.193030</td>\n",
       "      <td>0.194381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712888</th>\n",
       "      <td>2390.0</td>\n",
       "      <td>64.70</td>\n",
       "      <td>66.10</td>\n",
       "      <td>0.198239</td>\n",
       "      <td>0.194988</td>\n",
       "      <td>0.192448</td>\n",
       "      <td>0.193718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712889</th>\n",
       "      <td>2395.0</td>\n",
       "      <td>62.80</td>\n",
       "      <td>64.20</td>\n",
       "      <td>0.197590</td>\n",
       "      <td>0.194362</td>\n",
       "      <td>0.191806</td>\n",
       "      <td>0.193084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712890</th>\n",
       "      <td>2400.0</td>\n",
       "      <td>61.00</td>\n",
       "      <td>62.40</td>\n",
       "      <td>0.197067</td>\n",
       "      <td>0.193859</td>\n",
       "      <td>0.191285</td>\n",
       "      <td>0.192572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712891</th>\n",
       "      <td>2405.0</td>\n",
       "      <td>59.20</td>\n",
       "      <td>60.60</td>\n",
       "      <td>0.196481</td>\n",
       "      <td>0.193296</td>\n",
       "      <td>0.190703</td>\n",
       "      <td>0.192000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712892</th>\n",
       "      <td>2410.0</td>\n",
       "      <td>57.40</td>\n",
       "      <td>58.80</td>\n",
       "      <td>0.195832</td>\n",
       "      <td>0.192672</td>\n",
       "      <td>0.190059</td>\n",
       "      <td>0.191366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712893</th>\n",
       "      <td>2415.0</td>\n",
       "      <td>55.70</td>\n",
       "      <td>57.00</td>\n",
       "      <td>0.195215</td>\n",
       "      <td>0.191986</td>\n",
       "      <td>0.189540</td>\n",
       "      <td>0.190763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712894</th>\n",
       "      <td>2420.0</td>\n",
       "      <td>54.00</td>\n",
       "      <td>55.30</td>\n",
       "      <td>0.194631</td>\n",
       "      <td>0.191425</td>\n",
       "      <td>0.188958</td>\n",
       "      <td>0.190191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712895</th>\n",
       "      <td>2425.0</td>\n",
       "      <td>52.30</td>\n",
       "      <td>53.70</td>\n",
       "      <td>0.194080</td>\n",
       "      <td>0.190993</td>\n",
       "      <td>0.188313</td>\n",
       "      <td>0.189653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712896</th>\n",
       "      <td>2430.0</td>\n",
       "      <td>50.70</td>\n",
       "      <td>52.00</td>\n",
       "      <td>0.193466</td>\n",
       "      <td>0.190308</td>\n",
       "      <td>0.187796</td>\n",
       "      <td>0.189052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712897</th>\n",
       "      <td>2435.0</td>\n",
       "      <td>49.10</td>\n",
       "      <td>50.40</td>\n",
       "      <td>0.192885</td>\n",
       "      <td>0.189753</td>\n",
       "      <td>0.187217</td>\n",
       "      <td>0.188485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712898</th>\n",
       "      <td>2440.0</td>\n",
       "      <td>47.60</td>\n",
       "      <td>48.90</td>\n",
       "      <td>0.192441</td>\n",
       "      <td>0.189331</td>\n",
       "      <td>0.186771</td>\n",
       "      <td>0.188051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712899</th>\n",
       "      <td>2445.0</td>\n",
       "      <td>46.10</td>\n",
       "      <td>47.40</td>\n",
       "      <td>0.191935</td>\n",
       "      <td>0.188849</td>\n",
       "      <td>0.186262</td>\n",
       "      <td>0.187555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712900</th>\n",
       "      <td>2450.0</td>\n",
       "      <td>44.70</td>\n",
       "      <td>45.80</td>\n",
       "      <td>0.191363</td>\n",
       "      <td>0.188103</td>\n",
       "      <td>0.185891</td>\n",
       "      <td>0.186997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712901</th>\n",
       "      <td>2455.0</td>\n",
       "      <td>43.20</td>\n",
       "      <td>44.40</td>\n",
       "      <td>0.190830</td>\n",
       "      <td>0.187695</td>\n",
       "      <td>0.185255</td>\n",
       "      <td>0.186475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712902</th>\n",
       "      <td>2460.0</td>\n",
       "      <td>41.80</td>\n",
       "      <td>43.00</td>\n",
       "      <td>0.190336</td>\n",
       "      <td>0.187226</td>\n",
       "      <td>0.184759</td>\n",
       "      <td>0.185993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712903</th>\n",
       "      <td>2465.0</td>\n",
       "      <td>40.50</td>\n",
       "      <td>41.60</td>\n",
       "      <td>0.189884</td>\n",
       "      <td>0.186695</td>\n",
       "      <td>0.184406</td>\n",
       "      <td>0.185550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712904</th>\n",
       "      <td>2470.0</td>\n",
       "      <td>39.20</td>\n",
       "      <td>40.30</td>\n",
       "      <td>0.189474</td>\n",
       "      <td>0.186308</td>\n",
       "      <td>0.183992</td>\n",
       "      <td>0.185150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712905</th>\n",
       "      <td>2475.0</td>\n",
       "      <td>37.80</td>\n",
       "      <td>39.00</td>\n",
       "      <td>0.188893</td>\n",
       "      <td>0.185861</td>\n",
       "      <td>0.183302</td>\n",
       "      <td>0.184581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712906</th>\n",
       "      <td>2480.0</td>\n",
       "      <td>36.60</td>\n",
       "      <td>37.80</td>\n",
       "      <td>0.188574</td>\n",
       "      <td>0.185565</td>\n",
       "      <td>0.182975</td>\n",
       "      <td>0.184270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712907</th>\n",
       "      <td>2485.0</td>\n",
       "      <td>35.40</td>\n",
       "      <td>36.60</td>\n",
       "      <td>0.188194</td>\n",
       "      <td>0.185210</td>\n",
       "      <td>0.182586</td>\n",
       "      <td>0.183898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712908</th>\n",
       "      <td>2490.0</td>\n",
       "      <td>34.30</td>\n",
       "      <td>35.40</td>\n",
       "      <td>0.187864</td>\n",
       "      <td>0.184794</td>\n",
       "      <td>0.182357</td>\n",
       "      <td>0.183576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712909</th>\n",
       "      <td>2495.0</td>\n",
       "      <td>33.10</td>\n",
       "      <td>34.20</td>\n",
       "      <td>0.187357</td>\n",
       "      <td>0.184316</td>\n",
       "      <td>0.181844</td>\n",
       "      <td>0.183080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712910</th>\n",
       "      <td>2500.0</td>\n",
       "      <td>32.00</td>\n",
       "      <td>33.10</td>\n",
       "      <td>0.187016</td>\n",
       "      <td>0.183999</td>\n",
       "      <td>0.181493</td>\n",
       "      <td>0.182746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712911</th>\n",
       "      <td>2505.0</td>\n",
       "      <td>30.90</td>\n",
       "      <td>32.00</td>\n",
       "      <td>0.186611</td>\n",
       "      <td>0.183622</td>\n",
       "      <td>0.181079</td>\n",
       "      <td>0.182351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712912</th>\n",
       "      <td>2510.0</td>\n",
       "      <td>29.90</td>\n",
       "      <td>31.00</td>\n",
       "      <td>0.186382</td>\n",
       "      <td>0.183416</td>\n",
       "      <td>0.180837</td>\n",
       "      <td>0.182127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712913</th>\n",
       "      <td>2515.0</td>\n",
       "      <td>28.90</td>\n",
       "      <td>29.90</td>\n",
       "      <td>0.185972</td>\n",
       "      <td>0.182916</td>\n",
       "      <td>0.180535</td>\n",
       "      <td>0.181726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712914</th>\n",
       "      <td>2520.0</td>\n",
       "      <td>27.90</td>\n",
       "      <td>28.90</td>\n",
       "      <td>0.185620</td>\n",
       "      <td>0.182590</td>\n",
       "      <td>0.180172</td>\n",
       "      <td>0.181381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712915</th>\n",
       "      <td>2525.0</td>\n",
       "      <td>26.90</td>\n",
       "      <td>28.00</td>\n",
       "      <td>0.185329</td>\n",
       "      <td>0.182447</td>\n",
       "      <td>0.179746</td>\n",
       "      <td>0.181097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712916</th>\n",
       "      <td>2530.0</td>\n",
       "      <td>26.00</td>\n",
       "      <td>27.10</td>\n",
       "      <td>0.185105</td>\n",
       "      <td>0.182248</td>\n",
       "      <td>0.179505</td>\n",
       "      <td>0.180877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712917</th>\n",
       "      <td>2535.0</td>\n",
       "      <td>25.10</td>\n",
       "      <td>26.20</td>\n",
       "      <td>0.184820</td>\n",
       "      <td>0.181993</td>\n",
       "      <td>0.179204</td>\n",
       "      <td>0.180598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712918</th>\n",
       "      <td>2540.0</td>\n",
       "      <td>24.30</td>\n",
       "      <td>25.30</td>\n",
       "      <td>0.184606</td>\n",
       "      <td>0.181678</td>\n",
       "      <td>0.179101</td>\n",
       "      <td>0.180389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712919</th>\n",
       "      <td>2545.0</td>\n",
       "      <td>23.40</td>\n",
       "      <td>24.40</td>\n",
       "      <td>0.184198</td>\n",
       "      <td>0.181301</td>\n",
       "      <td>0.178679</td>\n",
       "      <td>0.179990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712920</th>\n",
       "      <td>2550.0</td>\n",
       "      <td>22.60</td>\n",
       "      <td>23.60</td>\n",
       "      <td>0.183997</td>\n",
       "      <td>0.181126</td>\n",
       "      <td>0.178460</td>\n",
       "      <td>0.179793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712921</th>\n",
       "      <td>2555.0</td>\n",
       "      <td>21.80</td>\n",
       "      <td>22.80</td>\n",
       "      <td>0.183736</td>\n",
       "      <td>0.180895</td>\n",
       "      <td>0.178182</td>\n",
       "      <td>0.179538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712922</th>\n",
       "      <td>2560.0</td>\n",
       "      <td>21.10</td>\n",
       "      <td>22.10</td>\n",
       "      <td>0.183697</td>\n",
       "      <td>0.180878</td>\n",
       "      <td>0.178120</td>\n",
       "      <td>0.179499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712923</th>\n",
       "      <td>2565.0</td>\n",
       "      <td>20.40</td>\n",
       "      <td>21.30</td>\n",
       "      <td>0.183460</td>\n",
       "      <td>0.180533</td>\n",
       "      <td>0.178005</td>\n",
       "      <td>0.179269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712924</th>\n",
       "      <td>2570.0</td>\n",
       "      <td>19.70</td>\n",
       "      <td>20.60</td>\n",
       "      <td>0.183310</td>\n",
       "      <td>0.180408</td>\n",
       "      <td>0.177835</td>\n",
       "      <td>0.179121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712925</th>\n",
       "      <td>2575.0</td>\n",
       "      <td>19.00</td>\n",
       "      <td>19.90</td>\n",
       "      <td>0.183102</td>\n",
       "      <td>0.180228</td>\n",
       "      <td>0.177608</td>\n",
       "      <td>0.178918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712926</th>\n",
       "      <td>2580.0</td>\n",
       "      <td>18.30</td>\n",
       "      <td>19.30</td>\n",
       "      <td>0.182987</td>\n",
       "      <td>0.180286</td>\n",
       "      <td>0.177321</td>\n",
       "      <td>0.178803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712927</th>\n",
       "      <td>2585.0</td>\n",
       "      <td>17.70</td>\n",
       "      <td>18.60</td>\n",
       "      <td>0.182816</td>\n",
       "      <td>0.179997</td>\n",
       "      <td>0.177277</td>\n",
       "      <td>0.178637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712928</th>\n",
       "      <td>2590.0</td>\n",
       "      <td>17.10</td>\n",
       "      <td>18.00</td>\n",
       "      <td>0.182745</td>\n",
       "      <td>0.179952</td>\n",
       "      <td>0.177182</td>\n",
       "      <td>0.178567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712929</th>\n",
       "      <td>2595.0</td>\n",
       "      <td>16.50</td>\n",
       "      <td>17.40</td>\n",
       "      <td>0.182619</td>\n",
       "      <td>0.179856</td>\n",
       "      <td>0.177032</td>\n",
       "      <td>0.178444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712930</th>\n",
       "      <td>2600.0</td>\n",
       "      <td>15.90</td>\n",
       "      <td>16.80</td>\n",
       "      <td>0.182438</td>\n",
       "      <td>0.179707</td>\n",
       "      <td>0.176826</td>\n",
       "      <td>0.178266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712931</th>\n",
       "      <td>2605.0</td>\n",
       "      <td>15.30</td>\n",
       "      <td>16.20</td>\n",
       "      <td>0.182199</td>\n",
       "      <td>0.179502</td>\n",
       "      <td>0.176562</td>\n",
       "      <td>0.178032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712932</th>\n",
       "      <td>2610.0</td>\n",
       "      <td>14.80</td>\n",
       "      <td>15.70</td>\n",
       "      <td>0.182240</td>\n",
       "      <td>0.179569</td>\n",
       "      <td>0.176573</td>\n",
       "      <td>0.178071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712933</th>\n",
       "      <td>2615.0</td>\n",
       "      <td>14.30</td>\n",
       "      <td>15.20</td>\n",
       "      <td>0.182232</td>\n",
       "      <td>0.179590</td>\n",
       "      <td>0.176536</td>\n",
       "      <td>0.178063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712934</th>\n",
       "      <td>2620.0</td>\n",
       "      <td>13.80</td>\n",
       "      <td>14.70</td>\n",
       "      <td>0.182173</td>\n",
       "      <td>0.179563</td>\n",
       "      <td>0.176447</td>\n",
       "      <td>0.178005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712935</th>\n",
       "      <td>2625.0</td>\n",
       "      <td>13.30</td>\n",
       "      <td>14.20</td>\n",
       "      <td>0.182062</td>\n",
       "      <td>0.179486</td>\n",
       "      <td>0.176304</td>\n",
       "      <td>0.177895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712936</th>\n",
       "      <td>2630.0</td>\n",
       "      <td>12.90</td>\n",
       "      <td>13.70</td>\n",
       "      <td>0.182080</td>\n",
       "      <td>0.179357</td>\n",
       "      <td>0.176473</td>\n",
       "      <td>0.177915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712937</th>\n",
       "      <td>2635.0</td>\n",
       "      <td>12.40</td>\n",
       "      <td>13.30</td>\n",
       "      <td>0.182049</td>\n",
       "      <td>0.179537</td>\n",
       "      <td>0.176225</td>\n",
       "      <td>0.177881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712938</th>\n",
       "      <td>2640.0</td>\n",
       "      <td>12.00</td>\n",
       "      <td>12.80</td>\n",
       "      <td>0.181967</td>\n",
       "      <td>0.179307</td>\n",
       "      <td>0.176299</td>\n",
       "      <td>0.177803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712939</th>\n",
       "      <td>2645.0</td>\n",
       "      <td>11.60</td>\n",
       "      <td>12.40</td>\n",
       "      <td>0.182028</td>\n",
       "      <td>0.179396</td>\n",
       "      <td>0.176328</td>\n",
       "      <td>0.177862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712940</th>\n",
       "      <td>2650.0</td>\n",
       "      <td>11.20</td>\n",
       "      <td>12.00</td>\n",
       "      <td>0.182043</td>\n",
       "      <td>0.179442</td>\n",
       "      <td>0.176309</td>\n",
       "      <td>0.177875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712941</th>\n",
       "      <td>2655.0</td>\n",
       "      <td>10.80</td>\n",
       "      <td>11.60</td>\n",
       "      <td>0.182008</td>\n",
       "      <td>0.179441</td>\n",
       "      <td>0.176240</td>\n",
       "      <td>0.177841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712942</th>\n",
       "      <td>2660.0</td>\n",
       "      <td>10.40</td>\n",
       "      <td>11.20</td>\n",
       "      <td>0.181924</td>\n",
       "      <td>0.179393</td>\n",
       "      <td>0.176120</td>\n",
       "      <td>0.177757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712943</th>\n",
       "      <td>2700.0</td>\n",
       "      <td>7.90</td>\n",
       "      <td>8.70</td>\n",
       "      <td>0.182649</td>\n",
       "      <td>0.180396</td>\n",
       "      <td>0.176516</td>\n",
       "      <td>0.178456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712944</th>\n",
       "      <td>2750.0</td>\n",
       "      <td>5.60</td>\n",
       "      <td>6.30</td>\n",
       "      <td>0.183680</td>\n",
       "      <td>0.181579</td>\n",
       "      <td>0.177325</td>\n",
       "      <td>0.179452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712945</th>\n",
       "      <td>2800.0</td>\n",
       "      <td>4.00</td>\n",
       "      <td>4.70</td>\n",
       "      <td>0.185586</td>\n",
       "      <td>0.183949</td>\n",
       "      <td>0.178624</td>\n",
       "      <td>0.181286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712946</th>\n",
       "      <td>2850.0</td>\n",
       "      <td>2.95</td>\n",
       "      <td>3.60</td>\n",
       "      <td>0.188439</td>\n",
       "      <td>0.187108</td>\n",
       "      <td>0.180979</td>\n",
       "      <td>0.184043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712947</th>\n",
       "      <td>2900.0</td>\n",
       "      <td>2.20</td>\n",
       "      <td>2.80</td>\n",
       "      <td>0.191572</td>\n",
       "      <td>0.190559</td>\n",
       "      <td>0.183572</td>\n",
       "      <td>0.187065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712948</th>\n",
       "      <td>2950.0</td>\n",
       "      <td>1.65</td>\n",
       "      <td>2.30</td>\n",
       "      <td>0.195505</td>\n",
       "      <td>0.195389</td>\n",
       "      <td>0.186198</td>\n",
       "      <td>0.190793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712949</th>\n",
       "      <td>3000.0</td>\n",
       "      <td>1.20</td>\n",
       "      <td>1.90</td>\n",
       "      <td>0.199011</td>\n",
       "      <td>0.200067</td>\n",
       "      <td>0.187942</td>\n",
       "      <td>0.194005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712950</th>\n",
       "      <td>3050.0</td>\n",
       "      <td>0.90</td>\n",
       "      <td>1.55</td>\n",
       "      <td>0.202493</td>\n",
       "      <td>0.204110</td>\n",
       "      <td>0.190362</td>\n",
       "      <td>0.197236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712951</th>\n",
       "      <td>3100.0</td>\n",
       "      <td>0.70</td>\n",
       "      <td>1.30</td>\n",
       "      <td>0.206590</td>\n",
       "      <td>0.208654</td>\n",
       "      <td>0.193474</td>\n",
       "      <td>0.201064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712952</th>\n",
       "      <td>3150.0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1.10</td>\n",
       "      <td>0.209953</td>\n",
       "      <td>0.213173</td>\n",
       "      <td>0.194601</td>\n",
       "      <td>0.203887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712953</th>\n",
       "      <td>3200.0</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.214405</td>\n",
       "      <td>0.217977</td>\n",
       "      <td>0.198016</td>\n",
       "      <td>0.207996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712954</th>\n",
       "      <td>3250.0</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.218852</td>\n",
       "      <td>0.223450</td>\n",
       "      <td>0.199971</td>\n",
       "      <td>0.211711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712955</th>\n",
       "      <td>3300.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.223561</td>\n",
       "      <td>0.228323</td>\n",
       "      <td>0.203848</td>\n",
       "      <td>0.216086</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        strike_price  best_bid  best_offer  impl_volatility  vol_high  \\\n",
       "712753        1150.0   1114.90     1118.50         0.497858  0.524338   \n",
       "712754        1200.0   1065.70     1069.30         0.484312  0.505587   \n",
       "712755        1250.0   1016.60     1020.20         0.470510  0.487543   \n",
       "712756        1300.0    967.60      971.20         0.456367  0.469955   \n",
       "712757        1350.0    918.70      922.30         0.441848  0.452639   \n",
       "712758        1400.0    870.00      873.60         0.428009  0.436380   \n",
       "712759        1450.0    821.50      825.00         0.413965  0.419950   \n",
       "712760        1500.0    773.10      776.60         0.399613  0.404034   \n",
       "712761        1550.0    725.00      728.50         0.385942  0.389007   \n",
       "712762        1600.0    677.20      680.60         0.372217  0.373887   \n",
       "712763        1650.0    629.70      633.10         0.358785  0.359554   \n",
       "712764        1700.0    582.70      586.00         0.345795  0.345585   \n",
       "712765        1750.0    536.10      539.40         0.332848  0.332053   \n",
       "712766        1780.0    508.50      511.70         0.325341  0.324057   \n",
       "712767        1785.0    503.90      507.10         0.324044  0.322718   \n",
       "712768        1790.0    499.30      502.50         0.322725  0.321359   \n",
       "712769        1795.0    494.70      498.00         0.321572  0.320339   \n",
       "712770        1800.0    490.20      493.40         0.320394  0.318938   \n",
       "712771        1805.0    485.60      488.80         0.319007  0.317517   \n",
       "712772        1810.0    481.10      484.30         0.317962  0.316425   \n",
       "712773        1815.0    476.50      479.70         0.316531  0.314964   \n",
       "712774        1820.0    472.00      475.20         0.315435  0.313824   \n",
       "712775        1825.0    467.50      470.60         0.314136  0.312324   \n",
       "712776        1830.0    462.90      466.10         0.312814  0.311138   \n",
       "712777        1835.0    458.40      461.60         0.311641  0.309928   \n",
       "712778        1840.0    453.90      457.10         0.310442  0.308695   \n",
       "712779        1845.0    449.40      452.60         0.309218  0.307438   \n",
       "712780        1850.0    444.90      448.10         0.307968  0.306157   \n",
       "712781        1855.0    440.50      443.60         0.306858  0.304855   \n",
       "712782        1860.0    436.00      439.10         0.305558  0.303530   \n",
       "712783        1865.0    431.50      434.60         0.304234  0.302182   \n",
       "712784        1870.0    427.10      430.20         0.303204  0.301118   \n",
       "712785        1875.0    422.60      425.70         0.301830  0.299724   \n",
       "712786        1880.0    418.20      421.30         0.300743  0.298608   \n",
       "712787        1885.0    413.80      416.80         0.299475  0.297170   \n",
       "712788        1890.0    409.40      412.40         0.298332  0.296003   \n",
       "712789        1895.0    405.00      408.00         0.297162  0.294809   \n",
       "712790        1900.0    400.60      403.60         0.295963  0.293590   \n",
       "712791        1905.0    396.20      399.20         0.294738  0.292346   \n",
       "712792        1910.0    391.80      394.80         0.293486  0.291077   \n",
       "712793        1915.0    387.50      390.50         0.292494  0.290059   \n",
       "712794        1920.0    383.10      386.10         0.291186  0.288738   \n",
       "712795        1925.0    378.80      381.70         0.289994  0.287392   \n",
       "712796        1930.0    374.40      377.40         0.288773  0.286291   \n",
       "712797        1935.0    370.10      373.10         0.287661  0.285162   \n",
       "712798        1940.0    365.80      368.80         0.286520  0.284004   \n",
       "712799        1945.0    361.50      364.40         0.285214  0.282558   \n",
       "712800        1950.0    357.20      360.20         0.284148  0.281604   \n",
       "712801        1955.0    353.00      355.90         0.283051  0.280363   \n",
       "712802        1960.0    348.70      351.60         0.281792  0.279095   \n",
       "712803        1965.0    344.50      347.30         0.280634  0.277801   \n",
       "712804        1970.0    340.20      343.10         0.279445  0.276728   \n",
       "712805        1975.0    336.00      338.90         0.278353  0.275624   \n",
       "712806        1980.0    331.80      334.70         0.277229  0.274490   \n",
       "712807        1985.0    327.60      330.50         0.276074  0.273326   \n",
       "712808        1990.0    323.40      326.30         0.274887  0.272132   \n",
       "712809        1995.0    319.30      322.10         0.273791  0.270908   \n",
       "712810        2000.0    315.10      317.90         0.272542  0.269656   \n",
       "712811        2005.0    311.00      313.80         0.271502  0.268607   \n",
       "712812        2010.0    306.90      309.60         0.270309  0.267296   \n",
       "712813        2015.0    302.80      305.50         0.269201  0.266184   \n",
       "712814        2020.0    298.70      301.40         0.268060  0.265040   \n",
       "712815        2025.0    294.60      297.30         0.266886  0.263865   \n",
       "712816        2030.0    290.60      293.30         0.265908  0.262880   \n",
       "712817        2035.0    286.50      289.20         0.264666  0.261640   \n",
       "712818        2040.0    282.50      285.20         0.263617  0.260588   \n",
       "712819        2045.0    278.50      281.10         0.262421  0.259285   \n",
       "712820        2050.0    274.50      277.10         0.261302  0.258167   \n",
       "712821        2055.0    270.50      273.20         0.260256  0.257227   \n",
       "712822        2060.0    266.60      269.20         0.259175  0.256040   \n",
       "712823        2065.0    262.60      265.20         0.257949  0.254820   \n",
       "712824        2070.0    258.70      261.30         0.256903  0.253774   \n",
       "712825        2075.0    254.80      257.40         0.255819  0.252693   \n",
       "712826        2080.0    250.90      253.50         0.254698  0.251576   \n",
       "712827        2085.0    247.10      249.60         0.253645  0.250424   \n",
       "712828        2090.0    243.20      245.80         0.252553  0.249438   \n",
       "712829        2095.0    239.40      241.90         0.251424  0.248214   \n",
       "712830        2100.0    235.60      238.10         0.250358  0.247154   \n",
       "712831        2105.0    231.90      234.30         0.249355  0.246056   \n",
       "712832        2110.0    228.10      230.50         0.248212  0.244922   \n",
       "712833        2115.0    224.40      226.80         0.247229  0.243945   \n",
       "712834        2120.0    220.70      223.10         0.246206  0.242928   \n",
       "712835        2125.0    217.00      219.40         0.245142  0.241872   \n",
       "712836        2130.0    213.30      215.70         0.244037  0.240777   \n",
       "712837        2135.0    209.70      212.00         0.242989  0.239643   \n",
       "712838        2140.0    206.00      208.40         0.241900  0.238658   \n",
       "712839        2145.0    202.40      204.80         0.240865  0.237632   \n",
       "712840        2150.0    198.90      201.20         0.239883  0.236566   \n",
       "712841        2155.0    195.30      197.60         0.238763  0.235459   \n",
       "712842        2160.0    191.80      194.10         0.237789  0.234495   \n",
       "712843        2165.0    188.30      190.60         0.236772  0.233488   \n",
       "712844        2170.0    184.90      187.10         0.235803  0.232439   \n",
       "712845        2175.0    181.40      183.60         0.234697  0.231348   \n",
       "712846        2180.0    178.00      180.20         0.233732  0.230394   \n",
       "712847        2185.0    174.60      176.80         0.232721  0.229396   \n",
       "712848        2190.0    171.30      173.40         0.231756  0.228355   \n",
       "712849        2195.0    167.90      170.10         0.230744  0.227446   \n",
       "712850        2200.0    164.60      166.80         0.229777  0.226492   \n",
       "712851        2205.0    161.40      163.50         0.228852  0.225492   \n",
       "712852        2210.0    158.10      160.20         0.227790  0.224447   \n",
       "712853        2215.0    154.90      157.00         0.226859  0.223531   \n",
       "712854        2220.0    151.70      153.80         0.225880  0.222567   \n",
       "712855        2225.0    148.60      150.60         0.224941  0.221557   \n",
       "712856        2230.0    145.50      147.50         0.224042  0.220672   \n",
       "712857        2235.0    142.40      144.40         0.223092  0.219739   \n",
       "712858        2240.0    139.30      141.30         0.222092  0.218757   \n",
       "712859        2245.0    136.30      138.30         0.221217  0.217898   \n",
       "712860        2250.0    133.30      135.30         0.220292  0.216989   \n",
       "712861        2255.0    130.40      132.30         0.219401  0.216031   \n",
       "712862        2260.0    127.50      129.40         0.218547  0.215192   \n",
       "712863        2265.0    124.60      126.50         0.217639  0.214303   \n",
       "712864        2270.0    121.70      123.40         0.216504  0.213022   \n",
       "712865        2275.0    118.90      120.60         0.215665  0.212200   \n",
       "712866        2280.0    116.20      117.80         0.214858  0.211325   \n",
       "712867        2285.0    113.40      115.10         0.213997  0.210568   \n",
       "712868        2290.0    110.70      112.40         0.213168  0.209758   \n",
       "712869        2295.0    108.00      109.70         0.212284  0.208894   \n",
       "712870        2300.0    105.40      107.10         0.211517  0.208146   \n",
       "712871        2305.0    102.80      104.50         0.210695  0.207343   \n",
       "712872        2310.0    100.30      101.90         0.209903  0.206485   \n",
       "712873        2315.0     97.80       99.40         0.209142  0.205743   \n",
       "712874        2320.0     95.30       96.90         0.208323  0.204945   \n",
       "712875        2325.0     92.80       94.50         0.207534  0.204262   \n",
       "712876        2330.0     90.40       92.10         0.206774  0.203523   \n",
       "712877        2335.0     88.10       89.70         0.206043  0.202726   \n",
       "712878        2340.0     85.80       87.40         0.205343  0.202045   \n",
       "712879        2345.0     83.50       85.10         0.204582  0.201307   \n",
       "712880        2350.0     81.20       82.80         0.203762  0.200510   \n",
       "712881        2355.0     79.00       80.60         0.203060  0.199829   \n",
       "712882        2360.0     76.90       78.40         0.202386  0.199089   \n",
       "712883        2365.0     74.70       76.20         0.201562  0.198289   \n",
       "712884        2370.0     72.60       74.10         0.200857  0.197606   \n",
       "712885        2375.0     70.60       72.10         0.200272  0.197041   \n",
       "712886        2380.0     68.60       70.10         0.199626  0.196417   \n",
       "712887        2385.0     66.60       68.10         0.198917  0.195733   \n",
       "712888        2390.0     64.70       66.10         0.198239  0.194988   \n",
       "712889        2395.0     62.80       64.20         0.197590  0.194362   \n",
       "712890        2400.0     61.00       62.40         0.197067  0.193859   \n",
       "712891        2405.0     59.20       60.60         0.196481  0.193296   \n",
       "712892        2410.0     57.40       58.80         0.195832  0.192672   \n",
       "712893        2415.0     55.70       57.00         0.195215  0.191986   \n",
       "712894        2420.0     54.00       55.30         0.194631  0.191425   \n",
       "712895        2425.0     52.30       53.70         0.194080  0.190993   \n",
       "712896        2430.0     50.70       52.00         0.193466  0.190308   \n",
       "712897        2435.0     49.10       50.40         0.192885  0.189753   \n",
       "712898        2440.0     47.60       48.90         0.192441  0.189331   \n",
       "712899        2445.0     46.10       47.40         0.191935  0.188849   \n",
       "712900        2450.0     44.70       45.80         0.191363  0.188103   \n",
       "712901        2455.0     43.20       44.40         0.190830  0.187695   \n",
       "712902        2460.0     41.80       43.00         0.190336  0.187226   \n",
       "712903        2465.0     40.50       41.60         0.189884  0.186695   \n",
       "712904        2470.0     39.20       40.30         0.189474  0.186308   \n",
       "712905        2475.0     37.80       39.00         0.188893  0.185861   \n",
       "712906        2480.0     36.60       37.80         0.188574  0.185565   \n",
       "712907        2485.0     35.40       36.60         0.188194  0.185210   \n",
       "712908        2490.0     34.30       35.40         0.187864  0.184794   \n",
       "712909        2495.0     33.10       34.20         0.187357  0.184316   \n",
       "712910        2500.0     32.00       33.10         0.187016  0.183999   \n",
       "712911        2505.0     30.90       32.00         0.186611  0.183622   \n",
       "712912        2510.0     29.90       31.00         0.186382  0.183416   \n",
       "712913        2515.0     28.90       29.90         0.185972  0.182916   \n",
       "712914        2520.0     27.90       28.90         0.185620  0.182590   \n",
       "712915        2525.0     26.90       28.00         0.185329  0.182447   \n",
       "712916        2530.0     26.00       27.10         0.185105  0.182248   \n",
       "712917        2535.0     25.10       26.20         0.184820  0.181993   \n",
       "712918        2540.0     24.30       25.30         0.184606  0.181678   \n",
       "712919        2545.0     23.40       24.40         0.184198  0.181301   \n",
       "712920        2550.0     22.60       23.60         0.183997  0.181126   \n",
       "712921        2555.0     21.80       22.80         0.183736  0.180895   \n",
       "712922        2560.0     21.10       22.10         0.183697  0.180878   \n",
       "712923        2565.0     20.40       21.30         0.183460  0.180533   \n",
       "712924        2570.0     19.70       20.60         0.183310  0.180408   \n",
       "712925        2575.0     19.00       19.90         0.183102  0.180228   \n",
       "712926        2580.0     18.30       19.30         0.182987  0.180286   \n",
       "712927        2585.0     17.70       18.60         0.182816  0.179997   \n",
       "712928        2590.0     17.10       18.00         0.182745  0.179952   \n",
       "712929        2595.0     16.50       17.40         0.182619  0.179856   \n",
       "712930        2600.0     15.90       16.80         0.182438  0.179707   \n",
       "712931        2605.0     15.30       16.20         0.182199  0.179502   \n",
       "712932        2610.0     14.80       15.70         0.182240  0.179569   \n",
       "712933        2615.0     14.30       15.20         0.182232  0.179590   \n",
       "712934        2620.0     13.80       14.70         0.182173  0.179563   \n",
       "712935        2625.0     13.30       14.20         0.182062  0.179486   \n",
       "712936        2630.0     12.90       13.70         0.182080  0.179357   \n",
       "712937        2635.0     12.40       13.30         0.182049  0.179537   \n",
       "712938        2640.0     12.00       12.80         0.181967  0.179307   \n",
       "712939        2645.0     11.60       12.40         0.182028  0.179396   \n",
       "712940        2650.0     11.20       12.00         0.182043  0.179442   \n",
       "712941        2655.0     10.80       11.60         0.182008  0.179441   \n",
       "712942        2660.0     10.40       11.20         0.181924  0.179393   \n",
       "712943        2700.0      7.90        8.70         0.182649  0.180396   \n",
       "712944        2750.0      5.60        6.30         0.183680  0.181579   \n",
       "712945        2800.0      4.00        4.70         0.185586  0.183949   \n",
       "712946        2850.0      2.95        3.60         0.188439  0.187108   \n",
       "712947        2900.0      2.20        2.80         0.191572  0.190559   \n",
       "712948        2950.0      1.65        2.30         0.195505  0.195389   \n",
       "712949        3000.0      1.20        1.90         0.199011  0.200067   \n",
       "712950        3050.0      0.90        1.55         0.202493  0.204110   \n",
       "712951        3100.0      0.70        1.30         0.206590  0.208654   \n",
       "712952        3150.0      0.50        1.10         0.209953  0.213173   \n",
       "712953        3200.0      0.40        0.95         0.214405  0.217977   \n",
       "712954        3250.0      0.30        0.85         0.218852  0.223450   \n",
       "712955        3300.0      0.25        0.75         0.223561  0.228323   \n",
       "\n",
       "         vol_low   vol_mid  \n",
       "712753  0.432651  0.478494  \n",
       "712754  0.431583  0.468585  \n",
       "712755  0.426303  0.456923  \n",
       "712756  0.418380  0.444168  \n",
       "712757  0.408614  0.430626  \n",
       "712758  0.398690  0.417535  \n",
       "712759  0.388319  0.404134  \n",
       "712760  0.376498  0.390266  \n",
       "712761  0.365020  0.377014  \n",
       "712762  0.353486  0.363686  \n",
       "712763  0.341641  0.350597  \n",
       "712764  0.330286  0.337936  \n",
       "712765  0.318532  0.325292  \n",
       "712766  0.311871  0.317964  \n",
       "712767  0.310674  0.316696  \n",
       "712768  0.309455  0.315407  \n",
       "712769  0.308213  0.314276  \n",
       "712770  0.307321  0.313129  \n",
       "712771  0.306031  0.311774  \n",
       "712772  0.305082  0.310753  \n",
       "712773  0.303745  0.309354  \n",
       "712774  0.302742  0.308283  \n",
       "712775  0.301710  0.307017  \n",
       "712776  0.300305  0.305721  \n",
       "712777  0.299222  0.304575  \n",
       "712778  0.298112  0.303403  \n",
       "712779  0.296975  0.302206  \n",
       "712780  0.295813  0.300985  \n",
       "712781  0.294951  0.299903  \n",
       "712782  0.293734  0.298632  \n",
       "712783  0.292494  0.297338  \n",
       "712784  0.291543  0.296330  \n",
       "712785  0.290251  0.294988  \n",
       "712786  0.289243  0.293925  \n",
       "712787  0.288205  0.292687  \n",
       "712788  0.287138  0.291570  \n",
       "712789  0.286042  0.290426  \n",
       "712790  0.284918  0.289254  \n",
       "712791  0.283766  0.288056  \n",
       "712792  0.282588  0.286832  \n",
       "712793  0.281665  0.285862  \n",
       "712794  0.280430  0.284584  \n",
       "712795  0.279446  0.283419  \n",
       "712796  0.278157  0.282224  \n",
       "712797  0.277114  0.281138  \n",
       "712798  0.276040  0.280022  \n",
       "712799  0.274936  0.278747  \n",
       "712800  0.273802  0.277703  \n",
       "712801  0.272899  0.276631  \n",
       "712802  0.271705  0.275400  \n",
       "712803  0.270737  0.274269  \n",
       "712804  0.269484  0.273106  \n",
       "712805  0.268452  0.272038  \n",
       "712806  0.267389  0.270939  \n",
       "712807  0.266294  0.269810  \n",
       "712808  0.265167  0.268649  \n",
       "712809  0.264249  0.267579  \n",
       "712810  0.263059  0.266357  \n",
       "712811  0.262073  0.265340  \n",
       "712812  0.261053  0.264174  \n",
       "712813  0.259999  0.263091  \n",
       "712814  0.258911  0.261976  \n",
       "712815  0.257791  0.260828  \n",
       "712816  0.256862  0.259871  \n",
       "712817  0.255674  0.258657  \n",
       "712818  0.254675  0.257632  \n",
       "712819  0.253640  0.256463  \n",
       "712820  0.252569  0.255368  \n",
       "712821  0.251464  0.254346  \n",
       "712822  0.250537  0.253289  \n",
       "712823  0.249361  0.252090  \n",
       "712824  0.248360  0.251067  \n",
       "712825  0.247323  0.250008  \n",
       "712826  0.246248  0.248912  \n",
       "712827  0.245341  0.247882  \n",
       "712828  0.244192  0.246815  \n",
       "712829  0.243208  0.245711  \n",
       "712830  0.242185  0.244669  \n",
       "712831  0.241321  0.243689  \n",
       "712832  0.240220  0.242571  \n",
       "712833  0.239276  0.241610  \n",
       "712834  0.238291  0.240609  \n",
       "712835  0.237266  0.239569  \n",
       "712836  0.236202  0.238489  \n",
       "712837  0.235287  0.237465  \n",
       "712838  0.234141  0.236399  \n",
       "712839  0.233143  0.235388  \n",
       "712840  0.232290  0.234428  \n",
       "712841  0.231207  0.233333  \n",
       "712842  0.230268  0.232381  \n",
       "712843  0.229284  0.231386  \n",
       "712844  0.228440  0.230440  \n",
       "712845  0.227369  0.229358  \n",
       "712846  0.226435  0.228415  \n",
       "712847  0.225456  0.227426  \n",
       "712848  0.224611  0.226483  \n",
       "712849  0.223541  0.225494  \n",
       "712850  0.222604  0.224548  \n",
       "712851  0.221796  0.223644  \n",
       "712852  0.220765  0.222606  \n",
       "712853  0.219862  0.221696  \n",
       "712854  0.218911  0.220739  \n",
       "712855  0.218085  0.219821  \n",
       "712856  0.217211  0.218942  \n",
       "712857  0.216287  0.218013  \n",
       "712858  0.215314  0.217036  \n",
       "712859  0.214463  0.216181  \n",
       "712860  0.213561  0.215275  \n",
       "712861  0.212780  0.214405  \n",
       "712862  0.211947  0.213570  \n",
       "712863  0.211062  0.212683  \n",
       "712864  0.210125  0.211573  \n",
       "712865  0.209305  0.210752  \n",
       "712866  0.208603  0.209964  \n",
       "712867  0.207676  0.209122  \n",
       "712868  0.206866  0.208312  \n",
       "712869  0.206001  0.207447  \n",
       "712870  0.205251  0.206698  \n",
       "712871  0.204446  0.205894  \n",
       "712872  0.203756  0.205121  \n",
       "712873  0.203009  0.204376  \n",
       "712874  0.202206  0.203576  \n",
       "712875  0.201346  0.202804  \n",
       "712876  0.200600  0.202061  \n",
       "712877  0.199968  0.201347  \n",
       "712878  0.199279  0.200662  \n",
       "712879  0.198531  0.199919  \n",
       "712880  0.197725  0.199117  \n",
       "712881  0.197032  0.198431  \n",
       "712882  0.196456  0.197772  \n",
       "712883  0.195644  0.196967  \n",
       "712884  0.194948  0.196277  \n",
       "712885  0.194369  0.195705  \n",
       "712886  0.193730  0.195074  \n",
       "712887  0.193030  0.194381  \n",
       "712888  0.192448  0.193718  \n",
       "712889  0.191806  0.193084  \n",
       "712890  0.191285  0.192572  \n",
       "712891  0.190703  0.192000  \n",
       "712892  0.190059  0.191366  \n",
       "712893  0.189540  0.190763  \n",
       "712894  0.188958  0.190191  \n",
       "712895  0.188313  0.189653  \n",
       "712896  0.187796  0.189052  \n",
       "712897  0.187217  0.188485  \n",
       "712898  0.186771  0.188051  \n",
       "712899  0.186262  0.187555  \n",
       "712900  0.185891  0.186997  \n",
       "712901  0.185255  0.186475  \n",
       "712902  0.184759  0.185993  \n",
       "712903  0.184406  0.185550  \n",
       "712904  0.183992  0.185150  \n",
       "712905  0.183302  0.184581  \n",
       "712906  0.182975  0.184270  \n",
       "712907  0.182586  0.183898  \n",
       "712908  0.182357  0.183576  \n",
       "712909  0.181844  0.183080  \n",
       "712910  0.181493  0.182746  \n",
       "712911  0.181079  0.182351  \n",
       "712912  0.180837  0.182127  \n",
       "712913  0.180535  0.181726  \n",
       "712914  0.180172  0.181381  \n",
       "712915  0.179746  0.181097  \n",
       "712916  0.179505  0.180877  \n",
       "712917  0.179204  0.180598  \n",
       "712918  0.179101  0.180389  \n",
       "712919  0.178679  0.179990  \n",
       "712920  0.178460  0.179793  \n",
       "712921  0.178182  0.179538  \n",
       "712922  0.178120  0.179499  \n",
       "712923  0.178005  0.179269  \n",
       "712924  0.177835  0.179121  \n",
       "712925  0.177608  0.178918  \n",
       "712926  0.177321  0.178803  \n",
       "712927  0.177277  0.178637  \n",
       "712928  0.177182  0.178567  \n",
       "712929  0.177032  0.178444  \n",
       "712930  0.176826  0.178266  \n",
       "712931  0.176562  0.178032  \n",
       "712932  0.176573  0.178071  \n",
       "712933  0.176536  0.178063  \n",
       "712934  0.176447  0.178005  \n",
       "712935  0.176304  0.177895  \n",
       "712936  0.176473  0.177915  \n",
       "712937  0.176225  0.177881  \n",
       "712938  0.176299  0.177803  \n",
       "712939  0.176328  0.177862  \n",
       "712940  0.176309  0.177875  \n",
       "712941  0.176240  0.177841  \n",
       "712942  0.176120  0.177757  \n",
       "712943  0.176516  0.178456  \n",
       "712944  0.177325  0.179452  \n",
       "712945  0.178624  0.181286  \n",
       "712946  0.180979  0.184043  \n",
       "712947  0.183572  0.187065  \n",
       "712948  0.186198  0.190793  \n",
       "712949  0.187942  0.194005  \n",
       "712950  0.190362  0.197236  \n",
       "712951  0.193474  0.201064  \n",
       "712952  0.194601  0.203887  \n",
       "712953  0.198016  0.207996  \n",
       "712954  0.199971  0.211711  \n",
       "712955  0.203848  0.216086  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with pd.option_context('display.max_rows', None, 'display.max_columns', None):  # more options can be specified also\n",
    "\n",
    "    display(processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x1f6a11cdc70>"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(processed['strike_price'].apply(np.log), processed['vol_low'])\n",
    "plt.scatter(processed['strike_price'].apply(np.log), processed['vol_high'])\n",
    "plt.scatter(processed['strike_price'].apply(np.log), processed['vol_mid'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Boundary shape (11,)\n",
      "Mid shape (11,)\n",
      "Strike shape (11,)\n",
      "Strike knots shape 11\n",
      "System shape: (27, 40) With 9 knots\n",
      "(40, 13) (27, 40) (40, 1)\n",
      "(40, 1)\n",
      "(40, 13)\n",
      "(13, 1)\n",
      "torch.Size([13])\n"
     ]
    }
   ],
   "source": [
    "import smilecorrector as smilenet\n",
    "importlib.reload(smilenet)\n",
    "import torch\n",
    "# For first try, we pass our boundaries as each strike price\n",
    "\n",
    "boundaries = processed['strike_price'].apply(np.log).to_numpy()\n",
    "ind = np.array([i for i in range(0,boundaries.shape[0],20)])\n",
    "boundaries = boundaries[ind]\n",
    "strikes = boundaries.copy()\n",
    "# boundaries = np.hstack([np.array([(1 - i/10) * hi + i/10 * lo for i in range(11)]) for hi, lo in zip(boundaries[:-1], boundaries[1:])])\n",
    "mids = processed['vol_mid'].to_numpy()[ind]\n",
    "print(' Boundary shape' , boundaries.shape)\n",
    "print('Mid shape', mids.shape)\n",
    "print('Strike shape', strikes.shape)\n",
    "model = smilenet.SmileNet(boundaries, strikes, mids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datum shape:  torch.Size([22, 1])\n",
      "(40, 1)\n",
      "Linear(in_features=44, out_features=13, bias=True)\n",
      "torch.Size([13, 40])\n",
      "With remaining arb: -0.0\n"
     ]
    }
   ],
   "source": [
    "datum = torch.tensor(np.vstack([processed['vol_high'].to_numpy()[ind].reshape(-1,1), processed['vol_low'].to_numpy()[ind].reshape(-1,1)])).double()\n",
    "print('Datum shape: ', datum.shape)\n",
    "print(model.xstar.shape)\n",
    "print(model.blackbox[-1])\n",
    "print(model.translate.shape)\n",
    "res1 = model.forward(datum.T.double())\n",
    "res1 = res1.reshape(-1)\n",
    "# print(res1.shape)\n",
    "# print(res1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n",
      "(40,)\n",
      "10 10\n",
      "10 10\n",
      "500\n",
      "500\n"
     ]
    }
   ],
   "source": [
    "print(len(boundaries))\n",
    "boundary_spaces = [np.linspace(x,y) for x, y in zip(boundaries[:-1],boundaries[1:])]\n",
    "resn = res1.detach().numpy()\n",
    "print(resn.shape)\n",
    "polys = [np.polynomial.polynomial.Polynomial(list(reversed(resn[4*i:4*i+4]))) for i in range(resn.shape[0]//4)]\n",
    "print(len(polys), len(boundary_spaces)) # Why am I throwing away the first polynomial\n",
    "polys = polys[:]\n",
    "print(len(polys), len(boundary_spaces))\n",
    "plot_points = np.hstack([poly(space) for poly, space in zip(polys, boundary_spaces)])\n",
    "print(len(plot_points))\n",
    "points = np.hstack(boundary_spaces)\n",
    "print(len(points))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.047517221357296\n",
      "7.047517221357296 0.47849416334538936\n",
      "[ -0.0759262    1.54410247 -10.7779175   26.32098824]\n"
     ]
    }
   ],
   "source": [
    "print(boundaries[0])\n",
    "print(np.log(processed['strike_price'].to_numpy()[0]), processed['vol_mid'].to_numpy()[0])\n",
    "print(resn[0:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x1f8d93c9310>"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(points, plot_points)\n",
    "plt.scatter(processed['strike_price'].apply(np.log), processed['vol_low'])\n",
    "plt.scatter(processed['strike_price'].apply(np.log), processed['vol_high'])\n",
    "plt.scatter(processed['strike_price'].apply(np.log), processed['vol_mid'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x1f6a11b6db0>"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "processed2 = processed2[processed2['vol_low'] != 0]\n",
    "plt.scatter(processed2['strike_price'].apply(np.log), processed2['vol_low'])\n",
    "plt.scatter(processed2['strike_price'].apply(np.log), processed2['vol_high'])\n",
    "plt.scatter(processed2['strike_price'].apply(np.log), processed2['vol_mid'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Boundary shape (68,)\n",
      "Mid shape (68,)\n",
      "Strike shape (68,)\n",
      "Strike knots shape 68\n",
      "System shape: (198, 268) With 66 knots\n",
      "(268, 70) (198, 268) (268, 1)\n",
      "(268, 1)\n",
      "(268, 70)\n",
      "(70, 1)\n",
      "torch.Size([70])\n",
      "Epoch: 0\n",
      "With remaining arb: -0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Project\\smilecorrector.py:390: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ctx.save_for_backward(coeffs, torch.tensor(x))\n",
      "d:\\Project\\smilecorrector.py:394: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(poly(x))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mid loss 9.585041730618696e-05\n",
      "Loss: tensor(9.5850e-05, grad_fn=<DivBackward0>)\n",
      "Epoch: 1\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[38], line 16\u001b[0m\n\u001b[0;32m     14\u001b[0m model \u001b[38;5;241m=\u001b[39m smilenet\u001b[38;5;241m.\u001b[39mSmileNet(boundaries, log_strikes, mids)\n\u001b[0;32m     15\u001b[0m datum \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(np\u001b[38;5;241m.\u001b[39mvstack([np\u001b[38;5;241m.\u001b[39msqrt(processed[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvol_high\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mto_numpy()\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m1\u001b[39m)), np\u001b[38;5;241m.\u001b[39msqrt(processed[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvol_low\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mto_numpy()\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m1\u001b[39m))]))\u001b[38;5;241m.\u001b[39mdouble()\n\u001b[1;32m---> 16\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdatum\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mT\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdouble\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlog_strikes\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Project\\smilecorrector.py:250\u001b[0m, in \u001b[0;36mSmileNet.train\u001b[1;34m(self, data, strikes, epochs, optimizer)\u001b[0m\n\u001b[0;32m    248\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEpoch:\u001b[39m\u001b[38;5;124m'\u001b[39m,e)\n\u001b[0;32m    249\u001b[0m \u001b[38;5;66;03m# Loss and prediction\u001b[39;00m\n\u001b[1;32m--> 250\u001b[0m pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscale\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    251\u001b[0m polys \u001b[38;5;241m=\u001b[39m [np\u001b[38;5;241m.\u001b[39mpolynomial\u001b[38;5;241m.\u001b[39mpolynomial\u001b[38;5;241m.\u001b[39mPolynomial(\u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mreversed\u001b[39m(pred[:,\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mnumpy()[\u001b[38;5;241m4\u001b[39m\u001b[38;5;241m*\u001b[39mi:\u001b[38;5;241m4\u001b[39m\u001b[38;5;241m*\u001b[39mi\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m4\u001b[39m]))) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m((pred\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m4\u001b[39m)]\n\u001b[0;32m    253\u001b[0m \u001b[38;5;66;03m# plot_polys([poly.deriv() for poly in polys], self.boundaries, e, 'dit')\u001b[39;00m\n\u001b[0;32m    254\u001b[0m \u001b[38;5;66;03m# plot_polys([poly.deriv(2) for poly in polys], self.boundaries, e, 'd2it')\u001b[39;00m\n",
      "File \u001b[1;32md:\\Project\\smilecorrector.py:239\u001b[0m, in \u001b[0;36mSmileNet.forward\u001b[1;34m(self, x, scale)\u001b[0m\n\u001b[0;32m    236\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m scale \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    237\u001b[0m     scale \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscale\n\u001b[1;32m--> 239\u001b[0m sol \u001b[38;5;241m=\u001b[39m \u001b[43mremove_arb\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcontrol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtranslate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mboundaries\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscale\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    240\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m sol\n",
      "File \u001b[1;32md:\\Project\\smilecorrector.py:515\u001b[0m, in \u001b[0;36mremove_arb\u001b[1;34m(control, translate, boundaries, scale, tol)\u001b[0m\n\u001b[0;32m    513\u001b[0m sol \u001b[38;5;241m=\u001b[39m translate\u001b[38;5;241m.\u001b[39mT \u001b[38;5;241m@\u001b[39m control\u001b[38;5;241m.\u001b[39mT\n\u001b[0;32m    514\u001b[0m \u001b[38;5;66;03m# polys = [np.polynomial.polynomial.Polynomial(list(reversed(pred[:,0].detach().numpy()[4*i:4*i+4]))) for i in range((pred.shape[0])//4)]\u001b[39;00m\n\u001b[1;32m--> 515\u001b[0m transformed \u001b[38;5;241m=\u001b[39m \u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43msol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscale\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    516\u001b[0m loss \u001b[38;5;241m=\u001b[39m scale \u001b[38;5;241m*\u001b[39m polyLoss\u001b[38;5;241m.\u001b[39mapply(transformed, boundaries)\n\u001b[0;32m    517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m loss \u001b[38;5;241m<\u001b[39m tol:\n",
      "File \u001b[1;32md:\\Project\\smilecorrector.py:304\u001b[0m, in \u001b[0;36mtransform\u001b[1;34m(sol, scale)\u001b[0m\n\u001b[0;32m    302\u001b[0m cond \u001b[38;5;241m=\u001b[39m differentiablePolyAdd\u001b[38;5;241m.\u001b[39mapply(cond, \u001b[38;5;241m4\u001b[39m \u001b[38;5;241m*\u001b[39m a2) \u001b[38;5;66;03m# + 4a^2\u001b[39;00m\n\u001b[0;32m    303\u001b[0m cond \u001b[38;5;241m=\u001b[39m differentiablePolySub\u001b[38;5;241m.\u001b[39mapply(cond, preservingPolyMul(a, b2)) \u001b[38;5;66;03m# - ab^2\u001b[39;00m\n\u001b[1;32m--> 304\u001b[0m cond \u001b[38;5;241m=\u001b[39m differentiablePolySub\u001b[38;5;241m.\u001b[39mapply(cond, \u001b[38;5;241m4\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[43mpreservingPolyMul\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreservingPolyMul\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m) \u001b[38;5;66;03m# - 4 * a b k\u001b[39;00m\n\u001b[0;32m    305\u001b[0m cond \u001b[38;5;241m=\u001b[39m differentiablePolyAdd\u001b[38;5;241m.\u001b[39mapply(cond, preservingPolyMul(b2,k2)) \u001b[38;5;66;03m# + b^2 x^2\u001b[39;00m\n\u001b[0;32m    306\u001b[0m transforms \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m [cond]\n",
      "File \u001b[1;32md:\\Project\\smilecorrector.py:289\u001b[0m, in \u001b[0;36mtransform.<locals>.<lambda>\u001b[1;34m(x, y)\u001b[0m\n\u001b[0;32m    287\u001b[0m \u001b[38;5;66;03m# max_degree = w.degree() * 2 + (w.deriv()).degree() * 2\u001b[39;00m\n\u001b[0;32m    288\u001b[0m max_degree \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m\n\u001b[1;32m--> 289\u001b[0m preservingPolyMul \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m x, y: \u001b[43mdifferentiablePolyMul\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_degree\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    290\u001b[0m \u001b[38;5;66;03m# preservingTensorPoly = lambda x: convertTensorPoly.apply(x, max_degree)\u001b[39;00m\n\u001b[0;32m    292\u001b[0m a \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mflip(sol[i:(i\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m4\u001b[39m)], dims\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m0\u001b[39m,))\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\autograd\\function.py:553\u001b[0m, in \u001b[0;36mFunction.apply\u001b[1;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[0;32m    550\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_are_functorch_transforms_active():\n\u001b[0;32m    551\u001b[0m     \u001b[38;5;66;03m# See NOTE: [functorch vjp and autograd interaction]\u001b[39;00m\n\u001b[0;32m    552\u001b[0m     args \u001b[38;5;241m=\u001b[39m _functorch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39munwrap_dead_wrappers(args)\n\u001b[1;32m--> 553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m    555\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_setup_ctx_defined:\n\u001b[0;32m    556\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    557\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIn order to use an autograd.Function with functorch transforms \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    558\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(vmap, grad, jvp, jacrev, ...), it must override the setup_context \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    559\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstaticmethod. For more details, please see \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    560\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://pytorch.org/docs/master/notes/extending.func.html\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    561\u001b[0m     )\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import smilecorrector as smilenet\n",
    "import torch\n",
    "importlib.reload(smilenet)\n",
    "# For first try, we pass our boundaries as each strike price\n",
    "boundaries = processed['strike_price'].apply(np.log).to_numpy()\n",
    "ind = np.array([i for i in range(0,boundaries.shape[0],3)])\n",
    "boundaries = boundaries[ind]\n",
    "strikes = boundaries.copy()\n",
    "log_strikes = torch.tensor(processed['strike_price'].apply(np.log).to_numpy())\n",
    "mids = np.sqrt((processed['vol_mid'].to_numpy() + processed['vol_mid'].to_numpy())/2)[ind]\n",
    "print(' Boundary shape' , boundaries.shape)\n",
    "print('Mid shape', mids.shape)\n",
    "print('Strike shape', strikes.shape)\n",
    "model = smilenet.SmileNet(boundaries, log_strikes, mids)\n",
    "datum = torch.tensor(np.vstack([np.sqrt(processed['vol_high'].to_numpy().reshape(-1,1)), np.sqrt(processed['vol_low'].to_numpy().reshape(-1,1))])).double()\n",
    "model.train(datum.T.double(), log_strikes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With remaining arb: 1.1102230246251565e-08\n",
      "42\n",
      "(164,)\n",
      "41 41\n",
      "41 41\n",
      "2050\n",
      "2050\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x1e8eb198e00>"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiMAAAGdCAYAAADAAnMpAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8g+/7EAAAACXBIWXMAAA9hAAAPYQGoP6dpAAB6t0lEQVR4nO3deVyU5drA8d/MsAkCisgiobgrUZobormGYS7tZYvL0fKUmZW0qG3aqraYlZbneLJsN9PMzBcX0tQkcS33HTUV3AFBtpnn/WMYBJmBmWF2ru/58OkwPs/M7URwcd/XolIURUEIIYQQwknUzl6AEEIIIWo3CUaEEEII4VQSjAghhBDCqSQYEUIIIYRTSTAihBBCCKeSYEQIIYQQTiXBiBBCCCGcSoIRIYQQQjiVl7MXYA6dTsepU6cIDAxEpVI5ezlCCCGEMIOiKOTm5tKoUSPUatP7H24RjJw6dYro6GhnL0MIIYQQVjhx4gTXXXedyT93i2AkMDAQ0P9lgoKCnLwaIYQQQpgjJyeH6Ojosp/jprhFMGI4mgkKCpJgRAghhHAz1aVYSAKrEEIIIZxKghEhhBBCOJUEI0IIIYRwKglGhBBCCOFUEowIIYQQwqmsCkZmz55NTEwMfn5+xMfHk56eXuX1M2fOpHXr1tSpU4fo6GjGjx9PQUGBVQsWQgghhGexOBhZsGABycnJTJ48mW3bttGuXTuSkpI4c+aM0eu//fZbJk6cyOTJk9m7dy+fffYZCxYs4MUXX6zx4oUQQgjh/iwORmbMmMHo0aMZOXIksbGxzJkzB39/f+bNm2f0+o0bN9K9e3ceeughYmJiuPXWW3nwwQer3U0RQgghRO1gUTBSVFTE1q1bSUxMvPoEajWJiYmkpaUZvadbt25s3bq1LPg4cuQIy5cvZ8CAASZfp7CwkJycnAofQgghhPBMFnVgPXfuHFqtlvDw8AqPh4eHs2/fPqP3PPTQQ5w7d46bb74ZRVEoKSnh8ccfr/KYZurUqbz22muWLE0IIYQQbsru1TRr167l7bff5pNPPmHbtm0sXryYX3/9lTfeeMPkPZMmTSI7O7vs48SJE/ZephBCCCGcxKKdkdDQUDQaDVlZWRUez8rKIiIiwug9r7zyCsOGDePRRx8F4IYbbiAvL49///vfvPTSS0ZHCvv6+uLr62vJ0oQQQgjhpizaGfHx8aFjx46kpqaWPabT6UhNTSUhIcHoPfn5+ZUCDo1GA4CiKJau16a+Sz/OlKW7OXnpilPXIYQQQtRmFk/tTU5OZsSIEXTq1IkuXbowc+ZM8vLyGDlyJADDhw8nKiqKqVOnAjB48GBmzJjBTTfdRHx8PIcOHeKVV15h8ODBZUGJMxRrdcz67RAnL13h6z+PcXv7RjzeqzmtwqsecyyEEEII27I4GBkyZAhnz57l1VdfJTMzk/bt25OSklKW1Hr8+PEKOyEvv/wyKpWKl19+mZMnT9KwYUMGDx7MW2+9Zbu/hRW81Cqm3XMDc34/zB+HzrN420kWbztJYtswxvRuTscmIU5dnxBCCFFbqBRnn5WYIScnh+DgYLKzswkKCrLNk+q0cGwjXM7ir/xQ5hyoS8qeLAzvRueY+ozp3Zw+rcNQqVS2eU0hhBCiFjH353ftDEb2LIWUCZBz6upjQY04nDCduadiWLTtH4q1+relTUQgj/dqzqAbI/HSyCgfIYQQwlwSjJiyZyn8MBy49q9duvtx/5dkRt3KvD+O8s2fx8gr0gIQVa8O/+7ZjPs7RVPHx3m5LkIIIYS7kGDEGJ0WZsZV3BGpQAVBjeCZnaDWkJ1fzNebjjFvw1HO5xUBEBLgw7+6xTA8oQn1/H2sX4sQQgjh4SQYMeboepg/qPrrRiyDpj3KPi0o1rJw6z/8d91hTlzQlwH7+2h4qEtjHunRlMjgOtavSQghhPBQ5v78rl1JEJezqr/GyHV+3hqGdW3Cmmd78+ED7WkTEUh+kZb/bThKz3fW8PzCvzh0JtcOCxZCCCE8n8WlvW6tbnj111RxnZdGzR3to7i9XSN+P3CWT9ceZtPRCyzc+g8/bvuH2+IiGNunBdc3CrbhooUQQgjPVruOacpyRk5TOYEVrs0ZMce24xf5dO1hVu25upvSt00YT/ZtQYfG9a1fqxBCCOHmJGfElLJqGqgYkFytpiH2doufdn9mLrPXHGLZ36fQlT5t9xYNeLJPS7o2C5FeJUIIIWodCUaqYrTPSBT0n2ZVIFLe0XN5fLr2EIu3naSkNCrp1KQ+T/ZtQa9WDSUoEUIIUWtIMFKdch1YqRsOTboZP5ox97pr/HMxn//8foQFW05QVKID4IaoYJ7s24J+bcNRqyUoEUII4dkkGLEFE51a6T/d7B2UrJwC5q47wjebjnOlWN9ArXV4IGP7tmDgDZFoJCgRQgjhoSQYqSkzOrVacqRz/nIh8/44ypcbj5FbWAJAs9AAxvRuzp03ReEtreaFEEJ4GAlGasLCTq2WyL5SzJcbM/jsj6Ncyi8GoHGIP0/2bcFdEpQIIYTwINL0rCaObawiEAFQIOek/joLBdfxZtwtLfljQl9eHNCG0Lo+HL+Qzws//k3ijN9ZuOUEJVqd9WsXQggh3IwEI8ZY2anVEgG+Xvy7Z3PWv9CXlwa0pUGAD8fO5/N8aVCyaOs/EpQIIYSoFSQYMaaGnVotUcdHw+iezVg/oQ+TbmtDSIAPGefzeXbhX/T7YB2Lt0lQIoQQwrNJzogxdujUaq68whK+TDvGf9cd5mJpTkmz0ACeuqUlg9s1kuobIYQQbkMSWGvKTp1azXW5sIT5GzOYu/5IWaJrs4YBPH1LSwbdKEGJEEII1yfBiC3YsVOruQxByX/XHSH7ij4oaRlWl2dvbU3S9eHS0VUIIYTLkmDEVuzcqdVcuQXFfPGHfqckp0Dfp6RddD1eSGpN9xahNnsdIYQQwlYkGHEkG3RqNVf2lWL+u+4w8zZklHV07d6iAc8ntaF9dD2bvpYQQghRExKMOIqNO7Wa60xuAZ+sOcw3m45RrNW/9q2x4TyX1JpW4YE2fz0hhBDCUhKMOIIdO7Wa68SFfGauPshP2/9Bp4BKBXfdFMX4xFZEh/jb5TWFEEIIc0gHVkewY6dWc0WH+PP+/e1Y8UxPkq4PR1Fg8baT9H1/LZN/3sXZ3EK7vbYQQghhCxKM1IQDOrWaq2V4IP8Z1omfx3bn5hahFGsV5qcdo9e7a/hw9UHyi0rsvgYhhBDCGhKM1IQDO7Waq110Pb5+NJ5vH42n3XXB5Bdp+WD1AXq/u5YFm4+j1bn8qZwQQohaRoKRmmjSTZ8TgqleHyp9X5Im3Ry5KgC6tQjlpye689GDNxEdUoczuYVMWLSTAR+uZ83+M7hBqpAQQohaQoKRmlBr9OW7QOWApPTz/tMqJq/qtHB0Pez8Uf9PndZ+y1OruL1dI1Yn9+LlgW0JruPN/qxcRn6+mWGfpbP7VLbdXlsIIYQwl1TT2IK5nVod2I/EmOz8YmatOcj8jcco0urKKm+eu7U1jerVsfvrCyGEqF2ktNfRquvA6qR+JMacuJDPuyv2s/QvfVDk66Vm1M1NGdO7OUF+3g5ZgxBCCM8nwYgrcYF+JMb8deISby/fy6ajFwBoEODDM4kteaBLY7w1coInhBCiZqTPiCtxgX4kxrSLrsf3/+7K/4Z3onnDAM7nFfHKz7vpP3Mdq/dkSZKrEEIIh7AqGJk9ezYxMTH4+fkRHx9Penq6yWt79+6NSqWq9DFw4ECrF+12XKgfybVUKhWJseGkPNOTN+64npAAHw6fzePRL7fw0NxN7DopSa5CCCHsy+JgZMGCBSQnJzN58mS2bdtGu3btSEpK4syZM0avX7x4MadPny772LVrFxqNhvvuu6/Gi3cbLtiP5FreGjXDEmJY+3xvxvRujo+XmrQj5xk8awPP/vAXp7OvOG1tQgghPJvFOSPx8fF07tyZWbNmAaDT6YiOjmbcuHFMnDix2vtnzpzJq6++yunTpwkICDDrNT0nZ+Q0lRNYwVk5I1X552I+763Yz5Id+uMlP281o3s047Fezanr6+Xk1QkhhHAHdskZKSoqYuvWrSQmJl59ArWaxMRE0tLSzHqOzz77jAceeKDKQKSwsJCcnJwKH27Nmn4kTnZdfX9mPnATP4/tTpeYEAqKdXz82yF6v7uWbzcdp0Src/YShRBCeAiLgpFz586h1WoJD694nBAeHk5mZma196enp7Nr1y4effTRKq+bOnUqwcHBZR/R0dGWLNM1xd6uL98Niqz4eFCjymW9DmyMVp120fVY8FhX5gztSEwDf85dLuTFn3Yy4CPp5CqEEMI2HLrf/tlnn3HDDTfQpUuXKq+bNGkSycnJZZ/n5OR4TkDSZmD1/Uic2BjNGJVKRf+4CPq2CeObTcf4MPUgB7IuM/LzzfRoGcqk29oS28gNj8+EEEK4BIuCkdDQUDQaDVlZFas+srKyiIiIqPLevLw8vv/+e15//fVqX8fX1xdfX19LluY+1Bpo2sP4n5lqjJZzWv+4AxujGePjpWZk96bcfdN1zF57iC/+yGD9wXNsOLSe+zpex7O3tiY8yM9p6xNCCOGeLDqm8fHxoWPHjqSmppY9ptPpSE1NJSEhocp7Fy5cSGFhIUOHDrVupZ5Op9XviBhNcC19LGWiU49sDIL9vXlxQFtWJ/di0I2RKAr8sOUfer+7lpmrD5BfVOLsJQohhHAjFpf2JicnM3fuXObPn8/evXsZM2YMeXl5jBw5EoDhw4czadKkSvd99tln3HnnnTRo0KDmq/ZELtoYrSqNG/gz66EOLH6iGx0a1+NKsZaZqw/S+921/LD5BFqd5JMIIYSonsU5I0OGDOHs2bO8+uqrZGZm0r59e1JSUsqSWo8fP45aXTHG2b9/Pxs2bGDlypW2WbUncuHGaNXp0Lg+i8Z0Y/nOTKal7OXEhSu8sOhv5v1xlJcGtqVHy4bOXqIQQggXJrNpXMXR9TB/UPXXjVhmOufEBRSWaPkq7RgfpR4kp0B/XNO7dUNeHNCWVuGBTl6dEEIIR5LZNO6mSTd91UylPiQGKgiK0l/nwny9NDzaoxnrXujDqO5N8daoWLv/LP1nrmPS4p2czS109hKFEEK4GAlGXIUbNkarSj1/H14dHMuq8b3of30EOgW+Sz9O73fX8HHqQa4UOT8RVwghhGuQYxpXY7TPSJQ+EHFiWW9Nbc64wJu/7uWvE5cAiAjy47mk1tx9UxRqtandICGEEO7M3J/fEoy4Ip226sZoll7nInQ6hV/+PsU7Kfs5eUk/eO/6RkG8NKAt3VqEOnl1QgghbE2CEU/ngp1azVVQrOWLjRnM/u0QuYX6JNe+bcKYdFsbWkqSqxBCeAwJRjyZqU6thtwSJ3dqNdeFvCI+Sj3I138eo0SnoFbBA10aMz6xFQ0DPbQDrxBC1CISjHgqnRZmxlXRIE2l3yF5ZqdLH9mUd+TsZaan7GPFbn0PlQAfDY/3as6jPZpRx8c9/g5CCCEqk9JeT+WGnVqr06xhXf4zrBM/PJZAu+uCySvS8v6qA/R+bw0Lt0gnVyGE8HQSjLgbN+7UWp0uTUP46YnufPTgTUTVq0NWTiHP//g3gz7ewIaD55y9PCGEEHYiwYi7qRtu2+tcjFqt4vZ2jUh9thcvDmhDoJ8Xe0/nMPSzTfzr83T2Z+Y6e4lCCCFsTIIRd+MhnVqr4+et4d89m7Pu+T6M7B6Dl1rfyfW2D9cxcdHfnMktcPYShRBC2IgEI+7G0k6tOq1+7s3OH/X/1LlX59P6AT5MHnw9q5J7cVucvpPr95tP0Pe935m77ghFJTpnL1EIIUQNSTWNuzKnU6sb9yIxZUvGBV5ftoe//8kGoFnDAF4dFEvv1mFOXpkQQohrSWlvbVBVB1YP6UVijE6n8OPWf3hnxT7OXS4CILFtGC8PjCUmNMDJqxNCCGEgwUht5oG9SIzJKSjmo9UH+WJjBiU6BR+Nmkd6NOXJPi0I8PVy9vKEEKLWkz4jtZkH9iIxJsjPm5cHxZLyTA96tAylSKvj07WH6fv+Wn7ecRI3iLOFEEIgwYhn8uBeJMa0CAvky1FdmDu8E41D/MnKKeTp73cw9LNNHDl72dnLE0IIUY1aG4xodVo2Z25m+ZHlbM7cjNbNqkyq5OG9SIxRqVT0iw1n5fiePNuvFb5eav44dJ7+M9fzwaoDFBR70L9fIYTwMLUyZ2T1sdVMS59GVv7VnYFw/3AmdplIYpPEGj+/05XljJymcgIreErOSFWOnc/j1Z938/uBswDENPDnjTvj6NGyoZNXJoQQtYfkjJiw+thqktcmVwhEAM7knyF5bTKrj6120spsyNJeJB6oSYMAvhjZmdkPdSAs0JeM8/kM+yydp77bLg3ThBDCxdSqnRGtTkvSoqRKgYiBChXh/uGk3JOCxhN+UJvTiwSqLhH2ALkFxby/8gBfpmWgUyDQ14vn+7dmaHwT1GpTnWyFEELUlJT2GrE5czOjVoyq9rp5SfPoHNHZ6tdxKdUFGh7YGM2UXSezefGnnWUN0zo1qc+0e26kRVhdJ69MCCE8kxzTGHE2/6xNr3MLag007QE33Kv/57WByA/DK5cB55zWP75nqWPXamdxUcH89ER3Xr/jegJ8NGw5dpEBH65n9ppDFGulrbwQQjhLrQpGGvqbl7xo7nVuTafV74gYTXAtfSxlotvNsqmORq1ieEIMK5N70bt1Q4q0Ot5dsZ87Zv3BrpPZzl6eEELUSrUqGOkQ1oFw/3BUJibeqlAR4R9Bh7AODl6ZE9SSxmimRNWrw+f/6swHQ9pRz9+bPadzuGP2H0xP2SdlwEII4WC1KhjRqDVM7DIRoFJAYvh8QpcJnpG8Wp1a1hjNGJVKxV03Xcfq5F4MvDESrU7h07WHGfDhejZnXHD28oQQotaoVcEIQGKTRGb0nkGYf8Upr+H+4czoPaNSnxGPbY5WCxujmRJa15fZD3XgP8M6Ehboy5Fzedz/nzTe+nWP7JIIIYQD1KpqmvK0Oi3bzmzjbP5ZGvo3pENYh0o7Ih7dHE0aoxmVfaWYt37dww9b/gGgRVhd3r+vHe2i6zl3YUII4YaktLeGDM3RlGt+UBuOc4ztorgdQzUNUDEgKT3Cuv/Lq+W9Ht6L5Fqpe7OYuHgnZ3ML0ahVjO3dnCf7tsTHq9ZtJgohhNUkGKmBWtUczZzGaLWoF0l5F/OKeHXpbn75S//3vr5REO/f3442EY4JiIUQwt1JMFIDta45WlW7HmW7J9d+mRjZPfFQy/4+xStLdnExvxgfjZrx/Vrx757N0Ej3ViGEqJJdm57Nnj2bmJgY/Pz8iI+PJz09vcrrL126xNixY4mMjMTX15dWrVqxfPlya17aIWpdczRTjdFqaS+Saw26sRErxvfkljZhFGl1TE/Zx31zNnL0XJ6zlyaEEB7B4mBkwYIFJCcnM3nyZLZt20a7du1ISkrizJkzRq8vKiqiX79+ZGRk8OOPP7J//37mzp1LVFRUjRdvL9IcrVQt70VSXligH/8b0Yl3772RQF8vth2/xG0frmPehqPodC6/uSiEEC7N4mBkxowZjB49mpEjRxIbG8ucOXPw9/dn3rx5Rq+fN28eFy5cYMmSJXTv3p2YmBh69epFu3btarx4e5HmaKWkF0kFKpWK+zpFkzK+J91bNKCgWMfry/bwwH//JEN2SYQQwmoWBSNFRUVs3bqVxMSrVSRqtZrExETS0tKM3rN06VISEhIYO3Ys4eHhxMXF8fbbb6PVmt7aLywsJCcnp8KHI1nTHM0j+5FILxKjourV4etH4nnzzjj8fTSkZ1yg/4fr+PwP2SURQghrWBSMnDt3Dq1WS3h4xR8+4eHhZGZmGr3nyJEj/Pjjj2i1WpYvX84rr7zC+++/z5tvvmnydaZOnUpwcHDZR3R0tCXLtAlLmqOtPraapEVJjFoxignrJzBqxSiSFiWx+thqRy/btpp001fNmNgh0vciidJfV8uoVCqGdm3Cimd60q25fpfktV/28MDcPzl2XnZJhBDCEhZV05w6dYqoqCg2btxIQkJC2eMvvPACv//+O5s2bap0T6tWrSgoKODo0aNoNPqdhBkzZvDuu+9y+vRpo69TWFhIYWFh2ec5OTlER0c7tM+IQXXN0Ty+H4klvUhqKZ1O4ZtNx5j6f/vIL9JSx1vDhP6tGZ4Qg1oqboQQtZhdqmlCQ0PRaDRkZVXMEcjKyiIiIsLoPZGRkbRq1aosEAFo27YtmZmZFBUVGb3H19eXoKCgCh/OolFr6BzRmQHNBtA5onOlo5lp6dMqBSJA2WPT06e795FN7O36gCMosuLjQY0kECmlVqsYlhDDimd60rVZCFeKtUz5ZQ9D/pvGgaxcZy9PCCFcnkXBiI+PDx07diQ1NbXsMZ1OR2pqaoWdkvK6d+/OoUOH0Ol0ZY8dOHCAyMhIfHx8rFy2a9h2ZpvJxmigD0gy8zPZdmabA1dlB7G3wzO7YMQyuOcz/T+f2Vk5ENFp4eh62Pmj/p/uHIRZITrEn28f7crrd1yPv4+GzRkXGfDheqan7ONKUe16L4QQwhJelt6QnJzMiBEj6NSpE126dGHmzJnk5eUxcuRIAIYPH05UVBRTp04FYMyYMcyaNYunn36acePGcfDgQd5++22eeuop2/5NnMCafiTmzMRxSYZeJKbU0i6t11KrVQxPiOGWtuFMWbqbVXuy+HTtYX756xSv33E9fdvUrmRfIYQwh8XByJAhQzh79iyvvvoqmZmZtG/fnpSUlLKk1uPHj6NWX91wiY6OZsWKFYwfP54bb7yRqKgonn76aSZMmGC7v4WTWNqPxGMH75nq0ppzWv94LTzOiapXh7nDO7FydyZTlu7mn4tXGPXFFm6Li+DVwbFEBtdx9hKFEMJlSDv4GjDMsDmTf8Zo3kj5GTZrTqzxzETXsum/ppqj1c7pv+XlFZbwUepB/rfhKFqdgr+PhvGJrfhX9xi8NTJ4TwjhuezaDl7omduPBPDcRFfp0lqtAF8vJg1oy7JxN9OxSX3yi7S8tXwvgz7awOaMC85enhBCOJ0EIzVkTj8Sj050lS6tZmsbGcTCxxJ4594bqe/vzf6sXO6bk8ZzC//i/OXC6p9ACCE8lMU5I6KyxCaJ9InuYzIx1aMH70mXVouo1Sru7xRNv7bhvLNiH9+ln+DHrf+wak8WL/RvzYOdG0tvEiFErSPBiI0Y+pEY49GD9wxdWnNOY3y6b2nOiKFLq06rP7K5nKUPUJp0q5W5JPUDfJh6943c1ymal3/axZ7TObz00y5+2PIP7993Iy3CAp29RCGEcBg5pnEAjx68p9boy3eBym3jSz/vP01/3Z6l+mTX+YNg0SP6f86M0z9eS3VoXJ+lT3Zn8uBY6vp68deJSwz8aAPzN2bgBrnlQghhExKMOIClg/fcbuieOV1aDeW/1ya7Gsp/a3FA4qVRM7J7U1Yn96JHy1AKS3RMXrqb4fPSycopcPbyhBDC7qS014GM9RmJ8I9gQpcJZWW9bt2LxNQRjJT/mk2nU/gyLYOp/7ePwhId9fy9mXb3DfSPi6z+ZiGEcDHm/vyWYMTBqurA6rFD946u1x/JVGfEsqq7vNYih87k8syCHew6mQPAkE7RvDo4lgBfSfMSQrgP6TPiokwN3vPooXtS/muxFmGBLB7Tncd7NUelggVbTjDwo/XsOHHJ2UsTQgibk2DERXh0LxIp/7WKj5eaibe14dtHuxIZ7EfG+Xzu+XQjs347iFbn8huaQghhNglGXIRH9yIxlP+aqCbS54xEXS3/FRUkNG9AytM9GXhjJFqdwnsrD/DAf9M4cSHf2UsTQgibkGDERXh0LxJLyn+FUcH+3sx68Cbev68dAT4aNmdcZMCH6/l203HZJRFCuD0JRlyER/ciAfPKf0WVVCoV93S8jv97uicdGtcjt7CEF3/aye2zNvDnkfPOXp4QQlhNqmlciKGaBqiQyGqqmqaqyhyXZU4HVunSWq0SrY75aceYufoAuQUlAHRsUp/RPZqS2DYcL5kGLIRwAVLa66bM6UVi6jq36UdSlT1LIWVCxZ4kQY30xzyye1LJ+cuFfLD6AD9s/ocirQ6AiCA/7u8czQOdo2lUr46TVyiEqM0kGHFj1e14eGw/EkOX1krlzaVHV3KcY9KZnALmp2XwXfoJLuQVAaBWwS1tw3llYCyNG/g7eYVCiNpIghEPpdVpSVqUZLIMWIWKcP9wUu5Jcf0jm/KkS6tNFJZoWbE7i2/+PMamoxcACPLz4vORnenYJMTJqxNC1DbS9MxDeWw/kmMbqwhEABTIOam/Tpjk66Xh9naNWPBYAquTe3JT43rkFJTwr883c+jMZWcvTwghjJJgxM14bD8S6dJqcy3CAvn20a50jqlPbkEJT323neLSvBIhhHAlEoy4GUv7kbjNBGDp0moXdXw0zH6oA/X9vdlzOodv/jzm7CUJIUQlMnXLzRj6kZzJP2N0jo0hZ6RDWAf3qrgxdGnNOU3lBFYoyxmRLq0WCwvy47mk1rz00y5mph7krpuuI9jf29nLEkKIMrIz4mY0ag0Tu0wEqNQgzfD5hC4TWHNiDclrkyvll5zJP0Py2mRWH1vtmAWby9IurTqtfhrwzh/1/3TVHR8XMaRTNC3D6nIpv5iv/sxw9nKEEKICCUbcUGKTRGb0nkGYf1iFx8P9w5nRewZ9ovu45wRgc7u07lmqr7yZPwgWPaL/58w4/ePCKC+Nmif7tgDg8z8yKCh2sX/3QohaTUp73ZipfiSbMzczasWoau+flzSPzhGdHbBSC1XVgVV6kVitRKuj17trOXnpCm/cGcewrk2cvSQhhIcz9+e35Iy4MY1aYzSYcPuKG7UGmvao/LhOq+/OajSnRAFUkDIR2gyUXiRGeGnUPNqjKa/9socvN2YwNL4xKpWpScpCCOE4ckzjgTx2ArD0IqmxezpeRx1vDQfPXCa9tCmaEEI4mwQjHshjJwBLL5IaC/Lz5s6bGgHw9abjTl6NEELoSTDigcytuDG0i5deJLXLw/H6XJGUXac5m1vo5NUIIYQEIx6ruoobQ5+R1cdWk7QoiVErRjFh/QRGrRhF0qIk1yv9hau9SEzs+Oh7kURJL5JqxEUF0z66HsVahR+2nHD2coQQQqppPF1VE4DdcvpvWTUNVExklWoaS/y49R+eW/gXUfXqsO6FPmjUksgqhLA9GZQngKsVNwOaDaBzROcKRzMe3YtEmqJVadCNkdTz9+bkpSv8tu+Ms5cjhKjlpLS3lrJk+q/L9SKJvV1fvltVL5KUCRUrb4Ia6Tu8yq4JAH7eGoZ0juY/vx/hy7QM+sVKno0Qwnms2hmZPXs2MTEx+Pn5ER8fT3p6uslrv/jiC1QqVYUPPz8/qxcsbMPSXiQul+Rq6EVyw736f17bFO3aEuCc0/rHpUtrmaHxTVCpYP3Bcxw+e9nZyxFC1GIW74wsWLCA5ORk5syZQ3x8PDNnziQpKYn9+/cTFhZm9J6goCD2799f9rk0WnI+S3qRuM3APWmKZpHoEH9uaRPG6r1n+CrtGFNuv97ZSxJC1FIW74zMmDGD0aNHM3LkSGJjY5kzZw7+/v7MmzfP5D0qlYqIiIiyj/Bw2RJ2NnN7kVwsuOg+A/ekKZrFhifEAPqE1tyCYucuRghRa1kUjBQVFbF161YSE6/+NqxWq0lMTCQtLc3kfZcvX6ZJkyZER0dzxx13sHv37ipfp7CwkJycnAofwrbM6UXyfOfneWfzO+6T5CpN0Sx2c4tQmjcM4HJhCV+mHXP2coQQtZRFwci5c+fQarWVdjbCw8PJzMw0ek/r1q2ZN28eP//8M19//TU6nY5u3brxzz//mHydqVOnEhwcXPYRHR1tyTLNotUppB0+z887TpJ2+DxanctXONtcdb1I6vvVNzvJ1SVIUzSLqdUqxvVtCcDc9Udkd0QI4RR2r6ZJSEggISGh7PNu3brRtm1b/vOf//DGG28YvWfSpEkkJyeXfZ6Tk2PTgCRl12le+2UPp7MLyh6LDPZj8uBY+sdFVnGn50lskkif6D5Ge5EsP7LcrOdwmYF7hqZoOacxnjei0v+5NEWrYHC7RnyUepAj5/KY8/thnk9q4+wlCSFqGYt2RkJDQ9FoNGRlVfxtOSsri4iICLOew9vbm5tuuolDhw6ZvMbX15egoKAKH7aSsus0Y77eViEQAcjMLmDM19tI2XXaZq/lLkz1InG7gXtqjb58F6jcpbX08/7TriavSi8SADRqFS/01wcg//n9CHtPy7GoEMKxLApGfHx86NixI6mpqWWP6XQ6UlNTK+x+VEWr1bJz504iIx2/A6HVKbz2yx6TtRYAr/2yp1Ye2RjjlgP3zG2KtmcpzIyD+YNg0SP6f86Mq7Wlv/3jIki6PpwSncJjX201e2aNTqeQfaWYrJwCCoprZzAnhKg5i49pkpOTGTFiBJ06daJLly7MnDmTvLw8Ro4cCcDw4cOJiopi6tSpALz++ut07dqVFi1acOnSJd59912OHTvGo48+atu/iRnSj16otCNSngKczi4g/egFEpo3cNzCXJQhyTV5bTIqVBUSWU0N3DPVet6hzGmK9sNwKh3lGHqR1NKW8m/ddQN7Tudw/EI+d87+gzfuvJ5ercLKWsXnF5Ww93QOu07msPd0DnszczmQmcuVckFIeJAvCc0aMOjGRvRu3RAvjTR5FkJUz+JgZMiQIZw9e5ZXX32VzMxM2rdvT0pKSllS6/Hjx1Grr34DunjxIqNHjyYzM5P69evTsWNHNm7cSGxsrO3+FmY6k2s6ELHmutrAkORqrM/IhC4TKgzcc6leJIamaNeSXiQmhdb15ctR8Yz8PJ2M8/mM+mILAT4aQgN9uVxQwvm8IpP3atQqtDqFrJxCluw4xZIdp4gM9uPxXs15oEs0vl61670UQlimVg3KSzt8ngfn/lntdd+N7io7I9fwmIF7R9frj2SqM2KZ8WCmFsgpKGbWb4f4btNxcgtLKvxZeJAvcY2CaRsZRNvIINpEBnJd/Tr4aNTkFJSw+1Q2v+09w+LtJ7lQGrxE1avDC/1bc3u7RtLwUIhaxtyf37UqGNHqFG6e/huZ2QWmai2ICPZjw4S+ZVvTWp1C+tELnMktICzQjy5NQ2TCaTlanZakRUkmS4BVqAj3DyflnhTnHNlca+eP+hyR6tzzmb7VfC1WotVx5FweuQXF+Pt4ER7kR0iAj1n3FpZo+WHLP8z67SBZOfr8k4RmDXjjzutpERZoz2ULIVyIuT+/a9WgPI1axeTBsYz5ehsqjA6gZ/Lg2LJgQ0qAq+d2A/ekF4nZvDRqWoVbFzj4emkY1rUJ93W8jv+tP8KsNYdIO3Ke2z5cz/h+rXisZ3MJ6oUQZWpddln/uEg+HdqBiOCKw/oigv34dGiHsiBDSoDNY+nAPacz9CIxUSGk70USJb1IbMTPW8OTfVuyanwvbmkTRrFW4Z2U/Tw0909OXrri7OUJIVxErdoZMegfF0m/2AiTxy/VlQCr0JcA94uNqPW/3Vnai8TpFTeGXiQ/DAdT+2OGXiQ6remKHGGR6BB//jeiEwu3/sOUpbvZdPQCgz5azycPd5T8LCFE7QxGQH9kY+qboJQAm8/Qi+RM/hmjM2wMOSMdwjq4TsWNoRdJyoSKg/WCGukDkdjb9eW/Rv98eq0s+7UFlUrF/Z2i6RITwrjvtrPzZDbDPtvElNuvZ2jXJs5enhDCiWpVAqu5ft5xkqe/31HtdR8+0J472kfZfT2uzlBNAxjtRTKj9wwA16u4MbXzYaoPiWHnpJb2IbGlgmItz//4N7/8pQ/2HuvVjIn920i1jRAextyf37UuZ8QcYYF+1V9kwXWerrqBe32i+zAtfZrrTf819CK54V79Pw1HM1X2IUHfh6SWto63FT9vDR890J7nbm0F6NvQv7xkFzrpfixErVRrj2mq0qVpCJHBftWWAHdpGlL2WG0vAa5q4N7mzM3uU3FzbGPFo5lKFMg5qb+ulvYhsRWVSsWTfVsSEuDLS0t28s2m41wp1vLeve1Q16L/doQQEowYJSXA1jEM3LuWW1XcXDYdNFWwt3SGjSS11thD8Y0J8NXw7A9/sXjbSXy9NLx9V5wc2QhRi8gxjQn2KgHW6hTSDp/n5x0nSTt8vlYM5XOr6b/m9hdJ/2+tH65nS3e0j+KDIe1Rq+C79OO89ete3CCdTQhhI7IzUgVblwDX1h0USypunM7QhyTnNMbzRq5Ry4fr2dLgdo24UqTlhUV/878NR/H39SK5XytnL0sI4QCyM1INQwnwHe2jSGjeoEIeiCUlwLW5iZph+i9crZ4xMDX9d3PmZpYfWc7mzM2OTWw19CEpXV31FP3HsvFQYnqQnDDP/Z2jmTxYP0Tzo9SDzF13xMkrEsI9/f3PJaYu3+s2SeGyM1ID5k73zcy+wjsr9tfqJmpuNf3XVB+SquSfgxltYdAHskNSQyO7NyWvsIT3Vh7greV7qevnxYNdGjt7WUK4vKISHf+36zRfbMxg+/FLAHRvEUrPVi5wBF4NCUZqwNzS3gt5RdJEjaorbsD09N8z+WdIXpvs2F4ksbdDm4H6qpm9S/U5ItXJPydHNjYytk8LcgtL+M/vR3jxp50E+Hpxe7tGzl6WEC7pQl4R3246xpdpxziTqx9M6a1RMfCGyEp5j5W4SKdpCUZqwNwS4JC6vmY9n7k7Le7MVMWNVqetsheJChXT06fTJ7qP49rHG/qQgHnBCAAK/PIU+AVDzM1SaWMllUrFxP5tuFxQwjebjpO8YAd1fTX0bSMDDIUw2J+Zy+d/HOWn7ScpLNEBEBboy8PxTXgwPrr6X5hdqNO05IzUgKEEGCpnF5QvAY4IkiZq1bFk+q/DVTtc7xpXLsKXt0ulTQ2pVCreuCOOO9o3okSnMObrbaQdPu/sZQnhVDqdwm/7shj6v00kzVzH95tPUFii44aoYGYOac+GCX15OrGleYHID8MrH0UbkvId/L1LgpEaMqcE2LCDUsWcWCLLNVGrjeW/Lt2LpEJSqwWc9B+1J1GrVbx3XzsS24ZTWKLj0fmb2Xb8orOXJYTD5RWW8FVaBokzfmfUF1vYcOgcahUMuCGCHx9PYOmT3bnzpih8vMz4se6CnablmMYGqisBtqSJWm0t/3X56b+GpNZlz0C+ub+dl/6bXjYeWvUHLx97rc6jeWvUzHroJkZ9sZmNh8/z8NxNfPJwB/q0Cav+ZiHc3MlLV/hyYwbfpR8np6AEgMDSpO7hCU24rr6/+U9myA85+rvLdZqWQXkOVF2gYSj/NTGerUKzNU+j1WlJWpRUbS+SlHtSWHNijfMqbkqK9FUz+ecsu88/VCptaiivsIQx32xj3YGzaNQqJt3WhlHdm0rreOGRth+/yP/WHyVld2bZ7njT0ABGdo/hng7XEeBr4V6CsfyQ6tzzmX52Vw2Y+/NbghEHMzXDRqtTuHn6byarbgzJsBsm9PXY8l+3mf5bNtVXv1KL3P+VBCQ1UKzV8eLinSzc+g8APVqGMnlwLC3CAp28MiFqTp8Pcob/rjtCesaFssdvbhHKqJtj6N0qzLrg2+Qk8mqMWFbjnREJRtxM2uHzPDj3z2qv+250V48u/zXWZyTCP4IJXSbQJ7oPSYuSTCa6lt89sXvFjTW/ZQDUCYHnD0mVTQ0oisLXfx7jzV/3UliiQ62CxLbh3Ncpmt6tG+KtkVQ44V4KS7Qs2X6S/647wuGzeYC+NPfO9lE80qMpbSJq8HNPp9Un01v0vUqlT9p/ZmeNv1eZ+/NbckZchLllvZ5e/us2038NfUiOrocf/6WvoDHHlQvw+zvQZ5Jdl+fJVCoVwxJi6NYilOn/t4+Ve7LKPkLr+nDXTVEM6RwtuyXC5WXnF/P1pmN8sTGDs6X9QQL9vHg4vgkju8cQbmYlZpWqnUR+rdKdl/7THPpLkwQjLsLcst7aUP7rNtN/1Rpo3hsGf2TZFujv0yGsLVx/px0X5/maN6zLf4d34kBWLgu3nOCn7Sc5d7mIueuPMnf9Ue7uEMWk29rSMNC8Pj9COMo/F/OZtyGD7zcfJ79IX7ESGezHIzc3ZUjnaAL9vGv2AuUbmZ3ZZ9m9QY30gYiDj5MlGHER5jZQM5T/gun8E0/lstN/La60UWDhCDj7IvR8To5saqhVeCAvDYzlhf5tWLv/LAs2n2D13iwWbzvJugNnmTnkJm5uGersZQrB7lPZ/HfdEZb9fbosKbVNRCCP9WrGoBsb2eaI0doj5B7PQ7NeTuvAKjkjLsRQTQPGy3/LV9PUxhJgSypuHNaltbySIninGRTlmn+Pk7oderodJy4x4ce/2Z+Vi1oFr90Rx7CuTZy9LFELKYrCpqMXmL3mEOsPXq3C696iAY/1bE6PlqGoVDb6JdKqRFXb5YcYIwmsbsqcIMOSEmBP2z0xp+ImsUmi4/uQGKydDmvftvAmlcyzsYOCYi2vLNlVVnkztk9znru1te2+8QtRBUVRWLv/LLPWHGLrMX1OmUatnxfz757NiIsKtu0LWpuoCnb9/iPBiBurKoCwpAR41Z5Mj9w9qariJrFJonMn/+q08G4LfaKq2ez7m0ltpigKH6Ue4oPVBwAYkdCEyYOvl94kwm60OoX/23Wa2WsOs/d0DgA+Xmru73Qdj/VsTnSIBU3KzFG+kdm6dy27NyjK7vkhEox4KHNLgMcntmLm6gMe20DN1M6Hqcm/ju9DMszy+5LehvjHJSCxg282HePlJbtQFHiwSzRv3XmDBCTCpoq1On7afpI5aw9z5Jy+PNffR8PQrk149OamhNmiMuZa1uSH9HweGrZx2IReCUY81M87TvL09zuqva5eHW8uXSk2+mee2kDNkFPiEn1Idi2BRSNB0Vl2n+SQ2M2PW//hhR//QqfA3R2iePfedh719S+co6BYy4LNJ/jvuiOcvHQFgOA63vyrWwz/6hZD/QA7jYFwYiMzS0ifEQ9lbmmvqUAE9F+6p7MLSD96waMaqFky+dfufUji7tRHfQtHWHafYbie5JDY3L0dr8NboyL5h79YvO0kxVqFGfe3kyZpwip5hSV8mXaMzzYc4dzlIgBC6/oyukdTHu7ahLqWtmu3RJWD7kwpPQ5u0s1eq6oRCUbcjDklwMFV7IqU52kN1FyuD8n1d4LqK/i/FyD3tJk3yXA9e7qjfRS+XmrGfbedX/46RXGJjo8evMm8SadCcDUI+e+6w1zM13+fjapXh8d7NeO+TtH4edtp17V875DLWW7RyMwSVv0XOHv2bGJiYvDz8yM+Pp709HSz7vv+++9RqVTceeed1rys4OoEYLia/2Fg+Hxk9xiznsvTGqhZM/l3c+Zmlh9ZzubMzWjtMS479nYYvxt6v2jZffnn9AP59iy1/Zpquf5xkcwZ2hEfjZqU3Zk8/vVWCoodNypduKe8whI+XXuYm6f/xvSUfVzMLyamgT/v3nsja5/vzbCEGPsFInuW6itl5g+CRY/ACgu/nwQ1cvndVotzRhYsWMDw4cOZM2cO8fHxzJw5k4ULF7J//37CwkyP9M7IyODmm2+mWbNmhISEsGTJErNfU3JGKquqBLhfbAQ3T/+t2gZqhpwRTyn/dfnJv9Y2I+otzdHsYd2Bs4z+cguFJTp6tAzlv8M6UcdH3mNRkbGdkJgG/ozr25I72jfCy97HfNbmhoDTG5mBHRNY4+Pj6dy5M7NmzQJAp9MRHR3NuHHjmDhxotF7tFotPXv2ZNSoUaxfv55Lly5JMGIDVQUR5jZQ87TmaS4/+VenhU1zrPvNRhJbbS7t8Hkemb+Z/CItXZuF8NmIzpaPZhceyelBCFjZOwRcqV2AuT+/LXo3i4qK2Lp1K4mJV79Rq9VqEhMTSUtLM3nf66+/TlhYGI888ohZr1NYWEhOTk6FD1GZRq0ioXkD7mgfRULzBhV2M/rHRfLp0A5EBFc8iokI9qsQiIz5elulniWZ2QWM+XobKbvMzXNwHYlNEpnRewZh/hV36cL9w5nRewZ9ovswLX2a0Z0Tw2PT06fb58gG9N8Y4h/Xf6OodNBWhZxT+nLhXUvss65aKqF5A74c1YW6vl78eeQCI+alk19U4uxlCScydRzz/n3tWJ3ci3s6XueYQASsGHIH7pAfYoxFvwKcO3cOrVZLeHh4hcfDw8PZt8/4MJ4NGzbw2WefsWPHDrNfZ+rUqbz22muWLE0Y0T8ukn6xEUZ3T7Q6hdd+2WN0409B/+X82i976Bcb4XZHOS4/+Vet0e9y/DDc8nsXjdT/y5EhezbTKSaEbx6NZ/i8dLYcu8i4b7fzn2EdHfcDR7iEgmIt32w6zidrDnE+T18d4/CdEKjZkDtw2qC7mrLrfmRubi7Dhg1j7ty5hIaaP6hq0qRJJCcnl32ek5NDdHS0PZbo8Qy7J9dKP3rBZBdXqFj+m32lyO2Oclx+8q/Fw/VKKTp9ubDqK7f7ZuPK2kXXY96/OvPQ3D9J3XeGyUt38+adcdI6vhYo0epYtO0fPlx9kFOl3+OaNPDnKUcHIWB9XlnS2/omZg5qZGYPFgUjoaGhaDQasrIq/maZlZVFREREpesPHz5MRkYGgwcPLntMp9M3gfLy8mL//v00b9680n2+vr74+srYb3syt6x31Z5MPv8jo9IOiuEox906uVpScWP3+Taxt+vLd2e01VfPWOKXp6HNQLf8puOqOjapz4cPtGfMN9v4ZtNxmjWsyyM3N3X2soSd6HQKv+48zYxVBzha2jE1IsiPpxNblvakcfDOWE2G3HlA52aLghEfHx86duxIampqWXmuTqcjNTWVJ598stL1bdq0YefOnRUee/nll8nNzeXDDz+U3Q4nMresd8mOU2Yf5biDDmEdCPcPr7bi5mLBxUrdXO1SbePlA4M+sPyb0JULsO496D3BdmsR9I+L5MXb2vLW8r289esemoUG0KeN6SpB4X4URWHN/jO8u+JA2eyYkAAfnujdnKFdm9ivPLcq1jYxA7fLDTHF4tAvOTmZuXPnMn/+fPbu3cuYMWPIy8tj5MiRAAwfPpxJkyYB4OfnR1xcXIWPevXqERgYSFxcHD4+0tDJWQzN00yFECogJMCbC6Vnp8aUP8pxFxq1hold9FVfqmv+9obPb2t6G8/9/lyl3JIz+WdIXpvM6mOrbbsow5FNoIU7TBs/hhLT/36EdR7t0ZQhnaLRKTDuu+3sz8x19pKEjfx55Dz3zklj1Bdb2Hs6h0BfL5L7tWLdC314tEczxwciOi0cXQ9rp1p+NOMGvUMsYXHOyJAhQzh79iyvvvoqmZmZtG/fnpSUlLKk1uPHj6NWS+KXqzM0Txvz9TZUGC//vat9FJ/9kVHtc7lbJ1dDxY2xPiPPd36edza/Y7LaRoWK6enT6RPdx/ZHNm0G6nc71r5t3j1FufojnkEfeMw3JFegUql44844Ms7nsenoBR6Zv5klY7sTWleOjt3VnlM5TP2/vaw/qD8O9fNWM6JbDI/3bG6/2THVLsr1h9w5kgzKq+Wq6jMSXMfHrAnB343u6pYzbozlhGw7s41RK0ZVe++8pHn2q7bZtQR+/Bfmb9mqPOo3JFdxMa+Iuz75g4zz+XRqUp9vRsfj6+U53/xrg1OXrvDeyv38tP0kigJeahUPdmnMk31bEG6PKbrmcpMhd7Ygg/KEWaor/61uDk5EsP56qLoJmysyVnFjbhXNqoxVALZPagX9kL2zE+D3aWbeoMAvT4FfMMTc7FG/LTlT/QAf/jeiM3d98gdbjl1k0qKdvH9/O6mwcQM5BcV8uvYw8zYcpbBEXzQxuF0jnr+1NY0b+Dt3cR445M4WZGdEVKm2dXLdnLnZrJ0Rg/q+9RnUbBB9GvexbWCi08K7LfSJqpaQTq02t+HgOUZ8no5Wp/BU3xaM79dKAhIXVVSi45tNx/go9WBZ19T4piG8OKAt7aLrOXdxBkfX62fMmK30a81Ndz/t1g7eGSQYca7qAg1DwHLtF9K1AYs7qG6+TVVsXm1Tk5kUMs/Gpr768xivLNkFwD0drmPK7bEE+nk7eVXCQFEUlu/M5J0V+zh2Ph+AFmF1mdi/Dbe0DXN+8HhtI7P175p/b1CUWzYxM5BgRNiUqSMYrU7h5um/mWyg5o5D+UzNt6mOXWbb7FlqeWM0A9klsan5GzN47Zfd6BRoGOjLozc35f5O0c5LgBQAbD12kTd/3cP245cACK3rS3K/VtzfyYFt26tibSMzFxhyZwsSjAiHSDt83uwkV3fq5Lr62OpK1TbmKD8Z2GZHNiVF1jVGK12Ru27vuqKNh87x0pJdZU2yfL3U3NPxOkZ1b0qLsLpOXl3tcjr7CtP+bx8/79D/kK/jreHfPZvx757NXGfYYU0ambnAkDtbkGBEOMTPO07y9Pc7qr1uVPcYo51cXfkox1BtsypjFd/t/86ie1/o/AIPtXnIdgFJ2Tc1sPjYxj8UkvfqG6yJGiss0fLz9lPMT8tg9yl90yy1Ckb3aEbyra2k4sbOrhRp+e+6I3z6+yEKinWoVHBfx+t47tbWhDmzQuZaVk3cde/8EGMkGBEOYe7OSEiAj8kGatce5bgaS5NaDWye3Grtdi/oAxLpR2JTiqI/cpy7/gir954B9M0E/zusI/X8JfCzNUVRWPb3aaYu31s2Q6ZzTH0mD76euKhgJ6/OCIsTVXH7/BBjJBgRDmHIGamq/Ld+gDcX8oqrfS5X7VdSk6RWA5sltxo6Nv74L7hy0fL775cBe/awak8WyQt2kFtYQpuIQBb8O4Fgf0lwtZWd/2Tz+rLdbM7Qf81H1avDpAFtGHhDpPOTU8uzJlHVgxuZgfk/v10gu0e4M0MnV6BSa/nynVzN4aqdXMu3kLdWVn4W49eOr3krebUGmveGwR9R+R03w5InpIW8HfSLDWfhmARC6/qyLzOXEZ+nc7mwxNnLcntncwt54ce/uH32BjZnXKSOt4bkfq1IfbYXg25s5FqByJ6l+mOZ+YNg0SPmV8w07QU33KtvZuZhgYglJBgRNdY/LpJPh3YgIrjieW1EsB+fDu1AYmzlic7GmDu8zxkMLeTD/cNr9DyvbXwNrU5b8wVZO8+mKBfebab/xilsqk1EEN88Gk89f292nLjE419tpai04ZawjFan8GVaBn3fX8sPW/5BUeDO9o347blePHVLS+cMs6uKIafL0vyQoCiPbmRmCTmmETZTXflvdZ1c3aH815DUuub4GpYdWcbFQsuPSsa0G8MT7Z+wzYJ0Wsvm2ZSRKht7+evEJR6c+yf5RVoGt2vEh0Pao3aRr193sO34RV5ZsqssOfiGqGCm3H49HZvUd/LKTJBE1SpJzohwKZ7YyVWr0/Ltvm95Z/M7Ft/7cNuHuaXxLbbr2mpNPxKpsrGb9QfPMuqLzRRrFf7VLYbJg2Nd60jBBV3MK2J6yj6+33wCgCA/L57v34aHujR2mV9GypTPDbmcBStetOx+D0xUNUWCEeFyPLGTa02TW23atbWkCN5ppj+KMZdU2dhN+bL355NaM7ZPC+cuyEXpdAoLtpxgeso+LpW2cL+nw3VMGtDGNSclW1vV5uGJqqZIMCJckq06uboSQ8dWa4IRm3dtXTtdjmxcyOd/HOW1X/YAMO3uG3igS2Mnr8i17DqZzctLdrHjxCUA2kQE8sadcXSOCXHuwkypyYgGN5y4awtSTSNckkatIqF5A+5oH0VC8wZlgUX60QsmAxHQ/6d/OruA9KP6wXFanULa4fP8vOMkaYfPo9U5L6auSXKrIYCZnj7dNomtPZ+DOlZ8I0+ZqN96FjY1sntTnujdHIAXf9rJsr+t6BHjgfIKS3hj2R5un7WBHScuUdfXi5cHtmXZuJtdNxCxatouSKKqeVykZ66o7cwt6z2TW+CSeSWJTRLpE92HLVlbeOq3p8gvyTf7XgWFzPxMvt33bc27tqo1MPhD+GGYBTcpkHNSfwZeC39zs7fnk1pz7nIhP2z5hye/3c7hM3mM69ui1ia1rt1/hpd+2sXJS1cAGNyuES8PbEu4K3VPNebYRisaDpb+O+4/rdYcy1hLdkaESzC3rDfjXD5jvt5WaRclM7uAMV9vI2XXaXsszywatYb4yHjeuvktq+5/Z/M79PmhD++kv8PmzM3W75TE3q5vblbHwuqDXOe9d55MpVLx9l038K9uMQB8sPoAD879k2Pn85y7MAe7kFfE+AU7+Nfnmzl56QpR9erw+cjOfPzgTa4diBgaDe61ohw+qJEcgZpJckaESzCn/Dc8yBdQkZnj+nklKzNW8vy659Ep1veZqHFyq6Hsd+NHUHS5+uslmdXufth8gim/7Ca/SEsdbw1jejdndI9m1PHx3N+aFUVhyY6TvP7LHi7mF6NSwchuTXn21lauM9DOFGuSVZPe1iep1rJEVVMkgVW4nerKf59JbMkHqw9W+zyu0lZ+ZcZKnv392Ro/z9h2Yxl942jrj2/Mnvpbe3ofONPx8/lMWPQ3aUf0ZdgRQX48n9Sau26K8rijmxMX8nlpyS7WHTgL6BNUp91zI+2j6zl3YeawOFnVs6bt2ooksAq3U10n15jQALOex1Xayt8acysf9P6gxl1bZ/81m6RFSda3kvfy0e94VNs+vvSbriSz2lXjBv58Ozqejx+8ievq1yEzp4BnF/7F3Z9u5O9/Ljl7eTahK+2gmjRzHesOnMXHS83zSa35ZdzN7hGIWJysKrkhNSU7I8LlmCr/NXdCsKvsjBjYomurwfu93ufWmFutu9mSxmi1tAzR0QqKtXz+RwazfjtIXpEWlQoejm/MSwNiLTq6WXfgLO+v3E9BsY6xfVtwe7tGdlx11TLO5TFh0d9sKq186xITwrR7bqBZw7pOW5PFLJ24W4uamFlKjmmEx7GkrTzgki3la9K1FUCtUvNuz3etD0j+/gEWj67+uns+0w/vEg6RlVPA28v38vMOfW5Cy7C6fPJwB1qGB1Z779//XOKeTzdSrL36X8VXj3ShR8uGdluvMVqdwhcbM3h3xT4KinX4+2iY0L8Nw7o2cY/jJ2sm7nb5N7S9XXJDqiDBiPBI5rSVB1yu9Le8mnZtBfig9wfWJbaa+xuf7Iw4xYaD5xj/ww7O5hYS6OvF/0Z0Ir6Z6V2+y4UlDPpoPRnn8+nduiHBdbz5eccp2kYGsfypmx3Wgv7w2cu88OPfbD2m3/Xr1rwB0++5kegQf4e8fo1Z21VV/jupluSMCI9UXV4J4LKlvwYatYaJXSbW6Dmsnv7bpJs+yc5k/og0aHKmm1uGsvypHnSJCSG3sITh89JZu/+Myesn/7ybjPP5NAr248MhN/Ha7ddTx1vD3tM5ZQ0C7UlRFP63/ggDPlzP1mMXCfDR8NZdcXzzaLx7BSIycdfpJBgRbqd/XCQbJvTlu9Fd+fCB9nw3uisbJvSlX2wEr/2yx+heg+Gx137Z49RurQY16doKcKnoElM2TrE8IFFroP/00k+uDUgkCc8VNAz05ctHupDYNozCEh3//nIra4wEJD/vOMmibf+gVsHMB24i2N+bev4+DLpRv/v36077Bt4X84p4dP4W3vx1L4UlOnq0DGVlci8ejm/iPkMBreqqKv+d2IMEI8ItGWsr724t5RObJLLinhXMS5rHsLbDqOdTz6L7lxxeYl2VTezt+vLdoGuOrKRBk8vw89bw6dCOJF0fTpFWx2NfbmXNvqsBybHzebz00y4AxvVtSZemV1uoD7hB/+91xe5MdHb6mt567CIDP1pP6r4z+HipeeOO6/lyVBei6tWxy+vZjTVdVeW/E7uQnBHhMcpPSa3Khw+0x9dL7XJ5JVqdlrk75zJ7x2yL7x3Wdhh9GvehQ1gH8/uRlE/YkwZNLqlYq2Pct9tJ2Z2Jj0bNJw93oGOT+jw490/2ZebSOaY+343uipfm6u+VhSVaOry+irwiLcuf6kFsI9t9z9TpFOauP8K7K/ZTolNoGhrArIdu4vpGwTZ7DbuzJlG1lk7ctQVJYBW1jrmlv+MTWzFz9YFKG7Plk2Cdmei6MmMlz/3+nFXJrTXu2ipcTrFWx1Pfbef/dmUC4KNRU6TV0TDQl1+evLlS/hTAyM/TWbP/LC8PbMujPZrZZB0X84p4duFf/Fa6QzO4XSPeviuOQD9vmzy/Q0iiqsNJAquodbo0DSEy2K+q1Ewignz5Lv24S+eV3BpzK4+3e9yqe7Pysxi/djxzdsyxzRRg4XTeGjUfPXgT93W8DpUKirQ6mjUM4JtH440GIgDdmocC+gDdFv48cp7bPlzPb6XHMm/fdQMfPdDe/QIRSVR1WRKMCI+hUauYPDgWMJmayYNdGpucbQMV80qcmVPy2I2PEexr/dZ3jbu2CpfirVHz7n3t2DTpFlaO78mq8b1oVUUPEkPTv01HL1CitX4+0uXCEqb93z4enPsnmTkFNGsYwJInuvNQfGP3SVIFSVR1Ay4+pUgIyxhKf6/NB4kozQcpLDHvG/OqPZkk/7DDaTklGrWGKQlTSF6bbHUvEsMuiVmzbSR/xC2EBfkRZsaE29jIIILreJN9pZi/T2bTobFlE5xLtDq+33yCmasPcO5yEQD3d7qOKbdfj7+PG/7YsDZRVbqqOozkjAiPVNOW8sY4I6dk9bHVTN00lTNXTPeaMEeVuSTGztGDGulLgOUbsdt67KstrNidxfNJrRnbp4XZ9/1+4Cyv/7Kbw2fzAIhp4M+kAW1Juj7CXku1D0lUdQl2zRmZPXs2MTEx+Pn5ER8fT3p6uslrFy9eTKdOnahXrx4BAQG0b9+er776ypqXFcJsxkp/ofq8EgBTnaudkVOS2CSRlfeuZGz7sTV6HsMuSaVjG1Pn6Dmn9Y/vWVqj1xXOk1DaufXPI+bljRSWaHlu4V+MmJfO4bN51Pf3ZsrgWFaO7+V+gciepTAzTt9teNEj5gUiAE176ccgNO0hgYiDWRyMLFiwgOTkZCZPnsy2bdto164dSUlJnDlj/De3kJAQXnrpJdLS0vj7778ZOXIkI0eOZMWKFTVevBCWMievpKo449peJY6gUWt4vN3jNpkA/PKGlykq0W+7V32Orug/lo0Hw/XCrSSUJrFuybhIUTXHk8VaHY/O38KPW/VN1EZ1b8rvL/ThX92b4uPlZqmFkqjqliw+pomPj6dz587MmjULAJ1OR3R0NOPGjWPiRPNaXHfo0IGBAwfyxhtvmHW9HNMIW0vZddpon5EBcRF89kdGtfcPT2hCUmwEqODc5UKHDeMrPwH4q73W7TAGeAfwZvc3SdT5mjenxicQuo2Dns/Jb4tuRFEUOr25mvN5RSx8PIHOMSEmr5388y7mpx0jwEfDnGEdHT5kz2Z0Wv2OiKWBCEgjMzsx9+e3RZlIRUVFbN26lUmTJpU9plarSUxMJC0trdr7FUXht99+Y//+/UyfPt3kdYWFhRQWFpZ9npOTY8kyhahW/7hI+sVGVMorST96waxg5Mu0Y3yZdqzCY45IcNWoNXSO6EzniM50CO9gVT5JXnGePrE1ojejgWrDi6JcWPs2bPwYbp8FcXdauXrhSCqViq7NGvDrztOkHT5vMhj5+59LzC/9Wv7wgZvcNxABSVR1Yxbtv507dw6tVkt4eMWt4vDwcDIzM03el52dTd26dfHx8WHgwIF8/PHH9OvXz+T1U6dOJTg4uOwjOjrakmUKYRZjeSXm5JSY4uhhfDXNJ5mduZak6Eas9jezhXdRLvw4Ala+ov8N9Oh62Pmj/p/S08QldW2mD0BM9RtRFIU3f90LwF03RZEYW7NjQKco/7V45Hfz7un5PNzzmb6Z2TM7JRBxAQ6p0QoMDGTHjh1cvnyZ1NRUkpOTadasGb179zZ6/aRJk0hOTi77PCcnRwIS4RCGnJIxX29DhWVdCQzXTly0k0A/b7o2a2D3YxtDPkmLei2s2iXJ0mgYHxbK2IvZjM7OqX6XBGDjR7D9K7hy8epjUn3jkgz9RrYev0hBsRY/74r/hlfsziL96AV8vdQ8n9TaGUusGWs7qjbtJR1VXYxFOyOhoaFoNBqysrIqPJ6VlUVEhOlsa7VaTYsWLWjfvj3PPvss9957L1OnTjV5va+vL0FBQRU+hHAUQ68SU90tq3PpSjEP/28Tnd9axRu/7HZIwzTDLsmdze+07EaVClQqZofUs2yXpHwgAlJ946KaN6xLw0Bfikp0bD9+qcKfFZXomPp/+l2Rf/dsRiN3G3IniaoexaJgxMfHh44dO5Kamlr2mE6nIzU1lYSEBLOfR6fTVcgJEcLV9I+LZMOEvnw3uivDE5pY9RwX8or57I8MHpz7J53fWsXyvy387c1CGrWGKd2mWN25NUujITks1PyApILSYCtlohzZuBCVSkX30t2R1Xsr/hL5ZVoGx87n0zDQl8d7NXfG8qwnHVU9jsU1W8nJycydO5f58+ezd+9exowZQ15eHiNHjgRg+PDhFRJcp06dyqpVqzhy5Ah79+7l/fff56uvvmLo0KG2+1sIYQeGnJLbbJCQeiGvmCe+3c7U5XtssDLTDJ1brVLa3nt6g/pYF04okHNSn0QoXMaAG/Rfv59tOFq2Q3c2t5APVx8E4LlbWxHg62ZdVa1NVJWKGZdl8VfgkCFDOHv2LK+++iqZmZm0b9+elJSUsqTW48ePo1ZfjXHy8vJ44okn+Oeff6hTpw5t2rTh66+/ZsiQIbb7WwhhR4ak1szsAisbs1/1n3VHuaFRPQa1b2STtRmT2CSRD3p/wJSNU8guyrboXkWlItPLi21+vnQusHL38nJW9dcIh+nV+mp1zMItJxjSOZo3lu0ht7CEG6KCua+jm+TjXdtR1RzSUdVtSDt4IcyQsus0Y77eBli2MWyMCvhXtxhuvT7Crr1JtDotc3fO5avdX5FTbFl5/PQz5xiQl2/dC8u4dZcz+OMN7DyZTWSwH/3jIvj8jww0ahULH0+weG6Nw+m0sO492PRp5Vyl6sjXotOZ+/NbghEhzGSsUVpNOaI3iSEomb1jttn3zPNtRed9Vkz89Q+F5L3g5WP5vcJusvOL6f/hugpfuy8NaMvons2cuCoz7FkKvzxleRCCSn8s88xO2Q1xMglGhLCD8gP4QgN80SkK477bzqUrxTV63ke6x5AYa9+dEnOG7qlQEe4fTso9KWj2/gJLx0GhhU0HpczXJR09l8dbv+7l3OVChnZtwr0dr3P2kqq2Zyn8MMyKG6WjqiuRYEQIBzEc4djiP6SQAG/uah9lt8Ckql0SVek38Rm9Z1yd7vv3D7B4tIWvIj8MRA1Z1da9VFCUdFR1IRKMCOFA7naEs/rYaqalTyMr/2qyaYR/BBO6TLgaiIC+s6U582uM8Q+F/lMhMFKSB4Vl1k7XjyAwlySquiwJRoRwMMMRztz1h/lt31mbPe/4xJY82belXXZJtp3Zxtn8szT0b0iHsA5orv0mXvYb6mlqlLrr3wAGzJC5NqJqhmRVSwIRkERVFybBiBBOtGzHKcYt2I6t/usKruPNqO4xdglKqmXodAnUuJao21Nwq3nTukUts2cp/N8LkGvhbKegKElUdWHm/vy2uOmZEKJ6g9o3YvaDHWz2fNlXivlg9UFufG2F3Tu5VhJ7uz7/I8gGx0UbP4LdS2r+PMKz7F6iT1a1NBBBJR1VPYTsjAhhR/bIJQF4rGdTJg2ItelzVqt80yn/UPh5jHXHN/6h8NwB+QEi9HYtgUUjQdFZdl+dEBj8oSSqujg5phHCRRhySVbtyWTJjlNcyCuyyfM+c0tLxt3ihGMbg7LjGyu+hfR7U7/TIgmHtZe1+SEA7R6GOz6Wrxs3IMGIEC6ofGAy74+MGj9feKAvD8U3JiY0gLBAP7v2KTFqz1L4ZRxcuWT9c0hfktpn9xJYlgxXzlt+b2AjGL9LAhE3IcGIEC7OlcqBzaqsMeXI7/BlTQIJ6UtSq6x4GdI+tvJmlXyduBkJRoRwA+V3Sn7afpKL+TXr5GpgSTmwsZ4j4f7hTOwysWLPEVNsVv4rreQ93oqXIG2WdfdKMzO3JMGIEG5Gq1OY9dshPlh9wCbPV9/fm7tvqrqb6+pjq0lem4xiIogY224so28cXWmXpPxOSoM6DVAyNnJhw7s01GrpUFCA1Rvo/qEw6AP5geNpdFr4/R34fZp19/d+EXo+J0czbkiCESHcVMqu00xY9DfZV0ps9pzGjm+0Oi1Ji5Iq7IgYE+QTxLC2w8qCEmM7KeWFl5Qw8fxFEvOvWLla2Yr3KNb2DwFQaeDeeXD9nTZflnAMCUaEcGNancLT329n2d9WfAOvQvnjm82Zmxm1YpTZ9wZ4B3Bvy3v5cs+XJndSQJ8BogBj63ek8f4VpbslhZbtlsiRjWeoScUVwL3zpWuvm5NgRAgPsPzv07y0ZKfNckkAIoL8mHJ7LCV1tjFpw0SbPW9V6mu1vHzuArdaslsiRzbuTYbdCSQYEcJj2DqXxKBucAaqRnNs+pxVUhRGZueQfDHbgpvkyMZtWTrszqDXROj1guSHeAhpBy+Eh9CoVTyd2JI5QzsQGexns+e9nN0YXXGwzebnmOPz4CBW+tex4A4FfnkGSmzTKE44gE5rfSCSMA76TJJApBaSnREh3IihFPhMbgEZ5/L5dtMxsnILrX4+r8Bd+EV9DYDKQb3S6qp8ef/8JS6V5JmfT+IbCHd8Ijskrq4myaoJT0LSW7Zfk3AqOaYRohawxRGOV+AufMOXovbOseHKzGdR9Y2UeLqu3Utg4QjL7/MPhQHvS6Kqh5JgRIhapObdXHX4NPgNn4arAcftkgCoSr8FzThzzryAxL8B3DgEWg+QuTauYtdiWPSI5cPuJLj0eBKMCFHLaHUKfx4+z+ivtpBfpLXqObwCd+EbsQi1l7U9QqykKNTX6Vh9/CQWFfPKXBvnW/kKbPzI8vt6vwi9J9h+PcKlSAKrELWMRq2ie8tQZtzfDms3NrS5cQSeeYukJklm3xPsHUx93/pWvmIplYqLGg2JjaNYbUmCa85pfR+LPUtr9vrCOrsWWxeIBDbS74gIp9PqtGzO3MzyI8vZnLkZrc66X2RqSoIRITxM/7hIPrWi8sYQwEwZHMd7vd/j/V7vU9e7brX3ZRdn81Dbh1CV/q8mLqrVJIeFWhCQlG7spkzUV3EIx9m1BH40v2neVSq4bboczbiA1cdWk7QoiVErRjFh/QRGrRhF0qIkVh9b7fC1yDGNEB7KUHmTmX2FPw6d48dtJ6u83ljL+GWHlzFpw6RqX+vR1q+QV6CQcvo/XCw6W7OFW3tkM2IZNO1Rs9cW5rE2WVWamTlV+ZlSx3OP88mOTyp1Uzb8QjGj9wzzBmVWw9yf3141fiUhhEvSqFUkNG8AwF0driMxNrxSkmtIgDd3tTc9TC88INys1/poZSba/ObAeOqFnKBzMy86N27M5wff5HKJJU3OqHBk8+q5C+bPuMk5CUfXw+UsqBsuya32smsJLBpp+X2SrOpU1c2UMlBQUKFievp0+kT3qTQk015kZ0SIWqR8n5KwQD+T03yvXq8fpncm/4zReTSKAkpJMHmHJmDs1LdGfUxKvzWNuZjNY9k51fciUakrVnNIcqtt6bSw7j3Lm5mp1HDv5zLszoHK74A09G/IxYKLPPf7c1XOlDJmXtI8Okd0rtFaZGdECFFJ+d0S867XMLHLRJLXJqNCVfGbWen/LcwajKn0s5LcOApODsU3/BdU3pbvkAB8GlKPb4MDmVLdLsm1ZaWG5FZpJ19zNWlmds9nEog4kLEdELVKbXEgAnA2v4ZHrhaQYEQIUaXEJonM6D2j0jc4XUkwhVmDKcmNq/L+ktw4SnJj0fgfReWVS7BPMD6R31t0fJOtVjM+LJSxF7MZbc4uCaCPllT65NY2A+V4wFo1mbzb7SmIu9vmSxJXmZMHorO0/0uphv4NbbFEs8gxjRDCLOW/6e0/BR8u02JtQV5Njm/qa7UMupxHn/wr5rWSB0lutZbVk3fVcO9nEojYmbl5IJZSoSLcP5yUe1JqnDMixzRCCJvSqDVl58f1lfN8yJ9WP1fZ8U3ET6i88iy696JGw1fBQXwVHGR+K/nLtv1mXWuse8+KQAR9joi0d7cpW+WBVMdQTTOhywSHJa+Clb/WzJ49m5iYGPz8/IiPjyc9Pd3ktXPnzqVHjx7Ur1+f+vXrk5iYWOX1QgjX16VpCJHBfjXqKlKSG0fewUnoSgKsnhx8RqMxry/JmX36ShvpRWIeayfvqjRw33wJRGzMWD+Q59c9b/NABCDcP9xmZb2WsPiYZsGCBQwfPpw5c+YQHx/PzJkzWbhwIfv37ycsLKzS9Q8//DDdu3enW7du+Pn5MX36dH766Sd2795NVFSUWa8pxzRCuBZbDOgzMBzZWDsPR6UohGu1/HriFH/5+XJWozE9DVgqbKq3ewksS4Yr5y2/914JRGxt9bHVJK9NtkvgYUhKH9tuLI2DGtPQvyEdwjrYdEfEbrNp4uPj6dy5M7NmzQJAp9MRHR3NuHHjmDhxYrX3a7Va6tevz6xZsxg+fLhZrynBiBCuo+ZD+SrzCvwbv6hvazSgr75Wy0XN1W+ixo9wSl9AKmyMW/EypH1s+X3SzMxmyh/HNKjTgJc2vGSznBC1Sl0hmTXCP4IJXSbYdRfELjkjRUVFbN26lUmTrnZkVKvVJCYmkpaWZtZz5OfnU1xcTEhIiMlrCgsLKSwsLPs8J8c5o82FqC3M7T+Ssus0Y77eZvJ3ND8vNQUllmful+TeSMFJ8Iv6FrBuavBFdcVTZ8MRTsVpwFJhY9KKlyBtluX3STMzm7FnQirAuz3fpb5f/bK8E1vvgtSERcHIuXPn0Gq1hIdX7MoYHh7Ovn37zHqOCRMm0KhRIxITTUdiU6dO5bXXXrNkaUIIKxnb6QgJ8OaOdo1oVK8Ol64Uo0JFfNMQpizdYzIQUQH1/L15oHNjvtiYwaUrxRatQx+QqPGNWIzKK9/yv8g1EYyiUoGi8HpoCAXnLxJednSj6Lu1HtsoFTYGu5ZYH4jI5F2rmVOWawvh/uF23wGpKYdW00ybNo3vv/+etWvX4udneojXpEmTSE5OLvs8JyeH6OhoRyxRiFrF1E7HhbxiPt94rMJjs9ZU/VwKkJlTSHyzBoy7pSV/Hj7P2G+3WRSUXO1JchjvepvwCtql/53O2uOb0tbyk8JCgWuObvYvl2AEoKQIfhln+X0yebdG7LkLYu88EHuwKBgJDQ1Fo9GQlVXxzcvKyiIiIqLKe9977z2mTZvG6tWrufHGG6u81tfXF19fX0uWJoSwkFan8Novpnc6rHUmtwCNWkX3lqFMu+cGxny9DbCkZZYabX5LtPkt8crdhW/4L6gt7d5qam3lj27+/AQaJ9TuPIc9S2HZM1Bo6VG4TN61hD3Lcq/NA3GHXRBjLApGfHx86NixI6mpqdx5552APoE1NTWVJ5980uR977zzDm+99RYrVqygU6dONVqwEMI20o9esGkSqkFY4NVdz/5xkXw6tEOlY6DSE5Rqle/eqqm7B+96W1FrrF+zolKhUhSmN6hPn/wraJaNh1b9wcui+cDuz9o5MyDJqhayZXv28twhD8QSFh/TJCcnM2LECDp16kSXLl2YOXMmeXl5jBypn+I4fPhwoqKimDp1KgDTp0/n1Vdf5dtvvyUmJobMzEwA6tatS926dW34VxFCWOJMrm0DERUQEaxPfi2vf1wk/WIjKiTIXswrYuy3phNhK1KjzW+ONr85uoLrqBO1oEbrVFQqMr282ObnS+f8czCjLQz6oPb8cK3JnJleE6HXC7IjYiZTZbnWtmcvz113QEyxOBgZMmQIZ8+e5dVXXyUzM5P27duTkpJSltR6/Phx1OWy2j/99FOKioq49957KzzP5MmTmTJlSs1WL4SwWvkdjJoypHRMHhxrtArH2IC+T9UdmLJ0N5k5hZWuN0UpsV1p/1lDGXD+OfhhGLR7GJr3hsBIaNLNM3/g1mTOTMI46DOp+utqsWvLcqelT7PJUYwKFWF1wnjz5je5UHDBrXdATJHZNELUUlqdws3TfyMzu6DG3y4jg/2YPDiW/nGRFq/BsuZpOgJaTEfllV2jniQAYy9e4vFLJnIlPLE5mtVzZoCEJyHpLduvyYPYuyzXGV1RbUFm0wghqqRRq5g8OLYswdRS9f29ufumKBJjI0z2JTFnDU8ntgQUPlh90Iw71BRmDcYv6msUxbp+JAAoCrPrBYOC8SnAOaf0uyX3f+U5AYk1c2Z8g2Dwx9JV9RqOmhMDnnccY4rsjAhRy1nbUdUQB3w6tIPFOyLX0uoUuk1NJSvXvCMbr8Bd+Eb8hNrCIXvGVDkFuE4IPH/IvY9srE1W9Q+F5L21L7m3GqYSUm2RB+KuZblVsVs7eGeQYEQI+zJ0YF21J5MlO05xIa/IrPsMSasbJvS1amekvJRdp3ncol2aEgJaTkWlyavxkY1BkFbLsOzcirsl7R6GOz52z4DE6mRVlbTML2XPxmTOaM/uaBKMCCGsYghMMrOvsPXYBb7edKLae74b3bVSgqo1UnadZuLinVzKN69RmmHIHtTgyMaIYK2WKecuXG0j7445JNYmq0rpbhl754G81+s9jyjLrYrkjAghrFK+8kWtVpkVjNiqTNhQBvzn4fOkHTnH4bN5/HnkPBdNBCcluXEUnByKb/gvqMo1RtOVBKDNa4p38C6r1pGtVjM+LJQPDHNtck7pf7C7y26BTgu/PI3FgYjMmSljz2m5tSUPxBISjAghTDK3/NeWZcKG7q3dW+pbuFdXcVO+MZrKKxelJBBtflP9c/lbWXlT2pXttdAQ+hw/efXIxl0G7K17D65csOyeWj5nRspynUuCESGESV2ahhAZ7Gey/NdUozNbMlTctI6oy4s/7eRCnrFdEn1jtGvVqPJGpeKSRsOU0BCmnLtwdcDe0fX6fiSuSqeFPz607J5aPmfG3scxE+Mn0rVRV5s+t6dRV3+JEKK2MpT/QuVZddU1OrO1/nGR/DkpkZAA86s7DMc4NWmWtiSwLknRjVjtX0f/wI//0udjuCKdFn4eB8WWVBnVrjkzWp2WzZmbWX5kOZszN7MyYyXJa5NtEoioVRV/pIb7h7ttfxBHkwRWIUS1jJX/WtvozBZrMTZpuGo6fBr8hk/D1YAVuySKggr0A/YMSa09J0LDllA33DU6tlpTOVPLklXtVZZbmxJSLSXVNEIImzJU2Rjmy1jb6MwWUnadZuKinVy6Yl7VjYFXoPVTgFWKQrhWS8qJU5WbpPk3gBuHQOsBjg9MrO0j4s4ly1awZ0KqJ5bk2ooEI0IIj/bHoXM8/L9NVtypKzcFOB21xrKA5n+ns4gvqKI5myPLgK3tI+JTFyYe9+hA5NqE1Jc2vGSToxhPbExmT1LaK4TwaF2bNag2uTbY35vs/OJr/vzqFOCiM7dRt9UboC40++jm2bDQij1IrpVz2jFlwDUZetftKY8OROyVkApSlmsvsjMihHBbhvwRqPgjuXyreqDKdvcWN04r/ZY55mI2MSUlNNRqK7eRR6XfIXlmp31+6Ndk6J0ntLgvx55zYqQst+ZkZ0QI4fH6x0Xy6dAOlYKNiGuSa/vFRphsd3+1cdpSVN4mpviWVxqxfBpSr+yh8JISJp6/WG63pLQM+NhGaNqjxn/PSqwZemcw+EOPCURMJaTaKhABKct1FNkZEUK4PUuSaw3Xrth9mi82Hiv3JzWouCn9Njr2YnbFuTZ3z4Ub77f471OlPUv1E4Ut5WGVM7ZOSK0Nc2KcQRJYhRCiGjNXHWBm6sEKj+knAi9C7WUiJ6QaFXZJfAKh2zjbtVgvKYIZbSH/nGX3uXGbd8MxTFZeFhcLL1Lftz4N/RvaNCEVpCzXXiQYEUKIamh1Ch3fXFVpMJ/G/xD+Tf5n3ZMa60lSJ0R/PBJ7uz7f49hGuJxlWY+SPUth2TOQf978tbj5bog9E1ENZAfEviRnRAghqqFRq5h29w2Vmqhp85uhKw6u0Vyb6Q3q0yf/iv7I5soF/dHK9XfDiT8r5nvUqQfxT5jeubC2j4gb74YArMxYybO/P2vT55SEVNclOyNCiFrPWIdZQ5WNxcFIOdX2JCnPO0B/pNOkG+SdBf9QOJ4Gm+ZAwSXLXthNh94ZjmRSj6Xy7b5vbdqgzHAcI+3ZHUuOaYQQwgKGxNZVezJZsOUEeYVavAL/xi/qO1Qq675N1tHpGHUpp2JSq70FNoLxu9xqR0Sr0zJ351y+3vM12UWWd8c1RhJSXYMEI0IIYaXy3V31Acm3gBUzbUoFaLXcfTmPPvlXjPQksSWV/Zut2YBWp2VL1hbST6dzNOcoG09uJK/EkuF+pklCqmuRnBEhhLCSobvr6ewCSnJvpOCkGt/wX1BZMdMGIE+j4avgIL4KDjLSk8RG/ENh0AcuH4iszFjJq3+8arPg41rSIdU9yc6IEEIYkbLrNI+XdnfVuzrTxifkD8DKnZLSb7n98vK5P/cynW2xU+ITCC8cAS+fmj6TXRhyQebvms/vJ3+32fNKQqrrk50RIYSogf5xkXzy0E08+d12dAqUn2mju9LU+p2S0ghmVd0AVtUNsE1eSbdxlQKRa9ukO+OHtD1yQa4lHVI9g+yMCCFEFZb/fZonvt1m5E9Kd0r8D+LbcG2NX8fqoMTIrBlj/TnC/cOZ2GWi3Y8vDEHQmuNrWHxwsd2OYyQh1T1IAqsQQtiIsdLfq3QEtJhuXU8SI4K12qqnAl/r/q8q5ImYapNu79JWR+yCADzc9mFuaXyLHMe4CQlGhBDChsqX/s77I6PCn1k8+bcqpubcXKu0u6q2zcCy45j6fvWZsG4CFwsvGr1FhYpw/3BS7kmx6Q9yeyelguyEuCsJRoQQwk5MNUnzjViM2ivfZq9TX6tlkKEkmDpoWg+E5r0hMBKadGP1iTVWtUuflzSPzhGda7w+rU7LxPUTSclIqfFzGRPgHcDdLe6mT+M+shPipiSBVQgh7KR/XCT9YiNIP3qBDQfPMnvtYUpy4yjJjcWnwW94h/xh9aC98i6WKwkO9A7kloYNiA/wJ7yOHxePp/Lc789Z1aX0bP7ZGq3LcCQzb+c8rmhtXKIMBPsEM7TtUEbfOFoCkFpCdkaEEKIGtDqFm6f/dk0+ydUyYO/g7TbdLTFQobK6Xbo1OyP2Tkz1U/txX+v7ZBfEw8jOiBBCOIBGrWLy4NhrepJcLQMuOjMQnwa/4dNwNWCDnJJS1gQihpyRDmEdzL7H3ompAV4BDL9+OI/d+JgEILWYBCNCCFFD/eMimTO0AxMX7+RSfvE1f6qm6HwiuqIIfCMWo7LDLoklJnSZUO0PfXvvgkguiLiW2pqbZs+eTUxMDH5+fsTHx5Oenm7y2t27d3PPPfcQExODSqVi5syZ1q5VCCFcVv+4SLa+3I/xia2oV8e70p+X5MaRd/Bl8o89QnF2HIrWsb8LhviFVFvWq9Vp+WTHJ3T/vjujVoziq71f2TQQCfYJZmy7sfzxwB+80OUFOkd0lkBEAFbsjCxYsIDk5GTmzJlDfHw8M2fOJCkpif379xMWFlbp+vz8fJo1a8Z9993H+PHjbbJoIYRwRRq1iqcTW/Jk3xZlZcBLdpziQl5R6RVqtPkt0ea3BHSlya4bUHsZ619iO/V967PqnlX4VNEufvWx1by04SXyS2y7cyO7IMIcFiewxsfH07lzZ2bNmgWATqcjOjqacePGMXHixCrvjYmJ4ZlnnuGZZ56xaJGSwCqEcFdancIXfxzljV/3mrhCZ5ecEjCv0ZkhJ2T2jtm2e+FS/WP6M63HNAlAajG7JLAWFRWxdetWJk2aVPaYWq0mMTGRtLQ061d7jcLCQgoLC8s+z8nJsdlzCyGEI2nUKv7VvSn/23DURAfXcjklNZgMbIypCbblc0J+OfwLl4ou2ew1Qb8b8nq317k15labPq/wXBYFI+fOnUOr1RIeHl7h8fDwcPbt22ezRU2dOpXXXnvNZs8nhBDOZLzipiJDn5KykuB6W1BrCk1eX5UHWz9Iv5h+lY5F7F0Z4+/lz8jrR0p/EGExl6ymmTRpEsnJyWWf5+TkEB0d7cQVCSFEzVRdcWNQuSTYmgZq/WL6lfURccTgOmlSJmrKomAkNDQUjUZDVlbF1sNZWVlERETYbFG+vr74+vra7PmEEMIVGDq3zvrtEP9Zd5j8Im0VV+uPb4rO9y3dLdmNT72tqKrYLbm2j8jKjJW8+eebJmfV1IQkpgpbsqi018fHh44dO5Kamlr2mE6nIzU1lYSEBJsvTgghPI2h4mbnlCTGJ7bC37u6H+Lq0p2S27l8YDJcNJ6HYUhWNfQRmbFlBs/+/qzNAxEpzxX2YPExTXJyMiNGjKBTp0506dKFmTNnkpeXx8iRIwEYPnw4UVFRTJ06FdAnve7Zs6fs/588eZIdO3ZQt25dWrRoYcO/ihBCuA9DUNIppj4P/2+TmXepyc3si1deGP6Ry1A0l8r+pHyy6sqMlXy++3ObrrfXdb0Ycf0I2QURdmFxMDJkyBDOnj3Lq6++SmZmJu3btyclJaUsqfX48eOo1Vc3XE6dOsVNN91U9vl7773He++9R69evVi7dm3N/wZCCOHGujZrQGSwH5nZBWY3eC/JjSMnNxYv/6M80juUxFYty4IErU7Lm3++abP1SWWMcAQZlCeEEE6Wsus0Y77eZvG0GRUQEezHhgl90aj1xzSbMzczasWoGq+pX+N+3N/6fjmGETUig/KEEMJN9I+L5NOhHZiydDeZOeaX8yrA6ewCvvjjKKGBvoQF+nGeMzVaS4R/hNHeJELYk+yMCCGEi9DqFGb9dogPVh+w+jmC6x9DF/GpRfdIZYywF9kZEUIIN2NIagWFD1YftOo5si9GE9AgGJVXdrWt5aU/iHAVEowIIYSLebJvS75LP0FmjjUD9NQUZg3GL+prFKXyrBtFgRtDEhjfZbTsggiXYVGfESGEEPanUauYcnss1s7MK8mNo+DkUJSS4AqP60oCKDj5EEMaT5bEVOFSZGdECCFckCGpdeKinVy6Yqp9vGnlZ92ovHJRSgLR5jcF1IQF+tl+wULUgAQjQgjhovrHRRLo521BU7Rr6bu3GhhKgbs0DbHJ+oSwFTmmEUIIF2Zoimbtkc21Jg+OLetJIoSrkGBECCFcmEatYvLgWIAaBSQNAnz4dGgH+sdF2mZhQtiQBCNCCOHiDPkj4UHWTTMPCfAmbdItEogIlyXBiBBCuIH+cZG8f397i+5RlX68fdcN+HjJt3vhuiSBVQgh3MS5y+a3igd9surkwbGyIyJcngQjQgjhJswtyX2yTwu6twilS9MQSVYVbkGCESGEcBNdmoYQGexHZnaB0Qm/htLd8f1aSRAi3IocIgohhJuoqrLG8LmU7gp3JMGIEEK4EUNlTURwxSObiGA/Kd0VbkuOaYQQws30j4ukX2wE6UcvcCa3gLBAP8kPEW5NghEhhHBDGrWKhOYNnL0MIWxCjmmEEEII4VQSjAghhBDCqSQYEUIIIYRTSTAihBBCCKeSYEQIIYQQTiXBiBBCCCGcSoIRIYQQQjiVBCNCCCGEcCoJRoQQQgjhVBKMCCGEEMKpJBgRQgghhFNJMCKEEEIIp5JBeUII4aG0OoU/D58n7cg5QEV80xDUahVncgq4kFdESF1fwur6ggrOXS4kNMAXnaKQduQcpy4VEFW/Dl2bNjB5j+Gxev4+XMgr5NKVYhQF6vv7EBpY+TrDvda+xqV8/Z9FBF2dUqzVKUanF9vzccCln9uS5zB1raOpFEVRLL1p9uzZvPvuu2RmZtKuXTs+/vhjunTpYvL6hQsX8sorr5CRkUHLli2ZPn06AwYMMPv1cnJyCA4OJjs7m6CgIEuXK4QQtU7KrtNMXLyTS/nFzl6KXUQG+3F7u0iW/nWa09kFDnu8nr83QIX31ZWe25LnMHXt5MGx9I+LxBbM/fltcTCyYMEChg8fzpw5c4iPj2fmzJksXLiQ/fv3ExYWVun6jRs30rNnT6ZOncqgQYP49ttvmT59Otu2bSMuLs6mfxkhhBD6QOTxr7c5exnCDRn2RD4d2sEmAYndgpH4+Hg6d+7MrFmzANDpdERHRzNu3DgmTpxY6fohQ4aQl5fHsmXLyh7r2rUr7du3Z86cOTb9ywghRG2n1Sl0n5ZKZk6hs5ci3JQKiAj2Y8OEvjU+sjH357dFCaxFRUVs3bqVxMTEq0+gVpOYmEhaWprRe9LS0ipcD5CUlGTyeoDCwkJycnIqfAghhKhe+tELEoiIGlGA09kFpB+94LDXtCgYOXfuHFqtlvDw8AqPh4eHk5mZafSezMxMi64HmDp1KsHBwWUf0dHRlixTCCFqrTO5BdVfJIQZHPm15JKlvZMmTSI7O7vs48SJE85ekhBCuIWwQD9nL0F4CEd+LVlU2hsaGopGoyErK6vC41lZWURERBi9JyIiwqLrAXx9ffH19bVkaUIIIYAuTUOICPKVoxphNUPOiKH01xEs2hnx8fGhY8eOpKamlj2m0+lITU0lISHB6D0JCQkVrgdYtWqVyeuFEEJYT6NWMeX26529DOGmDOmqkwfHOrTfiMXHNMnJycydO5f58+ezd+9exowZQ15eHiNHjgRg+PDhTJo0qez6p59+mpSUFN5//3327dvHlClT2LJlC08++aTt/hZCCCHK9I+LZM7QDmV9JDxRZLAfj/VsSmSwn0Mfr+fvXel9daXntuQ5jF0bEexns7JeS1jV9GzWrFllTc/at2/PRx99RHx8PAC9e/cmJiaGL774ouz6hQsX8vLLL5c1PXvnnXek6ZkQQtiZdGB13S6ptaUDq936jDiDBCNCCCGE+7FLnxEhhBBCCFuTYEQIIYQQTiXBiBBCCCGcSoIRIYQQQjiVBCNCCCGEcCoJRoQQQgjhVBKMCCGEEMKpJBgRQgghhFNJMCKEEEIIp7Joaq+zGJrE5uTkOHklQgghhDCX4ed2dc3e3SIYyc3NBSA6OtrJKxFCCCGEpXJzcwkODjb5524xm0an03Hq1CkCAwNRqfQDfHJycoiOjubEiRMyr6YK8j6ZR94n88l7ZR55n8wj75N53PV9UhSF3NxcGjVqhFptOjPELXZG1Go11113ndE/CwoKcqt/Mc4i75N55H0yn7xX5pH3yTzyPpnHHd+nqnZEDCSBVQghhBBOJcGIEEIIIZzKbYMRX19fJk+ejK+vr7OX4tLkfTKPvE/mk/fKPPI+mUfeJ/N4+vvkFgmsQgghhPBcbrszIoQQQgjPIMGIEEIIIZxKghEhhBBCOJUEI0IIIYRwKpcMRmJiYlCpVJU+xo4da/T6L774otK1fn5+Dl6141n6PgFcunSJsWPHEhkZia+vL61atWL58uUOXLVzWPpe9e7d2+j1AwcOdPDKHcuar6mZM2fSunVr6tSpQ3R0NOPHj6egoMCBq3Y8S9+n4uJiXn/9dZo3b46fnx/t2rUjJSXFwat2PK1WyyuvvELTpk2pU6cOzZs354033qh2TsnatWvp0KEDvr6+tGjRgi+++MIxC3YSa96n06dP89BDD9GqVSvUajXPPPOM4xZsD4oLOnPmjHL69Omyj1WrVimAsmbNGqPXf/7550pQUFCFezIzMx27aCew9H0qLCxUOnXqpAwYMEDZsGGDcvToUWXt2rXKjh07HLtwJ7D0vTp//nyF63ft2qVoNBrl888/d+i6Hc3S9+mbb75RfH19lW+++UY5evSosmLFCiUyMlIZP368YxfuYJa+Ty+88ILSqFEj5ddff1UOHz6sfPLJJ4qfn5+ybds2xy7cwd566y2lQYMGyrJly5SjR48qCxcuVOrWrat8+OGHJu85cuSI4u/vryQnJyt79uxRPv74Y0Wj0SgpKSkOXLljWfM+HT16VHnqqaeU+fPnK+3bt1eefvppxy3YDlwyGLnW008/rTRv3lzR6XRG//zzzz9XgoODHbsoF1Td+/Tpp58qzZo1U4qKihy8MtdT3Xt1rQ8++EAJDAxULl++bOeVuZbq3qexY8cqffv2rfBYcnKy0r17d0csz2VU9z5FRkYqs2bNqvDY3XffrTz88MOOWJ7TDBw4UBk1alSFx6r7e7/wwgvK9ddfX+GxIUOGKElJSXZZoyuw5n0qr1evXm4fjLjkMU15RUVFfP3114waNapsSJ4xly9fpkmTJkRHR3PHHXewe/duB67S+cx5n5YuXUpCQgJjx44lPDycuLg43n77bbRarYNX61zmfk2V99lnn/HAAw8QEBBg59W5DnPep27durF161bS09MBOHLkCMuXL2fAgAGOXKpTmfM+FRYWVjo6rlOnDhs2bHDEEp2mW7dupKamcuDAAQD++usvNmzYwG233WbynrS0NBITEys8lpSURFpaml3X6kzWvE8ex9nRUHUWLFigaDQa5eTJkyav2bhxozJ//nxl+/btytq1a5VBgwYpQUFByokTJxy4Uucy531q3bq14uvrq4waNUrZsmWL8v333yshISHKlClTHLhS5zPnvSpv06ZNCqBs2rTJzitzLea+Tx9++KHi7e2teHl5KYDy+OOPO2iFrsGc9+nBBx9UYmNjlQMHDiharVZZuXKlUqdOHcXHx8eBK3U8rVarTJgwQVGpVIqXl5eiUqmUt99+u8p7WrZsWemaX3/9VQGU/Px8ey7Xaax5n8rzhJ0Rlw9Gbr31VmXQoEEW3VNUVKQ0b95cefnll+20KtdjzvvUsmVLJTo6WikpKSl77P3331ciIiLsvTyXYunX1L///W/lhhtusOOKXJM579OaNWuU8PBwZe7cucrff/+tLF68WImOjlZef/11B63S+cx5n86cOaPccccdilqtVjQajdKqVSvliSeeUPz8/By0Suf47rvvlOuuu0757rvvlL///lv58ssvlZCQEOWLL74weU9tDEaseZ/Kk2DEzjIyMhS1Wq0sWbLE4nvvvfde5YEHHrDDqlyPue9Tz549lVtuuaXCY8uXL1cApbCw0J5LdBmWfk1dvnxZCQoKUmbOnGnnlbkWc9+nm2++WXnuuecqPPbVV18pderUUbRarT2X6BIs/Xq6cuWK8s8//yg6nU554YUXlNjYWDuv0Lmuu+66Srkyb7zxhtK6dWuT9/To0aPSD9Z58+YpQUFB9liiS7DmfSrPE4IRl84Z+fzzzwkLC7O4nFKr1bJz504iIyPttDLXYu771L17dw4dOoROpyt77MCBA0RGRuLj42PvZboES7+mFi5cSGFhIUOHDrXzylyLue9Tfn4+anXFbyMajQag2vJNT2Dp15Ofnx9RUVGUlJSwaNEi7rjjDjuv0LlMfX2U/x50rYSEBFJTUys8tmrVKhISEuyyRldgzfvkcZwdDZmi1WqVxo0bKxMmTKj0Z8OGDVMmTpxY9vlrr72mrFixQjl8+LCydetW5YEHHlD8/PyU3bt3O3LJTmHJ+3T8+HElMDBQefLJJ5X9+/cry5YtU8LCwpQ333zTkUt2GkveK4Obb75ZGTJkiCOW5zIseZ8mT56sBAYGKt99951y5MgRZeXKlUrz5s2V+++/35FLdgpL3qc///xTWbRokXL48GFl3bp1St++fZWmTZsqFy9edOCKHW/EiBFKVFRUWcnq4sWLldDQUOWFF14ou2bixInKsGHDyj43lPY+//zzyt69e5XZs2d7fGmvNe+ToijK9u3ble3btysdO3ZUHnroIWX79u1u+3PPZYORFStWKICyf//+Sn/Wq1cvZcSIEWWfP/PMM0rjxo0VHx8fJTw8XBkwYIDH1+8bWPI+KYo+2Tc+Pl7x9fVVmjVrprz11lsVckg8maXv1b59+xRAWblypYNW6BoseZ+Ki4uVKVOmKM2bN1f8/PyU6Oho5YknnvD4H7KKYtn7tHbtWqVt27aKr6+v0qBBA2XYsGFmJ1C7s5ycHOXpp59WGjdurPj5+SnNmjVTXnrppQrHwiNGjFB69epV4b41a9Yo7du3V3x8fJRmzZp5fH8fa98noNJHkyZNHLt4G1EpSi3YSxVCCCGEy3LpnBEhhBBCeD4JRoQQQgjhVBKMCCGEEMKpJBgRQgghhFNJMCKEEEIIp5JgRAghhBBOJcGIEEIIIZxKghEhhBBCOJUEI0IIIYRwKglGhBBCCOFUEowIIYQQwqkkGBFCCCGEU/0/VT2a8QC0mWYAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "res1 = model.forward(datum.T.double())\n",
    "res1 = res1.reshape(-1)\n",
    "\n",
    "print(len(boundaries))\n",
    "boundary_spaces = [np.linspace(x,y) for x, y in zip(boundaries[:-1],boundaries[1:])]\n",
    "resn = res1.detach().numpy()\n",
    "print(resn.shape)\n",
    "polys = [np.polynomial.polynomial.Polynomial(list(reversed(resn[4*i:4*i+4]))) for i in range(resn.shape[0]//4)]\n",
    "print(len(polys), len(boundary_spaces)) # Why am I throwing away the first polynomial\n",
    "polys = polys[:]\n",
    "print(len(polys), len(boundary_spaces))\n",
    "plot_points = np.hstack([poly(space) for poly, space in zip(polys, boundary_spaces)])\n",
    "print(len(plot_points))\n",
    "points = np.hstack(boundary_spaces)\n",
    "print(len(points))\n",
    "plt.plot(points, plot_points)\n",
    "plt.scatter(processed['strike_price'].apply(np.log), processed['vol_low'])\n",
    "plt.scatter(processed['strike_price'].apply(np.log), processed['vol_high'])\n",
    "plt.scatter(processed['strike_price'].apply(np.log), processed['vol_mid'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       secid        date              symbol      exdate last_date cp_flag  \\\n",
      "3397  100219  2022-01-05  RUI 220318C2280000  2022-03-18       NaN       C   \n",
      "3434  100219  2022-01-05  RUI 220318C2650000  2022-03-18       NaN       C   \n",
      "3366  100219  2022-01-05  RUI 220318C2025000  2022-03-18       NaN       C   \n",
      "3362  100219  2022-01-05  RUI 220318C1990000  2022-03-18       NaN       C   \n",
      "3396  100219  2022-01-05  RUI 220318C2275000  2022-03-18       NaN       C   \n",
      "...      ...         ...                 ...         ...       ...     ...   \n",
      "3421  100219  2022-01-05  RUI 220318C2480000  2022-03-18       NaN       C   \n",
      "3376  100219  2022-01-05  RUI 220318C2110000  2022-03-18       NaN       C   \n",
      "3356  100219  2022-01-05  RUI 220318C1940000  2022-03-18       NaN       C   \n",
      "3419  100219  2022-01-05  RUI 220318C2470000  2022-03-18       NaN       C   \n",
      "3392  100219  2022-01-05  RUI 220318C2240000  2022-03-18       NaN       C   \n",
      "\n",
      "      strike_price  best_bid  best_offer  volume  open_interest  \\\n",
      "3397       2280000     332.5       354.5       0              0   \n",
      "3434       2650000      46.5        54.5       0              0   \n",
      "3366       2025000     567.5       591.5       0              0   \n",
      "3362       1990000     601.5       625.5       0              0   \n",
      "3396       2275000     339.5       361.5       0              0   \n",
      "...            ...       ...         ...     ...            ...   \n",
      "3421       2480000     161.5       175.5       0              0   \n",
      "3376       2110000     485.5       509.5       0              0   \n",
      "3356       1940000     650.5       674.5       0              0   \n",
      "3419       2470000     170.0       184.0       0              0   \n",
      "3392       2240000     371.5       393.5       0              0   \n",
      "\n",
      "      impl_volatility   optionid  contract_size  forward_price  \\\n",
      "3397         0.275563  139347484            100            NaN   \n",
      "3434         0.154824  139347521            100            NaN   \n",
      "3366         0.274166  139347453            100            NaN   \n",
      "3362         0.263806  139347449            100            NaN   \n",
      "3396         0.287186  139347483            100            NaN   \n",
      "...               ...        ...            ...            ...   \n",
      "3421         0.211650  139347508            100            NaN   \n",
      "3376         0.275261  139347463            100            NaN   \n",
      "3356              NaN  139347443            100            NaN   \n",
      "3419         0.215880  139347506            100            NaN   \n",
      "3392         0.296898  139347479            100            NaN   \n",
      "\n",
      "      expiry_indicator  index_flag              issuer exercise_style  \n",
      "3397               NaN           1  RUSSELL 1000 INDEX              E  \n",
      "3434               NaN           1  RUSSELL 1000 INDEX              E  \n",
      "3366               NaN           1  RUSSELL 1000 INDEX              E  \n",
      "3362               NaN           1  RUSSELL 1000 INDEX              E  \n",
      "3396               NaN           1  RUSSELL 1000 INDEX              E  \n",
      "...                ...         ...                 ...            ...  \n",
      "3421               NaN           1  RUSSELL 1000 INDEX              E  \n",
      "3376               NaN           1  RUSSELL 1000 INDEX              E  \n",
      "3356               NaN           1  RUSSELL 1000 INDEX              E  \n",
      "3419               NaN           1  RUSSELL 1000 INDEX              E  \n",
      "3392               NaN           1  RUSSELL 1000 INDEX              E  \n",
      "\n",
      "[100 rows x 19 columns]\n",
      "2640.25 0.20273972602739726 0.0053\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Project\\pipeline.py:7: RuntimeWarning: overflow encountered in scalar power\n",
      "  d1 = (np.log(S/K) + (r + 0.5*vol**2)*T) / (vol*np.sqrt(T))\n",
      "d:\\Project\\pipeline.py:12: RuntimeWarning: overflow encountered in scalar power\n",
      "  d1 = (np.log(S / K) + (r + 0.5 * sigma ** 2) * T) / (sigma * np.sqrt(T))\n",
      "d:\\Project\\pipeline.py:27: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  sigma = max(sigma + diff/vega, PRECISION) # f(x) / f'(x)\n",
      "d:\\Project\\pipeline.py:7: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  d1 = (np.log(S/K) + (r + 0.5*vol**2)*T) / (vol*np.sqrt(T))\n",
      "d:\\Project\\pipeline.py:12: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  d1 = (np.log(S / K) + (r + 0.5 * sigma ** 2) * T) / (sigma * np.sqrt(T))\n",
      "d:\\Project\\pipeline.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  processed['vol_high'] = processed.apply(lambda x: implied_vol(x['best_offer'], S, x['strike_price'], T, R), axis=1)\n",
      "d:\\Project\\pipeline.py:7: RuntimeWarning: overflow encountered in scalar power\n",
      "  d1 = (np.log(S/K) + (r + 0.5*vol**2)*T) / (vol*np.sqrt(T))\n",
      "d:\\Project\\pipeline.py:12: RuntimeWarning: overflow encountered in scalar power\n",
      "  d1 = (np.log(S / K) + (r + 0.5 * sigma ** 2) * T) / (sigma * np.sqrt(T))\n",
      "d:\\Project\\pipeline.py:27: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  sigma = max(sigma + diff/vega, PRECISION) # f(x) / f'(x)\n",
      "d:\\Project\\pipeline.py:7: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  d1 = (np.log(S/K) + (r + 0.5*vol**2)*T) / (vol*np.sqrt(T))\n",
      "d:\\Project\\pipeline.py:12: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  d1 = (np.log(S / K) + (r + 0.5 * sigma ** 2) * T) / (sigma * np.sqrt(T))\n",
      "d:\\Project\\pipeline.py:37: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  processed['vol_low'] = processed.apply(lambda x: implied_vol(x['best_bid'], S, x['strike_price'], T, R), axis=1)\n",
      "d:\\Project\\pipeline.py:38: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  processed['vol_mid'] = (processed['vol_high'] + processed['vol_low']) / 2\n",
      "d:\\Project\\pipeline.py:27: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  sigma = max(sigma + diff/vega, PRECISION) # f(x) / f'(x)\n",
      "d:\\Project\\pipeline.py:7: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  d1 = (np.log(S/K) + (r + 0.5*vol**2)*T) / (vol*np.sqrt(T))\n",
      "d:\\Project\\pipeline.py:12: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  d1 = (np.log(S / K) + (r + 0.5 * sigma ** 2) * T) / (sigma * np.sqrt(T))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [1.4640e+01],\n",
      "        [1.4790e+01],\n",
      "        [1.4521e+01],\n",
      "        [1.4504e+01],\n",
      "        [1.4637e+01],\n",
      "        [1.4799e+01],\n",
      "        [1.4301e+01],\n",
      "        [1.4836e+01],\n",
      "        [1.4854e+01],\n",
      "        [1.4553e+01],\n",
      "        [1.4728e+01],\n",
      "        [1.4494e+01],\n",
      "        [1.4595e+01],\n",
      "        [1.4712e+01],\n",
      "        [1.4691e+01],\n",
      "        [1.4361e+01],\n",
      "        [1.4346e+01],\n",
      "        [1.4519e+01],\n",
      "        [1.4701e+01],\n",
      "        [1.4270e+01],\n",
      "        [1.4604e+01],\n",
      "        [1.4687e+01],\n",
      "        [1.4659e+01],\n",
      "        [1.4468e+01],\n",
      "        [1.4457e+01],\n",
      "        [1.4644e+01],\n",
      "        [1.4569e+01],\n",
      "        [1.4732e+01],\n",
      "        [1.4845e+01],\n",
      "        [1.4626e+01],\n",
      "        [1.4286e+01],\n",
      "        [1.4748e+01],\n",
      "        [1.4463e+01],\n",
      "        [1.4331e+01],\n",
      "        [1.4488e+01],\n",
      "        [1.4499e+01],\n",
      "        [1.4674e+01],\n",
      "        [1.4635e+01],\n",
      "        [1.4567e+01],\n",
      "        [1.4431e+01],\n",
      "        [1.4716e+01],\n",
      "        [1.4545e+01],\n",
      "        [1.4681e+01],\n",
      "        [1.4752e+01],\n",
      "        [1.4657e+01],\n",
      "        [1.4581e+01],\n",
      "        [1.4543e+01],\n",
      "        [1.4722e+01],\n",
      "        [1.4613e+01],\n",
      "        [1.4683e+01],\n",
      "        [1.4576e+01],\n",
      "        [1.4618e+01],\n",
      "        [1.4744e+01],\n",
      "        [1.4389e+01],\n",
      "        [1.4586e+01],\n",
      "        [1.4761e+01],\n",
      "        [1.4509e+01],\n",
      "        [1.4524e+01],\n",
      "        [1.4572e+01],\n",
      "        [1.4809e+01],\n",
      "        [1.4736e+01],\n",
      "        [1.4593e+01],\n",
      "        [1.4653e+01],\n",
      "        [1.4538e+01],\n",
      "        [1.4375e+01],\n",
      "        [1.4599e+01],\n",
      "        [1.4756e+01],\n",
      "        [1.4631e+01],\n",
      "        [1.4316e+01],\n",
      "        [1.4827e+01],\n",
      "        [1.4703e+01],\n",
      "        [1.4648e+01],\n",
      "        [1.4740e+01],\n",
      "        [1.4496e+01],\n",
      "        [1.4661e+01],\n",
      "        [1.4470e+01],\n",
      "        [1.4483e+01],\n",
      "        [1.4557e+01],\n",
      "        [1.4615e+01],\n",
      "        [1.4403e+01],\n",
      "        [1.4771e+01],\n",
      "        [1.4670e+01],\n",
      "        [1.4417e+01],\n",
      "        [1.4699e+01],\n",
      "        [1.4548e+01],\n",
      "        [1.4590e+01],\n",
      "        [1.4818e+01],\n",
      "        [1.4528e+01],\n",
      "        [1.4708e+01],\n",
      "        [1.4533e+01],\n",
      "        [1.4678e+01],\n",
      "        [1.4695e+01],\n",
      "        [1.4666e+01],\n",
      "        [1.4514e+01],\n",
      "        [1.4742e+01],\n",
      "        [1.4724e+01],\n",
      "        [1.4562e+01],\n",
      "        [1.4478e+01],\n",
      "        [1.4720e+01],\n",
      "        [1.4622e+01],\n",
      "        [2.6402e+03],\n",
      "        [2.0274e-01],\n",
      "        [5.3000e-03]])\n",
      "       secid        date              symbol      exdate last_date cp_flag  \\\n",
      "5042  100219  2022-01-06  RUI 220617C2450000  2022-06-17       NaN       C   \n",
      "5047  100219  2022-01-06  RUI 220617C2490000  2022-06-17       NaN       C   \n",
      "5029  100219  2022-01-06  RUI 220617C2340000  2022-06-17       NaN       C   \n",
      "5072  100219  2022-01-06  RUI 220617C2700000  2022-06-17       NaN       C   \n",
      "5000  100219  2022-01-06  RUI 220617C2100000  2022-06-17       NaN       C   \n",
      "...      ...         ...                 ...         ...       ...     ...   \n",
      "5039  100219  2022-01-06  RUI 220617C2425000  2022-06-17       NaN       C   \n",
      "4984  100219  2022-01-06  RUI 220617C1875000  2022-06-17       NaN       C   \n",
      "4976  100219  2022-01-06  RUI 220617C1675000  2022-06-17       NaN       C   \n",
      "5027  100219  2022-01-06  RUI 220617C2325000  2022-06-17       NaN       C   \n",
      "4997  100219  2022-01-06  RUI 220617C2075000  2022-06-17       NaN       C   \n",
      "\n",
      "      strike_price  best_bid  best_offer  volume  open_interest  \\\n",
      "5042       2450000     221.7       243.4       0              0   \n",
      "5047       2490000     193.7       207.3       0              0   \n",
      "5029       2340000     309.9       331.3       0              0   \n",
      "5072       2700000      64.0        72.0       0              0   \n",
      "5000       2100000     515.5       537.5       0              0   \n",
      "...            ...       ...         ...     ...            ...   \n",
      "5039       2425000     241.6       262.5       0              0   \n",
      "4984       1875000     718.5       742.5       0              0   \n",
      "4976       1675000     910.5       934.5       0              0   \n",
      "5027       2325000     322.1       343.9       0              0   \n",
      "4997       2075000     531.0       553.0       0              0   \n",
      "\n",
      "      impl_volatility   optionid  contract_size  forward_price  \\\n",
      "5042         0.211828  140957092            100            NaN   \n",
      "5047         0.200440  140957097            100            NaN   \n",
      "5029         0.234068  140957079            100            NaN   \n",
      "5072         0.154854  140957122            100            NaN   \n",
      "5000         0.265211  140957050            100            NaN   \n",
      "...               ...        ...            ...            ...   \n",
      "5039         0.217166  140957089            100            NaN   \n",
      "4984         0.220744  140957034            100            NaN   \n",
      "4976              NaN  140957026            100            NaN   \n",
      "5027         0.236818  140957077            100            NaN   \n",
      "4997         0.238673  140957047            100            NaN   \n",
      "\n",
      "      expiry_indicator  index_flag              issuer exercise_style  \n",
      "5042               NaN           1  RUSSELL 1000 INDEX              E  \n",
      "5047               NaN           1  RUSSELL 1000 INDEX              E  \n",
      "5029               NaN           1  RUSSELL 1000 INDEX              E  \n",
      "5072               NaN           1  RUSSELL 1000 INDEX              E  \n",
      "5000               NaN           1  RUSSELL 1000 INDEX              E  \n",
      "...                ...         ...                 ...            ...  \n",
      "5039               NaN           1  RUSSELL 1000 INDEX              E  \n",
      "4984               NaN           1  RUSSELL 1000 INDEX              E  \n",
      "4976               NaN           1  RUSSELL 1000 INDEX              E  \n",
      "5027               NaN           1  RUSSELL 1000 INDEX              E  \n",
      "4997               NaN           1  RUSSELL 1000 INDEX              E  \n",
      "\n",
      "[100 rows x 19 columns]\n",
      "2644.23 0.44931506849315067 0.0053\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Project\\pipeline.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  processed['vol_high'] = processed.apply(lambda x: implied_vol(x['best_offer'], S, x['strike_price'], T, R), axis=1)\n",
      "d:\\Project\\pipeline.py:27: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  sigma = max(sigma + diff/vega, PRECISION) # f(x) / f'(x)\n",
      "d:\\Project\\pipeline.py:7: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  d1 = (np.log(S/K) + (r + 0.5*vol**2)*T) / (vol*np.sqrt(T))\n",
      "d:\\Project\\pipeline.py:12: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  d1 = (np.log(S / K) + (r + 0.5 * sigma ** 2) * T) / (sigma * np.sqrt(T))\n",
      "d:\\Project\\pipeline.py:37: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  processed['vol_low'] = processed.apply(lambda x: implied_vol(x['best_bid'], S, x['strike_price'], T, R), axis=1)\n",
      "d:\\Project\\pipeline.py:38: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  processed['vol_mid'] = (processed['vol_high'] + processed['vol_low']) / 2\n",
      "d:\\Project\\pipeline.py:27: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  sigma = max(sigma + diff/vega, PRECISION) # f(x) / f'(x)\n",
      "d:\\Project\\pipeline.py:7: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  d1 = (np.log(S/K) + (r + 0.5*vol**2)*T) / (vol*np.sqrt(T))\n",
      "d:\\Project\\pipeline.py:12: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  d1 = (np.log(S / K) + (r + 0.5 * sigma ** 2) * T) / (sigma * np.sqrt(T))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [1.4712e+01],\n",
      "        [1.4728e+01],\n",
      "        [1.4666e+01],\n",
      "        [1.4809e+01],\n",
      "        [1.4557e+01],\n",
      "        [1.4586e+01],\n",
      "        [1.4581e+01],\n",
      "        [1.4801e+01],\n",
      "        [1.4708e+01],\n",
      "        [1.4524e+01],\n",
      "        [1.4756e+01],\n",
      "        [1.4346e+01],\n",
      "        [1.4767e+01],\n",
      "        [1.4538e+01],\n",
      "        [1.4483e+01],\n",
      "        [1.4657e+01],\n",
      "        [1.4648e+01],\n",
      "        [1.4897e+01],\n",
      "        [1.4528e+01],\n",
      "        [1.4812e+01],\n",
      "        [1.4533e+01],\n",
      "        [1.4724e+01],\n",
      "        [1.4670e+01],\n",
      "        [1.4599e+01],\n",
      "        [1.4683e+01],\n",
      "        [1.4457e+01],\n",
      "        [1.4699e+01],\n",
      "        [1.4553e+01],\n",
      "        [1.4695e+01],\n",
      "        [1.4845e+01],\n",
      "        [1.4496e+01],\n",
      "        [1.4653e+01],\n",
      "        [1.4798e+01],\n",
      "        [1.4863e+01],\n",
      "        [1.4816e+01],\n",
      "        [1.4361e+01],\n",
      "        [1.4543e+01],\n",
      "        [1.4678e+01],\n",
      "        [1.4836e+01],\n",
      "        [1.4799e+01],\n",
      "        [1.4644e+01],\n",
      "        [1.4854e+01],\n",
      "        [1.4771e+01],\n",
      "        [1.4775e+01],\n",
      "        [1.4637e+01],\n",
      "        [1.4872e+01],\n",
      "        [1.4548e+01],\n",
      "        [1.4403e+01],\n",
      "        [1.4752e+01],\n",
      "        [1.4593e+01],\n",
      "        [1.4720e+01],\n",
      "        [1.4794e+01],\n",
      "        [1.4906e+01],\n",
      "        [1.4631e+01],\n",
      "        [1.4781e+01],\n",
      "        [1.4827e+01],\n",
      "        [1.4687e+01],\n",
      "        [1.4569e+01],\n",
      "        [1.4779e+01],\n",
      "        [1.4622e+01],\n",
      "        [1.4567e+01],\n",
      "        [1.4736e+01],\n",
      "        [1.4744e+01],\n",
      "        [1.4691e+01],\n",
      "        [1.4590e+01],\n",
      "        [1.4703e+01],\n",
      "        [1.4389e+01],\n",
      "        [1.4761e+01],\n",
      "        [1.4889e+01],\n",
      "        [1.4818e+01],\n",
      "        [1.4732e+01],\n",
      "        [1.4375e+01],\n",
      "        [1.4626e+01],\n",
      "        [1.4609e+01],\n",
      "        [1.4880e+01],\n",
      "        [1.4742e+01],\n",
      "        [1.4431e+01],\n",
      "        [1.4572e+01],\n",
      "        [1.4615e+01],\n",
      "        [1.4417e+01],\n",
      "        [1.4716e+01],\n",
      "        [1.4748e+01],\n",
      "        [1.4661e+01],\n",
      "        [1.4595e+01],\n",
      "        [1.4759e+01],\n",
      "        [1.4782e+01],\n",
      "        [1.4613e+01],\n",
      "        [1.4640e+01],\n",
      "        [1.4914e+01],\n",
      "        [1.4509e+01],\n",
      "        [1.4519e+01],\n",
      "        [1.4470e+01],\n",
      "        [1.4763e+01],\n",
      "        [1.4604e+01],\n",
      "        [1.4562e+01],\n",
      "        [1.4701e+01],\n",
      "        [1.4444e+01],\n",
      "        [1.4331e+01],\n",
      "        [1.4659e+01],\n",
      "        [1.4545e+01],\n",
      "        [2.6442e+03],\n",
      "        [4.4932e-01],\n",
      "        [5.3000e-03]])\n",
      "       secid        date              symbol      exdate last_date cp_flag  \\\n",
      "6713  100219  2022-01-07  RUI 220916C2720000  2022-09-16       NaN       C   \n",
      "6722  100219  2022-01-07  RUI 220916C2790000  2022-09-16       NaN       C   \n",
      "6711  100219  2022-01-07  RUI 220916C2700000  2022-09-16       NaN       C   \n",
      "6650  100219  2022-01-07  RUI 220916C2190000  2022-09-16       NaN       C   \n",
      "6706  100219  2022-01-07  RUI 220916C2660000  2022-09-16       NaN       C   \n",
      "...      ...         ...                 ...         ...       ...     ...   \n",
      "6721  100219  2022-01-07  RUI 220916C2780000  2022-09-16       NaN       C   \n",
      "6639  100219  2022-01-07  RUI 220916C2050000  2022-09-16       NaN       C   \n",
      "6731  100219  2022-01-07  RUI 220916C2870000  2022-09-16       NaN       C   \n",
      "6696  100219  2022-01-07  RUI 220916C2575000  2022-09-16       NaN       C   \n",
      "6637  100219  2022-01-07  RUI 220916C2000000  2022-09-16       NaN       C   \n",
      "\n",
      "      strike_price  best_bid  best_offer  volume  open_interest  \\\n",
      "6713       2720000      85.0        93.0       0              0   \n",
      "6722       2790000      54.5        62.5       0              0   \n",
      "6711       2700000      94.5       102.5       0              0   \n",
      "6650       2190000     453.0       475.0       0              0   \n",
      "6706       2660000     110.0       124.0       0              0   \n",
      "...            ...       ...         ...     ...            ...   \n",
      "6721       2780000      60.0        68.0       0              0   \n",
      "6639       2050000     573.0       595.0       0              0   \n",
      "6731       2870000      31.0        39.0       0              0   \n",
      "6696       2575000     166.5       180.5       0              0   \n",
      "6637       2000000     615.0       637.0       0              0   \n",
      "\n",
      "      impl_volatility   optionid  contract_size  forward_price  \\\n",
      "6713         0.161319  142596779            100            NaN   \n",
      "6722         0.149423  142596788            100            NaN   \n",
      "6711         0.164296  142596777            100            NaN   \n",
      "6650         0.250918  142596716            100            NaN   \n",
      "6706         0.168034  142596772            100            NaN   \n",
      "...               ...        ...            ...            ...   \n",
      "6721         0.153130  142596787            100            NaN   \n",
      "6639         0.268662  142596705            100            NaN   \n",
      "6731         0.140987  142596797            100            NaN   \n",
      "6696         0.189537  142596762            100            NaN   \n",
      "6637         0.268704  142596703            100            NaN   \n",
      "\n",
      "      expiry_indicator  index_flag              issuer exercise_style  \n",
      "6713               NaN           1  RUSSELL 1000 INDEX              E  \n",
      "6722               NaN           1  RUSSELL 1000 INDEX              E  \n",
      "6711               NaN           1  RUSSELL 1000 INDEX              E  \n",
      "6650               NaN           1  RUSSELL 1000 INDEX              E  \n",
      "6706               NaN           1  RUSSELL 1000 INDEX              E  \n",
      "...                ...         ...                 ...            ...  \n",
      "6721               NaN           1  RUSSELL 1000 INDEX              E  \n",
      "6639               NaN           1  RUSSELL 1000 INDEX              E  \n",
      "6731               NaN           1  RUSSELL 1000 INDEX              E  \n",
      "6696               NaN           1  RUSSELL 1000 INDEX              E  \n",
      "6637               NaN           1  RUSSELL 1000 INDEX              E  \n",
      "\n",
      "[100 rows x 19 columns]\n",
      "2600.1 0.6958904109589041 0.0053\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Project\\pipeline.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  processed['vol_high'] = processed.apply(lambda x: implied_vol(x['best_offer'], S, x['strike_price'], T, R), axis=1)\n",
      "d:\\Project\\pipeline.py:27: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  sigma = max(sigma + diff/vega, PRECISION) # f(x) / f'(x)\n",
      "d:\\Project\\pipeline.py:7: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  d1 = (np.log(S/K) + (r + 0.5*vol**2)*T) / (vol*np.sqrt(T))\n",
      "d:\\Project\\pipeline.py:12: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  d1 = (np.log(S / K) + (r + 0.5 * sigma ** 2) * T) / (sigma * np.sqrt(T))\n",
      "d:\\Project\\pipeline.py:37: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  processed['vol_low'] = processed.apply(lambda x: implied_vol(x['best_bid'], S, x['strike_price'], T, R), axis=1)\n",
      "d:\\Project\\pipeline.py:38: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  processed['vol_mid'] = (processed['vol_high'] + processed['vol_low']) / 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [1.4816e+01],\n",
      "        [1.4842e+01],\n",
      "        [1.4809e+01],\n",
      "        [1.4599e+01],\n",
      "        [1.4794e+01],\n",
      "        [1.4779e+01],\n",
      "        [1.4695e+01],\n",
      "        [1.4569e+01],\n",
      "        [1.4716e+01],\n",
      "        [1.4389e+01],\n",
      "        [1.4724e+01],\n",
      "        [1.4798e+01],\n",
      "        [1.4775e+01],\n",
      "        [1.4859e+01],\n",
      "        [1.4863e+01],\n",
      "        [1.4823e+01],\n",
      "        [1.4854e+01],\n",
      "        [1.4748e+01],\n",
      "        [1.4496e+01],\n",
      "        [1.4922e+01],\n",
      "        [1.4889e+01],\n",
      "        [1.4880e+01],\n",
      "        [1.4827e+01],\n",
      "        [1.4914e+01],\n",
      "        [1.4586e+01],\n",
      "        [1.4836e+01],\n",
      "        [1.4722e+01],\n",
      "        [1.4457e+01],\n",
      "        [1.4763e+01],\n",
      "        [1.4742e+01],\n",
      "        [1.4613e+01],\n",
      "        [1.4906e+01],\n",
      "        [1.4740e+01],\n",
      "        [1.4831e+01],\n",
      "        [1.4483e+01],\n",
      "        [1.4670e+01],\n",
      "        [1.4444e+01],\n",
      "        [1.4657e+01],\n",
      "        [1.4866e+01],\n",
      "        [1.4593e+01],\n",
      "        [1.4581e+01],\n",
      "        [1.4631e+01],\n",
      "        [1.4615e+01],\n",
      "        [1.4801e+01],\n",
      "        [1.4786e+01],\n",
      "        [1.4648e+01],\n",
      "        [1.4703e+01],\n",
      "        [1.4849e+01],\n",
      "        [1.4744e+01],\n",
      "        [1.4756e+01],\n",
      "        [1.4595e+01],\n",
      "        [1.4653e+01],\n",
      "        [1.4852e+01],\n",
      "        [1.4872e+01],\n",
      "        [1.4691e+01],\n",
      "        [1.4856e+01],\n",
      "        [1.4557e+01],\n",
      "        [1.4661e+01],\n",
      "        [1.4812e+01],\n",
      "        [1.4683e+01],\n",
      "        [1.4470e+01],\n",
      "        [1.4736e+01],\n",
      "        [1.4681e+01],\n",
      "        [1.4609e+01],\n",
      "        [1.4622e+01],\n",
      "        [1.4403e+01],\n",
      "        [1.4820e+01],\n",
      "        [1.4576e+01],\n",
      "        [1.4782e+01],\n",
      "        [1.4678e+01],\n",
      "        [1.4637e+01],\n",
      "        [1.4939e+01],\n",
      "        [1.4618e+01],\n",
      "        [1.4834e+01],\n",
      "        [1.4708e+01],\n",
      "        [1.4666e+01],\n",
      "        [1.4845e+01],\n",
      "        [1.4604e+01],\n",
      "        [1.4963e+01],\n",
      "        [1.4674e+01],\n",
      "        [1.4644e+01],\n",
      "        [1.4771e+01],\n",
      "        [1.4767e+01],\n",
      "        [1.4699e+01],\n",
      "        [1.4590e+01],\n",
      "        [1.4728e+01],\n",
      "        [1.4640e+01],\n",
      "        [1.4687e+01],\n",
      "        [1.4572e+01],\n",
      "        [1.4521e+01],\n",
      "        [1.4431e+01],\n",
      "        [1.4947e+01],\n",
      "        [1.4790e+01],\n",
      "        [1.4897e+01],\n",
      "        [1.4955e+01],\n",
      "        [1.4838e+01],\n",
      "        [1.4533e+01],\n",
      "        [1.4870e+01],\n",
      "        [1.4761e+01],\n",
      "        [1.4509e+01],\n",
      "        [2.6001e+03],\n",
      "        [6.9589e-01],\n",
      "        [5.3000e-03]])\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "a must be greater than 0 unless no samples are taken",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[75], line 16\u001b[0m\n\u001b[0;32m     14\u001b[0m R \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0053\u001b[39m \u001b[38;5;66;03m# Arb for now\u001b[39;00m\n\u001b[0;32m     15\u001b[0m S \u001b[38;5;241m=\u001b[39m securities[(securities[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdate\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m dts(d)) \u001b[38;5;241m&\u001b[39m (securities[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msecid\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m==\u001b[39m\u001b[38;5;241m100219\u001b[39m)][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlow\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m---> 16\u001b[0m data_in \u001b[38;5;241m=\u001b[39m \u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdate\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdts\u001b[49m\u001b[43m(\u001b[49m\u001b[43md\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mdt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m&\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcp_flag\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mC\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m&\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mexdate\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28mprint\u001b[39m(data_in)\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28mprint\u001b[39m(S, T, R)\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\generic.py:6112\u001b[0m, in \u001b[0;36mNDFrame.sample\u001b[1;34m(self, n, frac, replace, weights, random_state, axis, ignore_index)\u001b[0m\n\u001b[0;32m   6109\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m weights \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   6110\u001b[0m     weights \u001b[38;5;241m=\u001b[39m sample\u001b[38;5;241m.\u001b[39mpreprocess_weights(\u001b[38;5;28mself\u001b[39m, weights, axis)\n\u001b[1;32m-> 6112\u001b[0m sampled_indices \u001b[38;5;241m=\u001b[39m \u001b[43msample\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj_len\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreplace\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   6113\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(sampled_indices, axis\u001b[38;5;241m=\u001b[39maxis)\n\u001b[0;32m   6115\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ignore_index:\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\sample.py:152\u001b[0m, in \u001b[0;36msample\u001b[1;34m(obj_len, size, replace, weights, random_state)\u001b[0m\n\u001b[0;32m    149\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    150\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid weights: weights sum to zero\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 152\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchoice\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj_len\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreplace\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweights\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mastype(\n\u001b[0;32m    153\u001b[0m     np\u001b[38;5;241m.\u001b[39mintp, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    154\u001b[0m )\n",
      "File \u001b[1;32mnumpy\\\\random\\\\mtrand.pyx:944\u001b[0m, in \u001b[0;36mnumpy.random.mtrand.RandomState.choice\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: a must be greater than 0 unless no samples are taken"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "importlib.reload(pipeline)\n",
    "dts = lambda x: datetime.datetime.strftime(x, \"%Y-%m-%d\")\n",
    "std = lambda x: datetime.datetime.strptime(x, \"%Y-%m-%d\")\n",
    "dt100219 = []\n",
    "d = std(\"2022-01-03\")\n",
    "date_end = std(\"2022-01-12\")\n",
    "dt = datetime.timedelta(days=1)\n",
    "# while d <= date_end:\n",
    "data = data[data['best_bid'] != 0]\n",
    "counts = data[(data['date'] == dts(d+ 2 *dt)) & (data['cp_flag'] == 'C')].groupby('exdate',as_index=False).count()\n",
    "for i in counts[counts['secid'] > 100]['exdate']:\n",
    "    T = (std(i) - d).days / 365\n",
    "    R = 0.0053 # Arb for now\n",
    "    S = securities[(securities['date'] == dts(d)) & (securities['secid']==100219)]['low'].iloc[0]\n",
    "    data_in = data[(data['date'] == dts(d+ 2 *dt)) & (data['cp_flag'] == 'C') & (data['exdate'] == i)].sample(100)\n",
    "    print(data_in)\n",
    "    print(S, T, R)\n",
    "    dt100219 += [pipeline.get_datum(data_in,S, T, R)]\n",
    "    d += dt\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1c843e99a00>]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiwAAAGdCAYAAAAxCSikAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8g+/7EAAAACXBIWXMAAA9hAAAPYQGoP6dpAABXkUlEQVR4nO3deVhVdeLH8fe9Fy4gsqjIpiguqbmiqGSbNUNh46ROZWqWSZZl2xi26K9JKy2srBzTycYWtSa1vZkWW0gr01xQ3DV3UQRFZRGU5d7z+wOjYXLhInAul8/rec7zjIdzDp97xqf78Zzv+R6LYRgGIiIiIm7ManYAERERkfNRYRERERG3p8IiIiIibk+FRURERNyeCouIiIi4PRUWERERcXsqLCIiIuL2VFhERETE7XmZHaA6OJ1OMjIyCAgIwGKxmB1HREREKsEwDPLz84mMjMRqPfc1FI8oLBkZGURFRZkdQ0RERKogPT2d5s2bn3MbjygsAQEBQNkHDgwMNDmNiIiIVEZeXh5RUVHl3+Pn4hGF5dfbQIGBgSosIiIidUxlhnNo0K2IiIi4PRUWERERcXsqLCIiIuL2VFhERETE7amwiIiIiNtTYRERERG3p8IiIiIibk+FRURERNyeCouIiIi4PRUWERERcXsqLCIiIuL2qlRYZs2aRXR0NL6+vsTFxbFq1aqzbjt37lwsFkuFxdfXt8I2hmEwceJEIiIi8PPzIz4+nh07dlQlmoiIiHgglwvLokWLSEpKYtKkSaxdu5Zu3bqRkJDA4cOHz7pPYGAghw4dKl/27dtX4efPP/88M2bMYPbs2axcuRJ/f38SEhI4deqU65+oGhmGwes/7ubJf282NYeIiEh953Jheemll7jrrrtITEykY8eOzJ49mwYNGvDmm2+edR+LxUJ4eHj5EhYWVv4zwzCYPn06f/vb3xg4cCBdu3Zl/vz5ZGRk8Mknn1TpQ1WXjQdzmfL5VuYu38vnGw6ZmkVERKQ+c6mwFBcXk5qaSnx8/G8HsFqJj49nxYoVZ93vxIkTtGzZkqioKAYOHMjmzb9dsdizZw+ZmZkVjhkUFERcXNw5j1kbujYPZsxVbQAY/+EG9h8tNDWPiIhIfeVSYcnOzsbhcFS4QgIQFhZGZmbmGfdp3749b775Jp9++invvPMOTqeTSy+9lAMHDgCU7+fKMYuKisjLy6uw1JSka9oR27IR+UWl3L9gLcWlzhr7XSIiInJmNf6UUJ8+fRgxYgQxMTH07duXjz76iKZNm/Laa69V+ZjJyckEBQWVL1FRUdWYuCJvm5UZw7oT5OfNhgO5PLd4W439LhERETkzlwpLSEgINpuNrKysCuuzsrIIDw+v1DG8vb3p3r07O3fuBCjfz5VjTpgwgdzc3PIlPT3dlY/hsmbBfkwb3A2AN5bt4dstWefZQ0RERKqTS4XFbrcTGxtLSkpK+Tqn00lKSgp9+vSp1DEcDgcbN24kIiICgFatWhEeHl7hmHl5eaxcufKsx/Tx8SEwMLDCUtOu6RhG4mXRADz8wXoyck7W+O8UERGRMi7fEkpKSmLOnDnMmzePrVu3MmbMGAoKCkhMTARgxIgRTJgwoXz7p59+mq+//prdu3ezdu1abr31Vvbt28edd94JlD1BNHbsWKZMmcK///1vNm7cyIgRI4iMjGTQoEHV8ymryfjrOtClWRA5hSU8uGAdpQ6NZxEREakNXq7uMGTIEI4cOcLEiRPJzMwkJiaGxYsXlw+a3b9/P1brbz3o+PHj3HXXXWRmZtKoUSNiY2NZvnw5HTt2LN/m0UcfpaCggNGjR5OTk8Pll1/O4sWLfzfBnNl8vGzMvKU7/WcsY82+47z87S88ktDB7FgiIiIez2IYhmF2iAuVl5dHUFAQubm5tXJ76LMNGdz/7josFpiX2Jsr2zWt8d8pIiLiaVz5/ta7hKrgz10juSWuBYYBSe+lcTjf3Bl5RUREPJ0KSxVN/HNHOoQHkH2imLEL03A46/yFKhEREbelwlJFvt5l41n8vG0s33WUfyzZaXYkERERj6XCcgHahgYweVBnAF7+9hdW7j5qciIRERHPpMJygW6Kbc4NPZrhNODBhes4VlBsdiQRERGPo8JSDSYP7Ezrpv5k5RXx8PvrcWo8i4iISLVSYakG/j5ezBzWA7uXle+2HeaNZXvMjiQiIuJRVFiqScfIQJ74c9lkeM8t3kZaeo65gURERDyICks1ujWuBX/qEk6p0+D+d9eSe7LE7EgiIiIeQYWlGlksFpJv6ErzRn4cOH6SCR9twAMmEhYRETGdCks1C/LzZuYtPfCyWvhiYybvrNxvdiQREZE6T4WlBsREBfNYv7KXIk7+bAtbMvJMTiQiIlK3qbDUkFGXt+IPHUIpLnVy/7trKSgqNTuSiIhInaXCUkOsVgvTBncjPNCX3dkFPPHpJrMjiYiI1FkqLDWosb+dvw+NwWqBj9Ye5IPUA2ZHEhERqZNUWGpYXOsmjI1vB8ATn2xi5+ETJicSERGpe1RYasF9V7fl0jZNOFni4P5313KqxGF2JBERkTpFhaUW2KwWpg+JoYm/nW2Z+Uz8dJPmZxEREXGBCkstCQ305eUhMVgs8N6aA7z0zS9mRxIREakzVFhq0ZXtmjJlUGcAXvluJ2/qJYkiIiKVosJSy4bHteTha8sG4T792RY+Xqcnh0RERM5HhcUE913dlsTLogF4+P0NfLcty9xAIiIibk6FxQQWi4Un+nfkL92b4XAajHlnLav3HjM7loiIiNtSYTGJ1Wrh+Zu68ocOoRSVOrlj7mq2HtI7h0RERM5EhcVE3jYrs27pQa/oRuSfKmXEm6vYf7TQ7FgiIiJuR4XFZH52G6/f3osO4QEcyS/i1jdWcjj/lNmxRERE3IoKixsI8vNm/h29adG4AfuPFTLijVXkniwxO5aIiIjbUGFxE6GBvrw9qjchDX3YlpnPnfNWc7JYU/iLiIiACotbadnEn/l39CbA14vVe4/zt082mR1JRETELaiwuJmOkYG8dlssVgt8uPYAH63VxHIiIiIqLG7o0jYh/PWPZbPh/u2TTew+csLkRCIiIuaqUmGZNWsW0dHR+Pr6EhcXx6pVqyq138KFC7FYLAwaNKjC+pEjR2KxWCos/fr1q0o0j3H/H9oS16oxhcUOHliwjqJSjWcREZH6y+XCsmjRIpKSkpg0aRJr166lW7duJCQkcPjw4XPut3fvXh5++GGuuOKKM/68X79+HDp0qHxZsGCBq9E8is1q4e9Du9OogTebM/KY+uU2syOJiIiYxuXC8tJLL3HXXXeRmJhIx44dmT17Ng0aNODNN9886z4Oh4Phw4fz1FNP0bp16zNu4+PjQ3h4ePnSqFEjV6N5nPAgX168uRsAb/20l2+26J1DIiJSP7lUWIqLi0lNTSU+Pv63A1itxMfHs2LFirPu9/TTTxMaGsqoUaPOus3SpUsJDQ2lffv2jBkzhqNHj55126KiIvLy8iosnuoPHcIYdXkrAB75YD2Hck+anEhERKT2uVRYsrOzcTgchIWFVVgfFhZGZmbmGfdZtmwZb7zxBnPmzDnrcfv168f8+fNJSUnhueee4/vvv+e6667D4TjzuI3k5GSCgoLKl6ioKFc+Rp3zaL/2dGkWRE5hCX9dkEapw2l2JBERkVpVo08J5efnc9tttzFnzhxCQkLOut3QoUMZMGAAXbp0YdCgQXz22WesXr2apUuXnnH7CRMmkJubW76kp6fX0CdwDz5eNl4Z1h1/u41Ve4/xync7zY4kIiJSq7xc2TgkJASbzUZWVsWxFFlZWYSHh/9u+127drF3716uv/768nVOZ9nVAS8vL7Zv306bNm1+t1/r1q0JCQlh586d/PGPf/zdz318fPDx8XElep0XHeLPszd04a8L03jlux1c0roJfdo0MTuWiIhIrXDpCovdbic2NpaUlJTydU6nk5SUFPr06fO77Tt06MDGjRtJS0srXwYMGMDVV19NWlraWW/lHDhwgKNHjxIREeHix/FsA2OaMTi2OU4Dxi5ax7GCYrMjiYiI1AqXrrAAJCUlcfvtt9OzZ0969+7N9OnTKSgoIDExEYARI0bQrFkzkpOT8fX1pXPnzhX2Dw4OBihff+LECZ566iluvPFGwsPD2bVrF48++iht27YlISHhAj+e53lqYCdS9x9n95ECHn5/PW/c3hOLxWJ2LBERkRrl8hiWIUOGMG3aNCZOnEhMTAxpaWksXry4fCDu/v37OXToUKWPZ7PZ2LBhAwMGDKBdu3aMGjWK2NhYfvzxx3p326cyGti9mDmsB3YvK99tO8wby/aYHUlERKTGWQzDMMwOcaHy8vIICgoiNzeXwMBAs+PUirdX7OWJTzfjbbPw4ZhL6do82OxIIiIiLnHl+1vvEqqjbr2kJQmdwihxGDywYB35p0rMjiQiIlJjVFjqKIvFwvM3dqNZsB/7jhbyxCeb8ICLZSIiImekwlKHBTXw5u9DY7BZLXySlsGHaw+aHUlERKRGqLDUcT2jG/NQ/EUAPPHJJnYdOWFyIhERkeqnwuIBxlzVlkvbNOFkiYP7313HqZIzv9JARESkrlJh8QA2q4WXh8TQ2N/O1kN5TP1ym9mRREREqpUKi4cIC/TlxcHdAJi7fC9fbz7zyyhFRETqIhUWD3J1h1DuvLwVAI9+uIGMnJMmJxIREakeKiwe5tF+HejSLIicwhLGLkyj1OE0O5KIiMgFU2HxMHYvK68M605DHy9W7T3GjO92mh1JRETkgqmweKDoEH+e+UvZyyVnfreDFbuOmpxIRETkwqiweKiBMc0YHNscpwFjF63jWEGx2ZFERESqTIXFgz01sBOtm/qTlVfE6PlrND+LiIjUWSosHqyB3YvZt8YS6OvFmn3Huf/ddRqEKyIidZIKi4drFxbA67f3wu5l5dutWTzxqV6SKCIidY8KSz3Qu1VjZgztjtUCC1al8/K3O8yOJCIi4hIVlnqiX+dwJg8qe3JoRsoO3vl5n8mJREREKk+FpR4ZHteSv/7x9JudP93E4k2HTE4kIiJSOSos9czY+IsY1rsFhgEPLkxj5W7N0SIiIu5PhaWesVgsTB7YiWs6hlFc6uTO+WvYlplndiwREZFzUmGph7xsZdP392zZiPxTpdz+5ioO6kWJIiLixlRY6ilfbxuv396Ti0IbkpVXxIg3VnJcs+GKiIibUmGpx4Ib2Jl3R28ignzZdaSAe95JxeHUHC0iIuJ+VFjquchgP+bd0Rt/u42Ve44xU293FhERN6TCIrQLC2DK6bc7/z3lF1bvPWZyIhERkYpUWASAv3Rvzg3dm+E04K8L1pFbWGJ2JBERkXIqLFLu6UGdiW7SgIzcU4z/aIPeOSQiIm5DhUXKNfTxYsaw7nhZLXy5KZMFq9LNjiQiIgKosMj/6No8mEf7tQfgqf9s5pesfJMTiYiIqLDIGdx5eWuuuCiEolInDy5Yx6kSh9mRRESknlNhkd+xWi28eHM3Qhra2ZaZz7NfbDU7koiI1HNVKiyzZs0iOjoaX19f4uLiWLVqVaX2W7hwIRaLhUGDBlVYbxgGEydOJCIiAj8/P+Lj49mxY0dVokk1CQ3wZdrgbgDMX7GPrzdnmpxIRETqM5cLy6JFi0hKSmLSpEmsXbuWbt26kZCQwOHDh8+53969e3n44Ye54oorfvez559/nhkzZjB79mxWrlyJv78/CQkJnDp1ytV4Uo2uah/KXVe0AuDRDzdwKFfvGxIREXO4XFheeukl7rrrLhITE+nYsSOzZ8+mQYMGvPnmm2fdx+FwMHz4cJ566ilat25d4WeGYTB9+nT+9re/MXDgQLp27cr8+fPJyMjgk08+cfkDSfV6JKEDXZoFkVNYwtiFaZq6X0RETOFSYSkuLiY1NZX4+PjfDmC1Eh8fz4oVK86639NPP01oaCijRo363c/27NlDZmZmhWMGBQURFxd31mMWFRWRl5dXYZGaYfeyMmNYdxqcnrp/1hJN3S8iIrXPpcKSnZ2Nw+EgLCyswvqwsDAyM888xmHZsmW88cYbzJkz54w//3U/V46ZnJxMUFBQ+RIVFeXKxxAXtQrxZ/LAsqn7X/72F77SeBYREallNfqUUH5+Prfddhtz5swhJCSk2o47YcIEcnNzy5f0dE1wVtNu6NGMW+JaYBjw4IJ1pO47bnYkERGpR7xc2TgkJASbzUZWVlaF9VlZWYSHh/9u+127drF3716uv/768nVOp7PsF3t5sX379vL9srKyiIiIqHDMmJiYM+bw8fHBx8fHlehygSwWC08P6ERm7im+23aYO+et5sMxl9K6aUOzo4mISD3g0hUWu91ObGwsKSkp5eucTicpKSn06dPnd9t36NCBjRs3kpaWVr4MGDCAq6++mrS0NKKiomjVqhXh4eEVjpmXl8fKlSvPeEwxj5fNysxbutOteRDHC0u4/a1VHMkvMjuWiIjUAy5dYQFISkri9ttvp2fPnvTu3Zvp06dTUFBAYmIiACNGjKBZs2YkJyfj6+tL586dK+wfHBwMUGH92LFjmTJlChdddBGtWrXiiSeeIDIy8nfztYj5Gti9eGNkL274x3L2HyvkjrmrWTj6Evx9XP6rJCIiUmkuf8sMGTKEI0eOMHHiRDIzM4mJiWHx4sXlg2b379+P1era0JhHH32UgoICRo8eTU5ODpdffjmLFy/G19fX1XhSC0Ia+jDvjt7c+OpyNh7M5b531/L6iJ542TRxsoiI1AyLYRh1fmKNvLw8goKCyM3NJTAw0Ow49ca6/ccZNudnTpU4GdoriuQbumCxWMyOJSIidYQr39/6J7FUWfcWjXhlWA+sFli4Op0ZKZqjRUREaoYKi1yQazqG8fR/zdHy3ho9Yi4iItVPhUUu2K2XtOTeq9oAMOGjjSzdfu73SomIiLhKhUWqxSMJ7flL92Y4nAb3/Wstu4+cMDuSiIh4EBUWqRYWi4XnbuxK71aNKSh28NeFaRSXOs2OJSIiHkKFRaqN3cvK34fGENzAm40Hc3nxm+1mRxIREQ+hwiLVKiLIj6k3dAXgte93s2xHtsmJRETEE6iwSLXr1zmcW+JaAJD0XhrHCopNTiQiInWdCovUiCf6d6RNU38O5xfx6Acb8ID5CUVExEQqLFIj/Ow2Zgzrjt1m5dutWbzz8z6zI4mISB2mwiI1plNkEI9d1wGAKZ9vZXtmvsmJRESkrlJhkRqVeGk0fds1pajUyYML1nGqxGF2JBERqYNUWKRGWa0Wpg3uRkhDO9uz8pn65TazI4mISB2kwiI1rmmADy/c1A2Aucv38t22LJMTiYhIXaPCIrXi6g6hJF4WDcDD72/gcN4pcwOJiEidosIitWb8dR24OCKQYwXFjHt/PQ6nHnUWEZHKUWGRWuPjZeOVYTH4elv5cUc2Uz7fYnYkERGpI1RYpFa1DQ1g2uCy8Sxv/bSXN5ftMTmRiIjUBSosUuv+3DWS8afnZ5n8+Ra+3pxpciIREXF3KixiiruvbM0tcS0wDHhw4TrWp+eYHUlERNyYCouYwmKx8PSATvRt15RTJU5GzVtN+rFCs2OJiIibUmER03jZrMwa3oOLIwLJPlFM4tzV5J4sMTuWiIi4IRUWMVVDHy/eGtmL8EBfdh4+wT1vp1Jc6jQ7loiIuBkVFjFdeJAvb47shb/dxordRxn/0QYMQ3O0iIjIb1RYxC10jAxk1vAe2KwWPlp7kL+n7DA7koiIuBEVFnEbV7UPZfLAzgBM/3YHH6YeMDmRiIi4CxUWcSu3xLVgzFVtAJjw8Ua2ZeaZnEhERNyBCou4nUeubc8fO4RSXOrkrwvSOFXiMDuSiIiYTIVF3I7VauG5m7oS0tCH7Vn5TP1ym9mRRETEZCos4pZCGvowbXBXAOYu38uS7YdNTiQiImZSYRG3dVX7UEZeGg3AI+9vIPtEkbmBRETENFUqLLNmzSI6OhpfX1/i4uJYtWrVWbf96KOP6NmzJ8HBwfj7+xMTE8Pbb79dYZuRI0disVgqLP369atKNPEw46/rQPuwALJPFPHYB5qfRUSkvnK5sCxatIikpCQmTZrE2rVr6datGwkJCRw+fOZL9o0bN+bxxx9nxYoVbNiwgcTERBITE/nqq68qbNevXz8OHTpUvixYsKBqn0g8iq+3jb8Pi8HuZSVl22HeWbnf7EgiImICi+HiP1nj4uLo1asXM2fOBMDpdBIVFcUDDzzA+PHjK3WMHj160L9/fyZPngyUXWHJycnhk08+cS39aXl5eQQFBZGbm0tgYGCVjiHu7c1le3j6sy34eFn5/MHLaRsaYHYkERG5QK58f7t0haW4uJjU1FTi4+N/O4DVSnx8PCtWrDjv/oZhkJKSwvbt27nyyisr/Gzp0qWEhobSvn17xowZw9GjR896nKKiIvLy8ios4tlGXhrNle2aUlTq5MEFaRSV6lFnEZH6xKXCkp2djcPhICwsrML6sLAwMjMzz7pfbm4uDRs2xG63079/f1555RWuueaa8p/369eP+fPnk5KSwnPPPcf333/Pddddh8Nx5i+l5ORkgoKCypeoqChXPobUQVarhWk3daWxv50th/J48etfzI4kIiK1qFaeEgoICCAtLY3Vq1fzzDPPkJSUxNKlS8t/PnToUAYMGECXLl0YNGgQn332GatXr66wzX+bMGECubm55Ut6enptfAwxWWigL8/dWPao8z9/2M2yHdkmJxIRkdriUmEJCQnBZrORlZVVYX1WVhbh4eFn/yVWK23btiUmJoZx48Zx0003kZycfNbtW7duTUhICDt37jzjz318fAgMDKywSP1wTccwhse1AGDc+2kcLyg2OZGIiNQGlwqL3W4nNjaWlJSU8nVOp5OUlBT69OlT6eM4nU6Kis4+p8aBAwc4evQoERERrsSTeuJv/TvSuqk/WXlFjHt/PQ6nHnUWEfF0Lt8SSkpKYs6cOcybN4+tW7cyZswYCgoKSExMBGDEiBFMmDChfPvk5GS++eYbdu/ezdatW3nxxRd5++23ufXWWwE4ceIEjzzyCD///DN79+4lJSWFgQMH0rZtWxISEqrpY4on8bPbmDG0Oz5eVr7bdphnv9hqdiQREalhXq7uMGTIEI4cOcLEiRPJzMwkJiaGxYsXlw/E3b9/P1brbz2ooKCAe++9lwMHDuDn50eHDh145513GDJkCAA2m40NGzYwb948cnJyiIyM5Nprr2Xy5Mn4+PhU08cUT9O5WRAv3tyN+99dxxvL9tAqxJ9bL2lpdiwREakhLs/D4o40D0v9NfO7HUz7+hdsVgtvjezFle2amh1JREQqqcbmYRFxN/dd3ZYbejTD4TS4719r2ZGVb3YkERGpASosUqdZLBaSb+hC7+jG5BeVcse81RzVSxJFRDyOCovUeT5eNmbfFkvLJg1IP3aS0W+ncqpEM+GKiHgSFRbxCI397bxxey8Cfb1I3Xecxz7Um51FRDyJCot4jLahDXn11li8rBY+TctgRsqZJx4UEZG6R4VFPMplbUOYPKgzAC9/+wv/Xp9hciIREakOKizicYb1bsHoK1sD8PD769lwIMfcQCIicsFUWMQjPdavA/EXh1Fc6mTswjQKi0vNjiQiIhdAhUU8ks1q4cXB3YgI8mV3dgHPfK7p+0VE6jIVFvFYQQ28eXFwNwD+tXI/KVuzzrOHiIi4KxUW8WiXtg3hzstbAfDoBxs4kq9J5URE6iIVFvF4Dye0p0N4AEcLihmv+VlEROokFRbxeL7eNqYPjcFus5Ky7TALVqWbHUlERFykwiL1QofwQB7t1x6AyZ9tYfeREyYnEhERV6iwSL1xx2WtuKxtE06WOHhoURolDqfZkUREpJJUWKTesFotTBvcjUBfL9YfyOWVlB1mRxIRkUpSYZF6JSLIj2dv6ALAzCU7Sd13zOREIiJSGSosUu/8uWskN3RvhtOAhxat50SRZsEVEXF3KixSLz05sBPNgv3Yf6yQJ/+92ew4IiJyHiosUi8F+nrz0s3dsFjgg9QDvL1ir9mRRETkHFRYpN6Ka92Ex/p1AODJ/2zhp53ZJicSEXE/hmHwxCeb+NfKfabmUGGReu3uK1tzQ/dmOJwG9/5rLXuyC8yOJCLiVmYt2cnbP+/jiU82sfNwvmk5VFikXrNYLDx7Qxe6twgm92QJo+atJvdkidmxRETcwgepB5j29S8APDmgE21DA0zLosIi9Z6vt43XboslIsiX3UcKeGDBOko1qZyI1HM/7jjC+A83AHB339aM6BNtah4VFhEgNMCXOSN64udt44dfjpD85TazI4mImGZzRi5j3llLqdNgQLdIHkvoYHYkFRaRX3VuFsSLN3cD4I1le1i0er/JiUREat+B44UkvrWaE0Wl9GndhBcGd8VqtZgdS4VF5L/9qUsED8W3A+Bvn2xi9V7NhCsi9UduYQkj31rN4fwi2ocFMPu2WHy8bGbHAlRYRH7nwT+2pX+XCEocBve8nUr6sUKzI4mI1LiiUgd3vb2GnYdPEB7oy1uJvQjy8zY7VjkVFpH/YbGUvSSxc7NAjhYUc9f8NZq+X0Q8mtNpMO699azac4wAHy/eSuxFZLCf2bEqUGEROQM/u405I3rSNMCHbZn5jHsvDafTMDuWiEiNeG7xNj7bcAgvq4XZt8VycUSg2ZF+R4VF5Cwigvz4522x2G1Wvtqcxd9TdpgdSUSk2s1fsZfXftgNwHM3duWytiEmJzqzKhWWWbNmER0dja+vL3Fxcaxateqs23700Uf07NmT4OBg/P39iYmJ4e23366wjWEYTJw4kYiICPz8/IiPj2fHDn05iPm6t2jEszd0AeDvKTv4cuMhkxOJiFSfrzdnlr8Adtw17bgxtrnJic7O5cKyaNEikpKSmDRpEmvXrqVbt24kJCRw+PDhM27fuHFjHn/8cVasWMGGDRtITEwkMTGRr776qnyb559/nhkzZjB79mxWrlyJv78/CQkJnDp1quqfTKSa3BTbnDsuawXAuPfXs/VQnsmJREQu3Lr9x3lw4TqcBgztFcX9f2hrdqRzshiG4dKN+bi4OHr16sXMmTMBcDqdREVF8cADDzB+/PhKHaNHjx7079+fyZMnYxgGkZGRjBs3jocffhiA3NxcwsLCmDt3LkOHDj3v8fLy8ggKCiI3N5fAQPe77yZ1X6nDSeLc1fy4I5vmjfz49/2X09jfbnYsEZEq2Xe0gBv+sZyjBcVc1b4pr4/oiZet9keJuPL97VK64uJiUlNTiY+P/+0AVivx8fGsWLHivPsbhkFKSgrbt2/nyiuvBGDPnj1kZmZWOGZQUBBxcXFnPWZRURF5eXkVFpGa5GWz8sqw7rRs0oADx09y37/WUqLp+0WkDjpWUMzIt1ZztKCYzs0CmXVLD1PKiqtcSpidnY3D4SAsLKzC+rCwMDIzM8+6X25uLg0bNsRut9O/f39eeeUVrrnmGoDy/Vw5ZnJyMkFBQeVLVFSUKx9DpEqCG9iZM6In/nYbK3YfZcpnW8yOJCLiklMlDu6av4Y92QU0C/bjzdt74e/jZXasSqmVShUQEEBaWhqrV6/mmWeeISkpiaVLl1b5eBMmTCA3N7d8SU9Pr76wIufQLiyA6UO7AzBvxT4WrtL0/SJSNzidBknvpZG67zgBvl7MTexFaKCv2bEqzaXCEhISgs1mIysrq8L6rKwswsPDz/5LrFbatm1LTEwM48aN46abbiI5ORmgfD9Xjunj40NgYGCFRaS2XNMxjHHXlE3f/8Snm1ij6ftFpA5I/nIrX2zMxNtm4Z+39eSisACzI7nEpcJit9uJjY0lJSWlfJ3T6SQlJYU+ffpU+jhOp5OioiIAWrVqRXh4eIVj5uXlsXLlSpeOKVKb7v/Df03f/04qGTknzY4kInJWc3/aw5wf9wDwwk3d6NOmicmJXOfyjaukpCRuv/12evbsSe/evZk+fToFBQUkJiYCMGLECJo1a1Z+BSU5OZmePXvSpk0bioqK+OKLL3j77bd59dVXgbJp0MeOHcuUKVO46KKLaNWqFU888QSRkZEMGjSo+j6pSDWyWCy8MLgru7ML2Hooj3v/tZYP7ulTJwauiUj98vXmTJ46PebukYT2DOrezOREVeNyYRkyZAhHjhxh4sSJZGZmEhMTw+LFi8sHze7fvx+r9bf/aBcUFHDvvfdy4MAB/Pz86NChA++88w5Dhgwp3+bRRx+loKCA0aNHk5OTw+WXX87ixYvx9a0799ak/mlg92LOiFj+9PcfSUvPYfb3u7j/DxeZHUtEpFxaeg4PLlyHYcCw3lHce1UbsyNVmcvzsLgjzcMiZvpk3UHGLkrDy2rhk/suo3OzILMjiYiQfqyQv/zjJ7JPFNO3XVPeuN2cuVbOpcbmYRGR3xsYE8l1ncMpPT0C/1SJw+xIIlLP5RaWMPKtVWSfKObiiEBmDa8bc62cS91OL+IGLBYLUwZ1JqShnV+yTvDyN7+YHUlE6rGiUgej317DriMFhAf68tbIXjSsI3OtnIsKi0g1aNLQh+QbugLwzx93s2qPHnUWkdpnGAaPfbCBlXuO0dDHi7cSexEe5BnjQVVYRKrJNR3DGBzbHMOAce+ncaKo1OxIIlLPvPTNL3ySloHNauEfw3twcYTnjOtUYRGpRhOv70izYD/Sj51kwkcbKdX7hkSklry3Op1XvtsJwLN/6cyV7ZqanKh6qbCIVKMAX2+mDe6GzWrhP+szuO/dtRqEKyI1btmObP7v440A3Hd1G4b0amFyouqnwiJSzfq0acI/hvfAbrPy1eYs7pi7WreHRKTG/JKVz5h3Uil1GgzoFsnD17Y3O1KNUGERqQEJncKZm9gLf7uN5buOctsbKykq1ZUWEaleh/NPkfjWavKLSukV3YgXBnfFYrGYHatGqLCI1JBL24bw7l2XEOTnzbr9OUz/dofZkUTEgxQWl3LnvDUczDlJqxB//nlbT3y8bGbHqjEqLCI1qFtUMM/fVPa482vf7yJ133GTE4mIJ3A4Df66MI0NB3Jp1MCbt0b2opG/3exYNUqFRaSGJXQK54buzXAa8PD76zlZrFtDInJhnv1iK99sycLuZWXOiJ5Eh/ibHanGqbCI1IJJ13ciLNCHPdkFPP/VNrPjiEgdNn/FXt5YtgeAFwd3o2d0Y5MT1Q4VFpFaENTAm+duLLs19NZPe/l8wyGTE4lIXbRk22Ge/PdmAB5JaM/13SJNTlR7VFhEaslV7UMZ0aclAA8sWMuHqQdMTiQidcnmjFzuf3ctTgNu7tmce69qY3akWqXCIlKLJl3fiSE9o3AaMO799fxr5T6zI4lIHZCZe4pRc9dQUOzg0jZNeOYvXTz28eWzUWERqUU2q4XkG7ow8tJoAB7/eBMLV+03N5SIuLWColJGzVtNZt4p2oY25NVbY/G21b+v7/r3iUVMZrVamHR9R+6+sjUAT/5nM3uzC0xOJSLuyOE0eHDBOjZn5NHE385bI3sR5OdtdixTqLCImMBisfBYvw70ad2EUyVOHn5/PQ6nYXYsEXEzkz/bQsq2w/h4WZlze0+iGjcwO5JpVFhETGK1Wnj+pq74222s2Xect37aY3YkEXEj85bvZe7yvQC8dHMMPVo0MjeQyVRYREwU1bgBj/fvCMALX21n15ETJicSEXewZNthnvpP2ePLj/ZrT/+uESYnMp8Ki4jJhvWO4oqLQigqdfLggnXkniwxO5KImGjrobwKjy+P6Vu/Hl8+GxUWEZNZLBaeu7ErjRp4szkjj9veWEluoUqLSH10OO8Uo+aupqDYQZ/WTZgyqP49vnw2KiwibiAy2I9377qExv52NhzI5ZbXf+Z4QbHZsUSkFhUWlzJq3hoyck/Ruqk/s2+Nxe6lr+lf6UyIuImLIwJZcNclNPG3szkjj+Gvr9SLEkXqCafT4KFFaWw8+Nvbl4Ma1M/Hl89GhUXEjbQPD2Dh6EsIaWhny6E8Xvhqu9mRRKQWPPfVNr7anIXdZuWfI3rSsonnv33ZVSosIm7morAApg3uBsBby/ewas8xkxOJSE1atHo/r32/G4DnbupCr3ry9mVXqbCIuKGr2odyc8/mGAY8+sF63RoS8VArdh3l8Y83AfDgH9ryl+7NTU7kvlRYRNzU3/7ckYggX/YeLWTa17o1JOJpdh85wT3vpFLqNPhz1wgeuqad2ZHcmgqLiJsK9PXm2Ru6APDmT3v4bluWyYlEpLrkFBYzat4ack+W0L1FMNMGd9Pjy+ehwiLixq5uH8qw3lEYBtzzzlq+/+WI2ZFE5AIVlzq5551U9mQX0CzYj3/e1hNfb5vZsdyeCouIm3t6YGcSOoVRXOpk9Pw1LNuRbXYkEakiwzD42ycb+Xn3MRr6ePHmyF40DfAxO1adUKXCMmvWLKKjo/H19SUuLo5Vq1addds5c+ZwxRVX0KhRIxo1akR8fPzvth85ciQWi6XC0q9fv6pEE/E43jYrrwzrwTUdwygqdTJq3mqW71JpEamL/vnDbt5bcwCrBV65pTvtwwPMjlRnuFxYFi1aRFJSEpMmTWLt2rV069aNhIQEDh8+fMbtly5dyrBhw1iyZAkrVqwgKiqKa6+9loMHD1bYrl+/fhw6dKh8WbBgQdU+kYgHsntZmXVLD/7YIbSstMxdw+q9etxZpC75enMmUxdvA2DinztydftQkxPVLRbDMAxXdoiLi6NXr17MnDkTAKfTSVRUFA888ADjx48/7/4Oh4NGjRoxc+ZMRowYAZRdYcnJyeGTTz5x/RMAeXl5BAUFkZubS2BgYJWOIVIXFJU6uGt+Kj/8coSGPl68c2ccMVHBZscSkfPYnJHLTa+u4GSJg1svacHkgZ01yBbXvr9dusJSXFxMamoq8fHxvx3AaiU+Pp4VK1ZU6hiFhYWUlJTQuHHFiXGWLl1KaGgo7du3Z8yYMRw9evSsxygqKiIvL6/CIlIf+HjZeO3WWC5p3ZgTRaWMeGMlmw7mmh1LRM7hcN4p7py3hpMlDq64KIRJ13dSWakClwpLdnY2DoeDsLCwCuvDwsLIzMys1DEee+wxIiMjK5Sefv36MX/+fFJSUnjuuef4/vvvue6663A4zjxZVnJyMkFBQeVLVFSUKx9DpE7zs9t44/ZexLZsRN6pUu55J5WColKzY4nIGZwqcXDX/DUcyj1Fm6b+zLylB942Pe9SFbV61qZOncrChQv5+OOP8fX1LV8/dOhQBgwYQJcuXRg0aBCfffYZq1evZunSpWc8zoQJE8jNzS1f0tPTa+kTiLgHfx8v3krsRbNgPw4cP6l3Dom4IafTYNx761l/IJfgBt68cXsvgvz0QsOqcqmwhISEYLPZyMqqOIFVVlYW4eHh59x32rRpTJ06la+//pquXbuec9vWrVsTEhLCzp07z/hzHx8fAgMDKywi9U2grzdTbyybWG7eir0ahCviZqan7ODzjYfwtlmYfWss0SF6oeGFcKmw2O12YmNjSUlJKV/ndDpJSUmhT58+Z93v+eefZ/LkySxevJiePXue9/ccOHCAo0ePEhER4Uo8kXrnioualr9z6LEPN3CqRO8cEnEHn6YdZEbKDgCeGdSFS1o3MTlR3efyLaGkpCTmzJnDvHnz2Lp1K2PGjKGgoIDExEQARowYwYQJE8q3f+6553jiiSd48803iY6OJjMzk8zMTE6cOAHAiRMneOSRR/j555/Zu3cvKSkpDBw4kLZt25KQkFBNH1PEcz3evyOhAT7sPlLA9G93mB1HpN5bt/84j3ywAYDRV7bm5l4aZ1kdXC4sQ4YMYdq0aUycOJGYmBjS0tJYvHhx+UDc/fv3c+jQofLtX331VYqLi7npppuIiIgoX6ZNmwaAzWZjw4YNDBgwgHbt2jFq1ChiY2P58ccf8fHR7H8i5xPk583kQZ0BmP39Lj5IPWByIpH6KyPnJKPfTqW41MkfO4TyWL8OZkfyGC7Pw+KONA+LCEz5bAuvL9uD1QL/GN6Dfp11S1WkNhUWlzJ49go2Z+TRPiyAD++9lIY+XmbHcms1Ng+LiLivx/tfzM09m+M04IEF6/hBL0oUqTVOp0HSovVszsijib+d12/vqbJSzVRYRDyExWIh+Yau9O8SQYnD4O63U0ndd9zsWCL1wkvf/MLizZnYbVZeuy2WqMYNzI7kcVRYRDyIzWrh5SEx9G3XlJMlDu6Yu5rtmflVPl6pw8l7q9NZo0emRc7q07SDzFxSNg1H8g1d6Bnd+Dx7SFWosIh4GLuXlVdv7UGPFsHknizhtjdWkn6s0OXjHDheyJB//syjH25g7KK06g8q4gH++4mgu/u25sbY5iYn8lwqLCIeqIHdizdH9qJ9WACH84u47Y2VHMkvqvT+X248xJ/+/mP5LaWsvFN4wPh8kWp1KPe3J4LiLw7lsQQ9EVSTVFhEPFRwAzvzR/WmeSM/9h4tJHHuKk5U4p1DGw7kMOZfa8k7VUqXZkEAlDgMTmpSOpFyJ4vL3hF0JL+I9mEBTB/aHatVLzSsSSosIh4sLNCXt0fF0cTfzqaDedxz+l+D5/Kf9RkAXN2+KR/deyn20y9qyyksqfG8InWBYRg8/P56Nh3Mo7GeCKo1KiwiHq5ViD9vJfaigd3Gsp3ZjHt/PU7nmW/vGIbBN1vK3hU2uGcU3jYrQQ3KXtamwiJSZkbKzvJ3BL06vIeeCKolKiwi9UDX5sHMvjUWL6uF/6zP4Jkvtp5xu11HTrD3aCF2m5Ur2zUFIPj022VzThbXWl4Rd/XFxkO8/O0vAEwZ1Jk4vSOo1qiwiNQTV7Zryos3dwPgjWV7eP3H3b/b5uvTV1f6tGlSfok7+PQVllxdYZF6btPBXJLeSwPgjstaMaRXC3MD1TMqLCL1yMCYZoy/ruxJhimfby0fr/Krb08Xlms6hpWvC/KzA5BzUoVF6q9jBcXc/XYqp0qcXNmuKf/3Jz0RVNtUWETqmbuvbM3IS6MBGPfeelafnhTuSH4R69JzAIi/+LfCEqwxLFLPlTqc3P/uWg7mnCS6SQNeGdodL5u+PmubzrhIPWOxWHjizx3p1ymcYoeTh99fz6kSB99ty8IwoGvzIMKDfMu31xgWqe+mfrmN5buO0sBu458jepYPRJfapeewROohm9XCC4O7kpaew76jhcxI2cEvWWVT+P/31RXQGBap3z5NO8jry/YA8OLgbrQLCzA5Uf2lKywi9VSArzdPDewEwOzvd7F0e9nbnf97/ApAUIPTY1hUWKSe2ZyRy2Mflk27f+9VbbiuS4TJieo3FRaReiyhUzi3XdISpwGlToPmjfzoEF7xX5BBuiUk9dCxgmJGzy8bZNu3XVPGXdve7Ej1nm4JidRzkwd1plerxkz/9hdGXd4Ki6Xi9OLlY1h0hUXqiVKHkwcWlA2ybdmkATOGdsemafdNp8IiIgzoFsmAbpFn/Fn5GBY91iz1xHOLt/HTztODbG/TIFt3oVtCInJOwX4awyL1x4epB5jzY9kg2xdu6kb7cA2ydRcqLCJyTr/+6/JkiYNTemOzeLC09BwmfLwRgAf+0Jb+XTXI1p2osIjIOQX4ePHr7fs83RYSD3U47xR3v72G4lIn8ReH8VB8O7Mjyf9QYRGRc7JaLf/1pJAKi3ieUyUORr+dSlZeEReFNuTlId2wapCt21FhEZHzCj49F4sG3oqnMQyDxz/eRFp6DkF+3rx+e08CfDXI1h2psIjIeQXp0WbxUG/+tJcP1x7AaoFZt/SgZRN/syPJWaiwiMh5/fYCRE0eJ55j2Y5snvl8CwCP9+/I5ReFmJxIzkWFRUTO69fJ43RLSDzFvqMF3PfuWpwG3BTbnDsuizY7kpyHCouInFew3ickHqSgqJTR81PJPVlCTFQwUwZ1/t0Mz+J+VFhE5Lz0PiHxFE6nwbj31rM9K5+mAT68dlssvt42s2NJJaiwiMh5/TaGRVdYpG6buWQnizdnYrdZmX1rLGGBvmZHkkpSYRGR89L7hMQTfLMli5e++QWAyYM6EduykcmJxBUqLCJyXnqfkNR1Ow/n89CiNABG9GnJkF4tzA0kLqtSYZk1axbR0dH4+voSFxfHqlWrzrrtnDlzuOKKK2jUqBGNGjUiPj7+d9sbhsHEiROJiIjAz8+P+Ph4duzYUZVoIlIDfn2f0IWMYTEMA6fTqK5IIpWWe7KEu+ancqKolLhWjXnizx3NjiRV4HJhWbRoEUlJSUyaNIm1a9fSrVs3EhISOHz48Bm3X7p0KcOGDWPJkiWsWLGCqKgorr32Wg4ePFi+zfPPP8+MGTOYPXs2K1euxN/fn4SEBE6dOlX1TyYi1Sb4AieOczgNRr+dymXPfcfGA7nl651Og2+3ZPGf9RnVklPkfzmcBmMXrmNPdgHNgv34x/AeeNt0c6EushiG4dI/eeLi4ujVqxczZ84EwOl0EhUVxQMPPMD48ePPu7/D4aBRo0bMnDmTESNGYBgGkZGRjBs3jocffhiA3NxcwsLCmDt3LkOHDj3vMfPy8ggKCiI3N5fAwEBXPo6IVMLRE0XETvkWgJ3PXIeXi//Bn/39LqZ+uQ2Axv523rv7Euw2G6PfXsO2zHwA5t3Rm77tmlZvcKn3pn21nZlLduLrbeWDey6lc7MgsyPJf3Hl+9ul/+oUFxeTmppKfHz8bwewWomPj2fFihWVOkZhYSElJSU0btwYgD179pCZmVnhmEFBQcTFxZ31mEVFReTl5VVYRKTm/PpYM0DeqVKX9t2WmcdLX5cNdAwL9OFYQTHDX1/JXfN/KysAc3/aUz1hRU5bvOkQM5fsBOC5G7uqrNRxLhWW7OxsHA4HYWFhFdaHhYWRmZlZqWM89thjREZGlheUX/dz5ZjJyckEBQWVL1FRUa58DBFxkZfNSoCPF+Da9PzFpU4eWrSeYoeT+ItD+fKvV3JRaEOy8orYnpVPSEM7C0dfgsUCS7YfYfeREzX1EaSe+SUrn6T31gMw6vJWDIxpZnIiuVC1eiNv6tSpLFy4kI8//hhf36o/+z5hwgRyc3PLl/T09GpMKSJn8tvA28qPY5n53Q62Hsqjsb+d5Bu60tjfzjt3xtGySQPsXlZeGdaDS1o34Y8dQgGYv2JfjWSX+iX3ZAl3v51KYbGDS9s0YcJ1HcyOJNXApcISEhKCzWYjKyurwvqsrCzCw8PPue+0adOYOnUqX3/9NV27di1f/+t+rhzTx8eHwMDACouI1KzyuVhcGHj7zsr9ADw1oBNNA3wACAv05ZuH+rJ8/B/o06YJACMvbQXA+2vSyT9VdvzlO7NZvOkQLg6zk3rufwfZzrylh8tjrsQ9ufT/ot1uJzY2lpSUlPJ1TqeTlJQU+vTpc9b9nn/+eSZPnszixYvp2bNnhZ+1atWK8PDwCsfMy8tj5cqV5zymiNSuX+diqezkcbknSzhWUHb76A+nr6D8yu5lJaShT/mfL2vbhLahDSkodvDa97u5719rueX1ldzzzlre/Glv9XwAqRde/uYXlmw/go+Xlddui6Wxv93sSFJNXK6dSUlJzJkzh3nz5rF161bGjBlDQUEBiYmJAIwYMYIJEyaUb//cc8/xxBNP8OabbxIdHU1mZiaZmZmcOFF2r9pisTB27FimTJnCv//9bzZu3MiIESOIjIxk0KBB1fMpReSCld8SquQYlvRjhQCENLTjf3r8y9lYLBZGXhoNlE2d/vnGQ/z6Lropn2/h682VGyMn9ZsG2Xo2lwvLkCFDmDZtGhMnTiQmJoa0tDQWL15cPmh2//79HDp0qHz7V199leLiYm666SYiIiLKl2nTppVv8+ijj/LAAw8wevRoevXqxYkTJ1i8ePEFjXMRkepVPhdLJa+wHDheVliaN2pQqe1v6NGs/LZT52aB/Of+y7klrgWGAX9dmFZh/haR/7UjK59x/zXIdlB3DbL1NC7Pw+KONA+LSM174attzFqyi5GXRvPkgE7n3f6fP+zi2S+2MaBbJDOGda/U79iSkcee7AISOoXhZbNS6nByx7w1/PDLEUIDfPgmqW+FR6xFAPJOlTBo5k/szi6gT+smvD2qt8at1BE1Ng+LiNRfro5h2X/6llCLxpW7wgLQMTKQ/l0jyr9svGxWZt3SndZN/TmcX8TM7/TKDqnI6TRIWpTG7uwCIoN8mXlLd5UVD6X/V0WkUlwfw3IScK2wnEmArzcTT7/7Ze7yvezNLrig44lneeW7nXy79TB2Lyuzb4ulyX8N5hbPosIiIpXi6hiWXwfdNm/sd8G/+6r2ofRt15QSh0Hyl1sv+HjiGb7blsX0lLJZlKcM6kzX5sHmBpIapcIiIpUS3OD0LaFKzMPicBocOF49V1h+9Xj/i7FZLXy1OYufdx+tlmNK3bU3u4CxC9MwDBge14Kbe2rGc0+nwiIilRLswky3WXmnKHY48bJaiAi68CssAO3CAhjWu+xLacrnWzShXD1WWFzKPe+kkneqlO4tgpl0/fkHgUvdp8IiIpXStKEPVgscKyhmwar959z219tBzRr5YbNaqi3DQ/Ht8PW2sulgHtuz8s+/g3gcwzCY8NFGtmXmE9LQh1eHx2L30ldZfaD/l0WkUhr527n3qrYAPP7xRr7ceOis21blCaHKaNLQh0tal03n//32I9V6bKkb3vppL5+mZeBltTDrlu6EB2m+rvpChUVEKm3cte0Y1jsK5+nJ3JbtyD7jdr9eYYmq5sIC0LddUwB+2KHCUt+s2nOMZ78oG3T9f3+6mLjT5VXqBxUWEak0i8XClEFduK5zOMUOJ3fMXc0rKTsocTgrbFdTV1jgt8Ly086jjP9wA1O/3FbpuWGk7srKO8W9/1pLqdNgYEwkiZdFmx1JapkKi4i4xGa1MH1oDAmdwih2OHnxm18YOPMntmXmlW+TfvoJoahKTsvvilYh/kSevg2wcHU6s7/fxR9fXMoHqQdwOjUQ1xMVlzq5919ryT5RRPuwAJJv6ILFUn1jo6RuUGEREZf5eNmYfWss04fEENzAmy2H8hj86gqO5BcBNXuFxWKxEN+x7N1lQX7etGnqT/aJYh5+fz03v7aC7ZkajOtpnv1iK6n7jhPg68Vrt8XSwH7ul2mKZ1JhEZEqsVgsDOrejK8fupJ2YQ3JLyrl/dR0ThY7yotLTRQWKHtaaMqgzqSM68uXf72SCdd1oIHdxpp9x+k/40eSv9xKYXFpjfxuqV2fph1k7vK9ALx0cwzRIf7mBhLTqLCIyAUJDfDlzstbA7BwVTr7jpVNnR/o61U+nX91a+Rv59ZLWhLS0Ae7l5W7+7bh26S+9OsUTqnT4LXvd3P/u+tq5HdL7dmemc/4DzcCcP/Vbbnm9JU1qZ9UWETkgv25WwQBPl7sP1bIwlXpQM08IXQukcF+zL4tltdH9MRqge+2HWb3kRO1mkGqT96pEu55J5WTJQ4ubxvCQ9e0MzuSmEyFRUQuWAO7F3/p0QyAf63cB9Tc7aDzie8YxtXtQwFYtCbdlAxyYQzD4JH317Pn9BuYZwzrXq0TEErdpMIiItXilrgWAJQ4yp7UMauwAAzpVTaF/4epBygurfjI9czvdvDyN79oan839s8fdvPV5izsNiv/uDWWxv52syOJG1BhEZFq0SE8kB4tgsv/3NzEwnJ1h1CaBviQfaKY77Zlla8/VlDMtK9/4e8pO0g/dtK0fHJ2K3Yd5bnF2wB44vqOxEQFmxtI3IYKi4hUm1viWpb/bzOvsHjbrNwU2xwom6vlV3uPFpT/77X7j9d6Ljm3rLxTPLBgHU4DbujejFtPX7UTARUWEalGf+4aQRN/O15WC+3CGpqa5eaeZbeFvv/lCBk5ZVdT9h8tLP956j4VFndS4nBy/7tlk8N1CA/gmb9ocjipSIVFRKqNr7eN9+7pw6K7LyEiyM/ULK1C/LmkdWMMA947Pfj2v6+wqLC4l+cXb2P13uME+Hjx6q2x+NltZkcSN6PCIiLVqk3ThsS2bGx2DACG9S67pfDuyv0UlzorXGHZlpnHwZyTzFqyk0feX0/eKb2PyCyLNx1izo97AHhhcFdaaXI4OQPNbywiHuu6zhE8G7iVrLwi/r0+g33HfissTgOufH4JjtPvH4oO8ee+q9uaFbXe2ptdwCPvbwDgrita0a9zhMmJxF3pCouIeCy7l5WRl7YCYM4Pu9l3+pZQ29Cy8TUOp0FIQx8Avth4yJyQ9dipEgf3vJNKflEpvaIb8Wi/DmZHEjemwiIiHu2WuBb4221sz8on+0QxADOGdmf0la15Z1QcXz90JTarhc0ZeeWFRmrHxE83sS0zn5CGdmbe0gNvm76S5Oz0t0NEPFqQnzc3n55IDqBRA286Rgbyf3+6mMsvCqGxv50+rZsA8MXGTLNi1jvvrU7nvTUHsFpgxrDuhAX6mh1J3JwKi4h4vDsua8WvM7u3aPL7AZ1/6lI2buLLTbotVBu2ZOTxxKebABh3bXsubRNiciKpC1RYRMTjRTVuwHWnS0mrJr+f0O7aTmFYLbDhQC7p/zUwV6pf/qkS7nt3LUWlTq5q35QxfduYHUnqCBUWEakXHv/TxdwU25y7z/AFGdLQh0tO3xbSVZaaYxgG4z/cyJ7sApoF+/HyzTFY9VJDqSQVFhGpFyKD/Zg2uBsXRwSe8ee/XoHROJaaM2/5Xj7feAhvm4WZt3SnkV5qKC5QYRERAfp1CsdigbT0HH7cccTsOB4nLT2HZ77YCsCE6y6me4tGJieSukaFRUQEaBrgw/VdIwG4Y+5qzctSjXIKi7nvX2spcRhc1zmcxMuizY4kdVCVCsusWbOIjo7G19eXuLg4Vq1addZtN2/ezI033kh0dDQWi4Xp06f/bpsnn3wSi8VSYenQQRMIiUjtemFwV/p3iaDEYXDfu2t566c9OE/PhCtVYxgGD7+/gYM5J2nRuAHP3dRVLzWUKnG5sCxatIikpCQmTZrE2rVr6datGwkJCRw+fPiM2xcWFtK6dWumTp1KeHj4WY/bqVMnDh06VL4sW7bM1WgiIhfEx8vGjGHdGR7XAsOAp/6zhetnLuOnndlmR6uz3li2h2+3ZmG3WfnH8B4E+nqbHUnqKJcLy0svvcRdd91FYmIiHTt2ZPbs2TRo0IA333zzjNv36tWLF154gaFDh+Lj43PW43p5eREeHl6+hITouXwRqX02q4Upgzrzt/4X09DHi80ZeQx/fSUPLUrT1RYXrd1/nKlfbgPgies70rlZkMmJpC5zqbAUFxeTmppKfHz8bwewWomPj2fFihUXFGTHjh1ERkbSunVrhg8fzv79+8+6bVFREXl5eRUWEZHqYrFYuPOK1nz/yFWMvDQaL6uFj9cd5IWvt5sdrc7IKSzmgXfXUeo0+HPXCG6Na2F2JKnjXCos2dnZOBwOwsLCKqwPCwsjM7PqjwLGxcUxd+5cFi9ezKuvvsqePXu44ooryM/PP+P2ycnJBAUFlS9RUVFn3E5E5EI0aejDkwM68cLgrgC8unQXq/ceMzmV+3M6DR5alMbBnJNEN2lA8g1dNG5FLphbPCV03XXXMXjwYLp27UpCQgJffPEFOTk5vPfee2fcfsKECeTm5pYv6enptZxYROqTv3Rvzg09mgHw/hr99+Z8Zi3ZyZLtR/DxsjJreA8CNG5FqoFLhSUkJASbzUZWVlaF9VlZWeccUOuq4OBg2rVrx86dO8/4cx8fHwIDAyssIiI1aUjPsiu5X27M5FSJw+Q07uvHHUd46dtfAJgyqDOdIjVuRaqHS4XFbrcTGxtLSkpK+Tqn00lKSgp9+vSptlAnTpxg165dREREVNsxRUQuRK/oxjQL9iO/qJSUrWd+KrK+y8o7xV8XpmEYMLRXFIN76na9VB+XbwklJSUxZ84c5s2bx9atWxkzZgwFBQUkJiYCMGLECCZMmFC+fXFxMWlpaaSlpVFcXMzBgwdJS0urcPXk4Ycf5vvvv2fv3r0sX76cv/zlL9hsNoYNG1YNH1FE5MJZrRYGxpRNLDft6+0cOK6XJP43h9PgwQXrOFZQTMeIQJ4c0MnsSOJhvFzdYciQIRw5coSJEyeSmZlJTEwMixcvLh+Iu3//fqzW33pQRkYG3bt3L//ztGnTmDZtGn379mXp0qUAHDhwgGHDhnH06FGaNm3K5Zdfzs8//0zTpk0v8OOJiFSf2y+N5tO0DPZkF3Djq8uZf0cc7cMDzI7lFmak7GDlnmP4223MvKU7vt42syOJh7EYhlHnJxbIy8sjKCiI3NxcjWcRkRp1KPckI95YxY7DJwj09WLR3X3O+kLF+mL5rmyGv74Sw4C/D41hYEwzsyNJHeHK97dbPCUkIlJXRAT58f49fejeIpi8U6XMSNlhdiRTHT1RxNjT41Zu7tlcZUVqjAqLiIiLghvYefYvXQD4dmsWxwqKTU5kDqfTYNz76zmcX0Tb0IYatyI1SoVFRKQKLo4IpEuzIEocBp+sO2h2HFO8sWwPS0/PtzLzlu40sLs8LFKk0lRYRESqaHDP5gC8tyYdDxgO6JL16Tk8t7jsPUETr+9Ih/D6PY5Hap4Ki4hIFQ3oFondy8q2zHw2Z9Sfd5rlnyrhgQVl7wn6U5dwbumt9wRJzVNhERGpouAGdhI6lc3y/V49mbLfMAz+9skm9h8rpFmwH8k3dNV7gqRWqLCIiFyAwbFlt4U+TcuoF1P2f7j2IJ+mZWCzWpgxrDtBfnpPkNQOFRYRkQtwWdsQIoN8yT1Zwv3vruNEUanZkWrM7iMnmPjpJgCSrmlHbMtGJieS+kSFRUTkAtisFp4c0Am7l5Vvt2Zx06vLWbn7KJ+sO8iLX29n+c5ssyNWi6JSBw8sWEdhsYM+rZtwT982ZkeSekYz3YqIVIO1+48zen4q2SeKKqwP8PVi9ePxdX6q+imfbeH1ZXto1MCbL/96JeFBvmZHEg+gmW5FRGpZjxaN+Pf9l9GndROC/LzpFd2IRg28yT9Vyrdbs8yOd0G+/+UIry/bA8ALN3VTWRFTaJYfEZFqEhnsx4LRl5T/+YWvtjFryS5eSdnJvqOFDIyJpHmjBiYmdN2R/CLGvZcGwIg+LYnvGGZuIKm3dIVFRKSG/KV72RNE27PyeeGr7Uz4aKPJiVxjGAaPfLCe7BPFtA8L4P/+dLHZkaQeU2EREakhbUMbcknrxuV//nFHdp1679Dc5XtZuv0Idi8rM4Z1r/PjcKRuU2EREalBr93Wky8evIJOkWUDCr/anGlyosrZeiiP5C/Kpt7/W/+LaR8eYHIiqe9UWEREalCQnzcdIwPp3zUCgC82HjI50fmdKnEwdmEaxQ4nf+gQym2XtDQ7kogKi4hIbejfpaywLN911O1vC039chvbs/IJaejD8zdp6n1xDyosIiK1oGUTfzpFBuJwGm5zW8jhNMjIOVlh3ZLth5m7fC8A0wZ3JaShjwnJRH5PhUVEpJb8qYt73RZ69IMNXDr1O346PRtv9okiHnl/AwAjL43mqvahZsYTqUCFRUSklvz3baH/nRG3tqXuO8aHaw8A8J/1GRiGwfgPN5B9ooh2YQ0Zf10HU/OJ/C8VFhGRWhId4k/HiLLbQlc+v4R7/5XKZxsyKHU4azWH02nw9Gdby//8445s3l21n2+3HsZus/L3oXqEWdyPCouISC16OKEdEUG+FBY7+GJjJve/u44/vPg9767cT1Gpo1Yy/GdDBuvTc2hgt2G3WTmYc5LHPy57C/Oj/dpzcYTeySbuRy8/FBGpZYZhsPFgLos3ZbJwdXr5U0PtwwKYd0fvGn1Xz8liB/Evfc/BnJOMu6YdP+7MZtWeYwBc2qYJ74yKw2rVU0FSO/TyQxERN2axWOjaPJhH+3Vg2WNXM/HPHQlpaGd7Vj43zV7OnuwCikodFJdW762iYwXFDH/9Zw7mnCQiyJc7r2hN33ZNy3/+4s3dVFbEbenlhyIiJmpg9+KOy1txTccwRry5ij3ZBQya9RNFpQ4ig/34+N7LCPLzvuDfsze7gJFvrWLv0UICfb14ZVh3/Ow2buvTkoM5JxkU04yIIL9q+EQiNUO3hERE3MSR/CJGvrWKzRl55ev6d4lg5i3dL2jythKHk6unLeXA8ZM0C/Zj3h29aBuqqfbFfK58f+sKi4iIm2ga4MPC0Zfw0dqDNLDbmPDRRj7feAjHOwaTB3WmaUDVJnFL2XqYA8dPEtLQzsf3XUpoQM2NkRGpKSosIiJuJMDXm9svjQag2OFk0qebWbw5k5/3HGXKoM78uWuky8dcsGo/AIN7RqmsSJ2lQbciIm5qeFxLPrnvMjpGBJJTWML9767jsw0ZLh0j/VghP+w4AsDQXlE1EVOkVqiwiIi4sc7Ngvj0/ssYHtcCgKT31pO671il939vTTqGAZe3DaFlE/+aiilS41RYRETcnLfNytMDOxN/cRjFpU7ump/K15szSUvP4VDuybPuV+pwsmh1OgDDereorbgiNaJKhWXWrFlER0fj6+tLXFwcq1atOuu2mzdv5sYbbyQ6OhqLxcL06dMv+JgiIvWNzWphxrAYujQL4lhBMaPfTmXQrJ/ok/wdY95J5cDxQo4XFPPlxkOs23+cH345wvNfbedwfhFN/O1c0zHM7I8gckFcHnS7aNEikpKSmD17NnFxcUyfPp2EhAS2b99OaOjv3+xZWFhI69atGTx4MA899FC1HFNEpD5qYPfijZE9mfzZVnYePkHeyRIO5Z7ky02ZfLftMH52GzmFJb/b76aezbF76YK61G0uz8MSFxdHr169mDlzJgBOp5OoqCgeeOABxo8ff859o6OjGTt2LGPHjq22Y4LmYRGR+mtbZh6TPt3MytPT6zdv5EdRqZMAXy/aNm3IxRGB3HlFKwJ8L3zyOZHqVmPzsBQXF5OamsqECRPK11mtVuLj41mxYkWVwlblmEVFRRQV/fZq9ry8vDNuJyLi6TqEB7Jw9CV8syWLnMISbujRDC+brqaI53Hpb3V2djYOh4OwsIr3QsPCwsjMzKxSgKocMzk5maCgoPIlKkqP6olI/WWxWLi2Uzg394pSWRGPVSf/Zk+YMIHc3NzyJT093exIIiIiUoNcuiUUEhKCzWYjKyurwvqsrCzCw8OrFKAqx/Tx8cHHp2pTVIuIiEjd49IVFrvdTmxsLCkpKeXrnE4nKSkp9OnTp0oBauKYIiIi4llcfqw5KSmJ22+/nZ49e9K7d2+mT59OQUEBiYmJAIwYMYJmzZqRnJwMlA2q3bJlS/n/PnjwIGlpaTRs2JC2bdtW6pgiIiJSv7lcWIYMGcKRI0eYOHEimZmZxMTEsHjx4vJBs/v378dq/e3CTUZGBt27dy//87Rp05g2bRp9+/Zl6dKllTqmiIiI1G8uz8PijjQPi4iISN3jyvd3nXxKSEREROoXFRYRERFxeyosIiIi4vZUWERERMTtqbCIiIiI21NhEREREbenwiIiIiJuz+WJ49zRr1PJ5OXlmZxEREREKuvX7+3KTAnnEYUlPz8fgKioKJOTiIiIiKvy8/MJCgo65zYeMdOt0+kkIyODgIAALBaL2XHcSl5eHlFRUaSnp2sW4HPQeaocnafK0XmqHJ2nyvHk82QYBvn5+URGRlZ4rc+ZeMQVFqvVSvPmzc2O4dYCAwM97i96TdB5qhydp8rReaocnafK8dTzdL4rK7/SoFsRERFxeyosIiIi4vZUWDycj48PkyZNwsfHx+wobk3nqXJ0nipH56lydJ4qR+epjEcMuhURERHPpissIiIi4vZUWERERMTtqbCIiIiI21NhEREREbenwuJhjh07xvDhwwkMDCQ4OJhRo0Zx4sSJc+5z991306ZNG/z8/GjatCkDBw5k27ZttZTYHK6ep2PHjvHAAw/Qvn17/Pz8aNGiBQ8++CC5ubm1mLr2VeXv0z//+U+uuuoqAgMDsVgs5OTk1E7YWjZr1iyio6Px9fUlLi6OVatWnXP7999/nw4dOuDr60uXLl344osvaimpuVw5T5s3b+bGG28kOjoai8XC9OnTay+oyVw5T3PmzOGKK66gUaNGNGrUiPj4+PP+/fMEKiweZvjw4WzevJlvvvmGzz77jB9++IHRo0efc5/Y2Fjeeusttm7dyldffYVhGFx77bU4HI5aSl37XD1PGRkZZGRkMG3aNDZt2sTcuXNZvHgxo0aNqsXUta8qf58KCwvp168f//d//1dLKWvfokWLSEpKYtKkSaxdu5Zu3bqRkJDA4cOHz7j98uXLGTZsGKNGjWLdunUMGjSIQYMGsWnTplpOXrtcPU+FhYW0bt2aqVOnEh4eXstpzePqeVq6dCnDhg1jyZIlrFixgqioKK699loOHjxYy8lrmSEeY8uWLQZgrF69unzdl19+aVgsFuPgwYOVPs769esNwNi5c2dNxDRddZ2n9957z7Db7UZJSUlNxDTdhZ6nJUuWGIBx/PjxGkxpjt69exv33Xdf+Z8dDocRGRlpJCcnn3H7m2++2ejfv3+FdXFxccbdd99doznN5up5+m8tW7Y0Xn755RpM5z4u5DwZhmGUlpYaAQEBxrx582oqolvQFRYPsmLFCoKDg+nZs2f5uvj4eKxWKytXrqzUMQoKCnjrrbdo1aqVx779ujrOE0Bubi6BgYF4eXnEK7l+p7rOk6cpLi4mNTWV+Pj48nVWq5X4+HhWrFhxxn1WrFhRYXuAhISEs27vCapynuqj6jhPhYWFlJSU0Lhx45qK6RZUWDxIZmYmoaGhFdZ5eXnRuHFjMjMzz7nvP/7xDxo2bEjDhg358ssv+eabb7Db7TUZ1zQXcp5+lZ2dzeTJk897e6Quq47z5Imys7NxOByEhYVVWB8WFnbW85KZmenS9p6gKuepPqqO8/TYY48RGRn5u1LsaVRY6oDx48djsVjOuVzoINnhw4ezbt06vv/+e9q1a8fNN9/MqVOnqukT1I7aOE9Q9qr3/v3707FjR5588skLD17Laus8iUjNmzp1KgsXLuTjjz/G19fX7Dg1yjOvZXuYcePGMXLkyHNu07p1a8LDw383SKu0tJRjx46ddwBbUFAQQUFBXHTRRVxyySU0atSIjz/+mGHDhl1o/FpTG+cpPz+ffv36ERAQwMcff4y3t/eFxq51tXGePFlISAg2m42srKwK67Oyss56XsLDw13a3hNU5TzVRxdynqZNm8bUqVP59ttv6dq1a03GdAsqLHVA06ZNadq06Xm369OnDzk5OaSmphIbGwvAd999h9PpJC4urtK/zzAMDMOgqKioypnNUNPnKS8vj4SEBHx8fPj3v/9dZ/81U9t/nzyN3W4nNjaWlJQUBg0aBIDT6SQlJYX777//jPv06dOHlJQUxo4dW77um2++oU+fPrWQ2BxVOU/1UVXP0/PPP88zzzzDV199VWGcmUcze9SvVK9+/foZ3bt3N1auXGksW7bMuOiii4xhw4aV//zAgQNG+/btjZUrVxqGYRi7du0ynn32WWPNmjXGvn37jJ9++sm4/vrrjcaNGxtZWVlmfYwa5+p5ys3NNeLi4owuXboYO3fuNA4dOlS+lJaWmvUxapyr58kwDOPQoUPGunXrjDlz5hiA8cMPPxjr1q0zjh49asZHqBELFy40fHx8jLlz5xpbtmwxRo8ebQQHBxuZmZmGYRjGbbfdZowfP758+59++snw8vIypk2bZmzdutWYNGmS4e3tbWzcuNGsj1ArXD1PRUVFxrp164x169YZERERxsMPP2ysW7fO2LFjh1kfoVa4ep6mTp1q2O1244MPPqjw36L8/HyzPkKtUGHxMEePHjWGDRtmNGzY0AgMDDQSExMr/CXes2ePARhLliwxDMMwDh48aFx33XVGaGio4e3tbTRv3ty45ZZbjG3btpn0CWqHq+fp10d0z7Ts2bPHnA9RC1w9T4ZhGJMmTTrjeXrrrbdq/wPUoFdeecVo0aKFYbfbjd69exs///xz+c/69u1r3H777RW2f++994x27doZdrvd6NSpk/H555/XcmJzuHKefv379L9L3759az94LXPlPLVs2fKM52nSpEm1H7wWWQzDMGrtco6IiIhIFegpIREREXF7KiwiIiLi9lRYRERExO2psIiIiIjbU2ERERERt6fCIiIiIm5PhUVERETcngqLiIiIuD0VFhEREXF7KiwiIiLi9lRYRERExO2psIiIiIjb+3/69CBLsdizDQAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(log_strikes, torch.sqrt(mids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "torch.Size([45])\n",
      "torch.Size([45])\n",
      "tensor(0.0111) tensor(0.0122)\n",
      "Mid shape torch.Size([45])\n",
      "0\n",
      "torch.Size([45]) torch.Size([45])\n",
      "tensor([[ 0.1436],\n",
      "        [ 0.1374],\n",
      "        [ 0.1312],\n",
      "        [ 0.1250],\n",
      "        [ 0.1188],\n",
      "        [ 0.1126],\n",
      "        [ 0.1065],\n",
      "        [ 0.1004],\n",
      "        [ 0.0944],\n",
      "        [ 0.0883],\n",
      "        [ 0.0824],\n",
      "        [ 0.0765],\n",
      "        [ 0.0706],\n",
      "        [ 0.0648],\n",
      "        [ 0.0591],\n",
      "        [ 0.0535],\n",
      "        [ 0.0481],\n",
      "        [ 0.0427],\n",
      "        [ 0.0376],\n",
      "        [ 0.0327],\n",
      "        [ 0.0281],\n",
      "        [ 0.0238],\n",
      "        [ 0.0200],\n",
      "        [ 0.0168],\n",
      "        [ 0.0143],\n",
      "        [ 0.0127],\n",
      "        [ 0.0122],\n",
      "        [ 0.0131],\n",
      "        [ 0.0153],\n",
      "        [ 0.0191],\n",
      "        [ 0.0243],\n",
      "        [ 0.0308],\n",
      "        [ 0.0383],\n",
      "        [ 0.0467],\n",
      "        [ 0.0558],\n",
      "        [ 0.0654],\n",
      "        [ 0.0755],\n",
      "        [ 0.0859],\n",
      "        [ 0.0965],\n",
      "        [ 0.1074],\n",
      "        [ 0.1185],\n",
      "        [ 0.1297],\n",
      "        [ 0.1410],\n",
      "        [ 0.1524],\n",
      "        [ 0.1639],\n",
      "        [ 0.1299],\n",
      "        [ 0.1243],\n",
      "        [ 0.1187],\n",
      "        [ 0.1131],\n",
      "        [ 0.1075],\n",
      "        [ 0.1019],\n",
      "        [ 0.0964],\n",
      "        [ 0.0909],\n",
      "        [ 0.0854],\n",
      "        [ 0.0799],\n",
      "        [ 0.0745],\n",
      "        [ 0.0692],\n",
      "        [ 0.0639],\n",
      "        [ 0.0586],\n",
      "        [ 0.0535],\n",
      "        [ 0.0484],\n",
      "        [ 0.0435],\n",
      "        [ 0.0387],\n",
      "        [ 0.0340],\n",
      "        [ 0.0296],\n",
      "        [ 0.0254],\n",
      "        [ 0.0215],\n",
      "        [ 0.0181],\n",
      "        [ 0.0152],\n",
      "        [ 0.0129],\n",
      "        [ 0.0115],\n",
      "        [ 0.0111],\n",
      "        [ 0.0118],\n",
      "        [ 0.0139],\n",
      "        [ 0.0173],\n",
      "        [ 0.0220],\n",
      "        [ 0.0278],\n",
      "        [ 0.0346],\n",
      "        [ 0.0422],\n",
      "        [ 0.0505],\n",
      "        [ 0.0592],\n",
      "        [ 0.0683],\n",
      "        [ 0.0777],\n",
      "        [ 0.0873],\n",
      "        [ 0.0972],\n",
      "        [ 0.1072],\n",
      "        [ 0.1173],\n",
      "        [ 0.1276],\n",
      "        [ 0.1379],\n",
      "        [ 0.1483],\n",
      "        [-1.5000],\n",
      "        [-1.4333],\n",
      "        [-1.3667],\n",
      "        [-1.3000],\n",
      "        [-1.2333],\n",
      "        [-1.1667],\n",
      "        [-1.1000],\n",
      "        [-1.0333],\n",
      "        [-0.9667],\n",
      "        [-0.9000],\n",
      "        [-0.8333],\n",
      "        [-0.7667],\n",
      "        [-0.7000],\n",
      "        [-0.6333],\n",
      "        [-0.5667],\n",
      "        [-0.5000],\n",
      "        [-0.4333],\n",
      "        [-0.3667],\n",
      "        [-0.3000],\n",
      "        [-0.2333],\n",
      "        [-0.1667],\n",
      "        [-0.1000],\n",
      "        [-0.0333],\n",
      "        [ 0.0333],\n",
      "        [ 0.1000],\n",
      "        [ 0.1667],\n",
      "        [ 0.2333],\n",
      "        [ 0.3000],\n",
      "        [ 0.3667],\n",
      "        [ 0.4333],\n",
      "        [ 0.5000],\n",
      "        [ 0.5667],\n",
      "        [ 0.6333],\n",
      "        [ 0.7000],\n",
      "        [ 0.7667],\n",
      "        [ 0.8333],\n",
      "        [ 0.9000],\n",
      "        [ 0.9667],\n",
      "        [ 1.0333],\n",
      "        [ 1.1000],\n",
      "        [ 1.1667],\n",
      "        [ 1.2333],\n",
      "        [ 1.3000],\n",
      "        [ 1.3667],\n",
      "        [ 1.4333],\n",
      "        [ 0.0000],\n",
      "        [ 1.0000],\n",
      "        [ 0.0000]])\n",
      "torch.Size([45]) torch.Size([138, 1])\n",
      "torch.Size([1, 138])\n",
      "0.0 0.0 0.0\n",
      "Epoch: 0\n",
      "Arb loss 259.6287687124959\n",
      "Real arb loss 259.6187687124959\n",
      "Bounds loss: 3.7874046924753433\n",
      "MAPE:  0.10478442903644694\n",
      "Delta:  0.003682722628424433\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "-1.4844823221730028 0.029835945948714082 -0.1803726260363543\n",
      "Epoch: 1\n",
      "Arb loss 306.45869151975404\n",
      "Real arb loss 306.44869151975405\n",
      "Bounds loss: 3.6744038907847427\n",
      "MAPE:  0.2862662194117892\n",
      "Delta:  0.009149659267786998\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.008598652988836664 0.061407338031720604 0.01406549168256388\n",
      "Epoch: 2\n",
      "Arb loss 302.1481993431335\n",
      "Real arb loss 302.1381993431335\n",
      "Bounds loss: 3.4487685289982544\n",
      "MAPE:  0.2791025692906875\n",
      "Delta:  0.009070984522777206\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "-0.011725004790744453 0.038022933923275604 0.014571552518777842\n",
      "Epoch: 3\n",
      "Arb loss 297.7454309879509\n",
      "Real arb loss 297.7354309879509\n",
      "Bounds loss: 3.3176362311034815\n",
      "MAPE:  0.27538464760337134\n",
      "Delta:  0.009177341859763537\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "-0.029727784700286808 0.026975808363562725 0.01249106506148856\n",
      "Epoch: 4\n",
      "Arb loss 294.02627343771945\n",
      "Real arb loss 294.01627343771946\n",
      "Bounds loss: 3.2281403119132217\n",
      "MAPE:  0.2734701528432413\n",
      "Delta:  0.009450163902691518\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "-0.05370061520118363 0.00963163159930236 0.01583187720753787\n",
      "Epoch: 5\n",
      "Arb loss 289.37128558086357\n",
      "Real arb loss 289.3612855808636\n",
      "Bounds loss: 3.1970480536780164\n",
      "MAPE:  0.2739904883088706\n",
      "Delta:  0.009957643518018072\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "-0.06968145440799067 0.007311994254516341 0.01641712464463374\n",
      "Epoch: 6\n",
      "Arb loss 284.6206411169046\n",
      "Real arb loss 284.6106411169046\n",
      "Bounds loss: 3.17367125667811\n",
      "MAPE:  0.2741105893419179\n",
      "Delta:  0.010651506600829872\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "-0.08270455078076688 0.004565479202899514 0.01420294264665789\n",
      "Epoch: 7\n",
      "Arb loss 280.5781904750662\n",
      "Real arb loss 280.5681904750662\n",
      "Bounds loss: 3.1591819265589063\n",
      "MAPE:  0.27439156165488204\n",
      "Delta:  0.01153243466938988\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "-0.09709775555386901 -0.004127306509150497 0.017280322751935695\n",
      "Epoch: 8\n",
      "Arb loss 275.72970878650295\n",
      "Real arb loss 275.71970878650296\n",
      "Bounds loss: 3.1722208386879833\n",
      "MAPE:  0.2758996392644715\n",
      "Delta:  0.012652208191859263\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "-0.10258496707438636 -0.0069433116746921986 0.014803304364113368\n",
      "Epoch: 9\n",
      "Arb loss 271.647997985108\n",
      "Real arb loss 271.63799798510803\n",
      "Bounds loss: 3.1942465566719473\n",
      "MAPE:  0.27703625455398545\n",
      "Delta:  0.013950134552639427\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "-0.10408691947458837 -0.009465442213359543 0.014831944440580669\n",
      "arb imp changed to 10005.0\n",
      "Epoch: 10\n",
      "Arb loss 267.75273943658374\n",
      "Real arb loss 267.74273443658376\n",
      "Bounds loss: 3.2244815128693483\n",
      "MAPE:  0.27785755790786637\n",
      "Delta:  0.01540216108447968\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "-0.10549446214871994 -0.01444672701612526 0.014902498216185056\n",
      "Epoch: 11\n",
      "Arb loss 263.7625547147514\n",
      "Real arb loss 263.7525497147514\n",
      "Bounds loss: 3.271064717054314\n",
      "MAPE:  0.2800445166045197\n",
      "Delta:  0.017027003784014807\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "-0.10033975939288275 -0.01571656211214023 0.014565139054784515\n",
      "Epoch: 12\n",
      "Arb loss 259.9208164278858\n",
      "Real arb loss 259.91081142788585\n",
      "Bounds loss: 3.3224746088527284\n",
      "MAPE:  0.28190123262958844\n",
      "Delta:  0.01873548924688456\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "-0.09324023321075692 -0.016319350506737162 0.01403547597731658\n",
      "Epoch: 13\n",
      "Arb loss 256.2727040529077\n",
      "Real arb loss 256.26269905290775\n",
      "Bounds loss: 3.3766952365443306\n",
      "MAPE:  0.2834023059580443\n",
      "Delta:  0.020482390633581704\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "-0.08890213556726945 -0.0188413900563702 0.013749095430440561\n",
      "Epoch: 14\n",
      "Arb loss 252.74918618866724\n",
      "Real arb loss 252.73918118866723\n",
      "Bounds loss: 3.4403168685975496\n",
      "MAPE:  0.28512584798393703\n",
      "Delta:  0.022303318902430154\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "-0.07935982828988952 -0.01768826408777424 0.012913842660909447\n",
      "Epoch: 15\n",
      "Arb loss 249.4852229655539\n",
      "Real arb loss 249.4752179655539\n",
      "Bounds loss: 3.5011701019149273\n",
      "MAPE:  0.28702160404398847\n",
      "Delta:  0.024073306460821658\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "-0.06963306174449913 -0.01607398308646224 0.009839918677604031\n",
      "Epoch: 16\n",
      "Arb loss 247.03030866030892\n",
      "Real arb loss 247.0203036603089\n",
      "Bounds loss: 3.557447850915935\n",
      "MAPE:  0.2886209985319314\n",
      "Delta:  0.0257496044960023\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "-0.06812343057645065 -0.01905778386743373 0.010102925590240619\n",
      "Epoch: 17\n",
      "Arb loss 244.53457983337964\n",
      "Real arb loss 244.52457483337963\n",
      "Bounds loss: 3.6252449231783572\n",
      "MAPE:  0.2907897765820704\n",
      "Delta:  0.027503755890256772\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "-0.06390061129983304 -0.01999945226186295 0.011962376589822687\n",
      "Epoch: 18\n",
      "Arb loss 241.60936510017868\n",
      "Real arb loss 241.59936010017867\n",
      "Bounds loss: 3.697747835957024\n",
      "MAPE:  0.2931586109887684\n",
      "Delta:  0.02926126270468556\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "-0.05733517450758763 -0.019236192439924915 0.009644617763260865\n",
      "Epoch: 19\n",
      "Arb loss 239.27913512576333\n",
      "Real arb loss 239.26913012576333\n",
      "Bounds loss: 3.76887842492381\n",
      "MAPE:  0.2954040556326166\n",
      "Delta:  0.030938962308171072\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "-0.05302585291925066 -0.01944793473000317 0.009669042475069722\n",
      "Epoch: 20\n",
      "Arb loss 236.96553500483438\n",
      "Real arb loss 236.95553000483437\n",
      "Bounds loss: 3.842175326537045\n",
      "MAPE:  0.2976808964961943\n",
      "Delta:  0.03257952717299839\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "-0.05328157873392669 -0.02304167411019553 0.010767636603885467\n",
      "Epoch: 21\n",
      "Arb loss 234.41397623625704\n",
      "Real arb loss 234.40397123625704\n",
      "Bounds loss: 3.9307054782853457\n",
      "MAPE:  0.30067777802789114\n",
      "Delta:  0.03431541581518061\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "-0.0520962917735035 -0.025336448847501192 0.010754404815970453\n",
      "Epoch: 22\n",
      "Arb loss 231.89299344129105\n",
      "Real arb loss 231.88298844129105\n",
      "Bounds loss: 4.030295596570515\n",
      "MAPE:  0.30404820165455804\n",
      "Delta:  0.036103121729817354\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "-0.05766184008604491 -0.033570468501973094 0.0154547222803737\n",
      "Epoch: 23\n",
      "Arb loss 228.30915162889139\n",
      "Real arb loss 228.29914662889138\n",
      "Bounds loss: 4.165594507948827\n",
      "MAPE:  0.30887772608826114\n",
      "Delta:  0.0381848941616091\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "-0.06699031309503445 -0.04531124735450742 0.021378565760686752\n",
      "Epoch: 24\n",
      "Arb loss 223.42822941702653\n",
      "Real arb loss 223.41822441702652\n",
      "Bounds loss: 4.354342791077073\n",
      "MAPE:  0.3157763145433287\n",
      "Delta:  0.04074291217699604\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "-0.08442496613819683 -0.062951739262745 0.03337463695109322\n",
      "Epoch: 25\n",
      "Arb loss 215.9713933756077\n",
      "Real arb loss 215.9613883756077\n",
      "Bounds loss: 4.628456243121571\n",
      "MAPE:  0.3251840748354476\n",
      "Delta:  0.04418263115791046\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "-0.09538689420259261 -0.0781523015868868 0.04295752589735147\n",
      "Epoch: 26\n",
      "Arb loss 206.69379665158795\n",
      "Real arb loss 206.68379165158794\n",
      "Bounds loss: 4.990180751315717\n",
      "MAPE:  0.337275036936272\n",
      "Delta:  0.04839707512176224\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "-0.08590888699971067 -0.06936234744504621 0.04232539105693078\n",
      "Epoch: 27\n",
      "Arb loss 197.94540087926777\n",
      "Real arb loss 197.93539587926776\n",
      "Bounds loss: 5.33631140240206\n",
      "MAPE:  0.3479915703631247\n",
      "Delta:  0.05255481397951422\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "-0.07758464013079647 -0.059786266170315905 0.041805056832022625\n",
      "Epoch: 28\n",
      "Arb loss 189.67028214587248\n",
      "Real arb loss 189.66027714587247\n",
      "Bounds loss: 5.655349536273761\n",
      "MAPE:  0.35710848739558615\n",
      "Delta:  0.05663226030925578\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "-0.07230039270062294 -0.054120528007209456 0.04370129821825697\n",
      "Epoch: 29\n",
      "Arb loss 181.38144458267476\n",
      "Real arb loss 181.37143958267475\n",
      "Bounds loss: 5.961420039242224\n",
      "MAPE:  0.3654088278206837\n",
      "Delta:  0.06072679496913888\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "-0.06752304263877851 -0.04905550254937485 0.04738039371834668\n",
      "Epoch: 30\n",
      "Arb loss 172.78752032514512\n",
      "Real arb loss 172.77751532514512\n",
      "Bounds loss: 6.253860495175165\n",
      "MAPE:  0.3738451100098115\n",
      "Delta:  0.0648272529351564\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "-0.061074434765848507 -0.04250110557482212 0.05271870951876678\n",
      "Epoch: 31\n",
      "Arb loss 163.67838523265578\n",
      "Real arb loss 163.66838023265578\n",
      "Bounds loss: 6.519656480330814\n",
      "MAPE:  0.3819484697737819\n",
      "Delta:  0.06878654076559376\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "-0.05178833993927179 -0.03355824956716935 0.06024629537119952\n",
      "Epoch: 32\n",
      "Arb loss 153.81736889004821\n",
      "Real arb loss 153.8073638900482\n",
      "Bounds loss: 6.738444739589969\n",
      "MAPE:  0.3894232550716491\n",
      "Delta:  0.07234888152200891\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "-0.03792462149369169 -0.02169467173573958 0.06937262923823495\n",
      "Epoch: 33\n",
      "Arb loss 143.1466535876381\n",
      "Real arb loss 143.1366485876381\n",
      "Bounds loss: 6.884633086224794\n",
      "MAPE:  0.39632193337327426\n",
      "Delta:  0.07509268546922304\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "-0.01894902372763352 -0.0074798428971984965 0.07865716718716942\n",
      "Epoch: 34\n",
      "Arb loss 131.8871433241114\n",
      "Real arb loss 131.8771383241114\n",
      "Bounds loss: 6.9361290601146095\n",
      "MAPE:  0.4006035109211964\n",
      "Delta:  0.07651561854795108\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.0036881486777389227 0.006373967148634252 0.08815621463766421\n",
      "Epoch: 35\n",
      "Arb loss 120.26047200928267\n",
      "Real arb loss 120.25046700928266\n",
      "Bounds loss: 6.891918401346752\n",
      "MAPE:  0.402179818812206\n",
      "Delta:  0.07623341757057707\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.024330064022938802 0.01732051117512845 0.10672443868145876\n",
      "Epoch: 36\n",
      "Arb loss 107.42574063852469\n",
      "Real arb loss 107.41573563852468\n",
      "Bounds loss: 6.772546851658152\n",
      "MAPE:  0.40128905154533956\n",
      "Delta:  0.0743786536403975\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.06779992349680797 0.03335758822854251 0.17636795278573547\n",
      "Epoch: 37\n",
      "Arb loss 88.4792826856167\n",
      "Real arb loss 88.46927768561669\n",
      "Bounds loss: 6.546631022522027\n",
      "MAPE:  0.39548246194842\n",
      "Delta:  0.06933578661378297\n",
      "GRAD\n",
      " tensor([-1829.7453, -3764.6899, -2389.7328, -6995.7556])\n",
      "0.020356680265325555 0.039980635226085415 -0.1254409923035371\n",
      "Epoch: 38\n",
      "Arb loss 99.57821170400562\n",
      "Real arb loss 99.56820670400562\n",
      "Bounds loss: 6.284892555650799\n",
      "MAPE:  0.37921004388117224\n",
      "Delta:  0.06792434017474135\n",
      "GRAD\n",
      " tensor([   287.5781,  -6308.7288,  -4062.5494, -12817.7405])\n",
      "-0.17132036183113164 0.01297645721112084 -0.6279516558444984\n",
      "arb imp changed to 10010.002499999999\n",
      "Epoch: 39\n",
      "Arb loss 162.18956888688473\n",
      "Real arb loss 162.17955888438473\n",
      "Bounds loss: 6.203336916325905\n",
      "MAPE:  0.3714479763508339\n",
      "Delta:  0.07956116271061892\n",
      "GRAD\n",
      " tensor([  3029.2635,  -6285.9696,  -3854.4877, -12239.5790])\n",
      "-0.034546132240020455 0.0062612086312534565 -0.04995593865272929\n",
      "Epoch: 40\n",
      "Arb loss 170.29190104031056\n",
      "Real arb loss 170.28189103781057\n",
      "Bounds loss: 6.1644965296828325\n",
      "MAPE:  0.36912792411031364\n",
      "Delta:  0.08230969315878972\n",
      "GRAD\n",
      " tensor([  3670.3389,  -6191.3203,  -3784.6119, -11882.6368])\n",
      "-0.047599071858947406 0.007267979562744831 -0.032903764222481646\n",
      "Epoch: 41\n",
      "Arb loss 175.89514560113912\n",
      "Real arb loss 175.88513559863912\n",
      "Bounds loss: 6.119693094890486\n",
      "MAPE:  0.367175144037185\n",
      "Delta:  0.08622755815814287\n",
      "GRAD\n",
      " tensor([  4173.9393,  -6145.3318,  -3728.3749, -11498.8410])\n",
      "-0.0582666807253287 0.0073591450951111526 -0.016013235890071975\n",
      "Epoch: 42\n",
      "Arb loss 178.7117960595687\n",
      "Real arb loss 178.70178605706872\n",
      "Bounds loss: 6.074657385467638\n",
      "MAPE:  0.36506033112035635\n",
      "Delta:  0.09125175175906809\n",
      "GRAD\n",
      " tensor([  4771.4035,  -6069.1108,  -3665.7077, -11085.7582])\n",
      "-0.06794763012787675 0.008003373801101943 0.00020048476802259074\n",
      "Epoch: 43\n",
      "Arb loss 178.67596706659282\n",
      "Real arb loss 178.66595706409282\n",
      "Bounds loss: 6.026039631698115\n",
      "MAPE:  0.3631084844761097\n",
      "Delta:  0.09745209203611407\n",
      "GRAD\n",
      " tensor([  5071.2719,  -6064.7831,  -3617.4904, -10652.6025])\n",
      "-0.06967586156667727 0.008108524533586459 0.014500714752944788\n",
      "Epoch: 44\n",
      "Arb loss 176.0850378349536\n",
      "Real arb loss 176.0750278324536\n",
      "Bounds loss: 5.977177341504127\n",
      "MAPE:  0.36091004533450144\n",
      "Delta:  0.10424215051020545\n",
      "GRAD\n",
      " tensor([  5854.8798,  -5954.3273,  -3566.2757, -10270.2588])\n",
      "-0.07886596918637667 0.008820576249599199 0.03061954486969709\n",
      "Epoch: 45\n",
      "Arb loss 170.69339411808392\n",
      "Real arb loss 170.68338411558392\n",
      "Bounds loss: 5.924455193006013\n",
      "MAPE:  0.3583066803186829\n",
      "Delta:  0.11246330874026496\n",
      "GRAD\n",
      " tensor([ 6745.3252, -5756.9412, -3463.9580, -9708.6031])\n",
      "-0.08405090357142897 0.009189631235936191 0.053226018294220245\n",
      "Epoch: 46\n",
      "Arb loss 161.60806440005226\n",
      "Real arb loss 161.59805439755226\n",
      "Bounds loss: 5.870011634508461\n",
      "MAPE:  0.3559675848872554\n",
      "Delta:  0.12191595145851682\n",
      "GRAD\n",
      " tensor([ 7532.4977, -5592.3505, -3367.6312, -9116.3196])\n",
      "-0.07928893624772737 0.008301700866233164 0.07982448267503517\n",
      "Epoch: 47\n",
      "Arb loss 148.7077842632043\n",
      "Real arb loss 148.6977742607043\n",
      "Bounds loss: 5.821280553837463\n",
      "MAPE:  0.3532496734129049\n",
      "Delta:  0.1315825375612922\n",
      "GRAD\n",
      " tensor([ 8447.6786, -5377.4925, -3261.2599, -8494.4264])\n",
      "-0.07359429201233936 0.005935371753280516 0.11345251918621424\n",
      "Epoch: 48\n",
      "Arb loss 131.8365115159437\n",
      "Real arb loss 131.8265015134437\n",
      "Bounds loss: 5.786729089670295\n",
      "MAPE:  0.35013889984820334\n",
      "Delta:  0.14126626125430256\n",
      "GRAD\n",
      " tensor([ 9510.1087, -5109.1888, -3145.2636, -7842.8968])\n",
      "-0.06661607056298857 0.0014296264429111138 0.15914030989130823\n",
      "Epoch: 49\n",
      "Arb loss 110.8560082183074\n",
      "Real arb loss 110.8459982158074\n",
      "Bounds loss: 5.778456228745739\n",
      "MAPE:  0.3473633286536886\n",
      "Delta:  0.15067686448218875\n",
      "GRAD\n",
      " tensor([10382.3459, -4757.1444, -2960.2944, -6985.3437])\n",
      "-0.04395124054001864 -0.002507921281042602 0.2026301781260833\n",
      "Epoch: 50\n",
      "Arb loss 88.39323552668522\n",
      "Real arb loss 88.38322552418522\n",
      "Bounds loss: 5.792948142093383\n",
      "MAPE:  0.3460014501054847\n",
      "Delta:  0.1572992995968612\n",
      "GRAD\n",
      " tensor([10851.3609, -4386.7416, -2746.9876, -6106.0750])\n",
      "-0.025328856857939286 -0.005898148015444082 0.25505767930322953\n",
      "Epoch: 51\n",
      "Arb loss 65.84786200714511\n",
      "Real arb loss 65.83785200464511\n",
      "Bounds loss: 5.827115807681242\n",
      "MAPE:  0.3457315128824189\n",
      "Delta:  0.16128351104020422\n",
      "GRAD\n",
      " tensor([10982.8323, -3941.1000, -2485.6794, -5166.0732])\n",
      "-0.21248422355196372 -0.06140656358385921 0.1709855291065071\n",
      "Epoch: 52\n",
      "Arb loss 54.58883048132114\n",
      "Real arb loss 54.578820478821136\n",
      "Bounds loss: 6.184938965036132\n",
      "MAPE:  0.3536561834336883\n",
      "Delta:  0.19555371265531657\n",
      "GRAD\n",
      " tensor([12322.9578, -3537.6857, -2245.4431, -4305.0594])\n",
      "0.0075999740621612855 -0.016769247012759392 0.4258139804276474\n",
      "Epoch: 53\n",
      "Arb loss 31.344143287179694\n",
      "Real arb loss 31.334133284679694\n",
      "Bounds loss: 6.288655734299663\n",
      "MAPE:  0.3602815660466978\n",
      "Delta:  0.19406750951137683\n",
      "GRAD\n",
      " tensor([11115.2977, -2728.0150, -1768.5108, -3111.2700])\n",
      "-0.18188598604358308 -0.08849293603093766 0.3923871121984529\n",
      "Epoch: 54\n",
      "Arb loss 19.045105418388733\n",
      "Real arb loss 19.035095415888733\n",
      "Bounds loss: 6.845157343915632\n",
      "MAPE:  0.3752210218525576\n",
      "Delta:  0.229365669837876\n",
      "GRAD\n",
      " tensor([11215.3930, -2274.7814, -1465.6694, -2332.7557])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[117], line 36\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28mprint\u001b[39m(log_strikes\u001b[38;5;241m.\u001b[39mshape, datum\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28mprint\u001b[39m(datum\u001b[38;5;241m.\u001b[39mT\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m---> 36\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdatum\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mT\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdouble\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlog_strikes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1601\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Project\\smilecorrector_gsvi_jo_mw_ar.py:360\u001b[0m, in \u001b[0;36mSmileNet.train\u001b[1;34m(self, data, strikes, epochs, optimizer)\u001b[0m\n\u001b[0;32m    358\u001b[0m arb_loss \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(\u001b[38;5;241m0.0\u001b[39m)\n\u001b[0;32m    359\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m g, a, b \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(g_loss, bounds[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m], bounds[\u001b[38;5;241m1\u001b[39m:]):\n\u001b[1;32m--> 360\u001b[0m     arb_loss \u001b[38;5;241m=\u001b[39m arb_loss \u001b[38;5;241m+\u001b[39m \u001b[43mdiff_integ\u001b[49m\u001b[43m(\u001b[49m\u001b[43mg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    361\u001b[0m \u001b[38;5;66;03m# area = torch.tensor(0.0)\u001b[39;00m\n\u001b[0;32m    362\u001b[0m \u001b[38;5;66;03m# for r, a, b in zip(rnms, ba[:-1].detach(), ba[1:].detach()):\u001b[39;00m\n\u001b[0;32m    363\u001b[0m \u001b[38;5;66;03m#     area += diff_integ(r, a, b, delta=1.0e-5).item()\u001b[39;00m\n\u001b[0;32m    364\u001b[0m \n\u001b[0;32m    365\u001b[0m \u001b[38;5;66;03m# print('Area',area)\u001b[39;00m\n\u001b[0;32m    366\u001b[0m raw_loss, delta_loss, delta_first, delta_last, mape \u001b[38;5;241m=\u001b[39m get_observe_losses(fs, bounds[\u001b[38;5;241m1\u001b[39m:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m], strikes, lows, highs, delta_imp)\n",
      "File \u001b[1;32md:\\Project\\smilecorrector_gsvi_jo_mw_ar.py:1035\u001b[0m, in \u001b[0;36mdiff_integ\u001b[1;34m(f, a, b, delta)\u001b[0m\n\u001b[0;32m   1032\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdiff_integ\u001b[39m(f,a,b, delta\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.0e-3\u001b[39m):\n\u001b[0;32m   1033\u001b[0m     \u001b[38;5;66;03m# Computes integral of f between a and b with step_size delta\u001b[39;00m\n\u001b[0;32m   1034\u001b[0m     rng \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;28mint\u001b[39m((b \u001b[38;5;241m-\u001b[39m a) \u001b[38;5;241m/\u001b[39m delta)) \u001b[38;5;241m*\u001b[39m delta \u001b[38;5;241m+\u001b[39m a\n\u001b[1;32m-> 1035\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39msum((\u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrng\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m+\u001b[39m f(rng[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]))\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m2\u001b[39m \u001b[38;5;241m*\u001b[39m delta)\n",
      "File \u001b[1;32md:\\Project\\smilecorrector_gsvi_jo_mw_ar.py:357\u001b[0m, in \u001b[0;36mSmileNet.train.<locals>.<lambda>\u001b[1;34m(x, g)\u001b[0m\n\u001b[0;32m    347\u001b[0m     plot_polys(polys,ba\u001b[38;5;241m.\u001b[39mdetach(), e, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mraw\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mp\u001b[39m\u001b[38;5;124m'\u001b[39m,)\n\u001b[0;32m    349\u001b[0m \u001b[38;5;66;03m# price_funcs = [lambda x, w=w: bsc_svi(x, w, S) for w in plottable_fs]\u001b[39;00m\n\u001b[0;32m    350\u001b[0m \u001b[38;5;66;03m# plot_polys(price_funcs, ba.detach().reshape(-1), e, 'prices')\u001b[39;00m\n\u001b[0;32m    351\u001b[0m \u001b[38;5;66;03m# plot_polys([p.deriv() for p in polys],ba.detach(), e, 'der','p',)\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    354\u001b[0m \n\u001b[0;32m    355\u001b[0m \u001b[38;5;66;03m# plot_polys([np.polynomial.polynomial.Polynomial(sol[p,:].detach()) for p in range(sol.shape[0])], bounds.reshape(-1), e, 'poly')\u001b[39;00m\n\u001b[1;32m--> 357\u001b[0m g_loss \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;01mlambda\u001b[39;00m x, g\u001b[38;5;241m=\u001b[39mi: \u001b[43mgloss_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43mg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marb_tol\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m gs]\n\u001b[0;32m    358\u001b[0m arb_loss \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(\u001b[38;5;241m0.0\u001b[39m)\n\u001b[0;32m    359\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m g, a, b \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(g_loss, bounds[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m], bounds[\u001b[38;5;241m1\u001b[39m:]):\n",
      "File \u001b[1;32md:\\Project\\smilecorrector_gsvi_jo_mw_ar.py:957\u001b[0m, in \u001b[0;36mgloss_func\u001b[1;34m(g, x, arb_tol)\u001b[0m\n\u001b[0;32m    956\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgloss_func\u001b[39m(g, x, arb_tol):\n\u001b[1;32m--> 957\u001b[0m     gs \u001b[38;5;241m=\u001b[39m \u001b[43mg\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    958\u001b[0m     x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mabs(torch\u001b[38;5;241m.\u001b[39mmin(gs \u001b[38;5;241m-\u001b[39m arb_tol, torch\u001b[38;5;241m.\u001b[39mtensor(\u001b[38;5;241m0.0\u001b[39m)))\n\u001b[0;32m    959\u001b[0m     y \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mabs(torch\u001b[38;5;241m.\u001b[39mmin(gs, torch\u001b[38;5;241m.\u001b[39mtensor(\u001b[38;5;241m0.0\u001b[39m)))\n",
      "File \u001b[1;32md:\\Project\\smilecorrector_gsvi_jo_mw_ar.py:979\u001b[0m, in \u001b[0;36mg_func.<locals>.<lambda>\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m    977\u001b[0m term2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m x: (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m/\u001b[39m w(x) \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m4\u001b[39m) \u001b[38;5;241m*\u001b[39m (a(x) \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m4\u001b[39m \u001b[38;5;241m*\u001b[39m w(x) \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m) )\n\u001b[0;32m    978\u001b[0m term3 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[38;5;241m0.5\u001b[39m \u001b[38;5;241m*\u001b[39m ((p_eval(x) \u001b[38;5;241m*\u001b[39m psub2(x) \u001b[38;5;241m+\u001b[39m psub(x)\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m) \u001b[38;5;241m/\u001b[39m w(x) \u001b[38;5;241m-\u001b[39m a(x) \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;241m/\u001b[39m (w(x) \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m3\u001b[39m))\n\u001b[1;32m--> 979\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mlambda\u001b[39;00m x: term1(x) \u001b[38;5;241m-\u001b[39m term2(x) \u001b[38;5;241m+\u001b[39m \u001b[43mterm3\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Project\\smilecorrector_gsvi_jo_mw_ar.py:978\u001b[0m, in \u001b[0;36mg_func.<locals>.<lambda>\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m    976\u001b[0m term1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m x: (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m a(x)\u001b[38;5;241m*\u001b[39mx\u001b[38;5;241m/\u001b[39m(\u001b[38;5;241m2\u001b[39m \u001b[38;5;241m*\u001b[39m w(x) \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m)) \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m\n\u001b[0;32m    977\u001b[0m term2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m x: (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m/\u001b[39m w(x) \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m4\u001b[39m) \u001b[38;5;241m*\u001b[39m (a(x) \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m4\u001b[39m \u001b[38;5;241m*\u001b[39m w(x) \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m) )\n\u001b[1;32m--> 978\u001b[0m term3 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[38;5;241m0.5\u001b[39m \u001b[38;5;241m*\u001b[39m ((\u001b[43mp_eval\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m*\u001b[39m psub2(x) \u001b[38;5;241m+\u001b[39m psub(x)\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m) \u001b[38;5;241m/\u001b[39m w(x) \u001b[38;5;241m-\u001b[39m a(x) \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;241m/\u001b[39m (w(x) \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m3\u001b[39m))\n\u001b[0;32m    979\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mlambda\u001b[39;00m x: term1(x) \u001b[38;5;241m-\u001b[39m term2(x) \u001b[38;5;241m+\u001b[39m term3(x)\n",
      "File \u001b[1;32md:\\Project\\smilecorrector_gsvi_jo_mw_ar.py:972\u001b[0m, in \u001b[0;36mg_func.<locals>.<lambda>\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m    970\u001b[0m psub \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m x: differentiablePolyEval\u001b[38;5;241m.\u001b[39mapply(psub_back, x)\n\u001b[0;32m    971\u001b[0m psub2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m x: differentiablePolyEval\u001b[38;5;241m.\u001b[39mapply(psub2_back, x)\n\u001b[1;32m--> 972\u001b[0m p_eval \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[43mdifferentiablePolyEval\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    973\u001b[0m a \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m x: differentiablePolyEval\u001b[38;5;241m.\u001b[39mapply(ap, x)\n\u001b[0;32m    974\u001b[0m p2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m x: differentiablePolyEval\u001b[38;5;241m.\u001b[39mapply(p, x) \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\autograd\\function.py:553\u001b[0m, in \u001b[0;36mFunction.apply\u001b[1;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[0;32m    550\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_are_functorch_transforms_active():\n\u001b[0;32m    551\u001b[0m     \u001b[38;5;66;03m# See NOTE: [functorch vjp and autograd interaction]\u001b[39;00m\n\u001b[0;32m    552\u001b[0m     args \u001b[38;5;241m=\u001b[39m _functorch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39munwrap_dead_wrappers(args)\n\u001b[1;32m--> 553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m    555\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_setup_ctx_defined:\n\u001b[0;32m    556\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    557\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIn order to use an autograd.Function with functorch transforms \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    558\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(vmap, grad, jvp, jacrev, ...), it must override the setup_context \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    559\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstaticmethod. For more details, please see \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    560\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://pytorch.org/docs/master/notes/extending.func.html\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    561\u001b[0m     )\n",
      "File \u001b[1;32md:\\Project\\smilecorrector_gsvi_jo_mw_ar.py:670\u001b[0m, in \u001b[0;36mdifferentiablePolyEval.forward\u001b[1;34m(ctx, coeffs, x)\u001b[0m\n\u001b[0;32m    666\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[0;32m    667\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(ctx, coeffs, x):\n\u001b[0;32m    668\u001b[0m     \u001b[38;5;66;03m# Scale is tuple (a, b) st result = poly1 * a + poly2 * b\u001b[39;00m\n\u001b[0;32m    669\u001b[0m     ctx\u001b[38;5;241m.\u001b[39msave_for_backward(coeffs, torch\u001b[38;5;241m.\u001b[39mtensor(x))\n\u001b[1;32m--> 670\u001b[0m     poly \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpolynomial\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpolynomial\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPolynomial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcoeffs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdetach\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    673\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mtensor(poly(x))\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we generate based on the svi curve:\n",
    " w(x) = a + b(c(x-m)+sqrt((x-m)^2 + k))\n",
    "taking\n",
    "a = -1.5\n",
    "b = 1.3\n",
    "c = -0.4\n",
    "m = -0.3\n",
    "k = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "def svi_with_noise(grid, a, b, c, m , k, noise_mid=0.00001, noise_spread=0.001):\n",
    "    # grid are our strike prices\n",
    "    true = a + b*(c * (grid - m) + torch.sqrt((grid - m)**2 + k))\n",
    "    mids = true * (torch.randn((grid.shape)) * noise_mid + 1.0)\n",
    "    return true * 1.05 + torch.randn((grid.shape))**2 * noise_spread, true * 0.95 - torch.randn((grid.shape))**2 * noise_spread  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def svi(xs, a,b,c,m,s):\n",
    "    return a + b*(c * (xs - m) + torch.sqrt((xs-m)**2 + s))\n",
    "\\\n",
    "def svi_sub(xs, a, b, c, m ,s):\n",
    "    return b * ((xs - m) / torch.sqrt((xs - m) ** 2 + s) + c)\n",
    "\n",
    "def svi_sub2(xs, a, b, c, m ,s):\n",
    "    return b * s / (torch.sqrt((xs - m) ** 2 + s) ** 3)\n",
    "\n",
    "def g_svi(a, b, c, m , s):\n",
    "    w = lambda x: svi(x, a, b, c, m ,s)\n",
    "    wsub = lambda x: svi_sub(x, a, b, c, m ,s)\n",
    "    wsub2 = lambda x: svi_sub2(x, a, b, c, m ,s)\n",
    "    term1 = lambda x: (1 - (x * wsub(x) / (2 * w(x))))**2\n",
    "    term2 = lambda x: ((wsub(x)**2)/4) * (1 / w(x) + 1/4)\n",
    "    term3 = lambda x: wsub2(x) / 2\n",
    "    return lambda x: term1(x) - term2(x) + term3(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Axel Vogt Curve\n",
    "a = -0.0410\n",
    "b = 0.1331\n",
    "m = 0.3586\n",
    "rho = 0.3060\n",
    "sig = 0.4153\n",
    "axel_svi = lambda k: svi_with_noise(k, a, b, rho, m, sig**2, noise_spread=0.0, noise_mid = 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x1d6c64fbc50>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "xs = torch.tensor(np.arange(45)/15 - 1.5)\n",
    "res = axel_svi(xs)\n",
    "plt.scatter(xs, res[0], s=1)\n",
    "plt.scatter(xs, res[1], s=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "torch.Size([45])\n",
      "torch.Size([45])\n",
      "tensor(0.0111) tensor(0.0122)\n",
      "Mid shape torch.Size([45])\n",
      "0\n",
      "torch.Size([45]) torch.Size([45])\n",
      "tensor([[ 0.1436],\n",
      "        [ 0.1374],\n",
      "        [ 0.1312],\n",
      "        [ 0.1250],\n",
      "        [ 0.1188],\n",
      "        [ 0.1126],\n",
      "        [ 0.1065],\n",
      "        [ 0.1004],\n",
      "        [ 0.0944],\n",
      "        [ 0.0883],\n",
      "        [ 0.0824],\n",
      "        [ 0.0765],\n",
      "        [ 0.0706],\n",
      "        [ 0.0648],\n",
      "        [ 0.0591],\n",
      "        [ 0.0535],\n",
      "        [ 0.0481],\n",
      "        [ 0.0427],\n",
      "        [ 0.0376],\n",
      "        [ 0.0327],\n",
      "        [ 0.0281],\n",
      "        [ 0.0238],\n",
      "        [ 0.0200],\n",
      "        [ 0.0168],\n",
      "        [ 0.0143],\n",
      "        [ 0.0127],\n",
      "        [ 0.0122],\n",
      "        [ 0.0131],\n",
      "        [ 0.0153],\n",
      "        [ 0.0191],\n",
      "        [ 0.0243],\n",
      "        [ 0.0308],\n",
      "        [ 0.0383],\n",
      "        [ 0.0467],\n",
      "        [ 0.0558],\n",
      "        [ 0.0654],\n",
      "        [ 0.0755],\n",
      "        [ 0.0859],\n",
      "        [ 0.0965],\n",
      "        [ 0.1074],\n",
      "        [ 0.1185],\n",
      "        [ 0.1297],\n",
      "        [ 0.1410],\n",
      "        [ 0.1524],\n",
      "        [ 0.1639],\n",
      "        [ 0.1299],\n",
      "        [ 0.1243],\n",
      "        [ 0.1187],\n",
      "        [ 0.1131],\n",
      "        [ 0.1075],\n",
      "        [ 0.1019],\n",
      "        [ 0.0964],\n",
      "        [ 0.0909],\n",
      "        [ 0.0854],\n",
      "        [ 0.0799],\n",
      "        [ 0.0745],\n",
      "        [ 0.0692],\n",
      "        [ 0.0639],\n",
      "        [ 0.0586],\n",
      "        [ 0.0535],\n",
      "        [ 0.0484],\n",
      "        [ 0.0435],\n",
      "        [ 0.0387],\n",
      "        [ 0.0340],\n",
      "        [ 0.0296],\n",
      "        [ 0.0254],\n",
      "        [ 0.0215],\n",
      "        [ 0.0181],\n",
      "        [ 0.0152],\n",
      "        [ 0.0129],\n",
      "        [ 0.0115],\n",
      "        [ 0.0111],\n",
      "        [ 0.0118],\n",
      "        [ 0.0139],\n",
      "        [ 0.0173],\n",
      "        [ 0.0220],\n",
      "        [ 0.0278],\n",
      "        [ 0.0346],\n",
      "        [ 0.0422],\n",
      "        [ 0.0505],\n",
      "        [ 0.0592],\n",
      "        [ 0.0683],\n",
      "        [ 0.0777],\n",
      "        [ 0.0873],\n",
      "        [ 0.0972],\n",
      "        [ 0.1072],\n",
      "        [ 0.1173],\n",
      "        [ 0.1276],\n",
      "        [ 0.1379],\n",
      "        [ 0.1483],\n",
      "        [-1.5000],\n",
      "        [-1.4333],\n",
      "        [-1.3667],\n",
      "        [-1.3000],\n",
      "        [-1.2333],\n",
      "        [-1.1667],\n",
      "        [-1.1000],\n",
      "        [-1.0333],\n",
      "        [-0.9667],\n",
      "        [-0.9000],\n",
      "        [-0.8333],\n",
      "        [-0.7667],\n",
      "        [-0.7000],\n",
      "        [-0.6333],\n",
      "        [-0.5667],\n",
      "        [-0.5000],\n",
      "        [-0.4333],\n",
      "        [-0.3667],\n",
      "        [-0.3000],\n",
      "        [-0.2333],\n",
      "        [-0.1667],\n",
      "        [-0.1000],\n",
      "        [-0.0333],\n",
      "        [ 0.0333],\n",
      "        [ 0.1000],\n",
      "        [ 0.1667],\n",
      "        [ 0.2333],\n",
      "        [ 0.3000],\n",
      "        [ 0.3667],\n",
      "        [ 0.4333],\n",
      "        [ 0.5000],\n",
      "        [ 0.5667],\n",
      "        [ 0.6333],\n",
      "        [ 0.7000],\n",
      "        [ 0.7667],\n",
      "        [ 0.8333],\n",
      "        [ 0.9000],\n",
      "        [ 0.9667],\n",
      "        [ 1.0333],\n",
      "        [ 1.1000],\n",
      "        [ 1.1667],\n",
      "        [ 1.2333],\n",
      "        [ 1.3000],\n",
      "        [ 1.3667],\n",
      "        [ 1.4333],\n",
      "        [ 0.0000],\n",
      "        [ 1.0000],\n",
      "        [ 0.0000]])\n",
      "torch.Size([45]) torch.Size([138, 1])\n",
      "torch.Size([1, 138])\n",
      "0.0 0.0 0.0\n",
      "Epoch: 0\n",
      "Arb loss 33.866091767628404\n",
      "Real arb loss 0.028362126652616528\n",
      "Bounds loss: 0.323319163814934\n",
      "MAPE:  0.03061039242697423\n",
      "Delta:  0.00567019967369077\n",
      "GRAD\n",
      " tensor([ 402.3705,  329.3689,   71.8236, 6535.3074])\n",
      "-34.57725058362523 -254.41624061425438 0.13578330186035226\n",
      "Epoch: 1\n",
      "Arb loss 29.267642006314126\n",
      "Real arb loss 0.025777982163715844\n",
      "Bounds loss: 82.5809653401547\n",
      "MAPE:  0.7410807492344492\n",
      "Delta:  0.2017301146500865\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.9668793560096879 0.5211252330603806 0.9465577600084847\n",
      "Epoch: 2\n",
      "Arb loss 1.5641283480871933\n",
      "Real arb loss 0.001506649222954241\n",
      "Bounds loss: 39.545940530915374\n",
      "MAPE:  0.5353082003774685\n",
      "Delta:  0.006681431309450355\n",
      "GRAD\n",
      " tensor([-455.7508,  -80.2488,  117.7083, 4638.0492])\n",
      "-9.083508282007811 0.8132448986697528 -9.256354638494898\n",
      "Epoch: 3\n",
      "Arb loss 16.04225503810545\n",
      "Real arb loss 0.013973280923468275\n",
      "Bounds loss: 7.385406131051031\n",
      "MAPE:  0.3489991795807029\n",
      "Delta:  0.06737226794450894\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.4550482228855095 0.24976983041050527 -0.9788632898792007\n",
      "Epoch: 4\n",
      "Arb loss 31.745429581786528\n",
      "Real arb loss 0.024664383340185995\n",
      "Bounds loss: 5.540754494185709\n",
      "MAPE:  0.3613966393829313\n",
      "Delta:  0.03671463714459377\n",
      "GRAD\n",
      " tensor([1668.1748,  681.9096,  137.9860,  630.4852])\n",
      "-0.20248579192332716 -0.17210034814261221 0.035914886250737244\n",
      "Epoch: 5\n",
      "Arb loss 30.605296089375877\n",
      "Real arb loss 0.023619167436940317\n",
      "Bounds loss: 6.494320271607812\n",
      "MAPE:  0.394727066635082\n",
      "Delta:  0.04414882952199445\n",
      "GRAD\n",
      " tensor([1756.1256,  672.6503,  126.9605,  685.7377])\n",
      "-0.2562376036000409 -0.06573250676606834 0.09836583126206533\n",
      "Epoch: 6\n",
      "Arb loss 27.59478069852278\n",
      "Real arb loss 0.021370121591489204\n",
      "Bounds loss: 6.921208222802287\n",
      "MAPE:  0.41610994877291096\n",
      "Delta:  0.05546141980045704\n",
      "GRAD\n",
      " tensor([1683.8387,  601.4475,  106.4580,  150.6994])\n",
      "-0.2048895483842028 0.04054464449458095 0.13434333410075194\n",
      "Epoch: 7\n",
      "Arb loss 23.88760585570415\n",
      "Real arb loss 0.018895552900725435\n",
      "Bounds loss: 6.640590295935798\n",
      "MAPE:  0.4140148883814549\n",
      "Delta:  0.06682488505611936\n",
      "GRAD\n",
      " tensor([ 930.0600,  325.5229,   57.9755, -566.9629])\n",
      "0.069050155444914 0.08590201686642684 -0.05746087562952873\n",
      "Epoch: 8\n",
      "Arb loss 25.26020860486597\n",
      "Real arb loss 0.0199180937603397\n",
      "Bounds loss: 6.070150196331291\n",
      "MAPE:  0.3922604081140982\n",
      "Delta:  0.062210616355405805\n",
      "GRAD\n",
      " tensor([ 995.3573,  363.9424,   72.0323, -613.7491])\n",
      "0.048826333107747755 0.03985139697240214 -0.061181547818927484\n",
      "Epoch: 9\n",
      "Arb loss 26.80566726554066\n",
      "Real arb loss 0.020985770310379525\n",
      "Bounds loss: 5.8282462311751875\n",
      "MAPE:  0.3825820332425164\n",
      "Delta:  0.05917310007839846\n",
      "GRAD\n",
      " tensor([1241.0893,  463.2333,   93.6806, -580.0383])\n",
      "0.012434261923303547 0.0036235424970139096 -0.041273851794466854\n",
      "Delta imp changed to 0.04878048780487806\n",
      "Epoch: 10\n",
      "Arb loss 27.912040403510378\n",
      "Real arb loss 0.02173936078606651\n",
      "Bounds loss: 5.807127333273463\n",
      "MAPE:  0.3810180116887115\n",
      "Delta:  0.05701202561288762\n",
      "GRAD\n",
      " tensor([1428.8163,  538.3612,  109.8647, -491.0979])\n",
      "-0.028377974372300052 -0.023315506123859464 -0.011176513332479487\n",
      "arb imp changed to 1000.5\n",
      "Epoch: 11\n",
      "Arb loss 28.23811169506453\n",
      "Real arb loss 0.02192189981821193\n",
      "Bounds loss: 5.942523446174432\n",
      "MAPE:  0.3854702600509521\n",
      "Delta:  0.058629911414643056\n",
      "GRAD\n",
      " tensor([1450.9171,  545.5178,  111.1548, -415.1763])\n",
      "-0.04231744693094486 -0.03916108301183119 -0.013139878281300588\n",
      "Epoch: 12\n",
      "Arb loss 28.60915704563144\n",
      "Real arb loss 0.0221347554448005\n",
      "Bounds loss: 6.175239100149822\n",
      "MAPE:  0.3933105593217044\n",
      "Delta:  0.061110979579498216\n",
      "GRAD\n",
      " tensor([1550.2512,  578.0136,  114.0704, -320.0127])\n",
      "-0.06146679081894346 -0.03479803760178357 0.015897422506352843\n",
      "Epoch: 13\n",
      "Arb loss 28.154345188526438\n",
      "Real arb loss 0.021782922102950256\n",
      "Bounds loss: 6.390125302556839\n",
      "MAPE:  0.401248338184064\n",
      "Delta:  0.06486727537805195\n",
      "GRAD\n",
      " tensor([1516.8470,  558.5251,  109.9098, -344.5786])\n",
      "-0.03152201498568785 -0.02777779382811829 -0.012375701806265349\n",
      "Epoch: 14\n",
      "Arb loss 28.5027749691303\n",
      "Real arb loss 0.02203955571001173\n",
      "Bounds loss: 6.567628885747105\n",
      "MAPE:  0.40696744130888957\n",
      "Delta:  0.06691202260459966\n",
      "GRAD\n",
      " tensor([1622.6343,  592.4633,  113.6627, -263.4392])\n",
      "0.004709371412710217 -0.026060424434385165 -0.015265705171781496\n",
      "Epoch: 15\n",
      "Arb loss 28.937889928386678\n",
      "Real arb loss 0.022245454253719446\n",
      "Bounds loss: 6.738784082037203\n",
      "MAPE:  0.4107832911817727\n",
      "Delta:  0.06659690903817893\n",
      "GRAD\n",
      " tensor([1739.0939,  628.9898,  115.9450,   31.8608])\n",
      "-0.06567548198621354 -0.03701869884512177 0.0027874484451030357\n",
      "Epoch: 16\n",
      "Arb loss 28.857227052101234\n",
      "Real arb loss 0.022367353949315424\n",
      "Bounds loss: 6.9882451005524375\n",
      "MAPE:  0.42051788594077366\n",
      "Delta:  0.07097069313805336\n",
      "GRAD\n",
      " tensor([1756.2799,  618.2506,  109.5966,   41.0972])\n",
      "0.03528808808762107 -0.021041604228232424 0.012073595334245124\n",
      "Epoch: 17\n",
      "Arb loss 28.508816570205735\n",
      "Real arb loss 0.021919294470159535\n",
      "Bounds loss: 7.135288988208146\n",
      "MAPE:  0.4220479142040635\n",
      "Delta:  0.06846627306695821\n",
      "GRAD\n",
      " tensor([1881.5394,  655.9940,  112.1760,  441.1828])\n",
      "-0.0679433024531162 -0.0318734615406715 0.019277518599254417\n",
      "Epoch: 18\n",
      "Arb loss 27.95923732853086\n",
      "Real arb loss 0.021823064918346693\n",
      "Bounds loss: 7.362715347355375\n",
      "MAPE:  0.4332052487840986\n",
      "Delta:  0.07311809776578419\n",
      "GRAD\n",
      " tensor([1849.0252,  619.9103,  101.0538,  436.6638])\n",
      "0.06565088408552311 -0.01732224122636139 0.0435541308687174\n",
      "Epoch: 19\n",
      "Arb loss 26.741497046934498\n",
      "Real arb loss 0.020758486849097126\n",
      "Bounds loss: 7.490254078683297\n",
      "MAPE:  0.4367538633525499\n",
      "Delta:  0.06831783000480875\n",
      "GRAD\n",
      " tensor([1892.8482,  632.8093,  103.3772,  922.2739])\n",
      "0.07482750517265635 -0.07011697489931223 0.1114134165942463\n",
      "Epoch: 20\n",
      "Arb loss 23.762135496090576\n",
      "Real arb loss 0.018704678748958335\n",
      "Bounds loss: 8.015448035907806\n",
      "MAPE:  0.45685345196929894\n",
      "Delta:  0.06320577722673926\n",
      "GRAD\n",
      " tensor([1750.4567,  591.9748,  109.2354, 1375.3969])\n",
      "0.2199415666106832 -0.11538547886172434 0.3050246938667235\n",
      "Delta imp changed to 0.04759071980963713\n",
      "Epoch: 21\n",
      "Arb loss 16.514097390775945\n",
      "Real arb loss 0.013405604413686469\n",
      "Bounds loss: 8.940314345822294\n",
      "MAPE:  0.4882081938658306\n",
      "Delta:  0.04810165811184818\n",
      "GRAD\n",
      " tensor([1158.3367,  520.4933,  162.2067, 1881.5802])\n",
      "-0.04959686661691198 -0.14467683582767865 0.8450957569749292\n",
      "Epoch: 22\n",
      "Arb loss 2.5581037555604444\n",
      "Real arb loss 0.002342067909166597\n",
      "Bounds loss: 10.233770736680668\n",
      "MAPE:  0.5253278272323824\n",
      "Delta:  0.05048734963327382\n",
      "GRAD\n",
      " tensor([ 77.6331, 266.7752, 140.8447, 960.7009])\n",
      "0.1831820748386921 0.14323209532298897 0.9999999366439694\n",
      "Epoch: 23\n",
      "Arb loss 1.620712999850303e-07\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 8.767966311010808\n",
      "MAPE:  0.49081919770703764\n",
      "Delta:  0.04123897217434424\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.036568391167702385 0.11700879191017932 -2458603.4065864556\n",
      "arb imp changed to 1001.0002499999999\n",
      "Epoch: 24\n",
      "Arb loss 0.39866844693055303\n",
      "Real arb loss 0.0003852147012796675\n",
      "Bounds loss: 7.742037165450281\n",
      "MAPE:  0.4544575170513019\n",
      "Delta:  0.03973092930851883\n",
      "GRAD\n",
      " tensor([164.6586, 104.8701,  48.7698, 316.1989])\n",
      "0.04320356507533185 0.062246914708097734 -0.5211313969098277\n",
      "Epoch: 25\n",
      "Arb loss 0.6064270915833436\n",
      "Real arb loss 0.0005803501196416654\n",
      "Bounds loss: 7.260119238345574\n",
      "MAPE:  0.43690018574014555\n",
      "Delta:  0.03801441151863482\n",
      "GRAD\n",
      " tensor([154.2354, 148.8165,  74.4851, 494.7913])\n",
      "-0.5477962867387283 0.05133968890741203 1.0\n",
      "Epoch: 26\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 6.887386975218195\n",
      "MAPE:  0.42432590144523874\n",
      "Delta:  0.05883856499110091\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "-0.05726155257893839 0.1054300364723948 -inf\n",
      "Epoch: 27\n",
      "Arb loss 0.018527449675272107\n",
      "Real arb loss 1.8375248676467608e-05\n",
      "Bounds loss: 6.161249515221444\n",
      "MAPE:  0.39834327701424915\n",
      "Delta:  0.062207752574008124\n",
      "GRAD\n",
      " tensor([-88.5965,  34.9359,  30.1076, 190.0173])\n",
      "-0.41439894863158444 0.0779421784383767 1.0\n",
      "Epoch: 28\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 5.681028306102693\n",
      "MAPE:  0.3881043021832638\n",
      "Delta:  0.08798657983741083\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.2905292738628723 0.08933951546482277 nan\n",
      "Epoch: 29\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 5.173487989893535\n",
      "MAPE:  0.35605715864404924\n",
      "Delta:  0.06242390268757022\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "-0.42797181671601425 0.0870247791319364 nan\n",
      "Epoch: 30\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 4.723266340231325\n",
      "MAPE:  0.34942823506925497\n",
      "Delta:  0.08913957372727332\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.28910641752978283 0.07272795067593019 nan\n",
      "Epoch: 31\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 4.3797528588097\n",
      "MAPE:  0.32048060370724757\n",
      "Delta:  0.06336875090684939\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "-0.3914362746636242 0.07059923226720144 nan\n",
      "Epoch: 32\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 4.070545669457654\n",
      "MAPE:  0.31844995475873056\n",
      "Delta:  0.08817357869191367\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.339246904377575 0.05289963042040369 -inf\n",
      "Epoch: 33\n",
      "Arb loss 0.18359757101347668\n",
      "Real arb loss 0.00018049974577376748\n",
      "Bounds loss: 3.8552153079339697\n",
      "MAPE:  0.28943857661785843\n",
      "Delta:  0.058260965072789446\n",
      "GRAD\n",
      " tensor([-392.7211,   60.2681,   77.6493,  661.5899])\n",
      "-1.1595665947742146 -0.7174989074442852 1.0\n",
      "Epoch: 34\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 6.621328079339077\n",
      "MAPE:  0.36650492864781054\n",
      "Delta:  0.12581843395050335\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.706965025460268 -0.06053732346124718 nan\n",
      "Epoch: 35\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 7.022165559021065\n",
      "MAPE:  0.3482172846246617\n",
      "Delta:  0.036869201589314705\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "-0.0014455745523036523 0.3395077635121052 -inf\n",
      "Epoch: 36\n",
      "Arb loss 0.9624869697376258\n",
      "Real arb loss 0.0009155659808200473\n",
      "Bounds loss: 4.638085835066091\n",
      "MAPE:  0.28872123818427553\n",
      "Delta:  0.03692249876889598\n",
      "GRAD\n",
      " tensor([-225.0460,  159.7791,  123.9501, 1133.9532])\n",
      "-2.495202310694692 -0.4747031789315235 1.0\n",
      "Epoch: 37\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 6.839799925129234\n",
      "MAPE:  0.3653271377487591\n",
      "Delta:  0.12905160301366717\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.6783545201914707 -0.14283416264335047 nan\n",
      "Epoch: 38\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 7.816757020083118\n",
      "MAPE:  0.3641435297574242\n",
      "Delta:  0.04150886477139081\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.16312313827464842 0.335467649968589 nan\n",
      "Epoch: 39\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 5.194487912180364\n",
      "MAPE:  0.3017092010189354\n",
      "Delta:  0.03473780848366354\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "-1.337058219612095 0.33599317138497853 nan\n",
      "Epoch: 40\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 3.4491754448459475\n",
      "MAPE:  0.27691491970575455\n",
      "Delta:  0.08118428084805665\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.031842754223007974 0.032276249482551256 nan\n",
      "Epoch: 41\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 3.33784899767901\n",
      "MAPE:  0.26853980425357143\n",
      "Delta:  0.07859914974624033\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.004592244452781946 0.03031436527253839 nan\n",
      "Epoch: 42\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 3.236664223938792\n",
      "MAPE:  0.2621980518911794\n",
      "Delta:  0.07823820323682477\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.03561281123213378 0.02866189816996123 nan\n",
      "Epoch: 43\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 3.143895283541902\n",
      "MAPE:  0.2548242323480675\n",
      "Delta:  0.07545192087381042\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.003769689840320889 0.027464375302776012 nan\n",
      "Epoch: 44\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 3.05755016356208\n",
      "MAPE:  0.2493782284670001\n",
      "Delta:  0.07516749053425972\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.038386604827173376 0.026511853735226798 nan\n",
      "Epoch: 45\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 2.9764888408376033\n",
      "MAPE:  0.24256040833763223\n",
      "Delta:  0.07228206577927081\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.004441214350762945 0.02585671560762015 nan\n",
      "Epoch: 46\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 2.89952661537081\n",
      "MAPE:  0.23753085908888963\n",
      "Delta:  0.0719610456314291\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.03804976601427723 0.025293850996386147 nan\n",
      "Epoch: 47\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 2.826186421201565\n",
      "MAPE:  0.23146973317213457\n",
      "Delta:  0.0692229446830105\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.007669094667243304 0.024998499060135182 nan\n",
      "Epoch: 48\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 2.755536002607391\n",
      "MAPE:  0.22673267791634752\n",
      "Delta:  0.06869206736709114\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.035379012658827924 0.024686349412362918 nan\n",
      "Epoch: 49\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 2.687511878028679\n",
      "MAPE:  0.22126186555221633\n",
      "Delta:  0.06626180984614977\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.011433852849527582 0.024487843820904076 nan\n",
      "Epoch: 50\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 2.621700506892688\n",
      "MAPE:  0.21681671591917598\n",
      "Delta:  0.06550418206282552\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.0321089184414467 0.024334624869229216 nan\n",
      "Epoch: 51\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 2.557902408537986\n",
      "MAPE:  0.21197219774168466\n",
      "Delta:  0.06340091362339657\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.016206896899783274 0.02417098600124623 nan\n",
      "Epoch: 52\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 2.496075385228661\n",
      "MAPE:  0.2078818536292705\n",
      "Delta:  0.06237338155295013\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.029563133461687152 0.02397291766569032 nan\n",
      "Epoch: 53\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 2.4362371755312178\n",
      "MAPE:  0.20362387563195491\n",
      "Delta:  0.06052942894964353\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.019664841947198197 0.023860194539514823 nan\n",
      "Epoch: 54\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 2.378108082578645\n",
      "MAPE:  0.19968779786094137\n",
      "Delta:  0.05933912729619462\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.02687276830169083 0.02369867668810599 nan\n",
      "Epoch: 55\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 2.3217500680002416\n",
      "MAPE:  0.19589312610468884\n",
      "Delta:  0.05774452067713944\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.021648386025722943 0.023576790559342697 nan\n",
      "Epoch: 56\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 2.2670106529158605\n",
      "MAPE:  0.19228757032008956\n",
      "Delta:  0.05649444500265039\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.025353621880351618 0.023472867678782983 nan\n",
      "Epoch: 57\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 2.213797411833575\n",
      "MAPE:  0.18876670206228907\n",
      "Delta:  0.05506210620571288\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.022944272963208112 0.02338690465269322 -inf\n",
      "Delta imp changed to 0.04642997054598745\n",
      "Epoch: 58\n",
      "Arb loss 6.626363111507684e-07\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 2.162023542842644\n",
      "MAPE:  0.18552551076909557\n",
      "Delta:  0.052486581669268145\n",
      "GRAD\n",
      " tensor([-0.0726, -0.0310, -0.0132,  0.0509])\n",
      "0.02438519405589057 0.02334238328195104 -74693.57119791047\n",
      "Epoch: 59\n",
      "Arb loss 0.04949533512157182\n",
      "Real arb loss 4.9234721718831084e-05\n",
      "Bounds loss: 2.1115567606410095\n",
      "MAPE:  0.1823904085849234\n",
      "Delta:  0.051206686189932696\n",
      "GRAD\n",
      " tensor([-375.9468,   14.0529,   59.0794,  631.1269])\n",
      "-0.33221894967735843 -0.28939915882418554 1.0\n",
      "Epoch: 60\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 2.7226395109800396\n",
      "MAPE:  0.20814462668257888\n",
      "Delta:  0.06821851769241023\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.3271426276082885 0.08775714955687364 -inf\n",
      "Epoch: 61\n",
      "Arb loss 0.21422090996563328\n",
      "Real arb loss 0.00021102254160992805\n",
      "Bounds loss: 2.4837084282255106\n",
      "MAPE:  0.19819716561931616\n",
      "Delta:  0.04590133256297263\n",
      "GRAD\n",
      " tensor([-490.7664,   31.1813,   80.9679,  866.8211])\n",
      "-0.8851217411030019 -0.6263077855459727 1.0\n",
      "Epoch: 62\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 4.039274353849299\n",
      "MAPE:  0.25100396862256974\n",
      "Delta:  0.08652959996005888\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.5965724678118354 0.04294846429710597 -inf\n",
      "Epoch: 63\n",
      "Arb loss 0.342978283952975\n",
      "Real arb loss 0.0003347395951268601\n",
      "Bounds loss: 3.8657937234767865\n",
      "MAPE:  0.241580778645802\n",
      "Delta:  0.034908422973115666\n",
      "GRAD\n",
      " tensor([-328.6496,   83.5986,   94.2392,  975.5695])\n",
      "-1.7666742915727198 -0.22183717074475595 1.0\n",
      "Epoch: 64\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 4.723370465775712\n",
      "MAPE:  0.275125539548852\n",
      "Delta:  0.09658023639906566\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.6782416769374351 -0.08605655754784247 nan\n",
      "Epoch: 65\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 5.129847468083519\n",
      "MAPE:  0.2869904078426938\n",
      "Delta:  0.031075494904749458\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "-1.0457661477766074 0.47279128504543877 nan\n",
      "Epoch: 66\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 2.704500291561222\n",
      "MAPE:  0.21680481723785935\n",
      "Delta:  0.06357319550154089\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "-0.05357058735927178 0.016645774349985376 nan\n",
      "Epoch: 67\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 2.6594817899784244\n",
      "MAPE:  0.21590047443636443\n",
      "Delta:  0.06697884892486426\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.07023335829313859 0.016550729315646717 nan\n",
      "Epoch: 68\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 2.6154654267526\n",
      "MAPE:  0.21105616064333607\n",
      "Delta:  0.06227469943026226\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "-0.042912140520728004 0.017500711369099364 nan\n",
      "Epoch: 69\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 2.5696929212231443\n",
      "MAPE:  0.20957467709510663\n",
      "Delta:  0.06494704008309977\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.059909439997485214 0.017401652705698045 nan\n",
      "Epoch: 70\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 2.5249760174477287\n",
      "MAPE:  0.2055061576663899\n",
      "Delta:  0.061056099282227036\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "-0.026931840408571217 0.017950799966388042 nan\n",
      "Epoch: 71\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 2.479650678038597\n",
      "MAPE:  0.20333993304247558\n",
      "Delta:  0.06270045240406585\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.0402690955267101 0.01571404356935957 nan\n",
      "Epoch: 72\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 2.440685339247107\n",
      "MAPE:  0.20046195462451166\n",
      "Delta:  0.060175561896638585\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "-0.00208150906712512 0.015485807384195693 nan\n",
      "Epoch: 73\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 2.402889356198096\n",
      "MAPE:  0.1982178155210172\n",
      "Delta:  0.06030081787434578\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.02087616691750538 0.015449006570982804 nan\n",
      "Epoch: 74\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 2.365767102744847\n",
      "MAPE:  0.19567455375836107\n",
      "Delta:  0.05904196793513885\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.010353712006489935 0.015626332862708647 nan\n",
      "Epoch: 75\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 2.32879883852171\n",
      "MAPE:  0.19331361437936082\n",
      "Delta:  0.05843066440284201\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.01582555380750328 0.015794312364739604 nan\n",
      "Epoch: 76\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 2.2920170622314555\n",
      "MAPE:  0.19090545269072168\n",
      "Delta:  0.057505966779326664\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.013978874113990791 0.01597284759499773 nan\n",
      "Epoch: 77\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 2.255407023011298\n",
      "MAPE:  0.18851171785498413\n",
      "Delta:  0.056702098108915126\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.01571791550464119 0.016069090937257835 nan\n",
      "Epoch: 78\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 2.2191646824579996\n",
      "MAPE:  0.1862357597492778\n",
      "Delta:  0.05581085932190332\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.015287393419074147 0.01614322654261502 nan\n",
      "Delta imp changed to 0.04529753223998776\n",
      "Epoch: 79\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 2.18334020425371\n",
      "MAPE:  0.18410302237060852\n",
      "Delta:  0.053617226105749066\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.01580787154990848 0.016208787377552936 nan\n",
      "Epoch: 80\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 2.1479509071100984\n",
      "MAPE:  0.18196453944465402\n",
      "Delta:  0.05276965188260698\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.01604003358368622 0.01628032991315531 nan\n",
      "Epoch: 81\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 2.112981557705085\n",
      "MAPE:  0.17981715605050666\n",
      "Delta:  0.051923224894210536\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.016238041673846126 0.016342971099339465 nan\n",
      "Epoch: 82\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 2.078449161174073\n",
      "MAPE:  0.17771851894193735\n",
      "Delta:  0.05108009340453786\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.016421354309947178 0.016398288595149024 nan\n",
      "Epoch: 83\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 2.0443661519987955\n",
      "MAPE:  0.17564207686944547\n",
      "Delta:  0.05024128909255675\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.016613631349588487 0.016454291102408036 nan\n",
      "Epoch: 84\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 2.0107275562138973\n",
      "MAPE:  0.17356362159045485\n",
      "Delta:  0.04940659883704491\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.01683115433944049 0.016508324933525276 nan\n",
      "Epoch: 85\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.9775338123631252\n",
      "MAPE:  0.17156854266073093\n",
      "Delta:  0.04857502874663178\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.01683803388845373 0.016557905796087846 nan\n",
      "Epoch: 86\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.9447899937894382\n",
      "MAPE:  0.16970361932105474\n",
      "Delta:  0.047757120766463386\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.01674133720205695 0.0166510453973302 nan\n",
      "Epoch: 87\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.9124072073145766\n",
      "MAPE:  0.16788052661149266\n",
      "Delta:  0.046957602703912665\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.016877023563052873 0.016752252934914447 -inf\n",
      "Epoch: 88\n",
      "Arb loss 0.004319669045208199\n",
      "Real arb loss 4.314234253272001e-06\n",
      "Bounds loss: 1.8803700780630894\n",
      "MAPE:  0.16605330205191338\n",
      "Delta:  0.04616509813661425\n",
      "GRAD\n",
      " tensor([-167.0697,    6.1183,   29.0714,  289.3267])\n",
      "-0.10578440379326337 -0.055233940417765304 1.0\n",
      "Epoch: 89\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.984230326918175\n",
      "MAPE:  0.17114289775680397\n",
      "Delta:  0.05104864551905348\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.09917946411338463 0.03506057891044301 nan\n",
      "Delta imp changed to 0.04419271438047587\n",
      "Epoch: 90\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.9146620629647662\n",
      "MAPE:  0.16903438448516786\n",
      "Delta:  0.044864066549033785\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "-0.007112178579850248 0.018970928023654077 nan\n",
      "Epoch: 91\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.8783391467786406\n",
      "MAPE:  0.1666361195155725\n",
      "Delta:  0.0451831478021488\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.020686625950582904 0.017133262930713378 -inf\n",
      "Epoch: 92\n",
      "Arb loss 0.006595319573028188\n",
      "Real arb loss 6.592397664404163e-06\n",
      "Bounds loss: 1.8461570683038304\n",
      "MAPE:  0.16477017739993624\n",
      "Delta:  0.044248460924295845\n",
      "GRAD\n",
      " tensor([-167.1582,    6.0490,   28.0281,  291.1230])\n",
      "-0.10781275989961303 -0.057435101861467164 1.0\n",
      "Epoch: 93\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.9521912875741287\n",
      "MAPE:  0.17026798939360502\n",
      "Delta:  0.04901900961785436\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.09943121437008173 0.03610917200739938 nan\n",
      "Epoch: 94\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.881699276579768\n",
      "MAPE:  0.16783265769157243\n",
      "Delta:  0.04414498996433239\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "-0.005961465536620247 0.019272006570206 nan\n",
      "Epoch: 95\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.8454351557583708\n",
      "MAPE:  0.16542523230437284\n",
      "Delta:  0.04440815880061919\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.020136418787699006 0.017448797824150653 -inf\n",
      "Epoch: 96\n",
      "Arb loss 0.007193421775278649\n",
      "Real arb loss 7.192755950183414e-06\n",
      "Bounds loss: 1.813234530827963\n",
      "MAPE:  0.16350446289858125\n",
      "Delta:  0.04351393751741929\n",
      "GRAD\n",
      " tensor([-167.1216,    6.0202,   27.9966,  292.7937])\n",
      "-0.10809256413570512 -0.05898367898702772 1.0\n",
      "Epoch: 97\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.9201857743225135\n",
      "MAPE:  0.16930141538757817\n",
      "Delta:  0.048217470599318\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.09856041508944069 0.03664374010679161 nan\n",
      "Epoch: 98\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.849822985851481\n",
      "MAPE:  0.1666375965884047\n",
      "Delta:  0.04346513668248631\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "-0.004624228544207742 0.01948501012665338 nan\n",
      "Epoch: 99\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.8137791662396485\n",
      "MAPE:  0.16419953651402475\n",
      "Delta:  0.04366612940821136\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.019614398890492102 0.017726508320678125 -inf\n",
      "Epoch: 100\n",
      "Arb loss 0.007376710224091387\n",
      "Real arb loss 7.378274679417852e-06\n",
      "Bounds loss: 1.7816271947574287\n",
      "MAPE:  0.1622148406139344\n",
      "Delta:  0.04280964452799485\n",
      "GRAD\n",
      " tensor([-166.9270,    6.2181,   28.1308,  291.2300])\n",
      "-0.10710387418060163 -0.05946745697458922 1.0\n",
      "Epoch: 101\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.8875760333064244\n",
      "MAPE:  0.16816078116141403\n",
      "Delta:  0.047394723309237496\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.09691669568789296 0.03683198204390736 nan\n",
      "Epoch: 102\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.8180528667411722\n",
      "MAPE:  0.1653332302711929\n",
      "Delta:  0.042801383333064234\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "-0.0031142530763534904 0.019618784247978915 nan\n",
      "Delta imp changed to 0.04311484329802524\n",
      "Epoch: 103\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.7823848797971575\n",
      "MAPE:  0.16289559823709704\n",
      "Delta:  0.04188749041246968\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.01912685961591165 0.0179788319470795 -inf\n",
      "Epoch: 104\n",
      "Arb loss 0.009861089759020444\n",
      "Real arb loss 9.865467625178593e-06\n",
      "Bounds loss: 1.750339681578269\n",
      "MAPE:  0.16088080615667952\n",
      "Delta:  0.04108631426368753\n",
      "GRAD\n",
      " tensor([-166.9529,    6.1374,   28.0662,  293.0107])\n",
      "-0.10739647823796439 -0.060893926470431126 1.0\n",
      "Epoch: 105\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.856924737446574\n",
      "MAPE:  0.167000263893671\n",
      "Delta:  0.045498839719385814\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.09593318382890914 0.03728166119531939 nan\n",
      "Epoch: 106\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.7876954985198834\n",
      "MAPE:  0.1640238888487541\n",
      "Delta:  0.041133991164583904\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "-0.0018994002093064566 0.019761712157897682 nan\n",
      "Epoch: 107\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.752367574652164\n",
      "MAPE:  0.1615876164743917\n",
      "Delta:  0.04121212107601152\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.018720781416934895 0.018217181832281493 -inf\n",
      "Epoch: 108\n",
      "Arb loss 0.012662932280896743\n",
      "Real arb loss 1.2669963145409046e-05\n",
      "Bounds loss: 1.7204443759077315\n",
      "MAPE:  0.1595473177134023\n",
      "Delta:  0.04044059796561925\n",
      "GRAD\n",
      " tensor([-182.7332,    7.3618,   29.1565,  321.9519])\n",
      "-0.11932681416542512 -0.07180317210686638 1.0\n",
      "Epoch: 109\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.8439777395313248\n",
      "MAPE:  0.1667604112636506\n",
      "Delta:  0.04526624568380137\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.1023404328676133 0.04106291397429518 nan\n",
      "Epoch: 110\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.7682586402424345\n",
      "MAPE:  0.1634017818042883\n",
      "Delta:  0.040633678506229405\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "-0.0035428629764282515 0.02033955297087764 nan\n",
      "Epoch: 111\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.7322930499630116\n",
      "MAPE:  0.16084966859543265\n",
      "Delta:  0.04077763806140521\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.01883333538340448 0.018470838086432684 -inf\n",
      "Epoch: 112\n",
      "Arb loss 0.003808775052098291\n",
      "Real arb loss 3.8116483573021956e-06\n",
      "Bounds loss: 1.700296145518892\n",
      "MAPE:  0.1587935785953801\n",
      "Delta:  0.04000965912765169\n",
      "GRAD\n",
      " tensor([-119.1678,    4.6380,   19.8621,  210.6423])\n",
      "-0.07029727434749922 -0.034664976103896405 1.0\n",
      "Epoch: 113\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.7592368707728516\n",
      "MAPE:  0.16252935142032884\n",
      "Delta:  0.04282222911189814\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.07072517907690168 0.028416273755674237 -inf\n",
      "Epoch: 114\n",
      "Arb loss 3.2990176080448474e-06\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.7092459142518945\n",
      "MAPE:  0.1598902684878144\n",
      "Delta:  0.039793619289487034\n",
      "GRAD\n",
      " tensor([-0.1503, -0.0646, -0.0278,  0.1140])\n",
      "0.00734163747164307 0.019082586604298957 -2681.666300251535\n",
      "Delta imp changed to 0.04206326175417097\n",
      "Epoch: 115\n",
      "Arb loss 0.00885016336103834\n",
      "Real arb loss 8.859920504733131e-06\n",
      "Bounds loss: 1.6766290810651385\n",
      "MAPE:  0.15761945445156927\n",
      "Delta:  0.038538018500467355\n",
      "GRAD\n",
      " tensor([-150.8767,    6.0423,   25.0323,  268.1021])\n",
      "-0.09502955647331546 -0.05379243461324745 1.0\n",
      "Epoch: 116\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.7668190412790041\n",
      "MAPE:  0.1632899993993989\n",
      "Delta:  0.0422002693059272\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.08512487812816671 0.03449260401034304 nan\n",
      "Epoch: 117\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.7058768517302334\n",
      "MAPE:  0.16011163629845335\n",
      "Delta:  0.03860797652428433\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.003650747696630985 0.019751939382303463 -inf\n",
      "Epoch: 118\n",
      "Arb loss 9.283357031617617e-07\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6721824755611832\n",
      "MAPE:  0.15777435345026095\n",
      "Delta:  0.03846702854291672\n",
      "GRAD\n",
      " tensor([-0.0695, -0.0300, -0.0130,  0.0530])\n",
      "0.0181295916981149 0.01875517758229739 -29490.924113407335\n",
      "Epoch: 119\n",
      "Arb loss 0.027378406109413313\n",
      "Real arb loss 2.7365965004063728e-05\n",
      "Bounds loss: 1.6408203962820274\n",
      "MAPE:  0.15566478442526344\n",
      "Delta:  0.03776963702159391\n",
      "GRAD\n",
      " tensor([-214.2508,    6.9277,   33.4295,  375.4747])\n",
      "-0.14459181325494885 -0.09616784864072847 1.0\n",
      "Epoch: 120\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.7986145637982975\n",
      "MAPE:  0.1653259197348642\n",
      "Delta:  0.04323081732452742\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.11370006580686365 0.05005518689120492 nan\n",
      "Epoch: 121\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.7085845756621307\n",
      "MAPE:  0.16103639416175242\n",
      "Delta:  0.03831547054984415\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "-0.005058228947865562 0.02143871352973703 nan\n",
      "Epoch: 122\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.671954720403183\n",
      "MAPE:  0.15844404070083118\n",
      "Delta:  0.03850927897213046\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.018727167809263645 0.019074246562027275 -inf\n",
      "Epoch: 123\n",
      "Arb loss 3.6173885114019894e-06\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6400634438256674\n",
      "MAPE:  0.15617461167356592\n",
      "Delta:  0.03778810924260562\n",
      "GRAD\n",
      " tensor([-0.1424, -0.0614, -0.0264,  0.1081])\n",
      "0.01770655670170629 0.018918344565098555 -9183.442001009775\n",
      "Epoch: 124\n",
      "Arb loss 0.033223694978090655\n",
      "Real arb loss 3.320182078188013e-05\n",
      "Bounds loss: 1.6090361584867514\n",
      "MAPE:  0.1540189429754045\n",
      "Delta:  0.03711901194365115\n",
      "GRAD\n",
      " tensor([-229.9708,    8.1820,   36.5341,  405.6332])\n",
      "-0.15828011344582604 -0.10994414089176763 1.0\n",
      "Epoch: 125\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.7859402565953673\n",
      "MAPE:  0.16499632264048053\n",
      "Delta:  0.04299421336508923\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.11973156046458666 0.05483155416981367 nan\n",
      "Delta imp changed to 0.04103732854065461\n",
      "Epoch: 126\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6880143766718074\n",
      "MAPE:  0.16028259527055838\n",
      "Delta:  0.036923364983355814\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "-0.006574163868598326 0.022024354258922574 nan\n",
      "Epoch: 127\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6508369500458333\n",
      "MAPE:  0.15761075924372198\n",
      "Delta:  0.037166105235336463\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.018729098004777067 0.019280135479307292 -inf\n",
      "Epoch: 128\n",
      "Arb loss 4.1032908527784654e-09\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6190085899947033\n",
      "MAPE:  0.15533031986257043\n",
      "Delta:  0.036470017607927986\n",
      "GRAD\n",
      " tensor([-0.0023, -0.0010, -0.0004,  0.0018])\n",
      "0.0177616897020767 0.019135412401415364 -4683925.448867765\n",
      "Epoch: 129\n",
      "Arb loss 0.01921951255272622\n",
      "Real arb loss 1.9232727790306785e-05\n",
      "Bounds loss: 1.5880281929437208\n",
      "MAPE:  0.1531177142966206\n",
      "Delta:  0.0358222484717467\n",
      "GRAD\n",
      " tensor([-182.3301,    5.6411,   29.3222,  322.8818])\n",
      "-0.12005203436239853 -0.07617838723027259 1.0\n",
      "Epoch: 130\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.7090016195583777\n",
      "MAPE:  0.16117683035365354\n",
      "Delta:  0.040122782276215206\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.09503245748938183 0.04165026916932679 nan\n",
      "Epoch: 131\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6378212420929559\n",
      "MAPE:  0.1572387396351463\n",
      "Delta:  0.03630981567519506\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.0026609010999774085 0.02056350756499814 nan\n",
      "Epoch: 132\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6041418925910627\n",
      "MAPE:  0.1548065730573829\n",
      "Delta:  0.03621319884672496\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.018070576814604 0.019303376275036643 -inf\n",
      "Epoch: 133\n",
      "Arb loss 0.011349525606824517\n",
      "Real arb loss 1.1370432449873333e-05\n",
      "Bounds loss: 1.573176538039828\n",
      "MAPE:  0.15254189133990495\n",
      "Delta:  0.03555880545526269\n",
      "GRAD\n",
      " tensor([-150.6669,    5.1738,   25.1067,  270.1443])\n",
      "-0.09639995167199666 -0.057092167704261065 1.0\n",
      "Epoch: 134\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6629925967780068\n",
      "MAPE:  0.15880239515184824\n",
      "Delta:  0.038986672582663945\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.08062605483753948 0.035010590452382306 nan\n",
      "Epoch: 135\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6047702440468683\n",
      "MAPE:  0.1552966873990554\n",
      "Delta:  0.03584333098108088\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.007253539636327022 0.020074991472595838 -inf\n",
      "Epoch: 136\n",
      "Arb loss 2.0216812690855624e-06\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.572554495082152\n",
      "MAPE:  0.15294358351316864\n",
      "Delta:  0.03558333995911162\n",
      "GRAD\n",
      " tensor([-0.0888, -0.0382, -0.0165,  0.0680])\n",
      "0.017723528291907487 0.019316942973207296 -14495.606455713001\n",
      "Epoch: 137\n",
      "Arb loss 0.02930751773681981\n",
      "Real arb loss 2.931516587234649e-05\n",
      "Bounds loss: 1.5421775495783892\n",
      "MAPE:  0.15070728163194033\n",
      "Delta:  0.034952677626625746\n",
      "GRAD\n",
      " tensor([-213.7858,    7.2228,   33.5973,  377.5700])\n",
      "-0.1454743794838287 -0.1003201298826264 1.0\n",
      "Epoch: 138\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6968890016541636\n",
      "MAPE:  0.1610168452905127\n",
      "Delta:  0.040037396715657425\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.10790470930880403 0.05034273420202984 nan\n",
      "Epoch: 139\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6114629696735403\n",
      "MAPE:  0.15633076871142138\n",
      "Delta:  0.03571717306157315\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "-0.00044468806162578645 0.021442975759571437 nan\n",
      "Delta imp changed to 0.04003641808844353\n",
      "Epoch: 140\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5769084082773837\n",
      "MAPE:  0.15375691983833528\n",
      "Delta:  0.03486151810929625\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.018180275476162078 0.019616259551896942 -inf\n",
      "Epoch: 141\n",
      "Arb loss 0.00017422882118302171\n",
      "Real arb loss 1.7106208017607372e-07\n",
      "Bounds loss: 1.5459753636510458\n",
      "MAPE:  0.15147872943515775\n",
      "Delta:  0.03422772610655203\n",
      "GRAD\n",
      " tensor([-23.8998,   0.6686,   5.5340,  45.6138])\n",
      "-0.001461112038606105 0.008674119544788805 0.9923696122576758\n",
      "Epoch: 142\n",
      "Arb loss 1.3294334615145256e-06\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5325653885334383\n",
      "MAPE:  0.15045711397956513\n",
      "Delta:  0.034277736649220424\n",
      "GRAD\n",
      " tensor([-0.0645, -0.0278, -0.0120,  0.0495])\n",
      "0.026784296161623367 0.019749728292158597 -35648.78021785284\n",
      "Epoch: 143\n",
      "Arb loss 0.04739401071725217\n",
      "Real arb loss 4.7329684180153755e-05\n",
      "Bounds loss: 1.5022976385199365\n",
      "MAPE:  0.1483249357393297\n",
      "Delta:  0.03335963159905757\n",
      "GRAD\n",
      " tensor([-229.4215,    6.6095,   35.7999,  404.8107])\n",
      "-0.15797720453638409 -0.11336766182100178 1.0\n",
      "Epoch: 144\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6726096091581544\n",
      "MAPE:  0.15984994605578642\n",
      "Delta:  0.03862969294344031\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.11215069512756204 0.05457186372176459 nan\n",
      "Epoch: 145\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5813321855074616\n",
      "MAPE:  0.15475464969126676\n",
      "Delta:  0.0342973460272692\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "-0.0005616245631321348 0.02168060485469714 nan\n",
      "Epoch: 146\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5470479472494598\n",
      "MAPE:  0.15217835294832843\n",
      "Delta:  0.03431660825924836\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.018020262605319748 0.01976322102013084 -inf\n",
      "Epoch: 147\n",
      "Arb loss 0.0006706637734197029\n",
      "Real arb loss 6.699765499093222e-07\n",
      "Bounds loss: 1.5164732967392291\n",
      "MAPE:  0.14990132860151387\n",
      "Delta:  0.033698213966692814\n",
      "GRAD\n",
      " tensor([-39.6951,   1.8958,   6.6300,  71.6422])\n",
      "-0.011609174623345986 0.0023611530092607635 1.0\n",
      "Epoch: 148\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5128926712511697\n",
      "MAPE:  0.1495311645315712\n",
      "Delta:  0.03408942241712703\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.03142393963550616 0.02050945267192028 -inf\n",
      "Epoch: 149\n",
      "Arb loss 0.033959739687065005\n",
      "Real arb loss 3.396959135762038e-05\n",
      "Bounds loss: 1.4818640706124488\n",
      "MAPE:  0.14739203676415097\n",
      "Delta:  0.03301819846488196\n",
      "GRAD\n",
      " tensor([-213.4392,    6.4935,   32.7657,  376.6408])\n",
      "-0.14508016606291085 -0.10209004014227863 1.0\n",
      "Epoch: 150\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6331476330666739\n",
      "MAPE:  0.15804244890203484\n",
      "Delta:  0.03780848418126518\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.10389055801220237 0.05012633097361219 nan\n",
      "Epoch: 151\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5512839342828026\n",
      "MAPE:  0.15307547114473455\n",
      "Delta:  0.03388053966207801\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.002557988107139253 0.021350375038342584 nan\n",
      "Epoch: 152\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5181634404949091\n",
      "MAPE:  0.15055640400169912\n",
      "Delta:  0.03379387364455896\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.01782329780347025 0.019864581502847423 -inf\n",
      "Epoch: 153\n",
      "Arb loss 0.0016187926476909018\n",
      "Real arb loss 1.6225338128553408e-06\n",
      "Bounds loss: 1.4880057590965547\n",
      "MAPE:  0.14828725669783674\n",
      "Delta:  0.03319155537065914\n",
      "GRAD\n",
      " tensor([-55.5199,   2.0962,   9.7083, 101.8746])\n",
      "-0.024379125533791957 -0.005938159349004213 1.0\n",
      "Delta imp changed to 0.03905992008628637\n",
      "Epoch: 154\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.496841774406306\n",
      "MAPE:  0.14889896993410126\n",
      "Delta:  0.03317145021044122\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.037467840443231704 0.02171820451297568 -inf\n",
      "Epoch: 155\n",
      "Arb loss 0.017719843941337615\n",
      "Real arb loss 1.7757495194695067e-05\n",
      "Bounds loss: 1.4643330586261845\n",
      "MAPE:  0.1466346168269236\n",
      "Delta:  0.03192858760668581\n",
      "GRAD\n",
      " tensor([-150.3159,    5.5274,   23.3457,  269.0717])\n",
      "-0.09652307790331971 -0.05948919556208021 1.0\n",
      "Epoch: 156\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5514450543188165\n",
      "MAPE:  0.15313669603934046\n",
      "Delta:  0.03501043315558891\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.07580419426822282 0.035227915190065406 nan\n",
      "Epoch: 157\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.4967908795232268\n",
      "MAPE:  0.14943544357438937\n",
      "Delta:  0.032356495479248015\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.010881802157708176 0.020243028957380838 -inf\n",
      "Epoch: 158\n",
      "Arb loss 0.0013637458809292772\n",
      "Real arb loss 1.3670531981683845e-06\n",
      "Bounds loss: 1.4664912984058946\n",
      "MAPE:  0.14711935045134072\n",
      "Delta:  0.03200439849692606\n",
      "GRAD\n",
      " tensor([-55.4174,   2.1960,   9.7751, 101.5674])\n",
      "-0.024518685561732534 -0.0060700918242759805 1.0\n",
      "Epoch: 159\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.47539303524672\n",
      "MAPE:  0.14780533643874436\n",
      "Delta:  0.03278910428026458\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.03682355888495159 0.021786527882576845 -inf\n",
      "Epoch: 160\n",
      "Arb loss 0.017463003472754774\n",
      "Real arb loss 1.7505676313018944e-05\n",
      "Bounds loss: 1.4432493437465577\n",
      "MAPE:  0.14546818668277758\n",
      "Delta:  0.03158169276801544\n",
      "GRAD\n",
      " tensor([-150.2562,    5.5578,   23.3608,  269.3368])\n",
      "-0.09629490624363046 -0.060200037873166634 1.0\n",
      "Epoch: 161\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5301330089005232\n",
      "MAPE:  0.15206081744325392\n",
      "Delta:  0.03462284891212663\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.07493696567412234 0.03525883779669581 nan\n",
      "Epoch: 162\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.4761822973323295\n",
      "MAPE:  0.14834186386805198\n",
      "Delta:  0.03202831767165827\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.011507667293738644 0.02031406930410995 -inf\n",
      "Epoch: 163\n",
      "Arb loss 0.0013627723847449253\n",
      "Real arb loss 1.3665178306305483e-06\n",
      "Bounds loss: 1.4461950278388205\n",
      "MAPE:  0.14599599801794674\n",
      "Delta:  0.03165974644791465\n",
      "GRAD\n",
      " tensor([-55.4070,   2.2037,   9.7799, 101.6841])\n",
      "-0.024645825064330884 -0.006300133570444011 1.0\n",
      "Epoch: 164\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.4553062496831168\n",
      "MAPE:  0.14675650451586703\n",
      "Delta:  0.03244002702045103\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.036278342672197206 0.021850000923050783 -inf\n",
      "Epoch: 165\n",
      "Arb loss 0.013933944222665178\n",
      "Real arb loss 1.3975637207037629e-05\n",
      "Bounds loss: 1.423507806784219\n",
      "MAPE:  0.144350824909436\n",
      "Delta:  0.03126315660390778\n",
      "GRAD\n",
      " tensor([-134.2544,    4.5003,   20.3727,  239.9498])\n",
      "-0.08316263675584001 -0.05017721700962818 1.0\n",
      "Epoch: 166\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.494935466920131\n",
      "MAPE:  0.14993683655407433\n",
      "Delta:  0.0338630831403995\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.06721094745975142 0.032075886219786076 -inf\n",
      "Epoch: 167\n",
      "Arb loss 3.639296748634494e-09\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.4469840869772779\n",
      "MAPE:  0.14652593651017246\n",
      "Delta:  0.03158711323862491\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.013530862230515583 0.020178594822567786 -2238609.256477173\n",
      "Epoch: 168\n",
      "Arb loss 0.008146967027857206\n",
      "Real arb loss 8.176784951846616e-06\n",
      "Bounds loss: 1.4177859813714602\n",
      "MAPE:  0.14419637392863033\n",
      "Delta:  0.031159712361133383\n",
      "GRAD\n",
      " tensor([-102.8046,    2.9262,   16.1046,  185.7073])\n",
      "-0.06030811616314513 -0.03192725165582044 1.0\n",
      "Epoch: 169\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.4630519911928013\n",
      "MAPE:  0.14784041235683248\n",
      "Delta:  0.033038895913818804\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.053838061457485265 0.02686444163383972 -inf\n",
      "Epoch: 170\n",
      "Arb loss 0.00017525022513703437\n",
      "Real arb loss 1.742199592297683e-07\n",
      "Bounds loss: 1.4237479163681293\n",
      "MAPE:  0.14493518057485233\n",
      "Delta:  0.031260145805123166\n",
      "GRAD\n",
      " tensor([-7.9751,  0.5735,  1.5278, 15.1988])\n",
      "0.009496441965209157 0.01625903423734476 -55.6305208006829\n",
      "Delta imp changed to 0.038107239108572076\n",
      "Epoch: 171\n",
      "Arb loss 0.009924511519947186\n",
      "Real arb loss 9.959468362579403e-06\n",
      "Bounds loss: 1.4005991502505515\n",
      "MAPE:  0.14307310222673209\n",
      "Delta:  0.030208083555766676\n",
      "GRAD\n",
      " tensor([-118.4302,    4.2396,   19.2430,  211.3337])\n",
      "-0.06771982992014225 -0.040650608753683315 1.0\n",
      "Epoch: 172\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.457534358328128\n",
      "MAPE:  0.14765700601135942\n",
      "Delta:  0.03225376983637664\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.05892864041464407 0.02894962037655835 -inf\n",
      "arb imp changed to 990.842349139851\n",
      "Epoch: 173\n",
      "Arb loss 1.1915499650149891e-06\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.4153392919687382\n",
      "MAPE:  0.1445589677308569\n",
      "Delta:  0.03035309903167211\n",
      "GRAD\n",
      " tensor([-0.0431, -0.0185, -0.0079,  0.0332])\n",
      "0.015403686799225214 0.020071509139179544 -13877.685170341916\n",
      "Epoch: 174\n",
      "Arb loss 0.016537146829174957\n",
      "Real arb loss 1.657671404073137e-05\n",
      "Bounds loss: 1.3869312964349476\n",
      "MAPE:  0.14225012613939444\n",
      "Delta:  0.029885549400802368\n",
      "GRAD\n",
      " tensor([-134.1537,    4.6666,   20.4965,  238.6737])\n",
      "-0.08360364492790473 -0.05062531246643065 1.0\n",
      "Epoch: 175\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.4571451266864386\n",
      "MAPE:  0.1478560935719606\n",
      "Delta:  0.032384090261382406\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.06532885528193422 0.0318466762264602 -inf\n",
      "Epoch: 176\n",
      "Arb loss 1.5043137173851456e-08\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.4107398976218912\n",
      "MAPE:  0.1444885548720967\n",
      "Delta:  0.03026847471525946\n",
      "GRAD\n",
      " tensor([-2.0681e-04, -8.8667e-05, -3.8015e-05,  1.6084e-04])\n",
      "0.014453855208144906 0.02023363823978619 -574797.6443211908\n",
      "Epoch: 177\n",
      "Arb loss 0.008646774853867525\n",
      "Real arb loss 8.674762857642987e-06\n",
      "Bounds loss: 1.3821954968829768\n",
      "MAPE:  0.14214781947963942\n",
      "Delta:  0.029830978564353704\n",
      "GRAD\n",
      " tensor([-102.6814,    3.0799,   15.2136,  184.3514])\n",
      "-0.060114027673582315 -0.03222155773613555 1.0\n",
      "Epoch: 178\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.4267319888884185\n",
      "MAPE:  0.14573902357443655\n",
      "Delta:  0.031624238835301306\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.05307911035928259 0.027033175722079972 -inf\n",
      "Epoch: 179\n",
      "Arb loss 0.00037763474944813686\n",
      "Real arb loss 3.7718332305731324e-07\n",
      "Bounds loss: 1.388162892324485\n",
      "MAPE:  0.14285452607187876\n",
      "Delta:  0.02994565237213403\n",
      "GRAD\n",
      " tensor([-23.7812,   0.7970,   5.6225,  45.4638])\n",
      "-0.0025729827019231877 0.008315596641838341 0.9967063852286127\n",
      "Epoch: 180\n",
      "Arb loss 1.2437833889715323e-06\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.3766194896387471\n",
      "MAPE:  0.14195311438583724\n",
      "Delta:  0.03002270201768534\n",
      "GRAD\n",
      " tensor([-0.0433, -0.0186, -0.0080,  0.0333])\n",
      "0.025544731813546884 0.020282380497039454 -29679.897885429564\n",
      "Epoch: 181\n",
      "Arb loss 0.03691660775965757\n",
      "Real arb loss 3.692895310359683e-05\n",
      "Bounds loss: 1.3486983693502537\n",
      "MAPE:  0.13966694851458994\n",
      "Delta:  0.029255780146325534\n",
      "GRAD\n",
      " tensor([-181.2398,    5.6143,   27.9559,  320.9280])\n",
      "-0.12122416262751767 -0.08443831620164799 1.0\n",
      "Epoch: 182\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.4625801887220975\n",
      "MAPE:  0.14882788100651978\n",
      "Delta:  0.032802287596578605\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.08326499604057669 0.04211009975650959 nan\n",
      "Epoch: 183\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.4009907910731152\n",
      "MAPE:  0.1443731461725964\n",
      "Delta:  0.030071005249727632\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.011685870376002994 0.020684964169405906 -inf\n",
      "Epoch: 184\n",
      "Arb loss 2.544334102075055e-05\n",
      "Real arb loss 2.4556049596981268e-08\n",
      "Bounds loss: 1.3720113467581\n",
      "MAPE:  0.1419676556390725\n",
      "Delta:  0.02971959938030321\n",
      "GRAD\n",
      " tensor([-0.0349, -0.0149, -0.0064,  0.0269])\n",
      "0.016556878700606292 0.0199970684372468 -775.8723097466894\n",
      "Delta imp changed to 0.037177794252265445\n",
      "Epoch: 185\n",
      "Arb loss 0.01976622710646317\n",
      "Real arb loss 1.9813294644116643e-05\n",
      "Bounds loss: 1.3445751419602994\n",
      "MAPE:  0.13966534911258277\n",
      "Delta:  0.028514668856910164\n",
      "GRAD\n",
      " tensor([-149.7388,    4.0670,   23.7018,  267.7017])\n",
      "-0.09665010281130715 -0.06295965343944077 1.0\n",
      "Epoch: 186\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.4292291269214066\n",
      "MAPE:  0.14668570423907565\n",
      "Delta:  0.03127061453356091\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.07022895930002071 0.03499455897743753 nan\n",
      "Epoch: 187\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.3792138839470838\n",
      "MAPE:  0.1428810496087602\n",
      "Delta:  0.029074511818196827\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.014194501574519736 0.020433447818271278 -inf\n",
      "Epoch: 188\n",
      "Arb loss 0.0017551276043638957\n",
      "Real arb loss 1.761940629662874e-06\n",
      "Bounds loss: 1.3510317890192158\n",
      "MAPE:  0.1404851892711941\n",
      "Delta:  0.02866181361441504\n",
      "GRAD\n",
      " tensor([-39.5387,   2.0842,   6.7629,  70.4647])\n",
      "-0.011739952981373536 0.001543628716897505 1.0\n",
      "Epoch: 189\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.3489462975522444\n",
      "MAPE:  0.14036948223498594\n",
      "Delta:  0.02899830195860916\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.029343808042645803 0.020850118005701135 -inf\n",
      "Epoch: 190\n",
      "Arb loss 0.02674386382449134\n",
      "Real arb loss 2.6786758471528203e-05\n",
      "Bounds loss: 1.3208206080649265\n",
      "MAPE:  0.1380434287566873\n",
      "Delta:  0.028147381352373053\n",
      "GRAD\n",
      " tensor([-149.5830,    4.2030,   23.7895,  266.2028])\n",
      "-0.09680982634866475 -0.06393041119078458 1.0\n",
      "Epoch: 191\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.4052612126477795\n",
      "MAPE:  0.14508267148617177\n",
      "Delta:  0.03087232445326593\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.0697987930675289 0.03526682049752772 nan\n",
      "Epoch: 192\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.3557021177091921\n",
      "MAPE:  0.14132534566582985\n",
      "Delta:  0.02871747346723881\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.014776742615162597 0.02035772213130771 -inf\n",
      "Epoch: 193\n",
      "Arb loss 0.005903420063408766\n",
      "Real arb loss 5.928645707305225e-06\n",
      "Bounds loss: 1.3281031107040429\n",
      "MAPE:  0.13895584590351454\n",
      "Delta:  0.028293122753255663\n",
      "GRAD\n",
      " tensor([-86.7146,   2.9917,  14.2053, 155.2943])\n",
      "-0.04766635482443493 -0.02405669856615278 1.0\n",
      "Epoch: 194\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.36005288690302\n",
      "MAPE:  0.14163872452602144\n",
      "Delta:  0.029641752781503643\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.044389478030526175 0.024751693983513956 -inf\n",
      "Epoch: 195\n",
      "Arb loss 0.0010348883322637817\n",
      "Real arb loss 1.0386634283740468e-06\n",
      "Bounds loss: 1.3263892740450016\n",
      "MAPE:  0.1390027090870388\n",
      "Delta:  0.028325970847622797\n",
      "GRAD\n",
      " tensor([-23.7086,   0.8697,   5.6715,  44.2282])\n",
      "-0.0003674103259039274 0.008249694274144459 -0.4860360379957074\n",
      "Delta imp changed to 0.036271018782698\n",
      "Epoch: 196\n",
      "Arb loss 0.0015378813570452554\n",
      "Real arb loss 1.5444311258979578e-06\n",
      "Bounds loss: 1.315446968045626\n",
      "MAPE:  0.13810822752678772\n",
      "Delta:  0.027645246928588756\n",
      "GRAD\n",
      " tensor([-39.4483,   2.1042,   6.7635,  70.3307])\n",
      "-0.003442173790219938 0.0015239348565406763 0.9836397488795657\n",
      "Epoch: 197\n",
      "Arb loss 2.516012519469467e-05\n",
      "Real arb loss 2.4164308938492974e-08\n",
      "Bounds loss: 1.3134423125590906\n",
      "MAPE:  0.13799758001117318\n",
      "Delta:  0.027740406672990502\n",
      "GRAD\n",
      " tensor([-0.0384, -0.0164, -0.0070,  0.0294])\n",
      "0.028998051999251984 0.02073611336471315 -1674.4174193320139\n",
      "Epoch: 198\n",
      "Arb loss 0.04215371202376573\n",
      "Real arb loss 4.217147304900587e-05\n",
      "Bounds loss: 1.2862066238678542\n",
      "MAPE:  0.13572313492769694\n",
      "Delta:  0.026935988917806724\n",
      "GRAD\n",
      " tensor([-180.7853,    5.9606,   27.1686,  319.6662])\n",
      "-0.11959373506067239 -0.08588651345941134 1.0\n",
      "Epoch: 199\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.3966744263802646\n",
      "MAPE:  0.14503394232190475\n",
      "Delta:  0.030157364440040108\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.07927659285403688 0.041430137960401625 nan\n",
      "Epoch: 200\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.3388100122095654\n",
      "MAPE:  0.14059823509842323\n",
      "Delta:  0.02776659133777624\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.013813715871067056 0.02064765879254893 -inf\n",
      "Epoch: 201\n",
      "Arb loss 0.0003595971903714982\n",
      "Real arb loss 3.600875711393045e-07\n",
      "Bounds loss: 1.3111667198894141\n",
      "MAPE:  0.13821231669180065\n",
      "Delta:  0.027383031534328167\n",
      "GRAD\n",
      " tensor([-7.9456,  0.6036,  1.5482, 15.1557])\n",
      "0.01042235025602467 0.01615622700939312 -24.905446409620996\n",
      "Epoch: 202\n",
      "Arb loss 0.009315525744219127\n",
      "Real arb loss 9.354186246590208e-06\n",
      "Bounds loss: 1.2899832127157194\n",
      "MAPE:  0.13636612852379237\n",
      "Delta:  0.027097635988605633\n",
      "GRAD\n",
      " tensor([-102.1421,    3.4987,   15.4729,  182.4647])\n",
      "-0.0564480988611431 -0.03373029931663574 1.0\n",
      "Epoch: 203\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.333494732594056\n",
      "MAPE:  0.14010441921652889\n",
      "Delta:  0.028627246023793712\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.049681086725504975 0.02684919748009329 -inf\n",
      "Epoch: 204\n",
      "Arb loss 0.0009773603002494165\n",
      "Real arb loss 9.81214444960736e-07\n",
      "Bounds loss: 1.2976914691799741\n",
      "MAPE:  0.1372664669942402\n",
      "Delta:  0.027205013331373252\n",
      "GRAD\n",
      " tensor([-23.7032,   0.8766,   5.6764,  44.2921])\n",
      "-0.0006156087492001916 0.008093976261987157 0.13322752913315028\n",
      "Epoch: 205\n",
      "Arb loss 0.0008471490023743529\n",
      "Real arb loss 8.50374420518739e-07\n",
      "Bounds loss: 1.2871879852330481\n",
      "MAPE:  0.13639239671852185\n",
      "Delta:  0.027221760975602156\n",
      "GRAD\n",
      " tensor([-23.6600,   0.8825,   5.6735,  44.1826])\n",
      "0.006329952578965847 0.00830032742638398 -4.509287413057617\n",
      "Epoch: 206\n",
      "Arb loss 0.00466718733576534\n",
      "Real arb loss 4.688860617170658e-06\n",
      "Bounds loss: 1.2765039034963062\n",
      "MAPE:  0.13551208773258244\n",
      "Delta:  0.02704944851951065\n",
      "GRAD\n",
      " tensor([-70.7511,   1.8053,  10.1135, 127.8566])\n",
      "-0.027108447882740805 -0.016034698946927994 1.0\n",
      "Epoch: 207\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.2969722592934478\n",
      "MAPE:  0.13731733248476735\n",
      "Delta:  0.027782717084958684\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.038826118867760995 0.023230470690562832 -inf\n",
      "Epoch: 208\n",
      "Arb loss 0.017928797648226538\n",
      "Real arb loss 1.7986639222078342e-05\n",
      "Bounds loss: 1.2668429832374584\n",
      "MAPE:  0.13486727423586978\n",
      "Delta:  0.026704022008948707\n",
      "GRAD\n",
      " tensor([-117.9304,    3.7953,   18.6266,  208.6159])\n",
      "-0.0697560442033398 -0.0436548345317076 1.0\n",
      "Epoch: 209\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.3221468040483444\n",
      "MAPE:  0.13971396602049585\n",
      "Delta:  0.028566788948611893\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.054200620907557395 0.02894998111338909 -inf\n",
      "arb imp changed to 989.8519525904672\n",
      "Epoch: 210\n",
      "Arb loss 9.449239883289147e-05\n",
      "Real arb loss 9.433250623743645e-08\n",
      "Bounds loss: 1.2838706790420171\n",
      "MAPE:  0.1366184534541494\n",
      "Delta:  0.02701845125026198\n",
      "GRAD\n",
      " tensor([-0.0243, -0.0103, -0.0044,  0.0186])\n",
      "0.017458555197516268 0.02011606412210354 -203.99062509836222\n",
      "Epoch: 211\n",
      "Arb loss 0.019370055903798172\n",
      "Real arb loss 1.9421530351116396e-05\n",
      "Bounds loss: 1.2580442541379193\n",
      "MAPE:  0.13430089200206863\n",
      "Delta:  0.026546748127757876\n",
      "GRAD\n",
      " tensor([-133.5310,    4.2266,   19.8609,  237.3033])\n",
      "-0.08335380350461752 -0.05423568618243291 1.0\n",
      "Epoch: 212\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.3262751475089563\n",
      "MAPE:  0.14040314042902116\n",
      "Delta:  0.02875952055488558\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.05953503368216706 0.03149276415595581 nan\n",
      "Delta imp changed to 0.03538635978799805\n",
      "Epoch: 213\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.2845070770825513\n",
      "MAPE:  0.1368975632320787\n",
      "Delta:  0.026387630760943893\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.017428074385022585 0.020397270895199382 -inf\n",
      "Epoch: 214\n",
      "Arb loss 0.006585568040840194\n",
      "Real arb loss 6.614174268013043e-06\n",
      "Bounds loss: 1.2583066382644976\n",
      "MAPE:  0.13454365008959057\n",
      "Delta:  0.025927745169197654\n",
      "GRAD\n",
      " tensor([-70.7842,   1.9014,  10.2014, 127.9687])\n",
      "-0.036568492467927705 -0.01675494419556034 1.0\n",
      "Epoch: 215\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.2793894957695224\n",
      "MAPE:  0.13648736371181072\n",
      "Delta:  0.026875883723127807\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.03879741829287664 0.023430290398001152 -inf\n",
      "Epoch: 216\n",
      "Arb loss 0.007697275760751689\n",
      "Real arb loss 7.730934255454028e-06\n",
      "Bounds loss: 1.2494130283514902\n",
      "MAPE:  0.13388707255543555\n",
      "Delta:  0.0258331688203309\n",
      "GRAD\n",
      " tensor([-86.3530,   3.3056,  14.4071, 153.5964])\n",
      "-0.045959031201591394 -0.025296059408046023 1.0\n",
      "Epoch: 217\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.281018254541856\n",
      "MAPE:  0.13680234579753675\n",
      "Delta:  0.027020436232180468\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.04307444007886607 0.024927954685031617 -inf\n",
      "Epoch: 218\n",
      "Arb loss 0.003020889627243702\n",
      "Real arb loss 3.0355990170122247e-06\n",
      "Bounds loss: 1.2490850895419383\n",
      "MAPE:  0.13403119679150063\n",
      "Delta:  0.025856546070792588\n",
      "GRAD\n",
      " tensor([-55.0266,   1.5944,   9.0443, 100.0441])\n",
      "-0.022677503245535524 -0.008421789022236226 1.0\n",
      "Epoch: 219\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.2596046206368816\n",
      "MAPE:  0.1350427858632905\n",
      "Delta:  0.026442907978231327\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.03346574726249418 0.02202344406106027 -inf\n",
      "Epoch: 220\n",
      "Arb loss 0.015467423697397273\n",
      "Real arb loss 1.5521855133048268e-05\n",
      "Bounds loss: 1.2318637887352322\n",
      "MAPE:  0.13258470836267575\n",
      "Delta:  0.025557976302946445\n",
      "GRAD\n",
      " tensor([-117.5744,    3.0960,   18.8178,  210.0208])\n",
      "-0.07128788186938717 -0.04547536419769593 1.0\n",
      "Epoch: 221\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.2878832431699205\n",
      "MAPE:  0.13771408498429658\n",
      "Delta:  0.027379950298451486\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.05316761241493828 0.02904661677966147 -inf\n",
      "Epoch: 222\n",
      "Arb loss 2.1832826272725115e-07\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.2504745921486162\n",
      "MAPE:  0.13450571350873214\n",
      "Delta:  0.02592422371304314\n",
      "GRAD\n",
      " tensor([-0.0015, -0.0006, -0.0003,  0.0011])\n",
      "0.018611533540598857 0.020277895019844894 -71538.34183047358\n",
      "arb imp changed to 989.75287835702\n",
      "Epoch: 223\n",
      "Arb loss 0.01562686974860751\n",
      "Real arb loss 1.5675409429742488e-05\n",
      "Bounds loss: 1.2251175996440433\n",
      "MAPE:  0.1321816959123249\n",
      "Delta:  0.02544173415389385\n",
      "GRAD\n",
      " tensor([-117.6475,    3.0901,   18.8260,  210.2144])\n",
      "-0.07281439013543789 -0.04577303710905234 1.0\n",
      "Epoch: 224\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.2811949529955031\n",
      "MAPE:  0.1373836929168954\n",
      "Delta:  0.027294258510297573\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.05285453020011921 0.02902822832085694 -inf\n",
      "Delta imp changed to 0.03452327784194932\n",
      "Epoch: 225\n",
      "Arb loss 4.422389308992443e-08\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.2440041333764202\n",
      "MAPE:  0.1341200828360498\n",
      "Delta:  0.02522110565812214\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.01876359128378613 0.020317455932384987 -243124.6587511687\n",
      "Epoch: 226\n",
      "Arb loss 0.010751963140029134\n",
      "Real arb loss 1.0792716497417816e-05\n",
      "Bounds loss: 1.21872913421684\n",
      "MAPE:  0.1317967959994567\n",
      "Delta:  0.024747867139827948\n",
      "GRAD\n",
      " tensor([-86.2660,   3.4264,  14.4939, 152.4002])\n",
      "-0.04734399341446793 -0.025721357654522548 1.0\n",
      "Epoch: 227\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.2500765021620177\n",
      "MAPE:  0.13481331017935785\n",
      "Delta:  0.025919529998718095\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.04208751971741631 0.024747748735354347 -inf\n",
      "Epoch: 228\n",
      "Arb loss 0.003198234633205915\n",
      "Real arb loss 3.2126615713077425e-06\n",
      "Bounds loss: 1.2191399229865416\n",
      "MAPE:  0.13200757864056809\n",
      "Delta:  0.02482864126883088\n",
      "GRAD\n",
      " tensor([-54.9164,   1.7001,   9.1143,  97.7695])\n",
      "-0.021666580841352312 -0.008203448165595706 1.0\n",
      "Epoch: 229\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.2291410741513698\n",
      "MAPE:  0.13305354782004458\n",
      "Delta:  0.02536659303206294\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.032736116372609536 0.02190281444381703 -inf\n",
      "Epoch: 230\n",
      "Arb loss 0.015919917919460597\n",
      "Real arb loss 1.597005672869093e-05\n",
      "Bounds loss: 1.2022194252789584\n",
      "MAPE:  0.13055665854931509\n",
      "Delta:  0.024536189290588702\n",
      "GRAD\n",
      " tensor([-101.8589,    3.8228,   15.6971,  181.1135])\n",
      "-0.058058745174697446 -0.03569608286892123 1.0\n",
      "Epoch: 231\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.245133949510343\n",
      "MAPE:  0.13465010494007437\n",
      "Delta:  0.02596072965216913\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.0463818512716726 0.026519550964337446 -inf\n",
      "Epoch: 232\n",
      "Arb loss 0.0012850809004155618\n",
      "Real arb loss 1.2910720244798877e-06\n",
      "Bounds loss: 1.2121135562788767\n",
      "MAPE:  0.13167122887678476\n",
      "Delta:  0.024756622950538123\n",
      "GRAD\n",
      " tensor([-23.6063,   0.9714,   4.7395,  44.0884])\n",
      "0.0008949943155787121 0.007694572364188024 -0.391807217900203\n",
      "Epoch: 233\n",
      "Arb loss 0.001788584872784071\n",
      "Real arb loss 1.7972229545476366e-06\n",
      "Bounds loss: 1.2027868608064756\n",
      "MAPE:  0.13086870997504552\n",
      "Delta:  0.024734465913724465\n",
      "GRAD\n",
      " tensor([-39.2202,   1.3378,   6.9213,  71.8508])\n",
      "-0.005448375591934562 -0.00030287562211128716 0.9506506085151649\n",
      "arb imp changed to 989.851754699254\n",
      "Epoch: 234\n",
      "Arb loss 8.830970787842058e-05\n",
      "Real arb loss 8.816865247615602e-08\n",
      "Bounds loss: 1.2031511556252095\n",
      "MAPE:  0.13100740583110496\n",
      "Delta:  0.02486922857408834\n",
      "GRAD\n",
      " tensor([-0.0206, -0.0088, -0.0037,  0.0157])\n",
      "0.02835734746151397 0.02084824847513722 -379.6822151224294\n",
      "Epoch: 235\n",
      "Arb loss 0.0336179352119718\n",
      "Real arb loss 3.364152286366948e-05\n",
      "Bounds loss: 1.1780675613795866\n",
      "MAPE:  0.12866096904660485\n",
      "Delta:  0.024164003218313104\n",
      "GRAD\n",
      " tensor([-148.5213,    4.1170,   22.3746,  262.9513])\n",
      "-0.09526030082296955 -0.0675166277985253 1.0\n",
      "Epoch: 236\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.2576067104427684\n",
      "MAPE:  0.1361270823444195\n",
      "Delta:  0.026465873433976814\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.06200632792532457 0.034076728888598584 nan\n",
      "Delta imp changed to 0.03368124667507251\n",
      "Epoch: 237\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.2147515875225279\n",
      "MAPE:  0.13240973239384973\n",
      "Delta:  0.024219338348292208\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.01859386164780652 0.02049506082489172 -inf\n",
      "Epoch: 238\n",
      "Arb loss 0.007655314739373569\n",
      "Real arb loss 7.687351526833983e-06\n",
      "Bounds loss: 1.18985517984912\n",
      "MAPE:  0.1299993397356005\n",
      "Delta:  0.023769007321842648\n",
      "GRAD\n",
      " tensor([-70.6472,   2.0565,  10.3085, 127.8955])\n",
      "-0.03700866005811654 -0.018244293797362365 1.0\n",
      "Epoch: 239\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.2115632473266007\n",
      "MAPE:  0.13226291685487654\n",
      "Delta:  0.024648666433735606\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.03738948429993416 0.023401350124596654 -inf\n",
      "Epoch: 240\n",
      "Arb loss 0.004932141095255664\n",
      "Real arb loss 4.95434687859183e-06\n",
      "Bounds loss: 1.1832110315778175\n",
      "MAPE:  0.12952939180385165\n",
      "Delta:  0.023727065507097134\n",
      "GRAD\n",
      " tensor([-54.8341,   1.7829,   9.1697,  97.6181])\n",
      "-0.022443476692088904 -0.008819827827316162 1.0\n",
      "Epoch: 241\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.193646749159715\n",
      "MAPE:  0.1306702845023011\n",
      "Delta:  0.024259583348777338\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.03281878289766893 0.022004638294059964 -inf\n",
      "Epoch: 242\n",
      "Arb loss 0.02076900908135699\n",
      "Real arb loss 2.0821736511719647e-05\n",
      "Bounds loss: 1.167380984193575\n",
      "MAPE:  0.12811674797367187\n",
      "Delta:  0.02346341334966591\n",
      "GRAD\n",
      " tensor([-117.4028,    3.2839,   17.9463,  209.0150])\n",
      "-0.07150079869148063 -0.04756221992244858 1.0\n",
      "Epoch: 243\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.2229042152970742\n",
      "MAPE:  0.13354411497214994\n",
      "Delta:  0.02514106614419537\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.051103028627035196 0.029062488696230293 -inf\n",
      "Epoch: 244\n",
      "Arb loss 3.011773938250737e-07\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.1873635753634304\n",
      "MAPE:  0.13031300064600246\n",
      "Delta:  0.02385628152131437\n",
      "GRAD\n",
      " tensor([-0.0038, -0.0016, -0.0007,  0.0029])\n",
      "0.01983557263876068 0.02031951802182974 -48621.97255498571\n",
      "Epoch: 245\n",
      "Arb loss 0.014644140154138681\n",
      "Real arb loss 1.4692318036274653e-05\n",
      "Bounds loss: 1.163236919795369\n",
      "MAPE:  0.12792987860983035\n",
      "Delta:  0.023383078516307616\n",
      "GRAD\n",
      " tensor([-101.5385,    3.0907,   14.8665,  179.7581])\n",
      "-0.05914879630236314 -0.03641658102486267 1.0\n",
      "Epoch: 246\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.2055980313362087\n",
      "MAPE:  0.13219047783657104\n",
      "Delta:  0.02476615946439086\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.045061375832051276 0.026361813788710275 -inf\n",
      "arb imp changed to 989.7526804856136\n",
      "Epoch: 247\n",
      "Arb loss 0.0005359490690880379\n",
      "Real arb loss 5.377959021048775e-07\n",
      "Bounds loss: 1.1738162805300878\n",
      "MAPE:  0.1292033263115642\n",
      "Delta:  0.023650162244849428\n",
      "GRAD\n",
      " tensor([-7.8885,  0.6546,  1.5812, 15.0522])\n",
      "0.013095064961171188 0.015897152302747908 -21.20234837399082\n",
      "Epoch: 248\n",
      "Arb loss 0.011899327942608692\n",
      "Real arb loss 1.193943882413389e-05\n",
      "Bounds loss: 1.155155944343056\n",
      "MAPE:  0.1273853082492866\n",
      "Delta:  0.023340461833910885\n",
      "GRAD\n",
      " tensor([-86.0318,   3.6064,  13.6044, 152.1546])\n",
      "-0.04433229640799463 -0.026996305539396914 1.0\n",
      "Epoch: 249\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.1863408871621917\n",
      "MAPE:  0.130569363151834\n",
      "Delta:  0.02437519810623131\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.0405780789902469 0.024586817775027248 -inf\n",
      "Epoch: 250\n",
      "Arb loss 0.005137682746334952\n",
      "Real arb loss 5.16015995846359e-06\n",
      "Bounds loss: 1.1571725399504706\n",
      "MAPE:  0.1277822160592648\n",
      "Delta:  0.02338609939207374\n",
      "GRAD\n",
      " tensor([-54.8428,   1.7866,   9.1744,  97.7510])\n",
      "-0.022032741685548807 -0.00925711213580227 1.0\n",
      "Epoch: 251\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.1678846159132632\n",
      "MAPE:  0.12896849010132758\n",
      "Delta:  0.023901359279011866\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.03235624336121001 0.021987024600657712 -inf\n",
      "Epoch: 252\n",
      "Arb loss 0.017551799068786067\n",
      "Real arb loss 1.7599130695977968e-05\n",
      "Bounds loss: 1.1422063081324485\n",
      "MAPE:  0.12642480058600475\n",
      "Delta:  0.023128001081516445\n",
      "GRAD\n",
      " tensor([-101.6031,    3.0437,   15.8384,  179.9714])\n",
      "-0.0587595960476075 -0.03778747836730534 1.0\n",
      "Epoch: 253\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.185367404292003\n",
      "MAPE:  0.1307779025193672\n",
      "Delta:  0.02448699308245498\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.045607088313594724 0.026747020921361497 -inf\n",
      "Epoch: 254\n",
      "Arb loss 0.0007034928813454469\n",
      "Real arb loss 7.064064807474901e-07\n",
      "Bounds loss: 1.1536623575299048\n",
      "MAPE:  0.12778924726269564\n",
      "Delta:  0.023370212626409072\n",
      "GRAD\n",
      " tensor([-7.8666,  0.6706,  1.5909, 15.0071])\n",
      "0.013240106503801696 0.015829073309190478 -20.638606740255828\n",
      "Epoch: 255\n",
      "Arb loss 0.015222605804003581\n",
      "Real arb loss 1.5270154224314727e-05\n",
      "Bounds loss: 1.1354009514985106\n",
      "MAPE:  0.1259896947784307\n",
      "Delta:  0.023060788522218923\n",
      "GRAD\n",
      " tensor([-101.5130,    3.0947,   14.8654,  179.8631])\n",
      "-0.05642032734156355 -0.03725893664182034 1.0\n",
      "Epoch: 256\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.177704783613456\n",
      "MAPE:  0.13030022070304723\n",
      "Delta:  0.024361885759397087\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.044516109307402796 0.02635614573352507 -inf\n",
      "Epoch: 257\n",
      "Arb loss 0.0006735760086704271\n",
      "Real arb loss 6.764342438530455e-07\n",
      "Bounds loss: 1.1466650247054702\n",
      "MAPE:  0.12732840520087335\n",
      "Delta:  0.023277389389997308\n",
      "GRAD\n",
      " tensor([-7.8659,  0.6715,  1.5916, 15.0114])\n",
      "0.013161553867526044 0.0158129349474595 -21.41010370223393\n",
      "arb imp changed to 989.8515568080803\n",
      "Epoch: 258\n",
      "Arb loss 0.015102455659743911\n",
      "Real arb loss 1.5144072424674865e-05\n",
      "Bounds loss: 1.1285328852632757\n",
      "MAPE:  0.1255346312970231\n",
      "Delta:  0.022971022775645476\n",
      "GRAD\n",
      " tensor([-101.5462,    3.0901,   15.8674,  179.9453])\n",
      "-0.0567573201141327 -0.03766367053709252 1.0\n",
      "Epoch: 259\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.171037576044106\n",
      "MAPE:  0.12989738022767103\n",
      "Delta:  0.024274796468671818\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.04446090110879619 0.026402544614622436 -inf\n",
      "Epoch: 260\n",
      "Arb loss 0.0005826812273316152\n",
      "Real arb loss 5.849225287539035e-07\n",
      "Bounds loss: 1.1401192041972024\n",
      "MAPE:  0.12690939874059098\n",
      "Delta:  0.023195517143442045\n",
      "GRAD\n",
      " tensor([-7.8645,  0.6732,  1.5927, 15.0131])\n",
      "0.013169696233789496 0.015808250050869832 -18.771565617454304\n",
      "Epoch: 261\n",
      "Arb loss 0.011520520120245837\n",
      "Real arb loss 1.1558015569796944e-05\n",
      "Bounds loss: 1.1220959147294542\n",
      "MAPE:  0.12511902411868359\n",
      "Delta:  0.022890039228677255\n",
      "GRAD\n",
      " tensor([-85.7609,   2.8147,  13.7320, 150.7578])\n",
      "-0.04426500554554069 -0.027571994367348474 1.0\n",
      "Epoch: 262\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.1530343369699994\n",
      "MAPE:  0.1283512383146277\n",
      "Delta:  0.0239032669420723\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.03978981423011363 0.02451134419578138 -inf\n",
      "Delta imp changed to 0.03285975285372928\n",
      "Epoch: 263\n",
      "Arb loss 0.0047052581671717456\n",
      "Real arb loss 4.726039767684341e-06\n",
      "Bounds loss: 1.124771915466973\n",
      "MAPE:  0.12558490987531187\n",
      "Delta:  0.02239235160093115\n",
      "GRAD\n",
      " tensor([-54.6657,   1.9246,   9.2594,  96.4655])\n",
      "-0.021526783798116123 -0.009400529540864344 1.0\n",
      "Epoch: 264\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.135345367085055\n",
      "MAPE:  0.12678526386236325\n",
      "Delta:  0.022874386912575793\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.03169530830199929 0.02192133567118737 -inf\n",
      "Epoch: 265\n",
      "Arb loss 0.016237458285803894\n",
      "Real arb loss 1.628252630714624e-05\n",
      "Bounds loss: 1.110457080190456\n",
      "MAPE:  0.12425829421676417\n",
      "Delta:  0.022149376167162487\n",
      "GRAD\n",
      " tensor([-101.2439,    3.3145,   15.0030,  178.4315])\n",
      "-0.057903327608828326 -0.03810323174701513 1.0\n",
      "Epoch: 266\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.152769083662067\n",
      "MAPE:  0.12863603331700108\n",
      "Delta:  0.02343189875170087\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.044494528446949566 0.02657240759881796 -inf\n",
      "Epoch: 267\n",
      "Arb loss 0.000919738680451846\n",
      "Real arb loss 9.23853875103825e-07\n",
      "Bounds loss: 1.1221372337036826\n",
      "MAPE:  0.12564687065063612\n",
      "Delta:  0.022389307466127273\n",
      "GRAD\n",
      " tensor([-23.4639,   1.0892,   4.8138,  43.8950])\n",
      "0.0013033977379477424 0.007106456951619267 -0.6705109888093304\n",
      "Epoch: 268\n",
      "Arb loss 0.001536433572527802\n",
      "Real arb loss 1.5435342198342612e-06\n",
      "Bounds loss: 1.1141628137585584\n",
      "MAPE:  0.12491571421140374\n",
      "Delta:  0.02236012529342171\n",
      "GRAD\n",
      " tensor([-23.4829,   1.0697,   4.8007,  43.8790])\n",
      "0.005156085368856922 0.007191226056496358 -2.139115083454069\n",
      "arb imp changed to 989.9504430082945\n",
      "Epoch: 269\n",
      "Arb loss 0.004825453323148368\n",
      "Real arb loss 4.845312648683688e-06\n",
      "Bounds loss: 1.1061506171010784\n",
      "MAPE:  0.12417299900641934\n",
      "Delta:  0.022244834578550487\n",
      "GRAD\n",
      " tensor([-54.6479,   1.9166,   9.2494,  96.3785])\n",
      "-0.01666518730135902 -0.00947304516946934 1.0\n",
      "Epoch: 270\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.1166292318611133\n",
      "MAPE:  0.1253575442587968\n",
      "Delta:  0.02261554891328978\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.031979832024802146 0.021941182537180803 -inf\n",
      "Epoch: 271\n",
      "Arb loss 0.023955559703545373\n",
      "Real arb loss 2.3992130362169847e-05\n",
      "Bounds loss: 1.0921290660584966\n",
      "MAPE:  0.12286221368978766\n",
      "Delta:  0.021892307457894077\n",
      "GRAD\n",
      " tensor([-116.7659,    3.7855,   18.2565,  207.1908])\n",
      "-0.07052648680326845 -0.04945552277925058 1.0\n",
      "Epoch: 272\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.1461408799628343\n",
      "MAPE:  0.12845131815016445\n",
      "Delta:  0.023436294990916335\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.04854321087773783 0.028666405897619263 -inf\n",
      "Epoch: 273\n",
      "Arb loss 4.440459187989015e-05\n",
      "Real arb loss 4.4208216319160946e-08\n",
      "Bounds loss: 1.1132851402819652\n",
      "MAPE:  0.12526177599921787\n",
      "Delta:  0.022298621980979413\n",
      "GRAD\n",
      " tensor([-0.0054, -0.0023, -0.0010,  0.0041])\n",
      "0.019497312409171963 0.020209807908908806 -391.669673699167\n",
      "Delta imp changed to 0.03205829546705296\n",
      "Epoch: 274\n",
      "Arb loss 0.017436336604221142\n",
      "Real arb loss 1.7478841502514844e-05\n",
      "Bounds loss: 1.0907858614490242\n",
      "MAPE:  0.12293298348770665\n",
      "Delta:  0.021330593933582664\n",
      "GRAD\n",
      " tensor([-101.2820,    3.3206,   14.0149,  179.7531])\n",
      "-0.059502678455315205 -0.039100158995794665 1.0\n",
      "Epoch: 275\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.1334357620620457\n",
      "MAPE:  0.1274303186798956\n",
      "Delta:  0.02259982140567353\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.043995647818290906 0.02661064693662374 -inf\n",
      "Epoch: 276\n",
      "Arb loss 0.0003141714594789258\n",
      "Real arb loss 3.153078540424903e-07\n",
      "Bounds loss: 1.1032743031724697\n",
      "MAPE:  0.12440522324451364\n",
      "Delta:  0.021605527622353248\n",
      "GRAD\n",
      " tensor([-0.0278, -0.0117, -0.0049,  0.0211])\n",
      "0.019149553426295762 0.02007806416781066 -56.79151717594494\n",
      "Epoch: 277\n",
      "Arb loss 0.01815644529666803\n",
      "Real arb loss 1.8198895715517597e-05\n",
      "Bounds loss: 1.0811226909186762\n",
      "MAPE:  0.12211049535826188\n",
      "Delta:  0.021191791416845684\n",
      "GRAD\n",
      " tensor([-100.9620,    3.5264,   14.1314,  178.1414])\n",
      "-0.05861275319408232 -0.038482880138589914 1.0\n",
      "Epoch: 278\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.1227274058484094\n",
      "MAPE:  0.12652507718686207\n",
      "Delta:  0.022433900656901734\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.04331850851215424 0.026331783864806613 -inf\n",
      "Epoch: 279\n",
      "Arb loss 0.000881014762799357\n",
      "Real arb loss 8.845480748951862e-07\n",
      "Bounds loss: 1.093163990458514\n",
      "MAPE:  0.12356670443040058\n",
      "Delta:  0.021462097540334915\n",
      "GRAD\n",
      " tensor([-23.3942,   1.1419,   4.8459,  42.7828])\n",
      "0.0017125358639056287 0.00719191953681797 -0.9009493066199035\n",
      "arb imp changed to 990.049339087243\n",
      "Epoch: 280\n",
      "Arb loss 0.001675601784666569\n",
      "Real arb loss 1.68192147112331e-06\n",
      "Bounds loss: 1.0853020429985896\n",
      "MAPE:  0.12282989170489628\n",
      "Delta:  0.02142534292858245\n",
      "GRAD\n",
      " tensor([-23.4327,   1.1138,   4.8291,  42.7896])\n",
      "0.005184622120726234 0.007242013848732243 -2.110997906479424\n",
      "Epoch: 281\n",
      "Arb loss 0.005212793644190883\n",
      "Real arb loss 5.233261973671521e-06\n",
      "Bounds loss: 1.0774422705731364\n",
      "MAPE:  0.12208803033312962\n",
      "Delta:  0.021314260621690777\n",
      "GRAD\n",
      " tensor([-54.4951,   2.0342,   9.3215,  96.1511])\n",
      "-0.01697464614206501 -0.009942581325764532 1.0\n",
      "Epoch: 282\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.0881548279721263\n",
      "MAPE:  0.12332549798775792\n",
      "Delta:  0.021676062653523728\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.031469013743264496 0.021877925377971064 -inf\n",
      "Epoch: 283\n",
      "Arb loss 0.02276299468106204\n",
      "Real arb loss 2.2794680629409023e-05\n",
      "Bounds loss: 1.064348257846073\n",
      "MAPE:  0.12085406018448241\n",
      "Delta:  0.020993938339980128\n",
      "GRAD\n",
      " tensor([-101.0628,    3.4594,   14.0929,  178.3756])\n",
      "-0.05731748212105292 -0.039077103226144994 1.0\n",
      "Epoch: 284\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.1059399045864917\n",
      "MAPE:  0.12530430805275225\n",
      "Delta:  0.022197258025432428\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.04306156865003363 0.026314720379017276 -inf\n",
      "Delta imp changed to 0.03127638582151508\n",
      "Epoch: 285\n",
      "Arb loss 0.002331344558179726\n",
      "Real arb loss 2.340861450615371e-06\n",
      "Bounds loss: 1.076837405241301\n",
      "MAPE:  0.12237011355495389\n",
      "Delta:  0.020723326122075864\n",
      "GRAD\n",
      " tensor([-38.9612,   0.5943,   6.0919,  71.5917])\n",
      "-0.010209571883938118 -0.002078687980135996 0.9998548531882389\n",
      "Epoch: 286\n",
      "Arb loss 3.3838722973649124e-07\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.079075814212137\n",
      "MAPE:  0.12274046923600175\n",
      "Delta:  0.020934902409793493\n",
      "GRAD\n",
      " tensor([-0.0042, -0.0018, -0.0007,  0.0032])\n",
      "0.026823427376950204 0.020941530623882043 -69801.03897731319\n",
      "Epoch: 287\n",
      "Arb loss 0.023620118599491594\n",
      "Real arb loss 2.3652748916131492e-05\n",
      "Bounds loss: 1.056478315003323\n",
      "MAPE:  0.12033655328842087\n",
      "Delta:  0.020373356575360855\n",
      "GRAD\n",
      " tensor([-116.3346,    4.1047,   17.4488,  205.7318])\n",
      "-0.07027197916549044 -0.0499534478957262 1.0\n",
      "Epoch: 288\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.109253049464806\n",
      "MAPE:  0.12598673812156502\n",
      "Delta:  0.02180503266415572\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.047194005625871616 0.028463687119079983 -inf\n",
      "Epoch: 289\n",
      "Arb loss 8.10487617457934e-06\n",
      "Real arb loss 7.659809281176932e-09\n",
      "Bounds loss: 1.0776796177289547\n",
      "MAPE:  0.12279643939724735\n",
      "Delta:  0.020775965829931242\n",
      "GRAD\n",
      " tensor([-0.0026, -0.0011, -0.0005,  0.0019])\n",
      "0.019470961880627358 0.02023966313801895 -1946.963915347952\n",
      "Epoch: 290\n",
      "Arb loss 0.015788006326443903\n",
      "Real arb loss 1.5827860750404572e-05\n",
      "Bounds loss: 1.0558677452954115\n",
      "MAPE:  0.12046495197211197\n",
      "Delta:  0.020371437791223433\n",
      "GRAD\n",
      " tensor([-85.5629,   3.0072,  13.8591, 150.9123])\n",
      "-0.047439942122335044 -0.02977116943280378 1.0\n",
      "Epoch: 291\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.0873021628392336\n",
      "MAPE:  0.12393669299010135\n",
      "Delta:  0.021337857620987822\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.03897391598337541 0.02474213980221851 -inf\n",
      "arb imp changed to 990.1482450459129\n",
      "Epoch: 292\n",
      "Arb loss 0.002559999262451489\n",
      "Real arb loss 2.5692902648172254e-06\n",
      "Bounds loss: 1.060399980719011\n",
      "MAPE:  0.12112128470179973\n",
      "Delta:  0.020506237750802216\n",
      "GRAD\n",
      " tensor([-38.8538,   0.6755,   6.1412,  70.3810])\n",
      "-0.01078719303117004 -0.002013465073166021 0.9998204873803085\n",
      "Epoch: 293\n",
      "Arb loss 4.5955217401102446e-07\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.0625350590437745\n",
      "MAPE:  0.12146801752850435\n",
      "Delta:  0.020727442495763183\n",
      "GRAD\n",
      " tensor([-0.0013, -0.0006, -0.0002,  0.0010])\n",
      "0.02716851351872096 0.02097060548501728 -59046.269388925575\n",
      "Epoch: 294\n",
      "Arb loss 0.027135301017095364\n",
      "Real arb loss 2.715271146754425e-05\n",
      "Bounds loss: 1.040253055506568\n",
      "MAPE:  0.11908012213852966\n",
      "Delta:  0.02016430869410853\n",
      "GRAD\n",
      " tensor([-116.4194,    3.0590,   17.4254,  206.0612])\n",
      "-0.07072807269315073 -0.050905275435377595 1.0\n",
      "Epoch: 295\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.0932074238196232\n",
      "MAPE:  0.12486183372088902\n",
      "Delta:  0.021590491385232568\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.046874667191561636 0.02848057805548032 -inf\n",
      "Epoch: 296\n",
      "Arb loss 6.509035132662373e-05\n",
      "Real arb loss 6.499598380250993e-08\n",
      "Bounds loss: 1.0620722444546977\n",
      "MAPE:  0.1216461513556186\n",
      "Delta:  0.020578444287047512\n",
      "GRAD\n",
      " tensor([-0.0070, -0.0029, -0.0012,  0.0053])\n",
      "0.01948885951231283 0.020216228709197703 -218.670103032653\n",
      "Epoch: 297\n",
      "Arb loss 0.014298404182351019\n",
      "Real arb loss 1.4332115483824266e-05\n",
      "Bounds loss: 1.0406011490551108\n",
      "MAPE:  0.11932286341920878\n",
      "Delta:  0.020177393877355287\n",
      "GRAD\n",
      " tensor([-85.2446,   2.2275,  12.9880, 149.3471])\n",
      "-0.0469932542762288 -0.029742873773903833 1.0\n",
      "Epoch: 298\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.071551617680436\n",
      "MAPE:  0.12278842430360493\n",
      "Delta:  0.021125595278465463\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.03848468377621561 0.024648512782088683 -inf\n",
      "Epoch: 299\n",
      "Arb loss 0.003511798554211572\n",
      "Real arb loss 3.5262813929373206e-06\n",
      "Bounds loss: 1.0451394639353722\n",
      "MAPE:  0.11998491380898098\n",
      "Delta:  0.020312583424589407\n",
      "GRAD\n",
      " tensor([-38.8671,   0.6704,   6.1393,  71.4640])\n",
      "-0.011228106553083927 -0.0025887739595302772 0.999846361249361\n",
      "Epoch: 300\n",
      "Arb loss 5.395483423649357e-07\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.0478450937636854\n",
      "MAPE:  0.12040097108601219\n",
      "Delta:  0.020540655275649102\n",
      "GRAD\n",
      " tensor([-0.0047, -0.0020, -0.0008,  0.0036])\n",
      "0.02710864943182123 0.02097700101438471 -44408.39606827623\n",
      "Delta imp changed to 0.030513547142941546\n",
      "Epoch: 301\n",
      "Arb loss 0.02396101603406633\n",
      "Real arb loss 2.3986480573535367e-05\n",
      "Bounds loss: 1.0258644461688866\n",
      "MAPE:  0.11801727560073685\n",
      "Delta:  0.01949641546603087\n",
      "GRAD\n",
      " tensor([-100.6875,    3.7312,   14.2551,  178.0356])\n",
      "-0.05782835050311097 -0.040294705456533686 1.0\n",
      "Epoch: 302\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.067201351865592\n",
      "MAPE:  0.12262903206693251\n",
      "Delta:  0.02062386101315478\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.04199176194783327 0.026209531872550706 -inf\n",
      "arb imp changed to 990.3461856013795\n",
      "Epoch: 303\n",
      "Arb loss 0.0019990601177712285\n",
      "Real arb loss 2.0057641353485383e-06\n",
      "Bounds loss: 1.0392305040194416\n",
      "MAPE:  0.11965878734834404\n",
      "Delta:  0.019757828751045182\n",
      "GRAD\n",
      " tensor([-23.3835,   1.1703,   4.8679,  42.7893])\n",
      "0.0017100814470796255 0.00670811292950424 -0.7123985979346075\n",
      "Epoch: 304\n",
      "Arb loss 0.0034231877428584426\n",
      "Real arb loss 3.435939919778454e-06\n",
      "Bounds loss: 1.0322592284386936\n",
      "MAPE:  0.11897784851629215\n",
      "Delta:  0.019724041254663444\n",
      "GRAD\n",
      " tensor([-38.8633,   0.6656,   6.1346,  71.4139])\n",
      "-0.007727795071484245 -0.002610987122391162 0.9301338646052264\n",
      "Epoch: 305\n",
      "Arb loss 0.00023916489832427718\n",
      "Real arb loss 2.3982233049624216e-07\n",
      "Bounds loss: 1.0349544439911165\n",
      "MAPE:  0.11938292188937345\n",
      "Delta:  0.019876464603460986\n",
      "GRAD\n",
      " tensor([-0.0227, -0.0095, -0.0040,  0.0171])\n",
      "0.027022796611716804 0.020860674161763404 -117.57080924739059\n",
      "Epoch: 306\n",
      "Arb loss 0.028357975537879436\n",
      "Real arb loss 2.836154767168385e-05\n",
      "Bounds loss: 1.0133645965627487\n",
      "MAPE:  0.117025969796769\n",
      "Delta:  0.01933934694312167\n",
      "GRAD\n",
      " tensor([-116.0030,    3.3346,   17.5834,  205.4994])\n",
      "-0.07059750045683466 -0.05211329674777598 1.0\n",
      "Epoch: 307\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.0661743664971135\n",
      "MAPE:  0.1229548886758781\n",
      "Delta:  0.020704656497773588\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.04671430064017135 0.028756848043660854 -inf\n",
      "Epoch: 308\n",
      "Arb loss 0.00020825435697853717\n",
      "Real arb loss 2.0910606541926086e-07\n",
      "Bounds loss: 1.0355145522517097\n",
      "MAPE:  0.11966998955261975\n",
      "Delta:  0.019737452949485118\n",
      "GRAD\n",
      " tensor([-0.0071, -0.0030, -0.0013,  0.0054])\n",
      "0.01963174109360366 0.020200312285060806 -87.45015096958969\n",
      "Epoch: 309\n",
      "Arb loss 0.018420129314826436\n",
      "Real arb loss 1.844920259146662e-05\n",
      "Bounds loss: 1.0145968349205003\n",
      "MAPE:  0.1173592773680419\n",
      "Delta:  0.019349972383333643\n",
      "GRAD\n",
      " tensor([-100.5767,    3.8354,   14.3231,  177.0222])\n",
      "-0.058271189097924836 -0.040553629809290115 1.0\n",
      "Epoch: 310\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.0557424193695437\n",
      "MAPE:  0.12208104837300014\n",
      "Delta:  0.020477518283122498\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.0416867513375333 0.026376564407329828 -inf\n",
      "Epoch: 311\n",
      "Arb loss 0.0003987960171176424\n",
      "Real arb loss 4.003149003431808e-07\n",
      "Bounds loss: 1.0278955614474927\n",
      "MAPE:  0.11899946864468396\n",
      "Delta:  0.019623877070444176\n",
      "GRAD\n",
      " tensor([-0.0235, -0.0099, -0.0041,  0.0178])\n",
      "0.019033290731809926 0.020084357949347154 -52.5360844716916\n",
      "Delta imp changed to 0.029769314285796634\n",
      "Epoch: 312\n",
      "Arb loss 0.021349977259384274\n",
      "Real arb loss 2.1377969443356814e-05\n",
      "Bounds loss: 1.007250939056836\n",
      "MAPE:  0.11672054010768967\n",
      "Delta:  0.018780848890611823\n",
      "GRAD\n",
      " tensor([-100.6217,    3.8007,   14.3019,  178.2125])\n",
      "-0.05882560176110663 -0.04118638219200599 1.0\n",
      "Epoch: 313\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.0487359611960878\n",
      "MAPE:  0.12151574137499281\n",
      "Delta:  0.019885643628186477\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.041516575245451715 0.026339738748309305 -inf\n",
      "arb imp changed to 990.5441657271466\n",
      "Epoch: 314\n",
      "Arb loss 0.0005374217398759378\n",
      "Real arb loss 5.39274654473225e-07\n",
      "Bounds loss: 1.021112529962226\n",
      "MAPE:  0.11843928416450164\n",
      "Delta:  0.019060059808192635\n",
      "GRAD\n",
      " tensor([-7.7802,  0.7358,  1.6305, 14.9132])\n",
      "0.013149642287838548 0.015511268414708623 -17.558571674327307\n",
      "Epoch: 315\n",
      "Arb loss 0.009973779878829279\n",
      "Real arb loss 9.996670677242388e-06\n",
      "Bounds loss: 1.0052737794283597\n",
      "MAPE:  0.11670918816435688\n",
      "Delta:  0.018809426839730095\n",
      "GRAD\n",
      " tensor([-69.5753,   1.8555,   9.7915, 124.4881])\n",
      "-0.03422521988748595 -0.0215653924636805 1.0\n",
      "Epoch: 316\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.0269529030151794\n",
      "MAPE:  0.11924797356122559\n",
      "Delta:  0.019453183609277436\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.03429873337938938 0.02326087111694386 -inf\n",
      "Epoch: 317\n",
      "Arb loss 0.00848125342506514\n",
      "Real arb loss 8.503943226563637e-06\n",
      "Bounds loss: 1.003065083894972\n",
      "MAPE:  0.1166130240321926\n",
      "Delta:  0.018785964051282522\n",
      "GRAD\n",
      " tensor([-54.2237,   2.2697,   9.4715,  96.0488])\n",
      "-0.021735998516901445 -0.011575302753242589 0.9999998989017113\n",
      "Epoch: 318\n",
      "Arb loss 8.574402076499062e-10\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.014675865922263\n",
      "MAPE:  0.11803903362703592\n",
      "Delta:  0.019194295738039765\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.029682517046256574 0.021724119502444794 -21719141.00224159\n",
      "Epoch: 319\n",
      "Arb loss 0.018622865628379826\n",
      "Real arb loss 1.8645604704950252e-05\n",
      "Bounds loss: 0.9926329261547212\n",
      "MAPE:  0.11559955365022884\n",
      "Delta:  0.01862456072760451\n",
      "GRAD\n",
      " tensor([-84.9916,   2.3953,  13.0843, 149.2111])\n",
      "-0.04574305908452758 -0.031133600550921958 1.0\n",
      "Epoch: 320\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.023537163171315\n",
      "MAPE:  0.11926786099475827\n",
      "Delta:  0.019476505109390693\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.03742959102052712 0.024534881577584433 -inf\n",
      "Epoch: 321\n",
      "Arb loss 0.005970527502090911\n",
      "Real arb loss 5.9908286017970396e-06\n",
      "Bounds loss: 0.9984248000826501\n",
      "MAPE:  0.11641837953892592\n",
      "Delta:  0.018747507488636992\n",
      "GRAD\n",
      " tensor([-54.1429,   2.3251,   9.5037,  94.9413])\n",
      "-0.020918020523560843 -0.011306697217993378 1.0\n",
      "Epoch: 322\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.0097136869921204\n",
      "MAPE:  0.11781551631682338\n",
      "Delta:  0.019139668235049912\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.029675396067812 0.021861152198086264 -inf\n",
      "Delta imp changed to 0.029043233449557695\n",
      "Epoch: 323\n",
      "Arb loss 0.015788603253066958\n",
      "Real arb loss 1.5818191090252735e-05\n",
      "Bounds loss: 0.9876401824042947\n",
      "MAPE:  0.11534366313409947\n",
      "Delta:  0.018118722926408086\n",
      "GRAD\n",
      " tensor([-84.9017,   2.4613,  13.1238, 149.1249])\n",
      "-0.045681888931611514 -0.031262075239594234 1.0\n",
      "Epoch: 324\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.0185158640962644\n",
      "MAPE:  0.1190683354124776\n",
      "Delta:  0.0189464204147149\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.037403309245198746 0.02466730843186027 -inf\n",
      "arb imp changed to 990.6431211190126\n",
      "Epoch: 325\n",
      "Arb loss 0.004417546927210079\n",
      "Real arb loss 4.432431026407328e-06\n",
      "Bounds loss: 0.993391819133859\n",
      "MAPE:  0.11615235474625564\n",
      "Delta:  0.01823776159285377\n",
      "GRAD\n",
      " tensor([-38.7617,   0.7590,   6.1951,  70.4168])\n",
      "-0.010867409385912907 -0.0030192562162660863 0.972398730280963\n",
      "Epoch: 326\n",
      "Arb loss 0.00012192990423442835\n",
      "Real arb loss 1.2227638925148277e-07\n",
      "Bounds loss: 0.9963911235589666\n",
      "MAPE:  0.11660819352268982\n",
      "Delta:  0.01843595881436599\n",
      "GRAD\n",
      " tensor([-0.0006, -0.0003, -0.0001,  0.0005])\n",
      "0.025982942605009995 0.020841056425147553 -194.93456375110634\n",
      "Epoch: 327\n",
      "Arb loss 0.02389028259438689\n",
      "Real arb loss 2.3895848661766734e-05\n",
      "Bounds loss: 0.9756252799313581\n",
      "MAPE:  0.11425004886049124\n",
      "Delta:  0.017956938354623992\n",
      "GRAD\n",
      " tensor([-100.2831,    3.0224,   14.4282,  176.7894])\n",
      "-0.0574281493536708 -0.04204272808700016 1.0\n",
      "Epoch: 328\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.0166432282903155\n",
      "MAPE:  0.11918520641917107\n",
      "Delta:  0.018988172092387998\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.04063048028907479 0.026236562292061616 -inf\n",
      "Epoch: 329\n",
      "Arb loss 0.001005138531819894\n",
      "Real arb loss 1.0078765106591863e-06\n",
      "Bounds loss: 0.9899700049024741\n",
      "MAPE:  0.11607137435876543\n",
      "Delta:  0.018216673540462667\n",
      "GRAD\n",
      " tensor([-7.7696,  0.7468,  1.6378, 14.8948])\n",
      "0.013321028841197236 0.015383449724567066 -15.041933378868336\n",
      "Epoch: 330\n",
      "Arb loss 0.016124365363988268\n",
      "Real arb loss 1.614933901972556e-05\n",
      "Bounds loss: 0.9747408511032275\n",
      "MAPE:  0.1143589780435318\n",
      "Delta:  0.01797400870683949\n",
      "GRAD\n",
      " tensor([-84.9090,   2.4632,  13.1267, 149.2239])\n",
      "-0.04511089896764475 -0.0317524210220006 1.0\n",
      "Epoch: 331\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.0056912329948005\n",
      "MAPE:  0.11817190484900396\n",
      "Delta:  0.018784832397657294\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.037152902447935676 0.024714001196164626 -inf\n",
      "Epoch: 332\n",
      "Arb loss 0.003057083282989708\n",
      "Real arb loss 3.067565530978634e-06\n",
      "Bounds loss: 0.9808365786595946\n",
      "MAPE:  0.11521584982246116\n",
      "Delta:  0.01808692135208631\n",
      "GRAD\n",
      " tensor([-23.2244,   0.2818,   4.9334,  42.5978])\n",
      "0.00038105112966346777 0.005984063898320402 -0.1561226501460824\n",
      "Epoch: 333\n",
      "Arb loss 0.0035343632268473473\n",
      "Real arb loss 3.54646695487458e-06\n",
      "Bounds loss: 0.9749671898990857\n",
      "MAPE:  0.11462437783371816\n",
      "Delta:  0.018080029310272965\n",
      "GRAD\n",
      " tensor([-38.5657,   0.8679,   6.2519,  70.0338])\n",
      "-0.006848361611937248 -0.002992813161004637 0.8613816382670153\n",
      "Epoch: 334\n",
      "Arb loss 0.0004899276402748848\n",
      "Real arb loss 4.91683544749523e-07\n",
      "Bounds loss: 0.9778850845365634\n",
      "MAPE:  0.11505755807830123\n",
      "Delta:  0.01820384788894414\n",
      "GRAD\n",
      " tensor([-0.0222, -0.0093, -0.0039,  0.0167])\n",
      "0.026281494011092144 0.02079065682896042 -65.948258866714\n",
      "Epoch: 335\n",
      "Arb loss 0.032799802487081316\n",
      "Real arb loss 3.278139196641172e-05\n",
      "Bounds loss: 0.9575542113258048\n",
      "MAPE:  0.11273556697752075\n",
      "Delta:  0.017725423569672022\n",
      "GRAD\n",
      " tensor([-115.5153,    3.6619,   16.7720,  204.4086])\n",
      "-0.07013105388216223 -0.05417776833741783 1.0\n",
      "Epoch: 336\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.0094323615575331\n",
      "MAPE:  0.11905449083982812\n",
      "Delta:  0.018968526205120836\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.04448090233735691 0.028490561710556084 -inf\n",
      "arb imp changed to 990.8411606051649\n",
      "Epoch: 337\n",
      "Arb loss 0.00018064974980539733\n",
      "Real arb loss 1.8116330775736627e-07\n",
      "Bounds loss: 0.9806730665679458\n",
      "MAPE:  0.11559724392986684\n",
      "Delta:  0.018124789043507263\n",
      "GRAD\n",
      " tensor([-0.0088, -0.0037, -0.0015,  0.0067])\n",
      "0.01992901551161841 0.02032128737062333 -83.94340835543937\n",
      "Delta imp changed to 0.02833486190200751\n",
      "Epoch: 338\n",
      "Arb loss 0.01534500546702782\n",
      "Real arb loss 1.536303062358677e-05\n",
      "Bounds loss: 0.9607445273655882\n",
      "MAPE:  0.11327883775187932\n",
      "Delta:  0.01733032179659941\n",
      "GRAD\n",
      " tensor([-69.3855,   1.9971,   9.8768, 124.5509])\n",
      "-0.036236310967435736 -0.022998401666461943 1.0\n",
      "Epoch: 339\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 0.9828401159047973\n",
      "MAPE:  0.11611530999759899\n",
      "Delta:  0.017958308726386717\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.03307451605907863 0.023161216595866452 -inf\n",
      "Epoch: 340\n",
      "Arb loss 0.00957658751337775\n",
      "Real arb loss 9.596628373775181e-06\n",
      "Bounds loss: 0.9600763431012198\n",
      "MAPE:  0.1133496773407735\n",
      "Delta:  0.01736434635602195\n",
      "GRAD\n",
      " tensor([-54.0158,   2.4148,   9.5566,  94.9141])\n",
      "-0.022202719226646073 -0.012378150940935306 0.9999991695914602\n",
      "Epoch: 341\n",
      "Arb loss 7.952480053693208e-09\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 0.9719603129909479\n",
      "MAPE:  0.11493571165389113\n",
      "Delta:  0.01774988206271894\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.029730363538630566 0.021948941049266812 -2368801.4882606175\n",
      "Epoch: 342\n",
      "Arb loss 0.0188378545390314\n",
      "Real arb loss 1.8852069517462813e-05\n",
      "Bounds loss: 0.9506268133788827\n",
      "MAPE:  0.11239412088499458\n",
      "Delta:  0.017222171616226488\n",
      "GRAD\n",
      " tensor([-84.6105,   2.6491,  13.2299, 147.9512])\n",
      "-0.0454450059899274 -0.03245033285809518 1.0\n",
      "Epoch: 343\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 0.9814749698968577\n",
      "MAPE:  0.11632547829268233\n",
      "Delta:  0.018004833308485457\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.036229818415491666 0.02453366455685768 -inf\n",
      "Epoch: 344\n",
      "Arb loss 0.005316066515525873\n",
      "Real arb loss 5.332771376202263e-06\n",
      "Bounds loss: 0.9573957922144563\n",
      "MAPE:  0.11335332480094971\n",
      "Delta:  0.017352521467117833\n",
      "GRAD\n",
      " tensor([-38.6160,   0.8544,   5.2494,  70.2993])\n",
      "-0.010444716324655934 -0.0034081739287394885 0.9415262343502483\n",
      "Epoch: 345\n",
      "Arb loss 0.0003108504276073522\n",
      "Real arb loss 3.117972646176359e-07\n",
      "Bounds loss: 0.9606587635929664\n",
      "MAPE:  0.11389888344763506\n",
      "Delta:  0.01753376363135938\n",
      "GRAD\n",
      " tensor([-0.0217, -0.0091, -0.0038,  0.0163])\n",
      "0.02543730129155064 0.020803086959026218 -80.33320215887248\n",
      "Epoch: 346\n",
      "Arb loss 0.02528246066976073\n",
      "Real arb loss 2.5282332795721258e-05\n",
      "Bounds loss: 0.9406740957959914\n",
      "MAPE:  0.11150184617978343\n",
      "Delta:  0.01708775200309366\n",
      "GRAD\n",
      " tensor([-99.8234,   3.3085,  14.5870, 175.4555])\n",
      "-0.057737411214495715 -0.04339813420505578 1.0\n",
      "Epoch: 347\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 0.9814975964485653\n",
      "MAPE:  0.1166693042368156\n",
      "Delta:  0.0180743545672276\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.04003678736812888 0.02642881626208482 -inf\n",
      "arb imp changed to 991.0392396813949\n",
      "Epoch: 348\n",
      "Arb loss 0.000958067446943234\n",
      "Real arb loss 9.601321582622392e-07\n",
      "Bounds loss: 0.9555577768103483\n",
      "MAPE:  0.11345171131589359\n",
      "Delta:  0.01735071547660334\n",
      "GRAD\n",
      " tensor([-7.7318,  0.7703,  1.6509, 14.8604])\n",
      "0.01357059625072543 0.015352185257208162 -15.399338655915933\n",
      "Delta imp changed to 0.02764376770927562\n",
      "Epoch: 349\n",
      "Arb loss 0.015711672517630865\n",
      "Real arb loss 1.5726836235982456e-05\n",
      "Bounds loss: 0.9408878767967899\n",
      "MAPE:  0.11172029465090473\n",
      "Delta:  0.0166978106558138\n",
      "GRAD\n",
      " tensor([-84.5473,   2.7004,  13.2618, 147.9306])\n",
      "-0.04509123792384728 -0.03284641280380751 1.0\n",
      "Epoch: 350\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 0.9717926684001553\n",
      "MAPE:  0.11575055105868572\n",
      "Delta:  0.01745073560890245\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.036099645580561335 0.024700076419306494 -inf\n",
      "Epoch: 351\n",
      "Arb loss 0.002511429198007514\n",
      "Real arb loss 2.5189353751069106e-06\n",
      "Bounds loss: 0.9477893152269496\n",
      "MAPE:  0.11272515072517322\n",
      "Delta:  0.016820770238300992\n",
      "GRAD\n",
      " tensor([-23.1101,   0.3551,   3.9748,  42.4885])\n",
      "0.000796163040770459 0.0058876740769606695 -0.24370594070664864\n",
      "Epoch: 352\n",
      "Arb loss 0.003123479413226079\n",
      "Real arb loss 3.132694112652275e-06\n",
      "Bounds loss: 0.9422090406452677\n",
      "MAPE:  0.11215939566927205\n",
      "Delta:  0.016807378162719964\n",
      "GRAD\n",
      " tensor([-23.1195,   0.3422,   3.9656,  42.4607])\n",
      "0.004070392850065052 0.005975417087034085 -1.5448920420310657\n",
      "Epoch: 353\n",
      "Arb loss 0.007948917902166912\n",
      "Real arb loss 7.967497484740016e-06\n",
      "Bounds loss: 0.936578948644238\n",
      "MAPE:  0.11155040669669727\n",
      "Delta:  0.01673896553081809\n",
      "GRAD\n",
      " tensor([-53.9506,   2.4411,   9.5672,  94.8164])\n",
      "-0.016750285948863075 -0.012353443230493255 0.9999820919938978\n",
      "Epoch: 354\n",
      "Arb loss 1.4234927029820885e-07\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 0.9481489235171896\n",
      "MAPE:  0.11315638670524396\n",
      "Delta:  0.017019347989947455\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.02918202889674204 0.021895875478673776 -163522.27798677373\n",
      "Epoch: 355\n",
      "Arb loss 0.023277419298188398\n",
      "Real arb loss 2.3275196970449977e-05\n",
      "Bounds loss: 0.9273883727526187\n",
      "MAPE:  0.11055612151026932\n",
      "Delta:  0.0165226888851011\n",
      "GRAD\n",
      " tensor([-99.7702,   3.3577,  14.6189, 175.5220])\n",
      "-0.05749430586909354 -0.044118658291506296 1.0\n",
      "Epoch: 356\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 0.9683035034736076\n",
      "MAPE:  0.11588966519008527\n",
      "Delta:  0.017472649413640975\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.039733076194244155 0.02656619877017108 -inf\n",
      "Epoch: 357\n",
      "Arb loss 0.000667751821729994\n",
      "Real arb loss 6.698318214204655e-07\n",
      "Bounds loss: 0.9425793601304747\n",
      "MAPE:  0.11261406359315848\n",
      "Delta:  0.016778407303173464\n",
      "GRAD\n",
      " tensor([-7.7196,  0.7776,  1.6549, 14.8601])\n",
      "0.013683957630524102 0.01544854178306887 -15.380181508467665\n",
      "Epoch: 358\n",
      "Arb loss 0.010937896042547244\n",
      "Real arb loss 1.0957130852874059e-05\n",
      "Bounds loss: 0.9280178835016408\n",
      "MAPE:  0.110824325817262\n",
      "Delta:  0.016548812288529162\n",
      "GRAD\n",
      " tensor([-53.7865,   2.5586,   9.6367,  94.7385])\n",
      "-0.02248665034418673 -0.013225715605495125 0.9999918592173297\n",
      "arb imp changed to 991.3364820914525\n",
      "Epoch: 359\n",
      "Arb loss 8.90875560702238e-08\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 0.940291584105647\n",
      "MAPE:  0.1125826226111769\n",
      "Delta:  0.0169209396440729\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.029005435920873235 0.021918269199853957 -209570.9543896617\n",
      "Delta imp changed to 0.026969529472464022\n",
      "Epoch: 360\n",
      "Arb loss 0.01867025323743537\n",
      "Real arb loss 1.8669339371689026e-05\n",
      "Bounds loss: 0.9196820200388622\n",
      "MAPE:  0.10995531375963925\n",
      "Delta:  0.016029405281469053\n",
      "GRAD\n",
      " tensor([-84.2365,   2.8886,  13.3647, 147.6218])\n",
      "-0.04539034324617086 -0.03361602342842396 1.0\n",
      "Epoch: 361\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 0.9505980723711889\n",
      "MAPE:  0.11409779257685353\n",
      "Delta:  0.016756985489226918\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.035342187008737036 0.024512305966230996 -inf\n",
      "Epoch: 362\n",
      "Arb loss 0.004764458082242196\n",
      "Real arb loss 4.776829610406791e-06\n",
      "Bounds loss: 0.927296721570317\n",
      "MAPE:  0.1111115712210611\n",
      "Delta:  0.016164756974363967\n",
      "GRAD\n",
      " tensor([-38.4426,   0.9683,   5.3143,  70.1228])\n",
      "-0.01004178595828975 -0.003566374136817263 0.9254348180851656\n",
      "Epoch: 363\n",
      "Arb loss 0.0003552626836279925\n",
      "Real arb loss 3.563305759222077e-07\n",
      "Bounds loss: 0.9306038086152807\n",
      "MAPE:  0.11168112772244179\n",
      "Delta:  0.016327080003968302\n",
      "GRAD\n",
      " tensor([-0.0161, -0.0067, -0.0028,  0.0122])\n",
      "0.024918277226611663 0.02083766733371728 -65.82739039752525\n",
      "Epoch: 364\n",
      "Arb loss 0.023741278052480358\n",
      "Real arb loss 2.372861364991048e-05\n",
      "Bounds loss: 0.9112121960318652\n",
      "MAPE:  0.10921024037292627\n",
      "Delta:  0.015920237298128352\n",
      "GRAD\n",
      " tensor([-84.2963,   2.8442,  13.3381, 147.8629])\n",
      "-0.04607934651216006 -0.03381096505531089 1.0\n",
      "Epoch: 365\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 0.9420211597498716\n",
      "MAPE:  0.11334898925398339\n",
      "Delta:  0.016653831429144623\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.035653036122331394 0.024625788835894502 -inf\n",
      "Epoch: 366\n",
      "Arb loss 0.0065689003297366225\n",
      "Real arb loss 6.583305411760228e-06\n",
      "Bounds loss: 0.9188231455909268\n",
      "MAPE:  0.11037675838365305\n",
      "Delta:  0.016060071775626114\n",
      "GRAD\n",
      " tensor([-53.6931,   2.6236,   9.6746,  94.6272])\n",
      "-0.020192443422125894 -0.012653913846600195 1.0\n",
      "Epoch: 367\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 0.9304498545154966\n",
      "MAPE:  0.11206666167644917\n",
      "Delta:  0.016384363866310724\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.028144333456011306 0.021925749987282694 -inf\n",
      "Epoch: 368\n",
      "Arb loss 0.015683948634365657\n",
      "Real arb loss 1.5697471223167632e-05\n",
      "Bounds loss: 0.9100490436296863\n",
      "MAPE:  0.10939484189414098\n",
      "Delta:  0.015923236866192653\n",
      "GRAD\n",
      " tensor([-69.0186,   2.2256,  10.0036, 122.3499])\n",
      "-0.034310825761809216 -0.023860258151975122 1.0\n",
      "Epoch: 369\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 0.9317630487416487\n",
      "MAPE:  0.11241743998902547\n",
      "Delta:  0.016469576271872607\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.03186969313304022 0.023181023194317585 -inf\n",
      "arb imp changed to 991.4355166357471\n",
      "Epoch: 370\n",
      "Arb loss 0.010544584986333946\n",
      "Real arb loss 1.0557818754316272e-05\n",
      "Bounds loss: 0.9101638278971604\n",
      "MAPE:  0.10959051331529922\n",
      "Delta:  0.015944695930056825\n",
      "GRAD\n",
      " tensor([-53.7837,   2.5717,   9.6472,  94.8414])\n",
      "-0.022160787841912777 -0.013661860957137506 0.9999985725598399\n",
      "Epoch: 371\n",
      "Arb loss 1.5051764081207996e-08\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 0.9225983595621076\n",
      "MAPE:  0.11139370427939195\n",
      "Delta:  0.016298042953766623\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.028722345632753554 0.022032332014583655 -1218447.3411532396\n",
      "Epoch: 372\n",
      "Arb loss 0.0183397969761778\n",
      "Real arb loss 1.8340118081007304e-05\n",
      "Bounds loss: 0.902271366188125\n",
      "MAPE:  0.10872280083474162\n",
      "Delta:  0.015829924930911076\n",
      "GRAD\n",
      " tensor([-84.1828,   2.9314,  13.3910, 147.7617])\n",
      "-0.04518248910273903 -0.03411933610247564 1.0\n",
      "Epoch: 373\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 0.9330562661867376\n",
      "MAPE:  0.11295795274124808\n",
      "Delta:  0.016545160341599145\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.034895956262301575 0.024596492666197456 -inf\n",
      "Epoch: 374\n",
      "Arb loss 0.002893704418602786\n",
      "Real arb loss 2.9011705813255344e-06\n",
      "Bounds loss: 0.9101063545783259\n",
      "MAPE:  0.10991723894184546\n",
      "Delta:  0.015967801149965932\n",
      "GRAD\n",
      " tensor([-23.0091,   0.4212,   4.0123,  42.4186])\n",
      "0.0010781713140488591 0.0058115226578071555 -0.28758896014001767\n",
      "Delta imp changed to 0.02631173607069661\n",
      "Epoch: 375\n",
      "Arb loss 0.0037259018633013356\n",
      "Real arb loss 3.7346903969389008e-06\n",
      "Bounds loss: 0.9048172508776796\n",
      "MAPE:  0.1093552610236295\n",
      "Delta:  0.015561546463236688\n",
      "GRAD\n",
      " tensor([-23.0250,   0.4056,   4.0020,  42.4027])\n",
      "0.003905735557434342 0.005853014503768739 -1.360155153908599\n",
      "Epoch: 376\n",
      "Arb loss 0.0087937064856283\n",
      "Real arb loss 8.807967850118577e-06\n",
      "Bounds loss: 0.8995213423850323\n",
      "MAPE:  0.10876367187967657\n",
      "Delta:  0.015500767177886557\n",
      "GRAD\n",
      " tensor([-53.7243,   2.5922,   9.6539,  94.6734])\n",
      "-0.018094020962106994 -0.013662054485710895 0.9999897078588276\n",
      "Epoch: 377\n",
      "Arb loss 9.050606857947461e-08\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 0.9118106519757565\n",
      "MAPE:  0.11051598796103826\n",
      "Delta:  0.015781238384131976\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.029260872526776227 0.02216226994925874 -240429.27666153267\n",
      "Epoch: 378\n",
      "Arb loss 0.021760399108110732\n",
      "Real arb loss 2.1752552514664355e-05\n",
      "Bounds loss: 0.8916028581640602\n",
      "MAPE:  0.10784308204652102\n",
      "Delta:  0.015319465579459223\n",
      "GRAD\n",
      " tensor([-84.2075,   2.9082,  13.3759, 147.9517])\n",
      "-0.045528194703697844 -0.034683767572358803 1.0\n",
      "Epoch: 379\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 0.9225270044634732\n",
      "MAPE:  0.11212065026432458\n",
      "Delta:  0.01601693319111744\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.03526486425130093 0.02480818899919257 -inf\n",
      "Epoch: 380\n",
      "Arb loss 0.00377294962204731\n",
      "Real arb loss 3.7824277360793e-06\n",
      "Bounds loss: 0.8996407801798845\n",
      "MAPE:  0.10906951554888285\n",
      "Delta:  0.015452098216410526\n",
      "GRAD\n",
      " tensor([-23.0260,   0.4108,   4.0066,  42.4777])\n",
      "0.0011466143429482711 0.005668048605854459 -0.27784143855681287\n",
      "arb imp changed to 991.732877901156\n",
      "Epoch: 381\n",
      "Arb loss 0.0048236419883256375\n",
      "Real arb loss 4.8323834457943344e-06\n",
      "Bounds loss: 0.8945415725100161\n",
      "MAPE:  0.10852471942557457\n",
      "Delta:  0.015434380618966945\n",
      "GRAD\n",
      " tensor([-38.2673,   1.0695,   5.3682,  69.8946])\n",
      "-0.007101092747196613 -0.0038868778751148803 0.8374920694408606\n",
      "Epoch: 382\n",
      "Arb loss 0.0007838800772809716\n",
      "Real arb loss 7.853181079001265e-07\n",
      "Bounds loss: 0.8980185463565757\n",
      "MAPE:  0.10910600176839319\n",
      "Delta:  0.015543981587237762\n",
      "GRAD\n",
      " tensor([-7.6889,  0.7947,  1.6638, 14.8105])\n",
      "0.01914614228586775 0.015886469127252112 -20.735785315109542\n",
      "Epoch: 383\n",
      "Arb loss 0.017038249072570674\n",
      "Real arb loss 1.7033031417296764e-05\n",
      "Bounds loss: 0.8837522024441822\n",
      "MAPE:  0.10724871076765184\n",
      "Delta:  0.015246374304079598\n",
      "GRAD\n",
      " tensor([-68.7353,   2.3893,  10.0908, 122.0235])\n",
      "-0.033062473773529444 -0.024592194468523676 1.0\n",
      "Epoch: 384\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 0.9054856084686755\n",
      "MAPE:  0.11029998726735547\n",
      "Delta:  0.015750457154649643\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.03208572408307697 0.023334253187705656 -inf\n",
      "Epoch: 385\n",
      "Arb loss 0.01260569100403737\n",
      "Real arb loss 1.261303455789431e-05\n",
      "Bounds loss: 0.8843567780228437\n",
      "MAPE:  0.10749177325428697\n",
      "Delta:  0.015245092332203228\n",
      "GRAD\n",
      " tensor([-53.5570,   1.7022,   8.7165,  94.6540])\n",
      "-0.022055827707214926 -0.014258569913045527 0.9999759507308775\n",
      "Epoch: 386\n",
      "Arb loss 3.03157655430532e-07\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 0.8969664409703582\n",
      "MAPE:  0.1093585901196555\n",
      "Delta:  0.015581335462062886\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.028261726592659242 0.021957372599064495 -67040.50006107122\n",
      "Delta imp changed to 0.02566998641043572\n",
      "Epoch: 387\n",
      "Arb loss 0.02032414397506022\n",
      "Real arb loss 2.0312016427431326e-05\n",
      "Bounds loss: 0.8772714146171152\n",
      "MAPE:  0.10671539476619471\n",
      "Delta:  0.01477168782369323\n",
      "GRAD\n",
      " tensor([-83.7868,   2.1584,  13.5114, 146.4404])\n",
      "-0.04546746315849037 -0.03488320131966538 1.0\n",
      "Epoch: 388\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 0.9078734499851917\n",
      "MAPE:  0.11102647722096766\n",
      "Delta:  0.015443318995605724\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.03482052371719535 0.02478120683360685 -inf\n",
      "Epoch: 389\n",
      "Arb loss 0.004980741727792783\n",
      "Real arb loss 4.991629044464721e-06\n",
      "Bounds loss: 0.8853752502423685\n",
      "MAPE:  0.10797188267082446\n",
      "Delta:  0.01490557454024702\n",
      "GRAD\n",
      " tensor([-38.2499,   1.0879,   5.3805,  70.0276])\n",
      "-0.009897256544190602 -0.004210359200251146 0.9208212475823102\n",
      "Epoch: 390\n",
      "Arb loss 0.00039436891612136104\n",
      "Real arb loss 3.953674912951996e-07\n",
      "Bounds loss: 0.889102998072901\n",
      "MAPE:  0.10863422077137071\n",
      "Delta:  0.015053098835410401\n",
      "GRAD\n",
      " tensor([-0.0187, -0.0078, -0.0032,  0.0142])\n",
      "0.02433168741436942 0.020932134194949326 -58.378902645384855\n",
      "Epoch: 391\n",
      "Arb loss 0.023417193476736244\n",
      "Real arb loss 2.339742426917168e-05\n",
      "Bounds loss: 0.8704921748041073\n",
      "MAPE:  0.10612136132449174\n",
      "Delta:  0.014686831539929588\n",
      "GRAD\n",
      " tensor([-83.8090,   2.1393,  13.4994, 147.6121])\n",
      "-0.04624642376277621 -0.035560109736758605 1.0\n",
      "Epoch: 392\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 0.901446972065131\n",
      "MAPE:  0.11051621100252113\n",
      "Delta:  0.015366044975057678\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.03467173752164854 0.024761077630660933 -inf\n",
      "arb imp changed to 991.9311352406083\n",
      "Epoch: 393\n",
      "Arb loss 0.0056778313228697565\n",
      "Real arb loss 5.687143133856737e-06\n",
      "Bounds loss: 0.8791261736099021\n",
      "MAPE:  0.10746441350189663\n",
      "Delta:  0.014833277496936631\n",
      "GRAD\n",
      " tensor([-38.2738,   1.0763,   5.3750,  70.0910])\n",
      "-0.009939291332414335 -0.0043509581868113045 0.9115273296938198\n",
      "Epoch: 394\n",
      "Arb loss 0.0005023328986823588\n",
      "Real arb loss 5.034453905272025e-07\n",
      "Bounds loss: 0.8829512148322101\n",
      "MAPE:  0.1081448424569882\n",
      "Delta:  0.01498070976339323\n",
      "GRAD\n",
      " tensor([-7.6809,  0.8005,  1.6672, 14.8231])\n",
      "0.018480515153150523 0.015905421816740817 -28.607182525395594\n",
      "Epoch: 395\n",
      "Arb loss 0.014872661819799647\n",
      "Real arb loss 1.487296874928867e-05\n",
      "Bounds loss: 0.8689075033167001\n",
      "MAPE:  0.10626200008758643\n",
      "Delta:  0.014703858529605892\n",
      "GRAD\n",
      " tensor([-68.6645,   2.4417,  10.1222, 122.0987])\n",
      "-0.03276819952489607 -0.02509074091244612 1.0\n",
      "Epoch: 396\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 0.8907090363592998\n",
      "MAPE:  0.10940173240790924\n",
      "Delta:  0.015185677499689864\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.031196764488951034 0.023335598450773265 -inf\n",
      "Epoch: 397\n",
      "Arb loss 0.010570502414745622\n",
      "Real arb loss 1.0579620006824491e-05\n",
      "Bounds loss: 0.869923807950344\n",
      "MAPE:  0.1065426288219445\n",
      "Delta:  0.014711933495126875\n",
      "GRAD\n",
      " tensor([-53.4963,   1.7478,   8.7439,  94.6954])\n",
      "-0.022249512275148486 -0.014678852307624668 0.9999989488153269\n",
      "Epoch: 398\n",
      "Arb loss 1.1111550125113148e-08\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 0.8826932910461336\n",
      "MAPE:  0.10846236603182956\n",
      "Delta:  0.015039266840017869\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.02810267091707619 0.022181193269373622 -1552978.0610874114\n",
      "Epoch: 399\n",
      "Arb loss 0.017256004680523927\n",
      "Real arb loss 1.7250393265427536e-05\n",
      "Bounds loss: 0.8631141005598599\n",
      "MAPE:  0.10577373037960552\n",
      "Delta:  0.014616623273178751\n",
      "GRAD\n",
      " tensor([-68.6851,   2.4308,  10.1167, 122.2827])\n",
      "-0.03406504379259667 -0.025344935137425084 1.0\n",
      "Epoch: 400\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 0.8849896714547465\n",
      "MAPE:  0.10896558378404814\n",
      "Delta:  0.015114539185079476\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.03083155697215334 0.02326026372452561 -inf\n",
      "Epoch: 401\n",
      "Arb loss 0.008207006716174586\n",
      "Real arb loss 8.21591019564686e-06\n",
      "Bounds loss: 0.8644045783032278\n",
      "MAPE:  0.10610851056603694\n",
      "Delta:  0.014648534409086854\n",
      "GRAD\n",
      " tensor([-38.1201,   1.1629,   5.4204,  69.9360])\n",
      "-0.011785440315019269 -0.0053328157097634055 0.9172945111666377\n",
      "Epoch: 402\n",
      "Arb loss 0.0006787645023199065\n",
      "Real arb loss 6.797310954737914e-07\n",
      "Bounds loss: 0.8690142886179946\n",
      "MAPE:  0.10690162263747105\n",
      "Delta:  0.014821173837067653\n",
      "GRAD\n",
      " tensor([-0.0207, -0.0086, -0.0036,  0.0156])\n",
      "0.02465986395747921 0.020891528886124222 -44.312032829237125\n",
      "Epoch: 403\n",
      "Arb loss 0.030756199412440406\n",
      "Real arb loss 3.069481881737457e-05\n",
      "Bounds loss: 0.8508592515048771\n",
      "MAPE:  0.10441398574152078\n",
      "Delta:  0.014455685706555414\n",
      "GRAD\n",
      " tensor([-98.8253,   2.9102,  13.9153, 175.1816])\n",
      "-0.05753457998944955 -0.04760504499308493 1.0\n",
      "Epoch: 404\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 0.8913644444555493\n",
      "MAPE:  0.11016759223721091\n",
      "Delta:  0.015287387512141568\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.0373631575559662 0.026441593516114192 -inf\n",
      "arb imp changed to 992.1294322136894\n",
      "Epoch: 405\n",
      "Arb loss 0.0010280020238023994\n",
      "Real arb loss 1.0289894706375161e-06\n",
      "Bounds loss: 0.8677953481405387\n",
      "MAPE:  0.10689512180848976\n",
      "Delta:  0.014716202443906314\n",
      "GRAD\n",
      " tensor([-7.6625,  0.8157,  1.6767, 14.8308])\n",
      "0.013395784325080373 0.015265562179087477 -11.191521555533408\n",
      "Delta imp changed to 0.0250438891809129\n",
      "Epoch: 406\n",
      "Arb loss 0.012532908832318918\n",
      "Real arb loss 1.2532975040682259e-05\n",
      "Bounds loss: 0.8545479642947765\n",
      "MAPE:  0.10513911483361428\n",
      "Delta:  0.014164943775496121\n",
      "GRAD\n",
      " tensor([-53.2740,   1.8743,   7.8107,  93.4704])\n",
      "-0.021970113186976947 -0.014446887815491971 0.9999688164919609\n",
      "Epoch: 407\n",
      "Arb loss 3.908200633257413e-07\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 0.8668935228679002\n",
      "MAPE:  0.1070265121518234\n",
      "Delta:  0.014476149193530937\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.02744513652382108 0.021916394115031657 -48957.15050702468\n",
      "Epoch: 408\n",
      "Arb loss 0.01913382748146656\n",
      "Real arb loss 1.91145897728565e-05\n",
      "Bounds loss: 0.8478943427649592\n",
      "MAPE:  0.10439377799269306\n",
      "Delta:  0.014078849302575277\n",
      "GRAD\n",
      " tensor([-68.3777,   2.6029,   9.2066, 120.9527])\n",
      "-0.033816517356426434 -0.025226160224176564 1.0\n",
      "Epoch: 409\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 0.8692834613087209\n",
      "MAPE:  0.10754348623306738\n",
      "Delta:  0.014554946954374327\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.030821489079624342 0.023231349980730398 -inf\n",
      "Epoch: 410\n",
      "Arb loss 0.012127599159774245\n",
      "Real arb loss 1.2130436181716255e-05\n",
      "Bounds loss: 0.8490888329865973\n",
      "MAPE:  0.10472583544727478\n",
      "Delta:  0.014106341815765568\n",
      "GRAD\n",
      " tensor([-53.2521,   1.8833,   7.8144,  93.4826])\n",
      "-0.021495523332530242 -0.01459492263778861 0.99997253952774\n",
      "Epoch: 411\n",
      "Arb loss 3.330296003075241e-07\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 0.861481218816647\n",
      "MAPE:  0.10662191034848109\n",
      "Delta:  0.014409565015403004\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.027449552933115906 0.021984317381227303 -57759.79973119203\n",
      "Epoch: 412\n",
      "Arb loss 0.019236056047921828\n",
      "Real arb loss 1.9218706286216677e-05\n",
      "Bounds loss: 0.8425421422842153\n",
      "MAPE:  0.10398309661115053\n",
      "Delta:  0.014014028897769525\n",
      "GRAD\n",
      " tensor([-68.3578,   2.6110,   9.2100, 121.0100])\n",
      "-0.034035895949013906 -0.02565872719663953 1.0\n",
      "Epoch: 413\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 0.8641607012647582\n",
      "MAPE:  0.1071875853660064\n",
      "Delta:  0.01449100892716048\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.030762994778296693 0.023307652187232297 -inf\n",
      "Epoch: 414\n",
      "Arb loss 0.011898692652971605\n",
      "Real arb loss 1.1903691761541476e-05\n",
      "Bounds loss: 0.8440191442058045\n",
      "MAPE:  0.1043512517667793\n",
      "Delta:  0.014045222095201992\n",
      "GRAD\n",
      " tensor([-53.2323,   1.8931,   7.8191,  93.5167])\n",
      "-0.02150800953620502 -0.014746540132743347 0.9999795595351663\n",
      "Epoch: 415\n",
      "Arb loss 2.432148087399062e-07\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 0.856465506388639\n",
      "MAPE:  0.10626426397592396\n",
      "Delta:  0.014347306865963715\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.027371679064067567 0.022046191045141383 -77625.8145883091\n",
      "arb imp changed to 992.4270016052051\n",
      "Epoch: 416\n",
      "Arb loss 0.01888943085861535\n",
      "Real arb loss 1.886610662346523e-05\n",
      "Bounds loss: 0.8375837042112213\n",
      "MAPE:  0.10361740813003142\n",
      "Delta:  0.013954596986994862\n",
      "GRAD\n",
      " tensor([-68.3650,   2.6107,   9.2109, 121.0767])\n",
      "-0.03407139582214347 -0.025882610375717707 1.0\n",
      "Epoch: 417\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 0.8592625568843708\n",
      "MAPE:  0.1068536428447136\n",
      "Delta:  0.014430049584477255\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.03067625340980229 0.023377722504336007 -inf\n",
      "Epoch: 418\n",
      "Arb loss 0.011550539946693212\n",
      "Real arb loss 1.1551996888020468e-05\n",
      "Bounds loss: 0.8391749552711618\n",
      "MAPE:  0.10399726738544918\n",
      "Delta:  0.013987389726707818\n",
      "GRAD\n",
      " tensor([-53.2370,   1.8938,   7.8205,  94.5651])\n",
      "-0.021938474584733303 -0.015287552824110984 0.9999904639823092\n",
      "Epoch: 419\n",
      "Arb loss 1.101461532708133e-07\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 0.8520038867285407\n",
      "MAPE:  0.10597993167953242\n",
      "Delta:  0.014294251720733956\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.027390216397176093 0.022156443120095348 -162061.81880863174\n",
      "Epoch: 420\n",
      "Arb loss 0.0178505960799956\n",
      "Real arb loss 1.78330833005961e-05\n",
      "Bounds loss: 0.8331265110741395\n",
      "MAPE:  0.10331054836555023\n",
      "Delta:  0.013902729072867347\n",
      "GRAD\n",
      " tensor([-68.3277,   2.6326,   9.2226, 121.0914])\n",
      "-0.034066942164074465 -0.02608447627188193 1.0\n",
      "Epoch: 421\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 0.8548581797837287\n",
      "MAPE:  0.10657750076009592\n",
      "Delta:  0.014376352540115513\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.030628383798413816 0.023477427574100096 -inf\n",
      "Epoch: 422\n",
      "Arb loss 0.010764850416661472\n",
      "Real arb loss 1.0769223170204792e-05\n",
      "Bounds loss: 0.8347883087817292\n",
      "MAPE:  0.10369252287320677\n",
      "Delta:  0.013936028096895554\n",
      "GRAD\n",
      " tensor([-53.2078,   1.9110,   7.8298,  94.5769])\n",
      "-0.021969586850771217 -0.015425886049120985 0.9999971960609559\n",
      "Epoch: 423\n",
      "Arb loss 3.0183984386696814e-08\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 0.8476656581081345\n",
      "MAPE:  0.1057041612298041\n",
      "Delta:  0.014242196876525089\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.027329012647806183 0.02224260522563748 -555565.9401239206\n",
      "Epoch: 424\n",
      "Arb loss 0.01676922384646534\n",
      "Real arb loss 1.675683860791655e-05\n",
      "Bounds loss: 0.8288113655115051\n",
      "MAPE:  0.10300818687610531\n",
      "Delta:  0.013852971697953988\n",
      "GRAD\n",
      " tensor([-68.2902,   2.6550,   9.2348, 121.1037])\n",
      "-0.03336952401047677 -0.025942941567355104 1.0\n",
      "Epoch: 425\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 0.8503131703373299\n",
      "MAPE:  0.10627800626605875\n",
      "Delta:  0.014315238769645319\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.02987451785877726 0.023313912064411246 -inf\n",
      "Epoch: 426\n",
      "Arb loss 0.007804545163647003\n",
      "Real arb loss 7.810341003824993e-06\n",
      "Bounds loss: 0.8304890438568746\n",
      "MAPE:  0.10339120790221455\n",
      "Delta:  0.013887577913368889\n",
      "GRAD\n",
      " tensor([-37.8967,   1.2900,   5.4874,  68.8299])\n",
      "-0.011520400118055552 -0.005585527019268621 0.9113306546802672\n",
      "arb imp changed to 992.6253977069412\n",
      "Epoch: 427\n",
      "Arb loss 0.000692369922133956\n",
      "Real arb loss 6.927276076404663e-07\n",
      "Bounds loss: 0.8351277628505438\n",
      "MAPE:  0.10422568415686514\n",
      "Delta:  0.014047568367601569\n",
      "GRAD\n",
      " tensor([-0.0157, -0.0065, -0.0027,  0.0119])\n",
      "0.024040610791474126 0.020951323652292464 -41.35672245419194\n",
      "Epoch: 428\n",
      "Arb loss 0.02932652062745846\n",
      "Real arb loss 2.924188114183518e-05\n",
      "Bounds loss: 0.8176307308000471\n",
      "MAPE:  0.10173696346414288\n",
      "Delta:  0.013709856243909437\n",
      "GRAD\n",
      " tensor([-98.2623,   3.2366,  14.0892, 173.9159])\n",
      "-0.05680367239387585 -0.048635006391812174 1.0\n",
      "Epoch: 429\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 0.8573962066186495\n",
      "MAPE:  0.10763303844716753\n",
      "Delta:  0.0144886264265556\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.03622374173153864 0.026526951591512082 -inf\n",
      "Epoch: 430\n",
      "Arb loss 0.0008736033785903586\n",
      "Real arb loss 8.741674392045985e-07\n",
      "Bounds loss: 0.8346520989509305\n",
      "MAPE:  0.10431825706742567\n",
      "Delta:  0.013963794164835305\n",
      "GRAD\n",
      " tensor([-7.6138,  0.8433,  1.6912, 14.8027])\n",
      "0.013229592905341092 0.015280516568030866 -12.100051927424\n",
      "Delta imp changed to 0.024433062615524782\n",
      "Epoch: 431\n",
      "Arb loss 0.011444249623506745\n",
      "Real arb loss 1.1440845011283054e-05\n",
      "Bounds loss: 0.8218981837243691\n",
      "MAPE:  0.10254563757760705\n",
      "Delta:  0.013442984246459082\n",
      "GRAD\n",
      " tensor([-52.9437,   1.0639,   7.9112,  93.2913])\n",
      "-0.02244702049847036 -0.015511393482862124 0.9999780539685873\n",
      "Epoch: 432\n",
      "Arb loss 2.5115586173214113e-07\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 0.8346469698549674\n",
      "MAPE:  0.10458551628192514\n",
      "Delta:  0.013744739189399963\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.02693614273997158 0.02210675920082994 -66818.40836450376\n",
      "Epoch: 433\n",
      "Arb loss 0.01678208608821878\n",
      "Real arb loss 1.676212316671371e-05\n",
      "Bounds loss: 0.8161956302746813\n",
      "MAPE:  0.10190865581456274\n",
      "Delta:  0.013374508932670606\n",
      "GRAD\n",
      " tensor([-67.9275,   2.8636,   9.3455, 120.6721])\n",
      "-0.03392572035901531 -0.026550359684436753 1.0\n",
      "Epoch: 434\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 0.8378659178313397\n",
      "MAPE:  0.1052381287987799\n",
      "Delta:  0.013828248782659541\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.030232282957934897 0.023484285258376758 -inf\n",
      "Epoch: 435\n",
      "Arb loss 0.009542233952346206\n",
      "Real arb loss 9.543720487358176e-06\n",
      "Bounds loss: 0.8181892356087168\n",
      "MAPE:  0.10233694580365206\n",
      "Delta:  0.01341018925264946\n",
      "GRAD\n",
      " tensor([-52.8951,   1.0930,   7.9269,  93.2392])\n",
      "-0.02191135573580061 -0.015617535224957457 0.9999923517561771\n",
      "Epoch: 436\n",
      "Arb loss 7.29813318826207e-08\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 0.830967334816517\n",
      "MAPE:  0.10439667627660437\n",
      "Delta:  0.013704024679848673\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.027028935147280886 0.02226494449147176 -207281.40946162795\n",
      "Epoch: 437\n",
      "Arb loss 0.015127746318348349\n",
      "Real arb loss 1.5114310515304338e-05\n",
      "Bounds loss: 0.8124658932326011\n",
      "MAPE:  0.10167782346060647\n",
      "Delta:  0.013333619485520306\n",
      "GRAD\n",
      " tensor([-52.9768,   2.0377,   7.8952,  93.4525])\n",
      "-0.022871146374917606 -0.015892606869833736 0.9996466795156027\n",
      "arb imp changed to 992.9231158533927\n",
      "Epoch: 438\n",
      "Arb loss 5.347615128367192e-06\n",
      "Real arb loss 4.875882448927837e-09\n",
      "Bounds loss: 0.8253780942688951\n",
      "MAPE:  0.10374185945142925\n",
      "Delta:  0.013638574648481094\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.02689434350730957 0.02198589151821484 -3569.646265161708\n",
      "Epoch: 439\n",
      "Arb loss 0.019094441985626563\n",
      "Real arb loss 1.905953739782082e-05\n",
      "Bounds loss: 0.8072314210267882\n",
      "MAPE:  0.10108994485593355\n",
      "Delta:  0.01327177413693476\n",
      "GRAD\n",
      " tensor([-67.9687,   2.8321,   9.3264, 120.8327])\n",
      "-0.033326510368367535 -0.026642137657032494 1.0\n",
      "Epoch: 440\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 0.8287377916668659\n",
      "MAPE:  0.10441956385534455\n",
      "Delta:  0.013714076055315948\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.030067938805744543 0.02344298044009452 -inf\n",
      "Epoch: 441\n",
      "Arb loss 0.011823952494827523\n",
      "Real arb loss 1.1817482047831247e-05\n",
      "Bounds loss: 0.8093097078268525\n",
      "MAPE:  0.10153697933026952\n",
      "Delta:  0.013301722055707382\n",
      "GRAD\n",
      " tensor([-52.9375,   2.0645,   7.9106,  93.3983])\n",
      "-0.0215636478131771 -0.015693049466105835 0.9999795630413544\n",
      "Epoch: 442\n",
      "Arb loss 2.416456281647707e-07\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 0.822010245105179\n",
      "MAPE:  0.10359471315799676\n",
      "Delta:  0.013588555705425425\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.02672040879925408 0.022184542895646975 -74059.24386419871\n",
      "Epoch: 443\n",
      "Arb loss 0.0178963341506004\n",
      "Real arb loss 1.7868810108010336e-05\n",
      "Bounds loss: 0.8037743235619819\n",
      "MAPE:  0.1008971653824369\n",
      "Delta:  0.013225463941985021\n",
      "GRAD\n",
      " tensor([-67.9239,   2.8619,   9.3434, 120.8589])\n",
      "-0.03383024059979034 -0.026842464871986715 1.0\n",
      "Epoch: 444\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 0.8253496076071992\n",
      "MAPE:  0.10426714674169688\n",
      "Delta:  0.013672884569186227\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.029968087018809042 0.023571506555543742 -inf\n",
      "Epoch: 445\n",
      "Arb loss 0.010413034908439298\n",
      "Real arb loss 1.0411647623047264e-05\n",
      "Bounds loss: 0.8058948739208707\n",
      "MAPE:  0.10135759535234418\n",
      "Delta:  0.013263134374618723\n",
      "GRAD\n",
      " tensor([-52.8960,   2.0907,   7.9252,  93.3843])\n",
      "-0.021582222309516785 -0.015800591296698308 0.9999937097299805\n",
      "Epoch: 446\n",
      "Arb loss 6.550080129651088e-08\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 0.8186284894517984\n",
      "MAPE:  0.10342889975869599\n",
      "Delta:  0.013549382289212736\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.02671067799436122 0.022325438263044672 -245293.79452978045\n",
      "Epoch: 447\n",
      "Arb loss 0.016067005595563615\n",
      "Real arb loss 1.60475947897451e-05\n",
      "Bounds loss: 0.8003522496501727\n",
      "MAPE:  0.1006901810012953\n",
      "Delta:  0.013187469101863074\n",
      "GRAD\n",
      " tensor([-67.8739,   2.8937,   9.3612, 120.8428])\n",
      "-0.033853251154295494 -0.027033076585742055 1.0\n",
      "Epoch: 448\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 0.8219882333105368\n",
      "MAPE:  0.104091140623187\n",
      "Delta:  0.013633907805457954\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.02995264863812852 0.023715657126675338 -inf\n",
      "arb imp changed to 993.1216111333379\n",
      "Epoch: 449\n",
      "Arb loss 0.00905264110363346\n",
      "Real arb loss 9.049858728499238e-06\n",
      "Bounds loss: 0.8024942422071825\n",
      "MAPE:  0.10115584619925391\n",
      "Delta:  0.013225536155396435\n",
      "GRAD\n",
      " tensor([-52.8829,   2.1046,   7.9344,  93.3913])\n",
      "-0.021592570255954735 -0.015918773682661147 0.9999999299341004\n",
      "Epoch: 450\n",
      "Arb loss 6.342814425355978e-10\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 0.8152689664305172\n",
      "MAPE:  0.10324174544406037\n",
      "Delta:  0.013511109474004501\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.02669527880981648 0.022453019479333425 -22763671.25937871\n",
      "Epoch: 451\n",
      "Arb loss 0.014438574878086297\n",
      "Real arb loss 1.4418738035728221e-05\n",
      "Bounds loss: 0.7969637164463568\n",
      "MAPE:  0.10047094929118432\n",
      "Delta:  0.013150426639565997\n",
      "GRAD\n",
      " tensor([-67.8601,   2.9100,   9.3723, 120.8544])\n",
      "-0.03334896266108589 -0.027152336401671695 1.0\n",
      "Epoch: 452\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 0.8186031433752347\n",
      "MAPE:  0.10390063254934405\n",
      "Delta:  0.013588979726546234\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.029257232045812098 0.023609119298073966 -inf\n",
      "Epoch: 453\n",
      "Arb loss 0.005740105133992844\n",
      "Real arb loss 5.739663417253328e-06\n",
      "Bounds loss: 0.7992766441055104\n",
      "MAPE:  0.10096323880027028\n",
      "Delta:  0.013191403793420833\n",
      "GRAD\n",
      " tensor([-22.6855,   0.6105,   4.1137,  41.3390])\n",
      "-0.0007606244339615209 0.004225472906941308 -0.27516493387071383\n",
      "Epoch: 454\n",
      "Arb loss 0.007319580783598929\n",
      "Real arb loss 7.319963173235411e-06\n",
      "Bounds loss: 0.7958993223006915\n",
      "MAPE:  0.1005982785931933\n",
      "Delta:  0.013201437497464363\n",
      "GRAD\n",
      " tensor([-37.8822,   1.2938,   5.4881,  68.9422])\n",
      "-0.008251618639131042 -0.006146645621757818 0.9079055344340726\n",
      "Epoch: 455\n",
      "Arb loss 0.0006740928804321751\n",
      "Real arb loss 6.742795391624472e-07\n",
      "Bounds loss: 0.8007914333854711\n",
      "MAPE:  0.10143967422701358\n",
      "Delta:  0.013310370725181764\n",
      "GRAD\n",
      " tensor([-0.0119, -0.0049, -0.0020,  0.0090])\n",
      "0.024245603115725656 0.021178680280289575 -41.89844814089508\n",
      "Epoch: 456\n",
      "Arb loss 0.028917538473366252\n",
      "Real arb loss 2.882240189058574e-05\n",
      "Bounds loss: 0.7838317276466054\n",
      "MAPE:  0.0989193430870421\n",
      "Delta:  0.012987652759255832\n",
      "GRAD\n",
      " tensor([-82.8656,   2.6607,  11.7697, 145.5508])\n",
      "-0.045617715473093456 -0.03893920999400735 1.0\n",
      "Epoch: 457\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 0.8143535158894022\n",
      "MAPE:  0.1036827869524718\n",
      "Delta:  0.0135801198074909\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.032917920207289564 0.025178285815913526 -inf\n",
      "Delta imp changed to 0.02383713425904857\n",
      "Epoch: 458\n",
      "Arb loss 0.004688934477064286\n",
      "Real arb loss 4.6898202560270095e-06\n",
      "Bounds loss: 0.7938494903111448\n",
      "MAPE:  0.10056769177582046\n",
      "Delta:  0.012812771226597545\n",
      "GRAD\n",
      " tensor([-22.6651,   0.6195,   4.1177,  41.3300])\n",
      "0.000994983430192109 0.004732954722555083 -0.24675147648082563\n",
      "Epoch: 459\n",
      "Arb loss 0.005845935982401747\n",
      "Real arb loss 5.846352170051549e-06\n",
      "Bounds loss: 0.7900922366169787\n",
      "MAPE:  0.10013330780138811\n",
      "Delta:  0.012800022731532239\n",
      "GRAD\n",
      " tensor([-37.6398,   1.4309,   5.5601,  68.6433])\n",
      "-0.008772758279571802 -0.006205507472849092 0.8836333484050076\n",
      "arb imp changed to 993.4194781090879\n",
      "Epoch: 460\n",
      "Arb loss 0.0006806121317086288\n",
      "Real arb loss 6.803614467680782e-07\n",
      "Bounds loss: 0.7949951598955454\n",
      "MAPE:  0.10099217991417109\n",
      "Delta:  0.012912314236928995\n",
      "GRAD\n",
      " tensor([-0.0153, -0.0063, -0.0026,  0.0116])\n",
      "0.02398242958797936 0.021186848242705003 -42.42536849065063\n",
      "Epoch: 461\n",
      "Arb loss 0.029555832618654448\n",
      "Real arb loss 2.944474407772654e-05\n",
      "Bounds loss: 0.7781517180891534\n",
      "MAPE:  0.09846260678824036\n",
      "Delta:  0.012602645569923982\n",
      "GRAD\n",
      " tensor([-82.8779,   2.6548,  11.7669, 145.6747])\n",
      "-0.04570681235484164 -0.03931096692286995 1.0\n",
      "Epoch: 462\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 0.8087416145399304\n",
      "MAPE:  0.1032796858006744\n",
      "Delta:  0.013178672326163075\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.032787646875375165 0.025259576030411623 -inf\n",
      "Epoch: 463\n",
      "Arb loss 0.0047255150862238965\n",
      "Real arb loss 4.724844502933059e-06\n",
      "Bounds loss: 0.7883131442385012\n",
      "MAPE:  0.10014202610579849\n",
      "Delta:  0.01274657467164656\n",
      "GRAD\n",
      " tensor([-22.6699,   0.6177,   4.1170,  41.3619])\n",
      "0.0009641384407778064 0.004685270598314806 -0.24956971611612122\n",
      "Epoch: 464\n",
      "Arb loss 0.005904860544795242\n",
      "Real arb loss 5.903431426518755e-06\n",
      "Bounds loss: 0.7846196838415355\n",
      "MAPE:  0.09971216425565489\n",
      "Delta:  0.012734285209017381\n",
      "GRAD\n",
      " tensor([-37.6457,   1.4289,   5.5594,  68.6946])\n",
      "-0.0088282029920701 -0.006332209125696986 0.8903888656328267\n",
      "Epoch: 465\n",
      "Arb loss 0.0006472384625949714\n",
      "Real arb loss 6.471336868821738e-07\n",
      "Bounds loss: 0.7895880597637583\n",
      "MAPE:  0.10059110630146095\n",
      "Delta:  0.012846706063801503\n",
      "GRAD\n",
      " tensor([-7.5624,  0.8688,  1.7036, 13.7559])\n",
      "0.01860961922178106 0.01624349730629615 -23.015948918626165\n",
      "Epoch: 466\n",
      "Arb loss 0.015544045855850964\n",
      "Real arb loss 1.5515596181122783e-05\n",
      "Bounds loss: 0.7767623882419021\n",
      "MAPE:  0.09865281243454618\n",
      "Delta:  0.012607633755700013\n",
      "GRAD\n",
      " tensor([-52.6643,   1.2044,   7.9797,  93.3261])\n",
      "-0.02194528485431313 -0.016876996298516023 0.9909190177097489\n",
      "Epoch: 467\n",
      "Arb loss 0.00014115520513583382\n",
      "Real arb loss 1.4123760692505427e-07\n",
      "Bounds loss: 0.7898718041930872\n",
      "MAPE:  0.10084262822975885\n",
      "Delta:  0.012884311869807702\n",
      "GRAD\n",
      " tensor([-0.0014, -0.0006, -0.0002,  0.0011])\n",
      "0.0265423885678987 0.022156820909888575 -143.73149537771755\n",
      "Epoch: 468\n",
      "Arb loss 0.020429603919657705\n",
      "Real arb loss 2.03781406330442e-05\n",
      "Bounds loss: 0.7723707560858104\n",
      "MAPE:  0.09814530885211781\n",
      "Delta:  0.012542331457729277\n",
      "GRAD\n",
      " tensor([-67.5274,   3.0673,   9.4455, 120.7145])\n",
      "-0.033251951716449346 -0.02800013831483006 1.0\n",
      "Epoch: 469\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 0.793997244086543\n",
      "MAPE:  0.10164115832316843\n",
      "Delta:  0.012959388457773394\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.029286983338819628 0.02361855410618463 -inf\n",
      "Epoch: 470\n",
      "Arb loss 0.011997907920330423\n",
      "Real arb loss 1.1984598988500792e-05\n",
      "Bounds loss: 0.7752441772169236\n",
      "MAPE:  0.09874391184462646\n",
      "Delta:  0.012579847063929294\n",
      "GRAD\n",
      " tensor([-52.5910,   1.2533,   8.0075,  93.2846])\n",
      "-0.021969989431519954 -0.016906045166785066 0.9999788992429415\n",
      "arb imp changed to 993.7174344240833\n",
      "Epoch: 471\n",
      "Arb loss 2.532915227073966e-07\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 0.78835049029224\n",
      "MAPE:  0.10095295925058403\n",
      "Delta:  0.012856226170973959\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.02622193905221104 0.02244232853671324 -68017.80758625864\n",
      "Delta imp changed to 0.023255740740535193\n",
      "Epoch: 472\n",
      "Arb loss 0.01722858734626487\n",
      "Real arb loss 1.7186472866887226e-05\n",
      "Bounds loss: 0.7706580695870225\n",
      "MAPE:  0.09819638594758212\n",
      "Delta:  0.012213766821343649\n",
      "GRAD\n",
      " tensor([-67.4826,   3.1090,   9.4724, 120.6932])\n",
      "-0.03378115943572646 -0.02818195630871645 1.0\n",
      "Epoch: 473\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 0.7923767216330838\n",
      "MAPE:  0.10174325620363428\n",
      "Delta:  0.012626362025646244\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.029255752438603566 0.023867850977351 -inf\n",
      "Epoch: 474\n",
      "Arb loss 0.009220169232530025\n",
      "Real arb loss 9.211511759225116e-06\n",
      "Bounds loss: 0.7734643921232234\n",
      "MAPE:  0.09876912983225113\n",
      "Delta:  0.012256968304023752\n",
      "GRAD\n",
      " tensor([-37.6796,   1.4124,   5.5516,  68.9443])\n",
      "-0.011609826620889274 -0.006808759438649004 0.9058348997893253\n",
      "Epoch: 475\n",
      "Arb loss 0.0008682181597405689\n",
      "Real arb loss 8.681994400566092e-07\n",
      "Bounds loss: 0.7787307251035513\n",
      "MAPE:  0.09974911686605366\n",
      "Delta:  0.012399269580931203\n",
      "GRAD\n",
      " tensor([-7.5733,  0.8643,  1.7017, 13.7885])\n",
      "0.0178899919609542 0.01615132586661394 -17.9234201788313\n",
      "Epoch: 476\n",
      "Arb loss 0.01642965704366246\n",
      "Real arb loss 1.6392955160367356e-05\n",
      "Bounds loss: 0.7661531914000594\n",
      "MAPE:  0.097813427203559\n",
      "Delta:  0.01217744674780664\n",
      "GRAD\n",
      " tensor([-67.4575,   3.1176,   9.4752, 120.6613])\n",
      "-0.03268855075949162 -0.028368295230401852 1.0\n",
      "Epoch: 477\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 0.7878876513254109\n",
      "MAPE:  0.10136466257624178\n",
      "Delta:  0.012575509833943323\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.029375075942721596 0.023961755702287757 -inf\n",
      "Epoch: 478\n",
      "Arb loss 0.009626354956240302\n",
      "Real arb loss 9.617796547199432e-06\n",
      "Bounds loss: 0.7690084799035022\n",
      "MAPE:  0.09837675640761795\n",
      "Delta:  0.012206103277552796\n",
      "GRAD\n",
      " tensor([-52.5421,   1.2888,   8.0286,  93.2833])\n",
      "-0.02194744412938343 -0.017144682287244084 0.9999991044328185\n",
      "Epoch: 479\n",
      "Arb loss 8.621047576844341e-09\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 0.7821928859676442\n",
      "MAPE:  0.10061170391702816\n",
      "Delta:  0.01247399604727437\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.026204874681101775 0.02271535692943727 -1669443.3201197602\n",
      "Epoch: 480\n",
      "Arb loss 0.014392358910645007\n",
      "Real arb loss 1.4366319789594563e-05\n",
      "Bounds loss: 0.7644250953752225\n",
      "MAPE:  0.0978068719102524\n",
      "Delta:  0.012147116544082986\n",
      "GRAD\n",
      " tensor([-52.6059,   2.2459,   8.0040,  93.4671])\n",
      "-0.022814103696042087 -0.017145819832464104 0.9999841230834865\n",
      "Epoch: 481\n",
      "Arb loss 2.285062808568934e-07\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 0.7775317903359403\n",
      "MAPE:  0.10003903920760548\n",
      "Delta:  0.012424242120527604\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.026448622020173618 0.022596588605324208 -81428.09568646792\n",
      "arb imp changed to 994.0154801051195\n",
      "Epoch: 482\n",
      "Arb loss 0.01861636333875931\n",
      "Real arb loss 1.856359224674236e-05\n",
      "Bounds loss: 0.7599622243421579\n",
      "MAPE:  0.09726611004122251\n",
      "Delta:  0.01209563803679465\n",
      "GRAD\n",
      " tensor([-67.4806,   2.1079,   9.4711, 120.8554])\n",
      "-0.03415812477109115 -0.028966638411290546 1.0\n",
      "Epoch: 483\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 0.7819757753009173\n",
      "MAPE:  0.10092435521095698\n",
      "Delta:  0.012508802350041438\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.02915661604209785 0.023991511552130973 -inf\n",
      "Epoch: 484\n",
      "Arb loss 0.007284221530009744\n",
      "Real arb loss 7.275802445263074e-06\n",
      "Bounds loss: 0.7632149944542987\n",
      "MAPE:  0.09791363167986748\n",
      "Delta:  0.012144088002774788\n",
      "GRAD\n",
      " tensor([-37.4256,   1.5560,   5.6269,  68.6453])\n",
      "-0.011489621859128274 -0.0069286106202763875 0.9093514128867839\n",
      "Epoch: 485\n",
      "Arb loss 0.0006603043899150525\n",
      "Real arb loss 6.599424413902509e-07\n",
      "Bounds loss: 0.768503013970429\n",
      "MAPE:  0.0989135026596521\n",
      "Delta:  0.012283618981750646\n",
      "GRAD\n",
      " tensor([-0.0104, -0.0043, -0.0018,  0.0080])\n",
      "0.023051730819320215 0.02128794282033364 -39.64364893241317\n",
      "Epoch: 486\n",
      "Arb loss 0.02683717981223865\n",
      "Real arb loss 2.673024086780605e-05\n",
      "Bounds loss: 0.7521431657517724\n",
      "MAPE:  0.09632541093131552\n",
      "Delta:  0.012000460303496238\n",
      "GRAD\n",
      " tensor([-82.2811,   2.9907,  11.9427, 145.3090])\n",
      "-0.04590181319489939 -0.04092764202169441 1.0\n",
      "Epoch: 487\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 0.7829266119887248\n",
      "MAPE:  0.10139838976569834\n",
      "Delta:  0.012551303190600126\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.032204149562492845 0.025623079108742286 -inf\n",
      "Epoch: 488\n",
      "Arb loss 0.0034096391594551777\n",
      "Real arb loss 3.408558337078326e-06\n",
      "Bounds loss: 0.7628656214733982\n",
      "MAPE:  0.09814069642322888\n",
      "Delta:  0.012147099145445846\n",
      "GRAD\n",
      " tensor([-22.4977,   0.7146,   4.1677,  41.2415])\n",
      "0.000858230331472587 0.004527126911576307 -0.2371959422024128\n",
      "Epoch: 489\n",
      "Arb loss 0.004218391732452391\n",
      "Real arb loss 4.215733702238187e-06\n",
      "Bounds loss: 0.7594120319885096\n",
      "MAPE:  0.09772326797383885\n",
      "Delta:  0.01213667413651982\n",
      "GRAD\n",
      " tensor([-22.5158,   0.7010,   4.1595,  41.2337])\n",
      "0.0027240961637130523 0.004515250359827361 -0.5032916601388269\n",
      "Epoch: 490\n",
      "Arb loss 0.006341473110594258\n",
      "Real arb loss 6.335576331941164e-06\n",
      "Bounds loss: 0.7559830965378163\n",
      "MAPE:  0.09727716895129936\n",
      "Delta:  0.012103612669064292\n",
      "GRAD\n",
      " tensor([-22.5454,   0.6821,   4.1489,  41.2781])\n",
      "0.0020944836562816205 0.0038520342768684213 -0.22347101599558394\n",
      "Epoch: 491\n",
      "Arb loss 0.007758608549527432\n",
      "Real arb loss 7.750396204991784e-06\n",
      "Bounds loss: 0.7530710237372195\n",
      "MAPE:  0.09691230225303704\n",
      "Delta:  0.012078261850146974\n",
      "GRAD\n",
      " tensor([-37.4295,   1.5411,   5.6152,  68.5969])\n",
      "-0.007779076246364758 -0.006918329834531001 0.8045449603925106\n",
      "Epoch: 492\n",
      "Arb loss 0.0015164591413468905\n",
      "Real arb loss 1.5166153510530328e-06\n",
      "Bounds loss: 0.7582810174682615\n",
      "MAPE:  0.09786815638303215\n",
      "Delta:  0.012172219570002824\n",
      "GRAD\n",
      " tensor([-7.5328,  0.8858,  1.7126, 13.7545])\n",
      "0.017780626949662093 0.01611645296674491 -10.530356696089486\n",
      "arb imp changed to 994.3136151790002\n",
      "Epoch: 493\n",
      "Arb loss 0.017494057472182616\n",
      "Real arb loss 1.743765112403304e-05\n",
      "Bounds loss: 0.7460602171146588\n",
      "MAPE:  0.09594066170740095\n",
      "Delta:  0.011955789874679228\n",
      "GRAD\n",
      " tensor([-52.3591,   1.3655,   8.0607,  93.2121])\n",
      "-0.021265814275237327 -0.017803641337536202 0.9790476277441617\n",
      "Epoch: 494\n",
      "Arb loss 0.00036654200442220027\n",
      "Real arb loss 3.667718464890821e-07\n",
      "Bounds loss: 0.7593428056363726\n",
      "MAPE:  0.09822673222329041\n",
      "Delta:  0.01221003948166792\n",
      "GRAD\n",
      " tensor([-0.0050, -0.0021, -0.0009,  0.0038])\n",
      "0.026056953722782605 0.022210450228754786 -59.919416911340846\n",
      "Epoch: 495\n",
      "Arb loss 0.022329525182914558\n",
      "Real arb loss 2.2240287747166566e-05\n",
      "Bounds loss: 0.7424774600452229\n",
      "MAPE:  0.09552764725419594\n",
      "Delta:  0.01189188304794075\n",
      "GRAD\n",
      " tensor([-67.1132,   2.2877,   9.5570, 119.5935])\n",
      "-0.03442962919553838 -0.030015585122773247 1.0\n",
      "Epoch: 496\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 0.7647633554489507\n",
      "MAPE:  0.09928825065914357\n",
      "Delta:  0.012301316171718058\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.029368348508207354 0.024072777002411616 -inf\n",
      "Delta imp changed to 0.022688527551741652\n",
      "Epoch: 497\n",
      "Arb loss 0.01166375065366158\n",
      "Real arb loss 1.1637069243630714e-05\n",
      "Bounds loss: 0.746353377733612\n",
      "MAPE:  0.09628998040390988\n",
      "Delta:  0.011648826176855996\n",
      "GRAD\n",
      " tensor([-52.2554,   1.4362,   8.1014,  93.1402])\n",
      "-0.02178109214139856 -0.017803791001667513 0.9999744269079853\n",
      "Epoch: 498\n",
      "Arb loss 2.9827816870286785e-07\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 0.75964129728417\n",
      "MAPE:  0.09861109054700709\n",
      "Delta:  0.011902550333153234\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.025699645835818297 0.022661766840875064 -55741.695372980816\n",
      "Epoch: 499\n",
      "Arb loss 0.01662682909441454\n",
      "Real arb loss 1.6578545316551175e-05\n",
      "Bounds loss: 0.7424264833224162\n",
      "MAPE:  0.09581385212040903\n",
      "Delta:  0.011596659005048195\n",
      "GRAD\n",
      " tensor([-52.3049,   1.4029,   8.0823,  93.3105])\n",
      "-0.023198965513487657 -0.01803980512271952 0.9943907924559582\n",
      "Epoch: 500\n",
      "Arb loss 9.32633351898849e-05\n",
      "Real arb loss 9.30851481956256e-08\n",
      "Bounds loss: 0.7558197123994986\n",
      "MAPE:  0.09816633220682881\n",
      "Delta:  0.011865689497377983\n",
      "GRAD\n",
      " tensor([-2.1384e-04, -8.8258e-05, -3.6427e-05,  1.6271e-04])\n",
      "0.025670214339762576 0.022413655161644286 -200.55600026227543\n",
      "Epoch: 501\n",
      "Arb loss 0.018797784811993123\n",
      "Real arb loss 1.873578280497732e-05\n",
      "Bounds loss: 0.7388790300014031\n",
      "MAPE:  0.09541109813694855\n",
      "Delta:  0.01156109470469122\n",
      "GRAD\n",
      " tensor([-67.0269,   2.3439,   9.5886, 119.5485])\n",
      "-0.03326650406047649 -0.02932505357805648 1.0\n",
      "Epoch: 502\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 0.7605466971438966\n",
      "MAPE:  0.09914489368013316\n",
      "Delta:  0.011945691908628384\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.02861365352771217 0.024048373959077995 -inf\n",
      "Epoch: 503\n",
      "Arb loss 0.010306140457483369\n",
      "Real arb loss 1.0287765199445254e-05\n",
      "Bounds loss: 0.7422567857576385\n",
      "MAPE:  0.09608015570710612\n",
      "Delta:  0.011603882019206096\n",
      "GRAD\n",
      " tensor([-37.4352,   1.5419,   5.6169,  68.8749])\n",
      "-0.011672874651068366 -0.007516282602554991 0.8875577187572766\n",
      "arb imp changed to 994.6118396725367\n",
      "Epoch: 504\n",
      "Arb loss 0.0011594253668192782\n",
      "Real arb loss 1.1582257732689408e-06\n",
      "Bounds loss: 0.7478357975230571\n",
      "MAPE:  0.09715728614401858\n",
      "Delta:  0.011739332679482075\n",
      "GRAD\n",
      " tensor([-7.5345,  0.8864,  1.7133, 13.7813])\n",
      "0.016829645813379646 0.016131581709256437 -12.878558183879028\n",
      "Epoch: 505\n",
      "Arb loss 0.016091152413266637\n",
      "Real arb loss 1.6040002274225386e-05\n",
      "Bounds loss: 0.735772023250207\n",
      "MAPE:  0.09520924239855716\n",
      "Delta:  0.011541763868400957\n",
      "GRAD\n",
      " tensor([-52.3120,   1.3943,   8.0764,  93.3077])\n",
      "-0.021540994973905825 -0.018249487370253004 0.9916721035716384\n",
      "Epoch: 506\n",
      "Arb loss 0.00013400545071066638\n",
      "Real arb loss 1.3386144634243076e-07\n",
      "Bounds loss: 0.7491994854958971\n",
      "MAPE:  0.09756513013663858\n",
      "Delta:  0.01179038494588019\n",
      "GRAD\n",
      " tensor([-0.0037, -0.0015, -0.0006,  0.0028])\n",
      "0.025900451681584724 0.02250871075205263 -151.86128051027995\n",
      "Epoch: 507\n",
      "Arb loss 0.020484244790989665\n",
      "Real arb loss 2.0405062521914395e-05\n",
      "Bounds loss: 0.7323359709812833\n",
      "MAPE:  0.09479739708623855\n",
      "Delta:  0.011485008650282135\n",
      "GRAD\n",
      " tensor([-67.0487,   2.3268,   9.5782, 119.6917])\n",
      "-0.033234305853159896 -0.029668760565842778 1.0\n",
      "Epoch: 508\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 0.754063471558081\n",
      "MAPE:  0.09859648142446896\n",
      "Delta:  0.0118667049404918\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.02847945992128864 0.024073811598259498 -inf\n",
      "Epoch: 509\n",
      "Arb loss 0.011363358968607419\n",
      "Real arb loss 1.1337027329593714e-05\n",
      "Bounds loss: 0.7359102896106622\n",
      "MAPE:  0.09550749938144888\n",
      "Delta:  0.011528747592741305\n",
      "GRAD\n",
      " tensor([-52.2192,   1.4588,   8.1139,  93.2466])\n",
      "-0.022031755537516684 -0.018247447935701766 0.9999913547545014\n",
      "Epoch: 510\n",
      "Arb loss 9.823902797273775e-08\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 0.7493387743056799\n",
      "MAPE:  0.09792710334998082\n",
      "Delta:  0.011782746141358316\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.025539689064385196 0.022918618594835682 -160002.10344806046\n",
      "Epoch: 511\n",
      "Arb loss 0.015718549355358862\n",
      "Real arb loss 1.5671654738672844e-05\n",
      "Bounds loss: 0.7321649647390464\n",
      "MAPE:  0.09503500569363091\n",
      "Delta:  0.01148181846858344\n",
      "GRAD\n",
      " tensor([-52.2652,   1.4275,   8.0959,  93.3981])\n",
      "-0.02324752790753637 -0.01847744959226416 0.999978429286463\n",
      "Epoch: 512\n",
      "Arb loss 3.3906032536175404e-07\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 0.7456935059682339\n",
      "MAPE:  0.09749316956052262\n",
      "Delta:  0.011748742363861102\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.02593174899780648 0.02287939312754328 -55454.13561717253\n",
      "Epoch: 513\n",
      "Arb loss 0.018802636325338712\n",
      "Real arb loss 1.873752822767444e-05\n",
      "Bounds loss: 0.7286324910925307\n",
      "MAPE:  0.0946154699421578\n",
      "Delta:  0.011444076925841559\n",
      "GRAD\n",
      " tensor([-66.9800,   2.3734,   9.6050, 119.6916])\n",
      "-0.033651626601031825 -0.029956046733502717 1.0\n",
      "Epoch: 514\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 0.7504594400472471\n",
      "MAPE:  0.09849774947099825\n",
      "Delta:  0.011829188729343463\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.028449437832040236 0.02430843636108937 -inf\n",
      "arb imp changed to 994.9101536125489\n",
      "Epoch: 515\n",
      "Arb loss 0.009706197374411035\n",
      "Real arb loss 9.683621522478918e-06\n",
      "Bounds loss: 0.7322169445072798\n",
      "MAPE:  0.09533071314763322\n",
      "Delta:  0.011492654959984536\n",
      "GRAD\n",
      " tensor([-37.4284,   1.5510,   5.6232,  68.9520])\n",
      "-0.011741785429040474 -0.007769896159960377 0.9336842426705433\n",
      "Epoch: 516\n",
      "Arb loss 0.0006436738296732523\n",
      "Real arb loss 6.427644368764626e-07\n",
      "Bounds loss: 0.7379061941326649\n",
      "MAPE:  0.09641951057019359\n",
      "Delta:  0.011627599248534673\n",
      "GRAD\n",
      " tensor([-0.0082, -0.0034, -0.0014,  0.0062])\n",
      "0.022625693844088968 0.021573666829467042 -38.9235117026761\n",
      "Epoch: 517\n",
      "Arb loss 0.02569771967166643\n",
      "Real arb loss 2.557176310377821e-05\n",
      "Bounds loss: 0.7219868517490468\n",
      "MAPE:  0.09378420643047362\n",
      "Delta:  0.011364516747795568\n",
      "GRAD\n",
      " tensor([-67.0762,   2.3062,   9.5659, 120.9714])\n",
      "-0.035710051752151584 -0.031657504555164806 1.0\n",
      "Epoch: 518\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 0.7448431537970612\n",
      "MAPE:  0.09786741652406261\n",
      "Delta:  0.011770344228997542\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.028958076332630034 0.0243818953914553 -inf\n",
      "Epoch: 519\n",
      "Arb loss 0.009254997356745634\n",
      "Real arb loss 9.231827495540028e-06\n",
      "Bounds loss: 0.7266824659381397\n",
      "MAPE:  0.09469489090792964\n",
      "Delta:  0.0114294977023529\n",
      "GRAD\n",
      " tensor([-37.1863,   1.6783,   5.6871,  68.6507])\n",
      "-0.011497622413810582 -0.007817102783007845 0.8839097556359583\n",
      "Epoch: 520\n",
      "Arb loss 0.0010744149047331602\n",
      "Real arb loss 1.0728923362165673e-06\n",
      "Bounds loss: 0.7323630174649877\n",
      "MAPE:  0.09579425846552084\n",
      "Delta:  0.01156090975131407\n",
      "GRAD\n",
      " tensor([-7.4730,  0.9187,  1.7295, 13.7280])\n",
      "0.01659734895392062 0.016113712394990043 -12.490405623404236\n",
      "Epoch: 521\n",
      "Arb loss 0.014494292872681551\n",
      "Real arb loss 1.4445507019674124e-05\n",
      "Bounds loss: 0.7205619304328298\n",
      "MAPE:  0.09384028341294604\n",
      "Delta:  0.011369029297946727\n",
      "GRAD\n",
      " tensor([-51.9355,   1.5981,   8.1806,  91.9797])\n",
      "-0.0211038216256505 -0.018252253653375794 0.9867157063647737\n",
      "Epoch: 522\n",
      "Arb loss 0.00019254644255566923\n",
      "Real arb loss 1.9251755410727712e-07\n",
      "Bounds loss: 0.7337138095600559\n",
      "MAPE:  0.09627805566113969\n",
      "Delta:  0.011608959264307389\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.02546876998035863 0.022523487178835788 -95.97208355784495\n",
      "Epoch: 523\n",
      "Arb loss 0.01867162971627415\n",
      "Real arb loss 1.859621707194035e-05\n",
      "Bounds loss: 0.7171880159774953\n",
      "MAPE:  0.09342734117783476\n",
      "Delta:  0.01131329335109339\n",
      "GRAD\n",
      " tensor([-51.9705,   1.5720,   8.1650,  93.1575])\n",
      "-0.02268338566593542 -0.01886380051970149 0.9810831050181442\n",
      "Epoch: 524\n",
      "Arb loss 0.0003532092584828556\n",
      "Real arb loss 3.5328367872592555e-07\n",
      "Bounds loss: 0.7307169076460153\n",
      "MAPE:  0.09595269730133123\n",
      "Delta:  0.011569917147328105\n",
      "GRAD\n",
      " tensor([-0.0027, -0.0011, -0.0005,  0.0021])\n",
      "0.02516854620116782 0.0223722977504619 -57.509746392612804\n",
      "Epoch: 525\n",
      "Arb loss 0.020666184137354705\n",
      "Real arb loss 2.0575235985567193e-05\n",
      "Bounds loss: 0.7143690914168618\n",
      "MAPE:  0.09312714316314599\n",
      "Delta:  0.011278719153061894\n",
      "GRAD\n",
      " tensor([-51.9846,   1.5592,   8.1568,  93.2298])\n",
      "-0.023997844112723987 -0.019921582790032533 0.9854262019592376\n",
      "arb imp changed to 995.308077881567\n",
      "Epoch: 526\n",
      "Arb loss 0.0003013353862879599\n",
      "Real arb loss 3.012696871711601e-07\n",
      "Bounds loss: 0.7286004544141631\n",
      "MAPE:  0.09578393092493315\n",
      "Delta:  0.011549384097088269\n",
      "GRAD\n",
      " tensor([-0.0019, -0.0008, -0.0003,  0.0014])\n",
      "0.025843530370738388 0.022608138919976595 -68.50018910826402\n",
      "Epoch: 527\n",
      "Arb loss 0.020942866332025002\n",
      "Real arb loss 2.0839669089537086e-05\n",
      "Bounds loss: 0.7121281541236096\n",
      "MAPE:  0.09291406338722623\n",
      "Delta:  0.011250907238411845\n",
      "GRAD\n",
      " tensor([-52.0092,   1.5453,   8.1495,  93.2804])\n",
      "-0.02385231849174807 -0.020024211328314223 0.9849022199521413\n",
      "Epoch: 528\n",
      "Arb loss 0.00031619078945261894\n",
      "Real arb loss 3.1610653799806975e-07\n",
      "Bounds loss: 0.7263879587746231\n",
      "MAPE:  0.09559026691971492\n",
      "Delta:  0.011519267461183558\n",
      "GRAD\n",
      " tensor([-0.0031, -0.0013, -0.0005,  0.0024])\n",
      "0.02582760207499346 0.02263275652105623 -66.99402749571509\n",
      "Epoch: 529\n",
      "Arb loss 0.021499085231933234\n",
      "Real arb loss 2.1392620028854188e-05\n",
      "Bounds loss: 0.70994779696385\n",
      "MAPE:  0.09270992733197113\n",
      "Delta:  0.011221752405000689\n",
      "GRAD\n",
      " tensor([-66.6056,   2.5531,   8.6896, 119.4794])\n",
      "-0.03401298898128968 -0.03143554685626926 1.0\n",
      "Epoch: 530\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 0.7322653942008123\n",
      "MAPE:  0.09679563556067407\n",
      "Delta:  0.011603437745902738\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.02854452296466292 0.02446819131693978 -inf\n",
      "Epoch: 531\n",
      "Arb loss 0.01063413789816394\n",
      "Real arb loss 1.0601324185812603e-05\n",
      "Bounds loss: 0.7143481844407324\n",
      "MAPE:  0.09357809984428506\n",
      "Delta:  0.011272223150695782\n",
      "GRAD\n",
      " tensor([-37.1966,   1.6644,   5.6774,  68.8107])\n",
      "-0.011535657736405858 -0.008169795855355932 0.8629054834691184\n",
      "Epoch: 532\n",
      "Arb loss 0.00145788199387151\n",
      "Real arb loss 1.456105073237478e-06\n",
      "Bounds loss: 0.7201842632772575\n",
      "MAPE:  0.09477416490222604\n",
      "Delta:  0.011402255658890598\n",
      "GRAD\n",
      " tensor([-7.4860,  0.9115,  1.7258, 13.7687])\n",
      "0.016353610921428507 0.01611348080067221 -10.19116253959402\n",
      "Epoch: 533\n",
      "Arb loss 0.01631539435696348\n",
      "Real arb loss 1.6251969031100148e-05\n",
      "Bounds loss: 0.7085795879779931\n",
      "MAPE:  0.09277077745474895\n",
      "Delta:  0.011215787606218445\n",
      "GRAD\n",
      " tensor([-51.9383,   1.5855,   8.1706,  93.1915])\n",
      "-0.021614649995537638 -0.019197080161573954 0.9890406673437677\n",
      "Epoch: 534\n",
      "Arb loss 0.0001788058341755769\n",
      "Real arb loss 1.7867073897380458e-07\n",
      "Bounds loss: 0.7221822471292616\n",
      "MAPE:  0.09537913205566678\n",
      "Delta:  0.011458212929751145\n",
      "GRAD\n",
      " tensor([-0.0022, -0.0009, -0.0004,  0.0017])\n",
      "0.025287189601706284 0.02270633729656868 -109.52606560344923\n",
      "Epoch: 535\n",
      "Arb loss 0.019762705358369277\n",
      "Real arb loss 1.9672781083032086e-05\n",
      "Bounds loss: 0.7057841334363507\n",
      "MAPE:  0.09243681673818566\n",
      "Delta:  0.011168466926899805\n",
      "GRAD\n",
      " tensor([-51.9618,   1.5681,   8.1602,  93.3435])\n",
      "-0.02279026687261787 -0.019372815178123393 0.983423993200083\n",
      "Epoch: 536\n",
      "Arb loss 0.0003275867384050862\n",
      "Real arb loss 3.2743809417956627e-07\n",
      "Bounds loss: 0.7194571590090652\n",
      "MAPE:  0.09509172138645233\n",
      "Delta:  0.011422999268721859\n",
      "GRAD\n",
      " tensor([-0.0070, -0.0029, -0.0012,  0.0054])\n",
      "0.024952443589143503 0.02255208834409428 -65.45363141308212\n",
      "arb imp changed to 995.7061613043772\n",
      "Epoch: 537\n",
      "Arb loss 0.021780213033970243\n",
      "Real arb loss 2.166471105966437e-05\n",
      "Bounds loss: 0.7032318975993016\n",
      "MAPE:  0.09217191198118196\n",
      "Delta:  0.01113796752385025\n",
      "GRAD\n",
      " tensor([-66.5894,   2.5612,   8.6935, 119.6116])\n",
      "-0.0342620103829987 -0.031888214391494696 1.0\n",
      "Epoch: 538\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 0.7256567071168858\n",
      "MAPE:  0.09635472695533617\n",
      "Delta:  0.011519576682797909\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.02832862998747865 0.02462841006171501 -inf\n",
      "Epoch: 539\n",
      "Arb loss 0.010389797322122859\n",
      "Real arb loss 1.0355338737180465e-05\n",
      "Bounds loss: 0.7077849361699773\n",
      "MAPE:  0.09307875878709049\n",
      "Delta:  0.01119324285733854\n",
      "GRAD\n",
      " tensor([-37.1885,   0.6692,   5.6799,  68.8700])\n",
      "-0.011912081200140978 -0.008571801286893166 0.88698932067329\n",
      "Epoch: 540\n",
      "Arb loss 0.001174158053439937\n",
      "Real arb loss 1.1719388664962888e-06\n",
      "Bounds loss: 0.7138519279966826\n",
      "MAPE:  0.09437562301847663\n",
      "Delta:  0.011326577675148055\n",
      "GRAD\n",
      " tensor([-7.4849,  0.9125,  1.7264, 13.7794])\n",
      "0.01638614260741167 0.01624842984623498 -12.524744907064676\n",
      "Epoch: 541\n",
      "Arb loss 0.015880188153350763\n",
      "Real arb loss 1.5814419599062298e-05\n",
      "Bounds loss: 0.702252955024029\n",
      "MAPE:  0.09230360926145692\n",
      "Delta:  0.011140978758109155\n",
      "GRAD\n",
      " tensor([-51.9225,   1.5957,   8.1763,  93.2644])\n",
      "-0.021603747449181476 -0.019482444996933967 0.9951940273781508\n",
      "Epoch: 542\n",
      "Arb loss 7.631974949481824e-05\n",
      "Real arb loss 7.598147656198707e-08\n",
      "Bounds loss: 0.715934559594219\n",
      "MAPE:  0.09497679574584354\n",
      "Delta:  0.01138166564953604\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.02515722827534861 0.022883164571882553 -250.58110321025345\n",
      "Epoch: 543\n",
      "Arb loss 0.01920060677463656\n",
      "Real arb loss 1.910904183485418e-05\n",
      "Bounds loss: 0.6995517112443262\n",
      "MAPE:  0.09196758715351858\n",
      "Delta:  0.011095334488636968\n",
      "GRAD\n",
      " tensor([-51.9452,   1.5787,   8.1662,  93.4124])\n",
      "-0.022749163469053535 -0.0196564197611222 0.9886817801501553\n",
      "Epoch: 544\n",
      "Arb loss 0.00021731668872575417\n",
      "Real arb loss 2.1715273416544541e-07\n",
      "Bounds loss: 0.7133023933251561\n",
      "MAPE:  0.09468884793764754\n",
      "Delta:  0.011347744066662798\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.024826236145793712 0.022725410523603107 -95.85268782828675\n",
      "Epoch: 545\n",
      "Arb loss 0.02104770541303243\n",
      "Real arb loss 2.0941712265717027e-05\n",
      "Bounds loss: 0.6970923036093732\n",
      "MAPE:  0.09170092673858626\n",
      "Delta:  0.011066022292741798\n",
      "GRAD\n",
      " tensor([-66.5333,   2.5895,   8.7072, 119.6711])\n",
      "-0.03296584548084591 -0.031242173712839216 1.0\n",
      "Epoch: 546\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 0.7188709824526205\n",
      "MAPE:  0.0958433018450063\n",
      "Delta:  0.01143082307373192\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.02742008342314195 0.024455724491885378 -inf\n",
      "Epoch: 547\n",
      "Arb loss 0.010831777669055626\n",
      "Real arb loss 1.0796122863271206e-05\n",
      "Bounds loss: 0.7012904717605483\n",
      "MAPE:  0.09258168058569158\n",
      "Delta:  0.011117388951455014\n",
      "GRAD\n",
      " tensor([-37.1689,   0.6785,   5.6843,  68.9273])\n",
      "-0.012068442026706538 -0.0087608128310388 0.9221542667917715\n",
      "arb imp changed to 996.0048034642886\n",
      "Epoch: 548\n",
      "Arb loss 0.0008436292784334491\n",
      "Real arb loss 8.412655757022401e-07\n",
      "Bounds loss: 0.7074343463238334\n",
      "MAPE:  0.09390974569730136\n",
      "Delta:  0.011251558515503997\n",
      "GRAD\n",
      " tensor([-0.0094, -0.0039, -0.0016,  0.0072])\n",
      "0.02151908892100607 0.02178009387291968 -29.246119894010018\n",
      "Epoch: 549\n",
      "Arb loss 0.02551651230159526\n",
      "Real arb loss 2.53645060798694e-05\n",
      "Bounds loss: 0.6920263598519728\n",
      "MAPE:  0.09109333828246254\n",
      "Delta:  0.011009435227308965\n",
      "GRAD\n",
      " tensor([-66.5916,   2.5493,   9.6840, 120.8451])\n",
      "-0.0349001729944487 -0.03316850654098058 1.0\n",
      "Epoch: 550\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 0.7149798406952539\n",
      "MAPE:  0.09548618222939892\n",
      "Delta:  0.011393666421313226\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.028102103094435726 0.024703191794037016 -inf\n",
      "Epoch: 551\n",
      "Arb loss 0.008894690170176385\n",
      "Real arb loss 8.861416408281763e-06\n",
      "Bounds loss: 0.697317556561689\n",
      "MAPE:  0.09218837857265097\n",
      "Delta:  0.011073480432917872\n",
      "GRAD\n",
      " tensor([-36.9135,   0.8170,   5.7551,  68.5896])\n",
      "-0.011718295716428573 -0.00872992732697786 0.8796789511472429\n",
      "Epoch: 552\n",
      "Arb loss 0.0010702184504959307\n",
      "Real arb loss 1.0676676500253925e-06\n",
      "Bounds loss: 0.7034050881542983\n",
      "MAPE:  0.09350730514630082\n",
      "Delta:  0.011203242751240888\n",
      "GRAD\n",
      " tensor([-0.0130, -0.0054, -0.0022,  0.0100])\n",
      "0.021416730942299123 0.021720651301324945 -24.367817558302008\n",
      "Epoch: 553\n",
      "Arb loss 0.02714910639970944\n",
      "Real arb loss 2.6984346650210365e-05\n",
      "Bounds loss: 0.6881266715109211\n",
      "MAPE:  0.09070178727527196\n",
      "Delta:  0.010963305915556299\n",
      "GRAD\n",
      " tensor([-66.5848,   2.5457,   9.6799, 120.9285])\n",
      "-0.03489092880820577 -0.03332458376615399 1.0\n",
      "Epoch: 554\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 0.7110582064174116\n",
      "MAPE:  0.09511999392247243\n",
      "Delta:  0.011345825841758556\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.027963195095690563 0.024663660301309842 -inf\n",
      "Epoch: 555\n",
      "Arb loss 0.009695086480376987\n",
      "Real arb loss 9.659295447855575e-06\n",
      "Bounds loss: 0.6935209083598739\n",
      "MAPE:  0.09182625858116737\n",
      "Delta:  0.011028560300223733\n",
      "GRAD\n",
      " tensor([-36.9113,   0.8151,   5.7531,  68.6343])\n",
      "-0.012301578472932784 -0.008795229100427404 0.8959725653621256\n",
      "Epoch: 556\n",
      "Arb loss 0.0010085549751459577\n",
      "Real arb loss 1.0061040426967496e-06\n",
      "Bounds loss: 0.6996205836348355\n",
      "MAPE:  0.09316935897034331\n",
      "Delta:  0.011164229000200407\n",
      "GRAD\n",
      " tensor([-0.0138, -0.0057, -0.0023,  0.0106])\n",
      "0.021978302218010226 0.021846508110323293 -26.80164207823541\n",
      "Epoch: 557\n",
      "Arb loss 0.028039484435231524\n",
      "Real arb loss 2.7868709343204514e-05\n",
      "Bounds loss: 0.6843363168803079\n",
      "MAPE:  0.09034022662553504\n",
      "Delta:  0.010918858201202928\n",
      "GRAD\n",
      " tensor([-66.5725,   2.5450,   9.6772, 120.9905])\n",
      "-0.03453683326810464 -0.03321466093105174 1.0\n",
      "Epoch: 558\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 0.7070663156082921\n",
      "MAPE:  0.0947446827700782\n",
      "Delta:  0.011295960986375949\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.02784522139148704 0.02463511356943593 -inf\n",
      "arb imp changed to 996.2039148044656\n",
      "Epoch: 559\n",
      "Arb loss 0.010630420159827856\n",
      "Real arb loss 1.0586461602441522e-05\n",
      "Bounds loss: 0.6896476566221592\n",
      "MAPE:  0.09145460477456967\n",
      "Delta:  0.010981422451880711\n",
      "GRAD\n",
      " tensor([-36.9279,   0.8047,   5.7474,  68.6966])\n",
      "-0.01232032701208663 -0.008931921015394195 0.8839692979286936\n",
      "Epoch: 560\n",
      "Arb loss 0.0012334551144577955\n",
      "Real arb loss 1.2304701808971002e-06\n",
      "Bounds loss: 0.69580753501956\n",
      "MAPE:  0.09281602921574632\n",
      "Delta:  0.011116717167545753\n",
      "GRAD\n",
      " tensor([-7.4260,  0.9425,  1.7411, 13.7338])\n",
      "0.016667014334348362 0.016311005611629126 -11.436926193885705\n",
      "Epoch: 561\n",
      "Arb loss 0.015340390221982449\n",
      "Real arb loss 1.526493531068029e-05\n",
      "Bounds loss: 0.6844582144112422\n",
      "MAPE:  0.09071845320456418\n",
      "Delta:  0.01093143468316337\n",
      "GRAD\n",
      " tensor([-51.5487,   1.7901,   8.2730,  92.0090])\n",
      "-0.02073897308853634 -0.01922814103018622 0.983255108450577\n",
      "Epoch: 562\n",
      "Arb loss 0.00025687317059292603\n",
      "Real arb loss 2.565699242776387e-07\n",
      "Bounds loss: 0.697619073487211\n",
      "MAPE:  0.09335943980054592\n",
      "Delta:  0.011158141412876587\n",
      "GRAD\n",
      " tensor([-5.7024e-04, -2.3454e-04, -9.6467e-05,  4.3804e-04])\n",
      "0.024564188868441583 0.022829655753365485 -74.05244104926021\n",
      "Epoch: 563\n",
      "Arb loss 0.019278958493062142\n",
      "Real arb loss 1.917189268621109e-05\n",
      "Bounds loss: 0.6816926701925161\n",
      "MAPE:  0.09035474679849048\n",
      "Delta:  0.010884050719789906\n",
      "GRAD\n",
      " tensor([-51.5717,   1.7720,   8.2620,  92.1722])\n",
      "-0.023231815261468114 -0.020411244112177318 0.9867724903738294\n",
      "Epoch: 564\n",
      "Arb loss 0.0002550126090495235\n",
      "Real arb loss 2.5470767206436234e-07\n",
      "Bounds loss: 0.6956068656932977\n",
      "MAPE:  0.09317213366193451\n",
      "Delta:  0.011136906975408515\n",
      "GRAD\n",
      " tensor([-0.0012, -0.0005, -0.0002,  0.0009])\n",
      "0.024933198759059638 0.022941949110180437 -76.97413996930493\n",
      "Epoch: 565\n",
      "Arb loss 0.019884388871965183\n",
      "Real arb loss 1.97726913293639e-05\n",
      "Bounds loss: 0.6796482883798699\n",
      "MAPE:  0.09015375109853885\n",
      "Delta:  0.010859228260229496\n",
      "GRAD\n",
      " tensor([-51.5724,   1.7681,   8.2589,  93.2053])\n",
      "-0.023504808220946805 -0.020941897026943046 0.9876430052765985\n",
      "Epoch: 566\n",
      "Arb loss 0.0002457112883689366\n",
      "Real arb loss 2.454064690568664e-07\n",
      "Bounds loss: 0.6938814128496592\n",
      "MAPE:  0.09303357591245133\n",
      "Delta:  0.011114472337913678\n",
      "GRAD\n",
      " tensor([-0.0017, -0.0007, -0.0003,  0.0013])\n",
      "0.024957402998793232 0.02298619953280634 -80.47125565674565\n",
      "Epoch: 567\n",
      "Arb loss 0.020018407192453992\n",
      "Real arb loss 1.9905828548565738e-05\n",
      "Bounds loss: 0.6779317162417914\n",
      "MAPE:  0.09000995755991553\n",
      "Delta:  0.010837083972657426\n",
      "GRAD\n",
      " tensor([-51.5668,   1.7690,   8.2588,  93.2305])\n",
      "-0.0234821679985453 -0.021018463543505117 0.9879530367762824\n",
      "Epoch: 568\n",
      "Arb loss 0.00024116101524489632\n",
      "Real arb loss 2.4085088900911364e-07\n",
      "Bounds loss: 0.6921807993046053\n",
      "MAPE:  0.09289759392140304\n",
      "Delta:  0.011091562199117713\n",
      "GRAD\n",
      " tensor([-0.0024, -0.0010, -0.0004,  0.0019])\n",
      "0.024910259885521535 0.023009408455208713 -82.52467474628621\n",
      "Epoch: 569\n",
      "Arb loss 0.020142895359814138\n",
      "Real arb loss 2.0029485765551977e-05\n",
      "Bounds loss: 0.6762541285685528\n",
      "MAPE:  0.08987142549887521\n",
      "Delta:  0.010815268502201263\n",
      "GRAD\n",
      " tensor([-51.5607,   1.7704,   8.2589,  93.2557])\n",
      "-0.023478745581845706 -0.02109435121178005 0.9883641376591049\n",
      "arb imp changed to 996.7020167618678\n",
      "Epoch: 570\n",
      "Arb loss 0.00023449714753262792\n",
      "Real arb loss 2.340633702413407e-07\n",
      "Bounds loss: 0.6905192706649941\n",
      "MAPE:  0.09276734813642903\n",
      "Delta:  0.011069197439763796\n",
      "GRAD\n",
      " tensor([-0.0031, -0.0013, -0.0005,  0.0024])\n",
      "0.024861010613118406 0.023033925279781986 -85.31734301749876\n",
      "Epoch: 571\n",
      "Arb loss 0.020241170720198855\n",
      "Real arb loss 2.0117089496797286e-05\n",
      "Bounds loss: 0.6746139013802471\n",
      "MAPE:  0.08973815873275637\n",
      "Delta:  0.010794006004735124\n",
      "GRAD\n",
      " tensor([-51.5799,   1.7616,   8.2549,  93.2996])\n",
      "-0.023488076513656253 -0.021178685463864477 0.9889275996112123\n",
      "Epoch: 572\n",
      "Arb loss 0.0002241183465518467\n",
      "Real arb loss 2.2368271524924114e-07\n",
      "Bounds loss: 0.6889013370071297\n",
      "MAPE:  0.09264348470459037\n",
      "Delta:  0.011047536443663209\n",
      "GRAD\n",
      " tensor([-0.0036, -0.0015, -0.0006,  0.0028])\n",
      "0.024818897996998546 0.023062546381917515 -89.50330615215725\n",
      "Epoch: 573\n",
      "Arb loss 0.02028345133229706\n",
      "Real arb loss 2.015915322706538e-05\n",
      "Bounds loss: 0.6730135179698379\n",
      "MAPE:  0.08961040222704297\n",
      "Delta:  0.010773348763549807\n",
      "GRAD\n",
      " tensor([-51.5727,   1.7639,   8.2555,  93.3217])\n",
      "-0.023482313471979488 -0.02125156656786298 0.9895512806287708\n",
      "Epoch: 574\n",
      "Arb loss 0.00021193609085115676\n",
      "Real arb loss 2.1149732576803902e-07\n",
      "Bounds loss: 0.6873161095480456\n",
      "MAPE:  0.09252358436693292\n",
      "Delta:  0.011026331916358448\n",
      "GRAD\n",
      " tensor([-0.0041, -0.0017, -0.0007,  0.0032])\n",
      "0.02479007543705869 0.023142988660791564 -95.12864054116667\n",
      "Epoch: 575\n",
      "Arb loss 0.02037312829513089\n",
      "Real arb loss 2.0248167526379992e-05\n",
      "Bounds loss: 0.6714095606183959\n",
      "MAPE:  0.08948251732543784\n",
      "Delta:  0.010752988316357874\n",
      "GRAD\n",
      " tensor([-51.5657,   1.7661,   8.2562,  93.3435])\n",
      "-0.02348803474997907 -0.021332234380622372 0.9901080685362079\n",
      "Epoch: 576\n",
      "Arb loss 0.00020152958879847727\n",
      "Real arb loss 2.0108398333357896e-07\n",
      "Bounds loss: 0.6857322267308982\n",
      "MAPE:  0.09240528677896359\n",
      "Delta:  0.011005554879598606\n",
      "GRAD\n",
      " tensor([-0.0046, -0.0019, -0.0008,  0.0036])\n",
      "0.024760917638892765 0.023175378222313858 -100.33402705032732\n",
      "Epoch: 577\n",
      "Arb loss 0.02042180480274624\n",
      "Real arb loss 2.0296524938358434e-05\n",
      "Bounds loss: 0.6698401230171801\n",
      "MAPE:  0.08935873570336662\n",
      "Delta:  0.010733047241654551\n",
      "GRAD\n",
      " tensor([-51.5583,   1.7687,   8.2571,  93.3642])\n",
      "-0.02349900064298005 -0.021413622931560683 0.9907996315358817\n",
      "Epoch: 578\n",
      "Arb loss 0.00018788812888756676\n",
      "Real arb loss 1.874361696803141e-07\n",
      "Bounds loss: 0.6841838268359002\n",
      "MAPE:  0.09229569426176361\n",
      "Delta:  0.010985263125687327\n",
      "GRAD\n",
      " tensor([-0.0051, -0.0021, -0.0009,  0.0039])\n",
      "0.02473476825890586 0.023210780043081303 -107.72249850979217\n",
      "Epoch: 579\n",
      "Arb loss 0.020427666812986117\n",
      "Real arb loss 2.0302430410221925e-05\n",
      "Bounds loss: 0.6683033865221786\n",
      "MAPE:  0.08923872552362155\n",
      "Delta:  0.010713545188010348\n",
      "GRAD\n",
      " tensor([-51.5505,   1.7716,   8.2582,  93.3838])\n",
      "-0.023508817134850535 -0.02149424234015651 0.9916099056094072\n",
      "Epoch: 580\n",
      "Arb loss 0.00017139005274053373\n",
      "Real arb loss 1.7099820662708556e-07\n",
      "Bounds loss: 0.6826680614688336\n",
      "MAPE:  0.09218979763628145\n",
      "Delta:  0.010965407962701242\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.024712141877234473 0.02325027636200716 -118.02026828727276\n",
      "arb imp changed to 997.2003677702486\n",
      "Epoch: 581\n",
      "Arb loss 0.020409089503977625\n",
      "Real arb loss 2.0273986768134726e-05\n",
      "Bounds loss: 0.6667958403761675\n",
      "MAPE:  0.08912170824588657\n",
      "Delta:  0.010694429245385212\n",
      "GRAD\n",
      " tensor([-51.5681,   1.7642,   8.2550,  93.4226])\n",
      "-0.023531499310455395 -0.02158424617219512 0.9925745001833363\n",
      "Epoch: 582\n",
      "Arb loss 0.0001515476903700593\n",
      "Real arb loss 1.5107969962316338e-07\n",
      "Bounds loss: 0.6811881259414424\n",
      "MAPE:  0.09208823533090331\n",
      "Delta:  0.010946085199798707\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.024692748006476917 0.023291757314690686 -133.1708108087171\n",
      "Epoch: 583\n",
      "Arb loss 0.020333276493139263\n",
      "Real arb loss 2.0198942761546966e-05\n",
      "Bounds loss: 0.6653220574263654\n",
      "MAPE:  0.08900855751363049\n",
      "Delta:  0.010675796276302652\n",
      "GRAD\n",
      " tensor([-51.5596,   1.7677,   8.2565,  93.4399])\n",
      "-0.023538635263866015 -0.02166340147526835 0.9936164525250343\n",
      "Epoch: 584\n",
      "Arb loss 0.000129798435815559\n",
      "Real arb loss 1.293372568906201e-07\n",
      "Bounds loss: 0.6797351962667443\n",
      "MAPE:  0.09198902990303928\n",
      "Delta:  0.010927089951001879\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.024670336260346093 0.023333121445734184 -154.96575230355572\n",
      "Epoch: 585\n",
      "Arb loss 0.02024411068979845\n",
      "Real arb loss 2.0110834172366655e-05\n",
      "Bounds loss: 0.6638748523813124\n",
      "MAPE:  0.08889775639681644\n",
      "Delta:  0.010657514967563614\n",
      "GRAD\n",
      " tensor([-51.5509,   1.7714,   8.2580,  93.4564])\n",
      "-0.02269451802881539 -0.02127187340426917 0.9889555180806063\n",
      "Epoch: 586\n",
      "Arb loss 0.00022358571448768326\n",
      "Real arb loss 2.2306721470417153e-07\n",
      "Bounds loss: 0.6779967141974456\n",
      "MAPE:  0.09183102540753203\n",
      "Delta:  0.010899382133137356\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.023982160581098255 0.023130739349040974 -93.30172253727184\n",
      "Epoch: 587\n",
      "Arb loss 0.021084518010915185\n",
      "Real arb loss 2.0943823505588813e-05\n",
      "Bounds loss: 0.6623141489218383\n",
      "MAPE:  0.08876817262015492\n",
      "Delta:  0.010637991400585703\n",
      "GRAD\n",
      " tensor([-66.0016,   1.8535,   8.8345, 119.6930])\n",
      "-0.03418318844696144 -0.03412742117447287 1.0\n",
      "Epoch: 588\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 0.6849172228319064\n",
      "MAPE:  0.09331906869335121\n",
      "Delta:  0.011001631865329079\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.027215397792474616 0.025312196718795255 -inf\n",
      "Epoch: 589\n",
      "Arb loss 0.006946443461122832\n",
      "Real arb loss 6.915847785105887e-06\n",
      "Bounds loss: 0.6675804633514942\n",
      "MAPE:  0.08989036717134535\n",
      "Delta:  0.010702218077747783\n",
      "GRAD\n",
      " tensor([-22.0574,   0.9360,   4.2753,  41.2395])\n",
      "-0.0007870790871689071 0.002736701910325934 0.06576987050762406\n",
      "Epoch: 590\n",
      "Arb loss 0.006489576774196252\n",
      "Real arb loss 6.461729866882579e-06\n",
      "Bounds loss: 0.665753494622144\n",
      "MAPE:  0.08971567325288353\n",
      "Delta:  0.0107106415697831\n",
      "GRAD\n",
      " tensor([-22.0604,   0.9319,   4.2725,  41.1904])\n",
      "0.001401355919264713 0.002841500409480835 -0.12346154766239481\n",
      "Epoch: 591\n",
      "Arb loss 0.0072907899664124524\n",
      "Real arb loss 7.257707179331184e-06\n",
      "Bounds loss: 0.6638617557945619\n",
      "MAPE:  0.08946569087325261\n",
      "Delta:  0.010695632148820161\n",
      "GRAD\n",
      " tensor([-22.0718,   0.9238,   4.2678,  41.2015])\n",
      "0.0019333383523829628 0.0028073959444090413 -0.14771146968753568\n",
      "arb imp changed to 997.5992080333303\n",
      "Epoch: 592\n",
      "Arb loss 0.008371907129168141\n",
      "Real arb loss 8.326409483841455e-06\n",
      "Bounds loss: 0.6619980329936959\n",
      "MAPE:  0.08921036843638823\n",
      "Delta:  0.010674953872983868\n",
      "GRAD\n",
      " tensor([-22.0956,   0.9106,   4.2609,  41.2359])\n",
      "0.002183272413809889 0.0030131143648073344 -0.2239184653627866\n",
      "Epoch: 593\n",
      "Arb loss 0.010246531725691243\n",
      "Real arb loss 1.0189158989467547e-05\n",
      "Bounds loss: 0.6600033572110084\n",
      "MAPE:  0.0889318887301874\n",
      "Delta:  0.010651647540674289\n",
      "GRAD\n",
      " tensor([-36.6595,   0.9327,   4.8072,  68.5413])\n",
      "-0.009162656466004337 -0.009323669937935097 0.8031198105706892\n",
      "Epoch: 594\n",
      "Arb loss 0.002017339107147536\n",
      "Real arb loss 2.010025007858133e-06\n",
      "Bounds loss: 0.6661570106715728\n",
      "MAPE:  0.09024716196248185\n",
      "Delta:  0.010749244927886446\n",
      "GRAD\n",
      " tensor([-7.3831,  0.9635,  1.7511, 13.7350])\n",
      "0.016852013681222466 0.016410471810206717 -7.86513372932416\n",
      "Epoch: 595\n",
      "Arb loss 0.017883980962258305\n",
      "Real arb loss 1.7761239916907235e-05\n",
      "Bounds loss: 0.6552250598267754\n",
      "MAPE:  0.0881177612865903\n",
      "Delta:  0.010568098505298893\n",
      "GRAD\n",
      " tensor([-51.1709,   1.9698,   8.3569,  91.9968])\n",
      "-0.02185189876844751 -0.021429836025788296 0.9840648496187421\n",
      "Epoch: 596\n",
      "Arb loss 0.00028498392604913965\n",
      "Real arb loss 2.842507567281695e-07\n",
      "Bounds loss: 0.6692664254188505\n",
      "MAPE:  0.09105422667948611\n",
      "Delta:  0.010799031524011665\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.024660250812696405 0.023362126734144395 -68.27329626777572\n",
      "Epoch: 597\n",
      "Arb loss 0.019741775940755938\n",
      "Real arb loss 1.960300643129481e-05\n",
      "Bounds loss: 0.6536309383693075\n",
      "MAPE:  0.08794160553701771\n",
      "Delta:  0.010532724698095323\n",
      "GRAD\n",
      " tensor([-51.1671,   1.9693,   8.3559,  92.1072])\n",
      "-0.02299424529248273 -0.02157365140601164 0.9847229956335394\n",
      "Epoch: 598\n",
      "Arb loss 0.00030159519724861614\n",
      "Real arb loss 3.008169972677152e-07\n",
      "Bounds loss: 0.6677321443818712\n",
      "MAPE:  0.09092825471071946\n",
      "Delta:  0.010774916753401517\n",
      "GRAD\n",
      " tensor([-1.0863e-04, -4.4616e-05, -1.8325e-05,  8.3988e-05])\n",
      "0.02433412518897582 0.023299252608253607 -64.88110315438519\n",
      "Epoch: 599\n",
      "Arb loss 0.01986942430080323\n",
      "Real arb loss 1.972984093005456e-05\n",
      "Bounds loss: 0.652174484475267\n",
      "MAPE:  0.08782230212600083\n",
      "Delta:  0.010512718580223453\n",
      "GRAD\n",
      " tensor([-51.1591,   1.9721,   8.3569,  92.1331])\n",
      "-0.02308796992278528 -0.021656790551633165 0.9855595545225364\n",
      "Epoch: 600\n",
      "Arb loss 0.0002869233382843386\n",
      "Real arb loss 2.8618293433354743e-07\n",
      "Bounds loss: 0.6662984906886673\n",
      "MAPE:  0.09082515957830155\n",
      "Delta:  0.010755435910610357\n",
      "GRAD\n",
      " tensor([-5.2550e-04, -2.1584e-04, -8.8656e-05,  4.0659e-04])\n",
      "0.024287404980329996 0.023331229370059492 -68.14593755342165\n",
      "Epoch: 601\n",
      "Arb loss 0.01983958323162815\n",
      "Real arb loss 1.970064559670366e-05\n",
      "Bounds loss: 0.6507529277734856\n",
      "MAPE:  0.08771282550098565\n",
      "Delta:  0.01049421428290938\n",
      "GRAD\n",
      " tensor([-51.1507,   1.9753,   8.3581,  92.1519])\n",
      "-0.02310370408360196 -0.02173645282863612 0.986493967077352\n",
      "Epoch: 602\n",
      "Arb loss 0.0002679540642979833\n",
      "Real arb loss 2.672579303619714e-07\n",
      "Bounds loss: 0.6648979880911308\n",
      "MAPE:  0.09072656533589814\n",
      "Delta:  0.010736669504291628\n",
      "GRAD\n",
      " tensor([-0.0008, -0.0003, -0.0001,  0.0006])\n",
      "0.024262383467029136 0.023371629573964325 -72.78451688991366\n",
      "arb imp changed to 998.098007637347\n",
      "Delta imp changed to 0.02213514883096747\n",
      "Epoch: 603\n",
      "Arb loss 0.01978074661350702\n",
      "Real arb loss 1.963291693931015e-05\n",
      "Bounds loss: 0.6493582386089907\n",
      "MAPE:  0.08760763841316967\n",
      "Delta:  0.010220655913775365\n",
      "GRAD\n",
      " tensor([-51.1675,   1.9683,   8.3551,  92.1895])\n",
      "-0.023128350370366313 -0.021826441769703164 0.9875775283121986\n",
      "Epoch: 604\n",
      "Arb loss 0.00024572576476986394\n",
      "Real arb loss 2.449523987776599e-07\n",
      "Bounds loss: 0.6635314183916668\n",
      "MAPE:  0.09063230060704783\n",
      "Delta:  0.010457042824764118\n",
      "GRAD\n",
      " tensor([-0.0010, -0.0004, -0.0002,  0.0008])\n",
      "0.02424305865628551 0.023415953671737433 -79.0491685913208\n",
      "Epoch: 605\n",
      "Arb loss 0.019670143171294074\n",
      "Real arb loss 1.9523733786888425e-05\n",
      "Bounds loss: 0.6479941974388653\n",
      "MAPE:  0.08750618142032739\n",
      "Delta:  0.010203532122192072\n",
      "GRAD\n",
      " tensor([-51.1585,   1.9720,   8.3567,  92.2055])\n",
      "-0.023133734246461257 -0.02190449550591156 0.9887088948649506\n",
      "Epoch: 606\n",
      "Arb loss 0.0002220976545685556\n",
      "Real arb loss 2.2137610594101868e-07\n",
      "Bounds loss: 0.6621881834245218\n",
      "MAPE:  0.09053993202775684\n",
      "Delta:  0.010439577922682094\n",
      "GRAD\n",
      " tensor([-0.0012, -0.0005, -0.0002,  0.0009])\n",
      "0.024222518442767127 0.023460302392186994 -86.9778723182507\n",
      "Epoch: 607\n",
      "Arb loss 0.019539679095815332\n",
      "Real arb loss 1.939486031741896e-05\n",
      "Bounds loss: 0.6466530484008495\n",
      "MAPE:  0.0874065537029036\n",
      "Delta:  0.010186705053915222\n",
      "GRAD\n",
      " tensor([-51.1493,   1.9760,   8.3584,  92.2210])\n",
      "-0.023141307128484723 -0.021982151625317137 0.9899222521672411\n",
      "Epoch: 608\n",
      "Arb loss 0.00019691595866065832\n",
      "Real arb loss 1.9624051088456758e-07\n",
      "Bounds loss: 0.6608678737597704\n",
      "MAPE:  0.09044941332578937\n",
      "Delta:  0.010422438724195163\n",
      "GRAD\n",
      " tensor([-0.0013, -0.0006, -0.0002,  0.0010])\n",
      "0.02420180142831052 0.02350516549733561 -97.45388863876491\n",
      "Epoch: 609\n",
      "Arb loss 0.01938714186517209\n",
      "Real arb loss 1.9244101006434303e-05\n",
      "Bounds loss: 0.6453340650151748\n",
      "MAPE:  0.08730869486680698\n",
      "Delta:  0.010170196931793458\n",
      "GRAD\n",
      " tensor([-51.1399,   1.9800,   8.3602,  92.2359])\n",
      "-0.023141741779709513 -0.022055858173348764 0.9911947545476847\n",
      "Epoch: 610\n",
      "Arb loss 0.0001707085427416983\n",
      "Real arb loss 1.700730866513768e-07\n",
      "Bounds loss: 0.6595674616275801\n",
      "MAPE:  0.09035990042151518\n",
      "Delta:  0.010405553003037816\n",
      "GRAD\n",
      " tensor([-0.0015, -0.0006, -0.0002,  0.0011])\n",
      "0.02417756500437973 0.02354904156799187 -111.57173449729561\n",
      "Epoch: 611\n",
      "Arb loss 0.0192169567499387\n",
      "Real arb loss 1.9075833142017767e-05\n",
      "Bounds loss: 0.6440352800568173\n",
      "MAPE:  0.08721200570637576\n",
      "Delta:  0.010153972068900351\n",
      "GRAD\n",
      " tensor([-51.1305,   1.9842,   8.3620,  92.2502])\n",
      "-0.02314031996822208 -0.022127760944764097 0.9925388309224223\n",
      "Epoch: 612\n",
      "Arb loss 0.0001433809634677906\n",
      "Real arb loss 1.4278152845142306e-07\n",
      "Bounds loss: 0.6582863387739089\n",
      "MAPE:  0.09027128998581577\n",
      "Delta:  0.010388938231523094\n",
      "GRAD\n",
      " tensor([-0.0016, -0.0006, -0.0003,  0.0012])\n",
      "0.024151822253872024 0.02359237234641487 -131.7227371316095\n",
      "Epoch: 613\n",
      "Arb loss 0.019029913924012477\n",
      "Real arb loss 1.8890834323955488e-05\n",
      "Bounds loss: 0.6427558023589965\n",
      "MAPE:  0.08711630958637538\n",
      "Delta:  0.010138026441948894\n",
      "GRAD\n",
      " tensor([-51.1210,   1.9885,   8.3639,  92.2639])\n",
      "-0.023139194899642224 -0.02219915902451075 0.9939654748621014\n",
      "arb imp changed to 998.5970566411656\n",
      "Epoch: 614\n",
      "Arb loss 0.00011489391219347328\n",
      "Real arb loss 1.1426854253299145e-07\n",
      "Bounds loss: 0.657024440629491\n",
      "MAPE:  0.09018365743948288\n",
      "Delta:  0.010372612211686876\n",
      "GRAD\n",
      " tensor([-0.0016, -0.0007, -0.0003,  0.0013])\n",
      "0.02412590882300958 0.02363577018298202 -162.93791277640324\n",
      "Epoch: 615\n",
      "Arb loss 0.018835468155713353\n",
      "Real arb loss 1.868914059368086e-05\n",
      "Bounds loss: 0.64149516194617\n",
      "MAPE:  0.0870215937318305\n",
      "Delta:  0.010122363515211282\n",
      "GRAD\n",
      " tensor([-51.1370,   1.9824,   8.3616,  92.2973])\n",
      "-0.023150518104008144 -0.02228033511605254 0.9955389846030935\n",
      "Epoch: 616\n",
      "Arb loss 8.402531345057814e-05\n",
      "Real arb loss 8.34486099194065e-08\n",
      "Bounds loss: 0.6557878891296571\n",
      "MAPE:  0.09009836323292224\n",
      "Delta:  0.010356701475025532\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.02410563763339335 0.023681816880485984 -220.42379825981965\n",
      "Epoch: 617\n",
      "Arb loss 0.018605204054198923\n",
      "Real arb loss 1.8461360734653254e-05\n",
      "Bounds loss: 0.6402576404268481\n",
      "MAPE:  0.0869287778959983\n",
      "Delta:  0.010107046582191338\n",
      "GRAD\n",
      " tensor([-51.1273,   1.9870,   8.3637,  92.3097])\n",
      "-0.023147798416186527 -0.022350534501798025 0.997173714352975\n",
      "Epoch: 618\n",
      "Arb loss 5.2583621178353826e-05\n",
      "Real arb loss 5.20425777884026e-08\n",
      "Bounds loss: 0.6545677409092482\n",
      "MAPE:  0.0900134613716757\n",
      "Delta:  0.01034100245905891\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.02408764337063607 0.023728010720430626 -349.09173163788756\n",
      "Epoch: 619\n",
      "Arb loss 0.018409090994120587\n",
      "Real arb loss 1.8267779633432804e-05\n",
      "Bounds loss: 0.6390361505357055\n",
      "MAPE:  0.08683605402770343\n",
      "Delta:  0.010091912079730227\n",
      "GRAD\n",
      " tensor([-51.1176,   1.9915,   8.3658,  92.3221])\n",
      "-0.022131346206105462 -0.021591017336384688 0.9904828635272956\n",
      "Epoch: 620\n",
      "Arb loss 0.00017520183132947793\n",
      "Real arb loss 1.744772511536978e-07\n",
      "Bounds loss: 0.6528335911404984\n",
      "MAPE:  0.0898276028853846\n",
      "Delta:  0.010315259679848315\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.023388626527241718 0.023485335022561782 -110.55447508200135\n",
      "Epoch: 621\n",
      "Arb loss 0.019544548327365248\n",
      "Real arb loss 1.939154709737707e-05\n",
      "Bounds loss: 0.6375015755385817\n",
      "MAPE:  0.08668870194688531\n",
      "Delta:  0.010073999923664829\n",
      "GRAD\n",
      " tensor([-51.1145,   1.9919,   8.3656,  93.3612])\n",
      "-0.02372173293196367 -0.022981707087439185 0.9989085972916943\n",
      "Epoch: 622\n",
      "Arb loss 2.1330972977097268e-05\n",
      "Real arb loss 2.081757253726696e-08\n",
      "Bounds loss: 0.6521524500153904\n",
      "MAPE:  0.08985630380782107\n",
      "Delta:  0.010312972659410627\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.024077303260418348 0.023808353126317683 -861.0587857459409\n",
      "Epoch: 623\n",
      "Arb loss 0.01838855266341595\n",
      "Real arb loss 1.8248178223223908e-05\n",
      "Bounds loss: 0.6366257741932306\n",
      "MAPE:  0.08666449634652433\n",
      "Delta:  0.010064664089173595\n",
      "GRAD\n",
      " tensor([-51.0984,   2.0014,   8.3707,  93.3448])\n",
      "-0.02251145143828981 -0.02219581351500355 0.9949134483386886\n",
      "Epoch: 624\n",
      "Arb loss 9.35343230992117e-05\n",
      "Real arb loss 9.294528494035656e-08\n",
      "Bounds loss: 0.6507562011560684\n",
      "MAPE:  0.08972779563884364\n",
      "Delta:  0.010291234286059724\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.023443086604258645 0.023625083050167417 -200.78633575181803\n",
      "arb imp changed to 999.0963551694862\n",
      "Epoch: 625\n",
      "Arb loss 0.018883385299379166\n",
      "Real arb loss 1.87283012438207e-05\n",
      "Bounds loss: 0.6353820318583447\n",
      "MAPE:  0.08656585072474422\n",
      "Delta:  0.010049975989426911\n",
      "GRAD\n",
      " tensor([-51.1159,   1.9950,   8.3684,  93.3904])\n",
      "-0.022694267114217626 -0.02228343522776388 0.9948639231538413\n",
      "Epoch: 626\n",
      "Arb loss 9.698651801323365e-05\n",
      "Real arb loss 9.634442081584218e-08\n",
      "Bounds loss: 0.6495405262101452\n",
      "MAPE:  0.08964216379563167\n",
      "Delta:  0.010278052829022439\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.023401878808556598 0.023638173642947513 -195.47167859462567\n",
      "Epoch: 627\n",
      "Arb loss 0.019055103995107917\n",
      "Real arb loss 1.889821353595081e-05\n",
      "Bounds loss: 0.6341865744634583\n",
      "MAPE:  0.08647727754832836\n",
      "Delta:  0.010037527082329713\n",
      "GRAD\n",
      " tensor([-51.1072,   1.9997,   8.3708,  93.4024])\n",
      "-0.02270418866376489 -0.022351962544319592 0.9952498475627292\n",
      "Epoch: 628\n",
      "Arb loss 9.051464868481191e-05\n",
      "Real arb loss 8.988443005476452e-08\n",
      "Bounds loss: 0.6483618890219759\n",
      "MAPE:  0.08955941206882309\n",
      "Delta:  0.010265420990924576\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.023396320832940076 0.02366489096761193 -210.51611274525192\n",
      "Epoch: 629\n",
      "Arb loss 0.019145306636313544\n",
      "Real arb loss 1.898759240118665e-05\n",
      "Bounds loss: 0.6330184756107159\n",
      "MAPE:  0.08638982432217558\n",
      "Delta:  0.010025247907935707\n",
      "GRAD\n",
      " tensor([-51.0984,   2.0044,   8.3732,  93.4132])\n",
      "-0.02270482663442208 -0.0224193685218268 0.9958955314490566\n",
      "Epoch: 630\n",
      "Arb loss 7.858130898691677e-05\n",
      "Real arb loss 7.79721199601624e-08\n",
      "Bounds loss: 0.6472103500965575\n",
      "MAPE:  0.08947728430933001\n",
      "Delta:  0.010252869423652491\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.023391027549111376 0.02369406396171203 -194.70765002913387\n",
      "Epoch: 631\n",
      "Arb loss 0.01537896331804274\n",
      "Real arb loss 1.5255190712615146e-05\n",
      "Bounds loss: 0.6318753066646876\n",
      "MAPE:  0.08630312212511375\n",
      "Delta:  0.010013044272506393\n",
      "GRAD\n",
      " tensor([-36.3719,   1.0739,   4.8747,  68.6968])\n",
      "-0.012659014959075066 -0.010550288754999748 0.8301734937680991\n",
      "Epoch: 632\n",
      "Arb loss 0.002611755609771761\n",
      "Real arb loss 2.597412821234605e-06\n",
      "Bounds loss: 0.638541773607154\n",
      "MAPE:  0.08786652582828829\n",
      "Delta:  0.010139799549737934\n",
      "GRAD\n",
      " tensor([-7.3312,  0.9902,  1.7643, 13.7414])\n",
      "0.015467282175588126 0.01616991855010763 -7.662417266974863\n",
      "Epoch: 633\n",
      "Arb loss 0.022624116891205366\n",
      "Real arb loss 2.2426941891053676e-05\n",
      "Bounds loss: 0.6282166051370851\n",
      "MAPE:  0.08578511134404186\n",
      "Delta:  0.009982964408898235\n",
      "GRAD\n",
      " tensor([-65.4599,   2.1158,   8.9586, 119.6706])\n",
      "-0.03304946844587753 -0.0362791743768025 1.0\n",
      "Epoch: 634\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 0.6510077849012563\n",
      "MAPE:  0.0905182317796738\n",
      "Delta:  0.010312896076126435\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.026787010162234726 0.025918757646931523 -inf\n",
      "Epoch: 635\n",
      "Arb loss 0.007581069895206933\n",
      "Real arb loss 7.5319811312511075e-06\n",
      "Bounds loss: 0.634134471898135\n",
      "MAPE:  0.08699420171575019\n",
      "Delta:  0.010036644424133165\n",
      "GRAD\n",
      " tensor([-21.8797,   1.0236,   4.3173,  41.2591])\n",
      "-0.0008092766748255542 0.0025202526818765003 0.05401165652171025\n",
      "arb imp changed to 999.4959537516958\n",
      "Epoch: 636\n",
      "Arb loss 0.0071751895538359175\n",
      "Real arb loss 7.126065697199733e-06\n",
      "Bounds loss: 0.6325362927946634\n",
      "MAPE:  0.08683628346508401\n",
      "Delta:  0.010044766846359136\n",
      "GRAD\n",
      " tensor([-21.8960,   1.0144,   4.3125,  41.2216])\n",
      "0.0011979640928159174 0.0026055239025440935 -0.1018191518330358\n",
      "Epoch: 637\n",
      "Arb loss 0.007905761268448748\n",
      "Real arb loss 7.84955062615788e-06\n",
      "Bounds loss: 0.6308882043645603\n",
      "MAPE:  0.08660805657913469\n",
      "Delta:  0.010032733576356489\n",
      "GRAD\n",
      " tensor([-21.9064,   1.0071,   4.3083,  41.2303])\n",
      "0.0017083010663915266 0.0025690027807123705 -0.148626642969651\n",
      "Epoch: 638\n",
      "Arb loss 0.009080768025897775\n",
      "Real arb loss 9.014040866273804e-06\n",
      "Bounds loss: 0.6292674508132291\n",
      "MAPE:  0.08637469480884226\n",
      "Delta:  0.010015594646889179\n",
      "GRAD\n",
      " tensor([-21.9174,   0.9996,   4.3039,  41.2530])\n",
      "0.0010230450411823355 0.0021319697603658927 -0.01332467185961117\n",
      "Epoch: 639\n",
      "Arb loss 0.009201766280076113\n",
      "Real arb loss 9.133950247124797e-06\n",
      "Bounds loss: 0.6279258716369127\n",
      "MAPE:  0.08621342824049405\n",
      "Delta:  0.010005348242451185\n",
      "GRAD\n",
      " tensor([-21.9221,   0.9952,   4.3012,  41.2498])\n",
      "0.0016827640732594018 0.0021755226377230263 -0.07578828382798619\n",
      "Epoch: 640\n",
      "Arb loss 0.009899152354629313\n",
      "Real arb loss 9.825753026314703e-06\n",
      "Bounds loss: 0.6265598046883547\n",
      "MAPE:  0.08603604841488702\n",
      "Delta:  0.00998851160188834\n",
      "GRAD\n",
      " tensor([-36.3557,   1.0815,   4.8782,  67.5365])\n",
      "-0.008237927660664335 -0.009811379569275358 0.792644768322834\n",
      "Epoch: 641\n",
      "Arb loss 0.002052641029901724\n",
      "Real arb loss 2.041474382324389e-06\n",
      "Bounds loss: 0.6327072207550032\n",
      "MAPE:  0.08741785187590399\n",
      "Delta:  0.0100707962379024\n",
      "GRAD\n",
      " tensor([-7.3276,  0.9911,  1.7644, 13.7447])\n",
      "0.016370437800321325 0.01649099044147806 -7.723533659906176\n",
      "Epoch: 642\n",
      "Arb loss 0.017906283116052166\n",
      "Real arb loss 1.7750367883707104e-05\n",
      "Bounds loss: 0.6222732520252783\n",
      "MAPE:  0.08530182270841684\n",
      "Delta:  0.00990593289449011\n",
      "GRAD\n",
      " tensor([-50.7223,   1.1893,   8.4616,  92.0227])\n",
      "-0.022299931969910203 -0.02332548813607538 0.9909806077405291\n",
      "Epoch: 643\n",
      "Arb loss 0.00016150379133281616\n",
      "Real arb loss 1.6066066902535593e-07\n",
      "Bounds loss: 0.636788079382791\n",
      "MAPE:  0.08842926529860758\n",
      "Delta:  0.010126834524135734\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.024099370449244706 0.023916088231065946 -113.25698516284092\n",
      "Epoch: 644\n",
      "Arb loss 0.01845293629005613\n",
      "Real arb loss 1.829196911431169e-05\n",
      "Bounds loss: 0.6215585994917812\n",
      "MAPE:  0.08527869568093965\n",
      "Delta:  0.009882784187460386\n",
      "GRAD\n",
      " tensor([-50.6975,   1.2028,   8.4685,  92.0952])\n",
      "-0.023418044500736368 -0.02344845329368228 0.9949198043899714\n",
      "Epoch: 645\n",
      "Arb loss 9.374452593288107e-05\n",
      "Real arb loss 9.307101046557991e-08\n",
      "Bounds loss: 0.6361331872812508\n",
      "MAPE:  0.0884425721555464\n",
      "Delta:  0.010114219667353508\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.02382933501093565 0.023953783895178105 -184.95772622184427\n",
      "Epoch: 646\n",
      "Arb loss 0.01743251888822328\n",
      "Real arb loss 1.728257334928306e-05\n",
      "Bounds loss: 0.6208953903845649\n",
      "MAPE:  0.08528463956861801\n",
      "Delta:  0.009873204538525946\n",
      "GRAD\n",
      " tensor([-50.6804,   1.2139,   8.4747,  92.0922])\n",
      "-0.023484335977501214 -0.02350648504943731 0.999710951742559\n",
      "arb imp changed to 999.9957017285716\n",
      "Delta imp changed to 0.021595267152163387\n",
      "Epoch: 647\n",
      "Arb loss 5.041358627053399e-06\n",
      "Real arb loss 4.5322336643775775e-09\n",
      "Bounds loss: 0.6354904585959041\n",
      "MAPE:  0.08845447963614776\n",
      "Delta:  0.009858605064471492\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.023828814294841516 0.024070825228547088 -3254.778193679897\n",
      "Epoch: 648\n",
      "Arb loss 0.01641354548448048\n",
      "Real arb loss 1.6266028466549515e-05\n",
      "Bounds loss: 0.6201936788326329\n",
      "MAPE:  0.08527819409414943\n",
      "Delta:  0.009623686195184018\n",
      "GRAD\n",
      " tensor([-50.6903,   1.2135,   8.4760,  92.1058])\n",
      "-0.022467693852682435 -0.022701693160529723 0.9953292208090763\n",
      "Epoch: 649\n",
      "Arb loss 7.666404669819206e-05\n",
      "Real arb loss 7.598930012730001e-08\n",
      "Bounds loss: 0.6342731254295915\n",
      "MAPE:  0.08834867219541932\n",
      "Delta:  0.0098399082303517\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.023172966888130864 0.0238828610653542 -219.31077463509502\n",
      "Epoch: 650\n",
      "Arb loss 0.01688991551473979\n",
      "Real arb loss 1.6737765359514476e-05\n",
      "Bounds loss: 0.6191248684974686\n",
      "MAPE:  0.08520294477064651\n",
      "Delta:  0.009611888362747512\n",
      "GRAD\n",
      " tensor([-50.6770,   1.2206,   8.4796,  92.1244])\n",
      "-0.023666887380123125 -0.02364788229963266 0.9999791228799714\n",
      "Epoch: 651\n",
      "Arb loss 3.526127934744256e-07\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 0.6337658605164722\n",
      "MAPE:  0.08838673972427886\n",
      "Delta:  0.009839371842138974\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.02418238312911425 0.024442894494481227 -47194.4613732028\n",
      "Epoch: 652\n",
      "Arb loss 0.016641723474119387\n",
      "Real arb loss 1.6492608032254426e-05\n",
      "Bounds loss: 0.618274788453664\n",
      "MAPE:  0.0851589227754197\n",
      "Delta:  0.00960143238250255\n",
      "GRAD\n",
      " tensor([-50.6626,   1.2292,   8.4843,  92.1336])\n",
      "-0.02278273882082904 -0.022836810870801916 0.9980702495257152\n",
      "Epoch: 653\n",
      "Arb loss 3.211437376709895e-05\n",
      "Real arb loss 3.154743596918419e-08\n",
      "Bounds loss: 0.6323942128637654\n",
      "MAPE:  0.08824553247795623\n",
      "Delta:  0.009820179308778956\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.023104257566261555 0.023957201170872744 -515.079974099565\n",
      "Epoch: 654\n",
      "Arb loss 0.016573585181948174\n",
      "Real arb loss 1.6425692073525444e-05\n",
      "Bounds loss: 0.6172438174868924\n",
      "MAPE:  0.08508917561171862\n",
      "Delta:  0.009593291356682056\n",
      "GRAD\n",
      " tensor([-50.6525,   1.2350,   8.4874,  92.1305])\n",
      "-0.022652551410182076 -0.022897038003254933 0.9988780572168692\n",
      "Epoch: 655\n",
      "Arb loss 1.859461428548992e-05\n",
      "Real arb loss 1.8057275398955518e-08\n",
      "Bounds loss: 0.6313768726331639\n",
      "MAPE:  0.08817522186084358\n",
      "Delta:  0.009810603882332151\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.02313881417119057 0.023995263774755693 -891.7951425998237\n",
      "Epoch: 656\n",
      "Arb loss 0.01660118131260269\n",
      "Real arb loss 1.645342984695992e-05\n",
      "Bounds loss: 0.6162268180330508\n",
      "MAPE:  0.08501615215466561\n",
      "Delta:  0.009583598142191707\n",
      "GRAD\n",
      " tensor([-50.6420,   1.2409,   8.4904,  92.1360])\n",
      "-0.022639964005857882 -0.022960886373263545 0.9998203843510816\n",
      "Epoch: 657\n",
      "Arb loss 2.9818319542755407e-06\n",
      "Real arb loss 2.4768664985859447e-09\n",
      "Bounds loss: 0.6303759319820655\n",
      "MAPE:  0.08810261763346379\n",
      "Delta:  0.009800570459177534\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.023139175765264586 0.024025005674103705 -5559.941428760117\n",
      "arb imp changed to 1000.4956995794358\n",
      "Epoch: 658\n",
      "Arb loss 0.016590083744555662\n",
      "Real arb loss 1.643473561359406e-05\n",
      "Bounds loss: 0.6152311466393781\n",
      "MAPE:  0.0849433472939368\n",
      "Delta:  0.009573793336722765\n",
      "GRAD\n",
      " tensor([-50.6569,   1.2363,   8.4891,  92.1621])\n",
      "-0.022649382813249908 -0.0230354051332069 0.9999720488942256\n",
      "Epoch: 659\n",
      "Arb loss 4.637111855492769e-07\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 0.6294032453527835\n",
      "MAPE:  0.08803140174600263\n",
      "Delta:  0.00979063384698114\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.023512685299591496 0.024301015860869413 -37695.02256215442\n",
      "Epoch: 660\n",
      "Arb loss 0.017480067312788918\n",
      "Real arb loss 1.7314565487938265e-05\n",
      "Bounds loss: 0.6141081071045829\n",
      "MAPE:  0.08484144339434664\n",
      "Delta:  0.009560429754453544\n",
      "GRAD\n",
      " tensor([-50.6464,   1.2414,   8.4916,  92.1957])\n",
      "-0.023993234348586245 -0.023996694875376035 0.9999864479443852\n",
      "Epoch: 661\n",
      "Arb loss 2.3689084437297626e-07\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 0.6288446719712663\n",
      "MAPE:  0.08804287765003928\n",
      "Delta:  0.009789815386025344\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.024099888709870676 0.0245804507363816 -69616.22729701489\n",
      "Epoch: 662\n",
      "Arb loss 0.016491683757295268\n",
      "Real arb loss 1.633848168435946e-05\n",
      "Bounds loss: 0.6133873864910405\n",
      "MAPE:  0.08481332902760894\n",
      "Delta:  0.009553881924731953\n",
      "GRAD\n",
      " tensor([-50.6340,   1.2494,   8.4960,  92.1801])\n",
      "-0.022799102131762616 -0.0231628677936333 0.999978155706472\n",
      "Epoch: 663\n",
      "Arb loss 3.602491807653453e-07\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 0.6275951974306149\n",
      "MAPE:  0.08790395899789133\n",
      "Delta:  0.009771701854488717\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.023465873016510486 0.024367130893853672 -47386.75279767099\n",
      "Epoch: 664\n",
      "Arb loss 0.017071399123671675\n",
      "Real arb loss 1.691151527774723e-05\n",
      "Bounds loss: 0.612302503106469\n",
      "MAPE:  0.08471691717259505\n",
      "Delta:  0.009542400339616085\n",
      "GRAD\n",
      " tensor([-50.6248,   1.2541,   8.4983,  92.2029])\n",
      "-0.022971974940239948 -0.023234795226647176 0.9999778026123468\n",
      "Epoch: 665\n",
      "Arb loss 3.7894046413076105e-07\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 0.6265292263829114\n",
      "MAPE:  0.08781011477963366\n",
      "Delta:  0.009761608121087484\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.023413437479039678 0.02435409026247659 -45692.489076901154\n",
      "Epoch: 666\n",
      "Arb loss 0.017315111958554782\n",
      "Real arb loss 1.7152567217604565e-05\n",
      "Bounds loss: 0.6112706770515024\n",
      "MAPE:  0.08463311299979155\n",
      "Delta:  0.009533055319649516\n",
      "GRAD\n",
      " tensor([-50.6168,   1.2585,   8.5006,  92.2129])\n",
      "-0.022984075880138954 -0.023300816744910025 0.9999782985929475\n",
      "Epoch: 667\n",
      "Arb loss 3.7576229277248036e-07\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 0.6255137830790165\n",
      "MAPE:  0.08772458021378743\n",
      "Delta:  0.009752163786485904\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.023403272561359434 0.024361036888686405 -46434.473305665655\n",
      "Epoch: 668\n",
      "Arb loss 0.017448699915312234\n",
      "Real arb loss 1.7284852846067584e-05\n",
      "Bounds loss: 0.6102756187350469\n",
      "MAPE:  0.0845538041324866\n",
      "Delta:  0.009523931239327753\n",
      "GRAD\n",
      " tensor([-50.6086,   1.2632,   8.5031,  92.2210])\n",
      "-0.022984306666278265 -0.023365335746826643 0.9999793685219\n",
      "arb imp changed to 1000.9959474292255\n",
      "Epoch: 669\n",
      "Arb loss 3.6017246641295834e-07\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 0.6245349134648935\n",
      "MAPE:  0.0876456741918166\n",
      "Delta:  0.00974283219560101\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.02339516965684485 0.024374126472018198 -48615.35414273668\n",
      "Epoch: 670\n",
      "Arb loss 0.017510272179595315\n",
      "Real arb loss 1.7337383703543548e-05\n",
      "Bounds loss: 0.6093124204979092\n",
      "MAPE:  0.08447787574674584\n",
      "Delta:  0.009514896983446753\n",
      "GRAD\n",
      " tensor([-50.6253,   1.2577,   8.5013,  92.2484])\n",
      "-0.02299618371404666 -0.02343980019222669 0.9999809884187201\n",
      "Epoch: 671\n",
      "Arb loss 3.328979627756191e-07\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 0.6235945818890222\n",
      "MAPE:  0.08757143040497097\n",
      "Delta:  0.009733703302498323\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.023390535609955854 0.024393823087253685 -41968.683119800735\n",
      "Epoch: 672\n",
      "Arb loss 0.013971622008919956\n",
      "Real arb loss 1.3835754883765972e-05\n",
      "Bounds loss: 0.6083827259802514\n",
      "MAPE:  0.08440584246682652\n",
      "Delta:  0.009506026768784492\n",
      "GRAD\n",
      " tensor([-36.0256,   1.2582,   4.9675,  67.5721])\n",
      "-0.012637864825405964 -0.010890313651399142 0.8532275922988605\n",
      "Epoch: 673\n",
      "Arb loss 0.0020506486017394135\n",
      "Real arb loss 2.0359054843572915e-06\n",
      "Bounds loss: 0.6150082046862697\n",
      "MAPE:  0.08590801236266513\n",
      "Delta:  0.009626162650115082\n",
      "GRAD\n",
      " tensor([-7.2599,  1.0278,  1.7832, 13.7116])\n",
      "0.015046480331152967 0.01622920472585343 -6.835685552075987\n",
      "Epoch: 674\n",
      "Arb loss 0.016068237621034348\n",
      "Real arb loss 1.5907512325876193e-05\n",
      "Bounds loss: 0.6050271106243366\n",
      "MAPE:  0.08392005333666806\n",
      "Delta:  0.009481322783135645\n",
      "GRAD\n",
      " tensor([-36.0604,   1.2318,   4.9518,  67.5939])\n",
      "-0.012421730016222154 -0.011867621834503295 0.8510823459930001\n",
      "Epoch: 675\n",
      "Arb loss 0.0023928442505514506\n",
      "Real arb loss 2.375400975330507e-06\n",
      "Bounds loss: 0.6122073435728485\n",
      "MAPE:  0.08548488727634283\n",
      "Delta:  0.009599097214944412\n",
      "GRAD\n",
      " tensor([-7.2676,  1.0226,  1.7802, 13.7185])\n",
      "0.015900867758672388 0.016239351214481612 -6.580548225001958\n",
      "Epoch: 676\n",
      "Arb loss 0.01813907123622394\n",
      "Real arb loss 1.7952156800252524e-05\n",
      "Bounds loss: 0.6022654935044841\n",
      "MAPE:  0.08352919072057204\n",
      "Delta:  0.00944646323952694\n",
      "GRAD\n",
      " tensor([-36.0824,   1.2128,   4.9399,  67.6559])\n",
      "-0.012251983521039733 -0.012008975703912128 0.831718628656557\n",
      "Epoch: 677\n",
      "Arb loss 0.0030524677825281665\n",
      "Real arb loss 3.029050450259318e-06\n",
      "Bounds loss: 0.6094980851832842\n",
      "MAPE:  0.08508921036715787\n",
      "Delta:  0.009562201151469732\n",
      "GRAD\n",
      " tensor([-7.2797,  1.0158,  1.7767, 13.7390])\n",
      "0.014972179947235986 0.015659033842943648 -5.090435694542674\n",
      "Epoch: 678\n",
      "Arb loss 0.018590858739151072\n",
      "Real arb loss 1.8398066091637374e-05\n",
      "Bounds loss: 0.5999539340401897\n",
      "MAPE:  0.08323919467183855\n",
      "Delta:  0.00941903415513826\n",
      "GRAD\n",
      " tensor([-36.0968,   1.1991,   4.9311,  68.6799])\n",
      "-0.012015227174442256 -0.012536290184574694 0.8255860561018395\n",
      "Epoch: 679\n",
      "Arb loss 0.0032425049931489223\n",
      "Real arb loss 3.2176673240381336e-06\n",
      "Bounds loss: 0.6074751306546948\n",
      "MAPE:  0.08483763961274406\n",
      "Delta:  0.009532205990276075\n",
      "GRAD\n",
      " tensor([-7.2840,  1.0128,  1.7749, 13.7489])\n",
      "0.01508542386102496 0.0156433535365198 -4.961982522798488\n",
      "arb imp changed to 1001.49644540294\n",
      "Epoch: 680\n",
      "Arb loss 0.019341423978290324\n",
      "Real arb loss 1.9129319148999416e-05\n",
      "Bounds loss: 0.5979721824212199\n",
      "MAPE:  0.08301645166085332\n",
      "Delta:  0.00938840862258216\n",
      "GRAD\n",
      " tensor([-50.3337,   1.3789,   8.5517,  91.9349])\n",
      "-0.021740265702887784 -0.024520453279784915 0.986129191377748\n",
      "Epoch: 681\n",
      "Arb loss 0.0002682811904847016\n",
      "Real arb loss 2.6651422390170515e-07\n",
      "Bounds loss: 0.6126347313828905\n",
      "MAPE:  0.08604121041559515\n",
      "Delta:  0.009592515120564379\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.023626077909576604 0.023904792608074432 -70.93859329571548\n",
      "Epoch: 682\n",
      "Arb loss 0.019299771451169324\n",
      "Real arb loss 1.908931776032183e-05\n",
      "Bounds loss: 0.597989825184679\n",
      "MAPE:  0.08313619156255952\n",
      "Delta:  0.009365881610977133\n",
      "GRAD\n",
      " tensor([-50.2899,   1.4047,   8.5655,  92.0236])\n",
      "-0.023455016412299523 -0.024694283991273602 0.9939673326300077\n",
      "Delta imp changed to 0.021068553319183794\n",
      "Epoch: 683\n",
      "Arb loss 0.000116429101481778\n",
      "Real arb loss 1.1547085623685865e-07\n",
      "Bounds loss: 0.6127567557516816\n",
      "MAPE:  0.08621719286156924\n",
      "Delta:  0.009351764407686104\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.023238673934805276 0.02403642563143682 -146.31839826071734\n",
      "Epoch: 684\n",
      "Arb loss 0.017152148741230045\n",
      "Real arb loss 1.697097388491723e-05\n",
      "Bounds loss: 0.5980282735618958\n",
      "MAPE:  0.08327127399885337\n",
      "Delta:  0.00913444180390077\n",
      "GRAD\n",
      " tensor([-36.0674,   1.2168,   4.9407,  68.7815])\n",
      "-0.013802878934557894 -0.012708250115642805 0.8723448581758153\n",
      "Epoch: 685\n",
      "Arb loss 0.002189559980151233\n",
      "Real arb loss 2.173210818071852e-06\n",
      "Bounds loss: 0.6056281664385463\n",
      "MAPE:  0.08490341660786792\n",
      "Delta:  0.009260523398254776\n",
      "GRAD\n",
      " tensor([-7.2716,  1.0191,  1.7780, 13.7489])\n",
      "0.015493075669298695 0.016295758455336373 -7.078047936431393\n",
      "Epoch: 686\n",
      "Arb loss 0.01768737047935343\n",
      "Real arb loss 1.7499068623588223e-05\n",
      "Bounds loss: 0.5957589961245155\n",
      "MAPE:  0.0830055808403522\n",
      "Delta:  0.009117049408508304\n",
      "GRAD\n",
      " tensor([-36.0821,   1.2042,   4.9328,  68.7812])\n",
      "-0.01282493202160051 -0.012772574573442164 0.8522878545733927\n",
      "Epoch: 687\n",
      "Arb loss 0.002612639440460534\n",
      "Real arb loss 2.592412143682728e-06\n",
      "Bounds loss: 0.603368372330315\n",
      "MAPE:  0.08460802218277991\n",
      "Delta:  0.009233974947409997\n",
      "GRAD\n",
      " tensor([-7.2797,  1.0144,  1.7756, 13.7617])\n",
      "0.015669204901123335 0.016226471904292605 -6.464167945733945\n",
      "Epoch: 688\n",
      "Arb loss 0.019501179565245788\n",
      "Real arb loss 1.9289502365957953e-05\n",
      "Bounds loss: 0.5935778323887584\n",
      "MAPE:  0.08274481827378685\n",
      "Delta:  0.00908928590190719\n",
      "GRAD\n",
      " tensor([-50.2866,   1.3963,   8.5581,  92.0578])\n",
      "-0.02252293251881854 -0.024907305724420237 0.9919330178103327\n",
      "Epoch: 689\n",
      "Arb loss 0.0001573156682303417\n",
      "Real arb loss 1.5617062474309122e-07\n",
      "Bounds loss: 0.6083622569313039\n",
      "MAPE:  0.08579175306685827\n",
      "Delta:  0.009294003274920094\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.02336060784144145 0.024120773117828342 -116.2604066821447\n",
      "Epoch: 690\n",
      "Arb loss 0.01844689923416322\n",
      "Real arb loss 1.824958176126494e-05\n",
      "Bounds loss: 0.593688088958414\n",
      "MAPE:  0.08288206867647695\n",
      "Delta:  0.009076889709137614\n",
      "GRAD\n",
      " tensor([-50.2492,   1.4203,   8.5714,  92.0944])\n",
      "-0.023536986469081533 -0.0250131415189343 0.9999736182388322\n",
      "arb imp changed to 1001.9971936256414\n",
      "Epoch: 691\n",
      "Arb loss 4.86905020727388e-07\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 0.6085380931456363\n",
      "MAPE:  0.08597143834792366\n",
      "Delta:  0.00929053233940293\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.023542719227068076 0.024578548463458305 -35480.159169709535\n",
      "Epoch: 692\n",
      "Arb loss 0.017275954540959173\n",
      "Real arb loss 1.708525362778541e-05\n",
      "Bounds loss: 0.5935811101313958\n",
      "MAPE:  0.08297979156343667\n",
      "Delta:  0.009071807945066372\n",
      "GRAD\n",
      " tensor([-36.0595,   1.2188,   4.9410,  68.8664])\n",
      "-0.014156416571956987 -0.012917213313538456 0.8817157184230279\n",
      "Epoch: 693\n",
      "Arb loss 0.002043473871433785\n",
      "Real arb loss 2.0275324242013808e-06\n",
      "Bounds loss: 0.6012485239498501\n",
      "MAPE:  0.08460821654070999\n",
      "Delta:  0.00920023223739752\n",
      "GRAD\n",
      " tensor([-7.2728,  1.0184,  1.7777, 13.7651])\n",
      "0.015364961491628248 0.016409855001249363 -7.514607158769859\n",
      "Epoch: 694\n",
      "Arb loss 0.017399377254469266\n",
      "Real arb loss 1.720707759781801e-05\n",
      "Bounds loss: 0.5913821228521178\n",
      "MAPE:  0.08272361116727131\n",
      "Delta:  0.009058871023355869\n",
      "GRAD\n",
      " tensor([-50.2677,   1.4115,   8.5674,  92.0858])\n",
      "-0.022612847413598036 -0.025133000677442396 0.9999752642886712\n",
      "Delta imp changed to 0.020554686165057363\n",
      "Epoch: 695\n",
      "Arb loss 4.303859730665482e-07\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 0.6062453301463874\n",
      "MAPE:  0.0857952025051445\n",
      "Delta:  0.009037773552728275\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.023759250018366096 0.024724501420494205 -40668.31460096273\n",
      "Epoch: 696\n",
      "Arb loss 0.01750350253848492\n",
      "Real arb loss 1.731053856338708e-05\n",
      "Bounds loss: 0.591256216620015\n",
      "MAPE:  0.08279984350591771\n",
      "Delta:  0.008823042831279626\n",
      "GRAD\n",
      " tensor([-50.2309,   1.4335,   8.5792,  92.1467])\n",
      "-0.023844419506197312 -0.025242249529989103 0.9999853228930025\n",
      "Epoch: 697\n",
      "Arb loss 2.5690077958848265e-07\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 0.6061808535760949\n",
      "MAPE:  0.08591310476863874\n",
      "Delta:  0.009033423165869806\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.023489887849243996 0.02482694748261649 -62351.082116998\n",
      "Epoch: 698\n",
      "Arb loss 0.016018298504821872\n",
      "Real arb loss 1.5844893923346756e-05\n",
      "Bounds loss: 0.5911312333593934\n",
      "MAPE:  0.08288666075149688\n",
      "Delta:  0.00882122906880876\n",
      "GRAD\n",
      " tensor([-36.0304,   1.2345,   4.9490,  68.8746])\n",
      "-0.014005982602318445 -0.012679446884626966 0.8906087485447007\n",
      "Epoch: 699\n",
      "Arb loss 0.0017522617196270131\n",
      "Real arb loss 1.738839745008828e-06\n",
      "Bounds loss: 0.5986264504346178\n",
      "MAPE:  0.08447124763684874\n",
      "Delta:  0.008944779049677562\n",
      "GRAD\n",
      " tensor([-7.2676,  1.0211,  1.7790, 13.7678])\n",
      "0.015372117451667888 0.016540456360126243 -8.485597046689907\n",
      "Epoch: 700\n",
      "Arb loss 0.016621248592721776\n",
      "Real arb loss 1.6439806501814486e-05\n",
      "Bounds loss: 0.5887248957551868\n",
      "MAPE:  0.08258234462994099\n",
      "Delta:  0.008807278855546701\n",
      "GRAD\n",
      " tensor([-36.0506,   1.2188,   4.9395,  68.8640])\n",
      "-0.012743932756455134 -0.012758106255730262 0.863284360734976\n",
      "Epoch: 701\n",
      "Arb loss 0.002272384626736836\n",
      "Real arb loss 2.2543946372245335e-06\n",
      "Bounds loss: 0.5962359105306252\n",
      "MAPE:  0.08413824224560597\n",
      "Delta:  0.008919518225049137\n",
      "GRAD\n",
      " tensor([-7.2777,  1.0155,  1.7761, 13.7817])\n",
      "0.01561104412468739 0.01643594147898042 -7.32481131389328\n",
      "arb imp changed to 1002.4981922224542\n",
      "Epoch: 702\n",
      "Arb loss 0.018926631836801062\n",
      "Real arb loss 1.870679833221407e-05\n",
      "Bounds loss: 0.5864362119974772\n",
      "MAPE:  0.08228392064689229\n",
      "Delta:  0.008780275232466942\n",
      "GRAD\n",
      " tensor([-50.2669,   1.4056,   8.5624,  92.1949])\n",
      "-0.022577285704103334 -0.025460209506467324 0.9999735366647889\n",
      "Epoch: 703\n",
      "Arb loss 5.008618027141781e-07\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 0.6013670008171121\n",
      "MAPE:  0.08534278504313864\n",
      "Delta:  0.008978510014951011\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.023658664946449304 0.02475949684594181 -37559.01008978103\n",
      "Epoch: 704\n",
      "Arb loss 0.01881237436353045\n",
      "Real arb loss 1.859467763404879e-05\n",
      "Bounds loss: 0.5864774564571273\n",
      "MAPE:  0.08239025707987685\n",
      "Delta:  0.008766090454788945\n",
      "GRAD\n",
      " tensor([-50.2271,   1.4299,   8.5756,  92.2561])\n",
      "-0.02388673313533851 -0.02557393529642038 0.9999850762894256\n",
      "Epoch: 705\n",
      "Arb loss 2.807504302189609e-07\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 0.6014759929813711\n",
      "MAPE:  0.085494759780479\n",
      "Delta:  0.008975483718122727\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.023376414547942925 0.02488883244089357 -60313.42101598296\n",
      "Epoch: 706\n",
      "Arb loss 0.016933299648644755\n",
      "Real arb loss 1.6740840965827397e-05\n",
      "Bounds loss: 0.5865059577748376\n",
      "MAPE:  0.08250378700164816\n",
      "Delta:  0.008765669089959578\n",
      "GRAD\n",
      " tensor([-50.2025,   1.4481,   8.5864,  92.2289])\n",
      "-0.02379218849625353 -0.02526688171615299 0.9999916262083851\n",
      "Epoch: 707\n",
      "Arb loss 1.4179592260968525e-07\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 0.6013251344357534\n",
      "MAPE:  0.08558761804508619\n",
      "Delta:  0.00897422354124368\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.023412495506052622 0.025057281491228434 -110846.86912394363\n",
      "Epoch: 708\n",
      "Arb loss 0.01571777587174723\n",
      "Real arb loss 1.554182055944917e-05\n",
      "Bounds loss: 0.586257561274446\n",
      "MAPE:  0.08255901386767814\n",
      "Delta:  0.008764114572914001\n",
      "GRAD\n",
      " tensor([-36.0161,   1.2417,   4.9525,  68.9359])\n",
      "-0.01299525257346934 -0.012023072502374443 0.8937458782836221\n",
      "Epoch: 709\n",
      "Arb loss 0.001670078470587378\n",
      "Real arb loss 1.6559327556777727e-06\n",
      "Bounds loss: 0.5933061784387139\n",
      "MAPE:  0.08404560429541987\n",
      "Delta:  0.00887800645537184\n",
      "GRAD\n",
      " tensor([-0.0104, -0.0043, -0.0017,  0.0083])\n",
      "0.019727359319388293 0.02262236705527365 -15.615461081412949\n",
      "Epoch: 710\n",
      "Arb loss 0.02774912383095024\n",
      "Real arb loss 2.7391497198193643e-05\n",
      "Bounds loss: 0.5798841882939116\n",
      "MAPE:  0.08150559950959448\n",
      "Delta:  0.008702866831986872\n",
      "GRAD\n",
      " tensor([-64.3407,   1.6498,   8.2084, 119.6397])\n",
      "-0.03469692852563622 -0.039957739071914355 1.0\n",
      "Delta imp changed to 0.020053352356153527\n",
      "Epoch: 711\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 0.6030550493816886\n",
      "MAPE:  0.08621739674878681\n",
      "Delta:  0.008785199590658\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.025823536202988273 0.02666200699368315 -inf\n",
      "Epoch: 712\n",
      "Arb loss 0.007805666187642754\n",
      "Real arb loss 7.727666162787187e-06\n",
      "Bounds loss: 0.5869763914374981\n",
      "MAPE:  0.08290576276354782\n",
      "Delta:  0.008558334670978166\n",
      "GRAD\n",
      " tensor([-21.5025,   1.2071,   4.4044,  41.1898])\n",
      "-0.001924851662148841 0.0011984647711318352 0.23904229212113004\n",
      "arb imp changed to 1002.8991514034251\n",
      "Epoch: 713\n",
      "Arb loss 0.005942751741541534\n",
      "Real arb loss 5.881692823002368e-06\n",
      "Bounds loss: 0.5862729209108742\n",
      "MAPE:  0.08288360280540055\n",
      "Delta:  0.008574808195694825\n",
      "GRAD\n",
      " tensor([-21.5188,   1.1999,   4.4012,  41.1256])\n",
      "0.0013364356533164257 0.0018927063858094062 -0.11994711926100643\n",
      "Epoch: 714\n",
      "Arb loss 0.006655567693422771\n",
      "Real arb loss 6.586347302330799e-06\n",
      "Bounds loss: 0.585163278409639\n",
      "MAPE:  0.08273738754811875\n",
      "Delta:  0.008563348516301748\n",
      "GRAD\n",
      " tensor([-21.5200,   1.1976,   4.3995,  41.1395])\n",
      "0.001319154822905344 0.0018144825253845198 -0.11547024320799149\n",
      "Epoch: 715\n",
      "Arb loss 0.007424087713669549\n",
      "Real arb loss 7.346420674060315e-06\n",
      "Bounds loss: 0.584101509866468\n",
      "MAPE:  0.08260130802775743\n",
      "Delta:  0.00855205213380625\n",
      "GRAD\n",
      " tensor([-21.5247,   1.1940,   4.3973,  41.1562])\n",
      "0.0004644367690408435 0.0012892260583555748 0.05920940736729485\n",
      "Epoch: 716\n",
      "Arb loss 0.00698451187990036\n",
      "Real arb loss 6.9115666705245815e-06\n",
      "Bounds loss: 0.5833484709792233\n",
      "MAPE:  0.08253150052805483\n",
      "Delta:  0.008548080246344557\n",
      "GRAD\n",
      " tensor([-21.5255,   1.1926,   4.3964,  41.1435])\n",
      "0.0011093883201372945 0.0013781056694828209 -0.006557074525895157\n",
      "Epoch: 717\n",
      "Arb loss 0.007030309844823866\n",
      "Real arb loss 6.956985483761488e-06\n",
      "Bounds loss: 0.5825445551440827\n",
      "MAPE:  0.08244635163197903\n",
      "Delta:  0.008538597105959667\n",
      "GRAD\n",
      " tensor([-21.5269,   1.1909,   4.3952,  41.1485])\n",
      "0.0012661405720679753 0.0013817680352683492 -0.024103624465900086\n",
      "Epoch: 718\n",
      "Arb loss 0.007199765793202422\n",
      "Real arb loss 7.124760517693848e-06\n",
      "Bounds loss: 0.5817396136986649\n",
      "MAPE:  0.08236226392858591\n",
      "Delta:  0.008527786041735269\n",
      "GRAD\n",
      " tensor([-21.5282,   1.1892,   4.3940,  41.1581])\n",
      "0.0012883359845118347 0.0013608296478245796 -0.026792589573966907\n",
      "Epoch: 719\n",
      "Arb loss 0.00739266616312838\n",
      "Real arb loss 7.315699183984157e-06\n",
      "Bounds loss: 0.5809479651850298\n",
      "MAPE:  0.08228211138211061\n",
      "Delta:  0.008516799388109482\n",
      "GRAD\n",
      " tensor([-21.5293,   1.1877,   4.3929,  41.1686])\n",
      "0.0012746874758260418 0.001334723917521985 -0.025612060335019393\n",
      "Epoch: 720\n",
      "Arb loss 0.0075820075749350796\n",
      "Real arb loss 7.503080182575603e-06\n",
      "Bounds loss: 0.5801725600410615\n",
      "MAPE:  0.08220564529447918\n",
      "Delta:  0.008505943130595337\n",
      "GRAD\n",
      " tensor([-21.5301,   1.1863,   4.3920,  41.1791])\n",
      "0.001252885002561266 0.0013090189534606944 -0.02364520735958786\n",
      "Epoch: 721\n",
      "Arb loss 0.007761285716246385\n",
      "Real arb loss 7.680472988122015e-06\n",
      "Bounds loss: 0.5794131031636901\n",
      "MAPE:  0.08213270760329398\n",
      "Delta:  0.008495286162014375\n",
      "GRAD\n",
      " tensor([-21.5307,   1.1851,   4.3911,  41.1892])\n",
      "0.0012315942099390131 0.0012855733074330633 -0.02175018777846649\n",
      "Epoch: 722\n",
      "Arb loss 0.007930095137977072\n",
      "Real arb loss 7.847481726458633e-06\n",
      "Bounds loss: 0.5786682251442858\n",
      "MAPE:  0.08206287338577785\n",
      "Delta:  0.008484823416765463\n",
      "GRAD\n",
      " tensor([-21.5311,   1.1840,   4.3903,  41.1991])\n",
      "0.0012103624368134946 0.0012636568522845781 -0.019945087680706575\n",
      "Epoch: 723\n",
      "Arb loss 0.00808826158082037\n",
      "Real arb loss 8.003938943581056e-06\n",
      "Bounds loss: 0.577936987076383\n",
      "MAPE:  0.08199587467005255\n",
      "Delta:  0.008474553705218813\n",
      "GRAD\n",
      " tensor([-21.5313,   1.1831,   4.3895,  41.2086])\n",
      "0.0011901906512151728 0.0012433148295041274 -0.018311799472336965\n",
      "arb imp changed to 1003.4006009791268\n",
      "Epoch: 724\n",
      "Arb loss 0.008240490391070644\n",
      "Real arb loss 8.15042966631907e-06\n",
      "Bounds loss: 0.5772184294498319\n",
      "MAPE:  0.08193144536128819\n",
      "Delta:  0.008464467370625641\n",
      "GRAD\n",
      " tensor([-21.5422,   1.1778,   4.3871,  41.2263])\n",
      "0.0011654798430755786 0.0012204803641445716 -0.01625613033284079\n",
      "Epoch: 725\n",
      "Arb loss 0.00837444887687441\n",
      "Real arb loss 8.282843116236116e-06\n",
      "Bounds loss: 0.5765139456908661\n",
      "MAPE:  0.0818697874267263\n",
      "Delta:  0.008454602204522807\n",
      "GRAD\n",
      " tensor([-21.5420,   1.1771,   4.3865,  41.2351])\n",
      "0.001150200994893047 0.0012036568928406322 -0.015196888888445281\n",
      "Epoch: 726\n",
      "Arb loss 0.008501714445958236\n",
      "Real arb loss 8.408625725525996e-06\n",
      "Bounds loss: 0.5758200207063165\n",
      "MAPE:  0.08181013612159714\n",
      "Delta:  0.008444877712655738\n",
      "GRAD\n",
      " tensor([-21.5418,   1.1765,   4.3859,  41.2436])\n",
      "0.0011343385789117644 0.0011876477771506355 -0.014111039333488451\n",
      "Epoch: 727\n",
      "Arb loss 0.008621682472907238\n",
      "Real arb loss 8.527182638387573e-06\n",
      "Bounds loss: 0.5751361493386858\n",
      "MAPE:  0.08175234028450246\n",
      "Delta:  0.008435298362072081\n",
      "GRAD\n",
      " tensor([-21.5414,   1.1760,   4.3854,  41.2519])\n",
      "0.0011189784790440749 0.0011725856437531101 -0.013093777482371616\n",
      "Epoch: 728\n",
      "Arb loss 0.008734572864731149\n",
      "Real arb loss 8.638733058993798e-06\n",
      "Bounds loss: 0.5744617529467678\n",
      "MAPE:  0.08169623755757084\n",
      "Delta:  0.008425859444740606\n",
      "GRAD\n",
      " tensor([-21.5409,   1.1755,   4.3850,  41.2600])\n",
      "0.0011043483238000196 0.0011584454046603687 -0.012161203309336122\n",
      "Epoch: 729\n",
      "Arb loss 0.008840795781159356\n",
      "Real arb loss 8.74368408216368e-06\n",
      "Bounds loss: 0.5737962703689136\n",
      "MAPE:  0.08164167384809483\n",
      "Delta:  0.008416554360986234\n",
      "GRAD\n",
      " tensor([-21.5403,   1.1751,   4.3845,  41.2679])\n",
      "0.0010904982299223542 0.0011451363820268456 -0.011311157045791553\n",
      "Epoch: 730\n",
      "Arb loss 0.008940795410649821\n",
      "Real arb loss 8.842476360232436e-06\n",
      "Bounds loss: 0.5731391953838427\n",
      "MAPE:  0.08158851032076815\n",
      "Delta:  0.008407376123353533\n",
      "GRAD\n",
      " tensor([-21.5397,   1.1748,   4.3842,  41.2755])\n",
      "0.0010773577662660516 0.0011325737767702293 -0.01053350274706033\n",
      "Epoch: 731\n",
      "Arb loss 0.009034973303668805\n",
      "Real arb loss 8.935508155772972e-06\n",
      "Bounds loss: 0.5724900729607117\n",
      "MAPE:  0.08153662262501868\n",
      "Delta:  0.008398318371393118\n",
      "GRAD\n",
      " tensor([-21.5389,   1.1746,   4.3838,  41.2830])\n",
      "0.001064859054560996 0.0011206810056634264 -0.009819197129276702\n",
      "Epoch: 732\n",
      "Arb loss 0.009123689487595283\n",
      "Real arb loss 9.023136486625658e-06\n",
      "Bounds loss: 0.5718484942100138\n",
      "MAPE:  0.08148589948228321\n",
      "Delta:  0.008389375346032254\n",
      "GRAD\n",
      " tensor([-21.5381,   1.1744,   4.3835,  41.2903])\n",
      "0.001052939938898767 0.0011093895093495787 -0.009160386866408299\n",
      "Epoch: 733\n",
      "Arb loss 0.009207266012950637\n",
      "Real arb loss 9.105680665416539e-06\n",
      "Bounds loss: 0.5712140914895999\n",
      "MAPE:  0.0814362413326026\n",
      "Delta:  0.008380541837668004\n",
      "GRAD\n",
      " tensor([-21.5372,   1.1742,   4.3833,  41.2975])\n",
      "0.001041544362160307 0.001098638070000435 -0.008550293606103931\n",
      "Epoch: 734\n",
      "Arb loss 0.009285990840670867\n",
      "Real arb loss 9.183426169667733e-06\n",
      "Bounds loss: 0.5705865339425688\n",
      "MAPE:  0.0813875590990909\n",
      "Delta:  0.008371813131565133\n",
      "GRAD\n",
      " tensor([-21.5362,   1.1741,   4.3830,  41.3045])\n",
      "0.0011839796481345477 0.0014234097951738578 -0.0446990352092278\n",
      "arb imp changed to 1003.9023012796163\n",
      "Epoch: 735\n",
      "Arb loss 0.009705916205046685\n",
      "Real arb loss 9.593060619335523e-06\n",
      "Bounds loss: 0.5697743554811606\n",
      "MAPE:  0.081305321297351\n",
      "Delta:  0.008361901075199374\n",
      "GRAD\n",
      " tensor([-21.5484,   1.1681,   4.3801,  41.3246])\n",
      "0.0011570646227232473 0.0013819654860964814 -0.03883405106722759\n",
      "Epoch: 736\n",
      "Arb loss 0.010082836250607699\n",
      "Real arb loss 9.964716797208486e-06\n",
      "Bounds loss: 0.5689869469870227\n",
      "MAPE:  0.08122783910376911\n",
      "Delta:  0.00835222581528655\n",
      "GRAD\n",
      " tensor([-21.5494,   1.1668,   4.3792,  41.3354])\n",
      "0.0011407853333165185 0.0013486529324621133 -0.040445769240473606\n",
      "Epoch: 737\n",
      "Arb loss 0.01049064431888926\n",
      "Real arb loss 1.036730213600088e-05\n",
      "Bounds loss: 0.568219581072436\n",
      "MAPE:  0.081154113286875\n",
      "Delta:  0.008342697718575924\n",
      "GRAD\n",
      " tensor([-35.7192,   1.3760,   5.0127,  67.6678])\n",
      "-0.008715780529072736 -0.011636230247987323 0.8160663406255988\n",
      "Delta imp changed to 0.019564246201125395\n",
      "Epoch: 738\n",
      "Arb loss 0.0019295825987685742\n",
      "Real arb loss 1.9110082197691668e-06\n",
      "Bounds loss: 0.5748315149492098\n",
      "MAPE:  0.08252454104311865\n",
      "Delta:  0.008210156917962369\n",
      "GRAD\n",
      " tensor([-7.2060,  1.0483,  1.7909, 13.7722])\n",
      "0.015196593704256522 0.016852464073422446 -8.04233204760709\n",
      "Epoch: 739\n",
      "Arb loss 0.01744792657135005\n",
      "Real arb loss 1.7223405075983e-05\n",
      "Bounds loss: 0.5651441874952572\n",
      "MAPE:  0.08068268363422547\n",
      "Delta:  0.008085390499031904\n",
      "GRAD\n",
      " tensor([-35.7265,   1.3620,   5.0024,  68.8889])\n",
      "-0.012746784367338782 -0.013635707763787419 0.8573801795041323\n",
      "Epoch: 740\n",
      "Arb loss 0.002488420155631025\n",
      "Real arb loss 2.463643648283269e-06\n",
      "Bounds loss: 0.5728503284803456\n",
      "MAPE:  0.08225594397776999\n",
      "Delta:  0.008188453228248793\n",
      "GRAD\n",
      " tensor([-7.2151,  1.0435,  1.7885, 13.7879])\n",
      "0.015089836689108793 0.01668037267242639 -6.747399242845751\n",
      "Epoch: 741\n",
      "Arb loss 0.019278784429617907\n",
      "Real arb loss 1.902522634951493e-05\n",
      "Bounds loss: 0.5632949715157716\n",
      "MAPE:  0.0804531873447148\n",
      "Delta:  0.008064890806298113\n",
      "GRAD\n",
      " tensor([-49.7827,   1.6212,   8.6578,  92.2027])\n",
      "-0.02241667653200441 -0.026427198941644248 0.9963165250441414\n",
      "Epoch: 742\n",
      "Arb loss 7.101291962589599e-05\n",
      "Real arb loss 7.007708563386978e-08\n",
      "Bounds loss: 0.5781812797908467\n",
      "MAPE:  0.08345799823207324\n",
      "Delta:  0.008245678854768833\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.02260682026057559 0.02505961968339676 -254.00878126044697\n",
      "Epoch: 743\n",
      "Arb loss 0.018108918087545813\n",
      "Real arb loss 1.7874165458194372e-05\n",
      "Bounds loss: 0.5636922768112284\n",
      "MAPE:  0.08061667757205468\n",
      "Delta:  0.008059270274972646\n",
      "GRAD\n",
      " tensor([-35.7017,   1.3744,   5.0085,  68.9490])\n",
      "-0.013708673823528139 -0.013762546017201505 0.870457683824412\n",
      "Epoch: 744\n",
      "Arb loss 0.0023458711924946828\n",
      "Real arb loss 2.3228178107502218e-06\n",
      "Bounds loss: 0.571450117710384\n",
      "MAPE:  0.08221492354048121\n",
      "Delta:  0.008169752182427902\n",
      "GRAD\n",
      " tensor([-7.2114,  1.0455,  1.7895, 13.7922])\n",
      "0.014831057934362568 0.016722930068783115 -6.950241553304046\n",
      "Epoch: 745\n",
      "Arb loss 0.018650242633270142\n",
      "Real arb loss 1.8407235574552543e-05\n",
      "Bounds loss: 0.5618937973541154\n",
      "MAPE:  0.0803987029160816\n",
      "Delta:  0.008048586114500928\n",
      "GRAD\n",
      " tensor([-49.7556,   1.6359,   8.6653,  92.2144])\n",
      "-0.02246360729990693 -0.02655991785186096 0.9999739027938824\n",
      "arb imp changed to 1004.4042524302561\n",
      "Epoch: 746\n",
      "Arb loss 4.869625857561424e-07\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 0.5768176504533109\n",
      "MAPE:  0.08341559232177584\n",
      "Delta:  0.008229386392296562\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.022977850667362132 0.02551946164216945 -37996.73245392945\n",
      "Epoch: 747\n",
      "Arb loss 0.018503474048635574\n",
      "Real arb loss 1.8254212508933676e-05\n",
      "Bounds loss: 0.5620975745480413\n",
      "MAPE:  0.08051867977754261\n",
      "Delta:  0.008040292780690348\n",
      "GRAD\n",
      " tensor([-49.7365,   1.6527,   8.6758,  92.2802])\n",
      "-0.02363970547205807 -0.02666912165954427 0.9999848278268627\n",
      "Epoch: 748\n",
      "Arb loss 2.807379119062385e-07\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 0.5770882231481979\n",
      "MAPE:  0.08357236534563024\n",
      "Delta:  0.008230362933934983\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.022741059012710507 0.02565750571894876 -60031.05916675432\n",
      "Delta imp changed to 0.019087069464512583\n",
      "Epoch: 749\n",
      "Arb loss 0.016853274937906372\n",
      "Real arb loss 1.663050344804975e-05\n",
      "Bounds loss: 0.5622815787624349\n",
      "MAPE:  0.0806355796797498\n",
      "Delta:  0.007847020258300821\n",
      "GRAD\n",
      " tensor([-35.6791,   1.3917,   5.0189,  68.9636])\n",
      "-0.014033491725878866 -0.013827038420511029 0.9124305975317581\n",
      "Epoch: 750\n",
      "Arb loss 0.0014758312159454574\n",
      "Real arb loss 1.4608809743341112e-06\n",
      "Bounds loss: 0.5700562677551287\n",
      "MAPE:  0.08225719494071386\n",
      "Delta:  0.00795714135216849\n",
      "GRAD\n",
      " tensor([-0.0056, -0.0023, -0.0009,  0.0045])\n",
      "0.019819114316861786 0.023384047103446326 -17.30623891918813\n",
      "Epoch: 751\n",
      "Arb loss 0.02701691884349347\n",
      "Real arb loss 2.6621536103266734e-05\n",
      "Bounds loss: 0.5567260451383279\n",
      "MAPE:  0.0797231210822178\n",
      "Delta:  0.007799437858074435\n",
      "GRAD\n",
      " tensor([-49.7804,   1.6090,   8.6474,  92.4446])\n",
      "-0.024430752005287326 -0.027831104322608713 0.9911384228107649\n",
      "Epoch: 752\n",
      "Arb loss 0.00023941251174691849\n",
      "Real arb loss 2.3711074212294514e-07\n",
      "Bounds loss: 0.5722203457796862\n",
      "MAPE:  0.08282222305081972\n",
      "Delta:  0.0079899839901657\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.022831984927396243 0.024969842419174104 -89.11778039803218\n",
      "Epoch: 753\n",
      "Arb loss 0.0215753241581501\n",
      "Real arb loss 2.1277102245620746e-05\n",
      "Bounds loss: 0.5579320939165221\n",
      "MAPE:  0.08003866377108729\n",
      "Delta:  0.0078075567961321\n",
      "GRAD\n",
      " tensor([-49.7334,   1.6437,   8.6680,  92.3529])\n",
      "-0.023251461434114384 -0.02690701015414443 0.9976197558949997\n",
      "Epoch: 754\n",
      "Arb loss 5.135453814090654e-05\n",
      "Real arb loss 5.051810703936288e-08\n",
      "Bounds loss: 0.572944378432857\n",
      "MAPE:  0.08307038003043\n",
      "Delta:  0.007989093901872022\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.022286527971953962 0.02512709060407836 -361.3462331480439\n",
      "Epoch: 755\n",
      "Arb loss 0.018608123450415036\n",
      "Real arb loss 1.835872625361583e-05\n",
      "Bounds loss: 0.5585479531248772\n",
      "MAPE:  0.08023395006364657\n",
      "Delta:  0.007811044737157384\n",
      "GRAD\n",
      " tensor([-49.7007,   1.6684,   8.6827,  92.3090])\n",
      "-0.02336682438952553 -0.026932366382216966 0.9999880682901551\n",
      "Epoch: 756\n",
      "Arb loss 2.2202672976969408e-07\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 0.5735909712404736\n",
      "MAPE:  0.08329056217458698\n",
      "Delta:  0.007993564047829268\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.022735154895829224 0.02576500976855578 -76363.81446546549\n",
      "arb imp changed to 1004.9064545564711\n",
      "Epoch: 757\n",
      "Arb loss 0.016963507540249348\n",
      "Real arb loss 1.6730979439677268e-05\n",
      "Bounds loss: 0.5588123942633074\n",
      "MAPE:  0.08035663842813809\n",
      "Delta:  0.007811829131032138\n",
      "GRAD\n",
      " tensor([-49.6977,   1.6785,   8.6905,  92.3115])\n",
      "-0.023643164025878738 -0.02697869088523852 0.9999959180866274\n",
      "Epoch: 758\n",
      "Arb loss 6.924356827466212e-08\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 0.5738884211109773\n",
      "MAPE:  0.08343287135062696\n",
      "Delta:  0.00799652548851927\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.022746243031438573 0.025977655307200753 -176198.89101224783\n",
      "Epoch: 759\n",
      "Arb loss 0.012200709183294606\n",
      "Real arb loss 1.2037168905006655e-05\n",
      "Bounds loss: 0.5589801455225627\n",
      "MAPE:  0.08045499804447347\n",
      "Delta:  0.007814634576350317\n",
      "GRAD\n",
      " tensor([-21.3221,   1.2840,   4.4371,  41.2911])\n",
      "-0.0026013363894206165 0.0007709318143338528 0.21559254296891617\n",
      "Epoch: 760\n",
      "Arb loss 0.009570327264443915\n",
      "Real arb loss 9.448385818772408e-06\n",
      "Bounds loss: 0.5585492099447984\n",
      "MAPE:  0.08047586111970315\n",
      "Delta:  0.007834963069643801\n",
      "GRAD\n",
      " tensor([-21.3243,   1.2833,   4.4369,  41.1989])\n",
      "8.49420739478246e-05 0.0010396613782198694 0.06718154599061832\n",
      "Epoch: 761\n",
      "Arb loss 0.008927377883182408\n",
      "Real arb loss 8.814732881219652e-06\n",
      "Bounds loss: 0.5579685079033835\n",
      "MAPE:  0.08043184636525423\n",
      "Delta:  0.00783429755163136\n",
      "GRAD\n",
      " tensor([-21.3254,   1.2822,   4.4362,  41.1793])\n",
      "0.0008476808137398706 0.0011541949214227687 0.008079109906931614\n",
      "Epoch: 762\n",
      "Arb loss 0.008855252616083466\n",
      "Real arb loss 8.743738271931618e-06\n",
      "Bounds loss: 0.5573245034852475\n",
      "MAPE:  0.08036958167986065\n",
      "Delta:  0.007827656567907714\n",
      "GRAD\n",
      " tensor([-21.3261,   1.2810,   4.4353,  41.1804])\n",
      "0.001050893608307124 0.0011732232888779226 -0.009444093979333879\n",
      "Epoch: 763\n",
      "Arb loss 0.008938882454000499\n",
      "Real arb loss 8.826323998498649e-06\n",
      "Bounds loss: 0.5566706373982964\n",
      "MAPE:  0.08030456397979824\n",
      "Delta:  0.007819430533652477\n",
      "GRAD\n",
      " tensor([-21.3266,   1.2800,   4.4346,  41.1873])\n",
      "0.0010931821655019158 0.0011617037324282986 -0.013388988680688385\n",
      "Epoch: 764\n",
      "Arb loss 0.009058565049995117\n",
      "Real arb loss 8.944443948076954e-06\n",
      "Bounds loss: 0.5560239510410975\n",
      "MAPE:  0.08024103796535703\n",
      "Delta:  0.007810882471648707\n",
      "GRAD\n",
      " tensor([-21.3270,   1.2790,   4.4338,  41.1956])\n",
      "0.0010900710025579796 0.0011423969586268345 -0.013454883448097199\n",
      "Epoch: 765\n",
      "Arb loss 0.009180446986949807\n",
      "Real arb loss 9.064714190478108e-06\n",
      "Bounds loss: 0.5553887509705046\n",
      "MAPE:  0.08018000556161753\n",
      "Delta:  0.0078023680551619744\n",
      "GRAD\n",
      " tensor([-21.3271,   1.2782,   4.4332,  41.2040])\n",
      "0.0010749024838097032 0.0011220891417036416 -0.01252969104821755\n",
      "Epoch: 766\n",
      "Arb loss 0.009295475151380827\n",
      "Real arb loss 9.178210700935768e-06\n",
      "Bounds loss: 0.5547655552836162\n",
      "MAPE:  0.080121553614905\n",
      "Delta:  0.007793981270359883\n",
      "GRAD\n",
      " tensor([-21.3270,   1.2775,   4.4326,  41.2123])\n",
      "0.0010572251185008152 0.001102637764647585 -0.011427516139259186\n",
      "Epoch: 767\n",
      "Arb loss 0.009401699343695315\n",
      "Real arb loss 9.283013795058824e-06\n",
      "Bounds loss: 0.5541538498318348\n",
      "MAPE:  0.08006552556007161\n",
      "Delta:  0.007785741277587734\n",
      "GRAD\n",
      " tensor([-21.3268,   1.2769,   4.4321,  41.2203])\n",
      "0.0010397076659546256 0.0010844605491800996 -0.010365542577517317\n",
      "arb imp changed to 1005.4089077837492\n",
      "Epoch: 768\n",
      "Arb loss 0.009503902635072677\n",
      "Real arb loss 9.379159267117521e-06\n",
      "Bounds loss: 0.5535528918435159\n",
      "MAPE:  0.08001171353585365\n",
      "Delta:  0.007777646382696286\n",
      "GRAD\n",
      " tensor([-21.3371,   1.2721,   4.4299,  41.2366])\n",
      "0.0010172845050294699 0.0010634441420029894 -0.008873715178029595\n",
      "Epoch: 769\n",
      "Arb loss 0.009588237560136036\n",
      "Real arb loss 9.46232364686122e-06\n",
      "Bounds loss: 0.552964219263396\n",
      "MAPE:  0.07996037995095596\n",
      "Delta:  0.007769734303545571\n",
      "GRAD\n",
      " tensor([-21.3366,   1.2717,   4.4295,  41.2439])\n",
      "0.0010039558640927426 0.001048483962823643 -0.008197941628836691\n",
      "Epoch: 770\n",
      "Arb loss 0.009666841371977451\n",
      "Real arb loss 9.539833463116467e-06\n",
      "Bounds loss: 0.5523844451474831\n",
      "MAPE:  0.07991076762257404\n",
      "Delta:  0.007761933833229084\n",
      "GRAD\n",
      " tensor([-21.3359,   1.2714,   4.4291,  41.2511])\n",
      "0.0009899634533878654 0.0010342351175204323 -0.0074768145802597274\n",
      "Epoch: 771\n",
      "Arb loss 0.00973911855249251\n",
      "Real arb loss 9.611103649833489e-06\n",
      "Bounds loss: 0.5518131497559395\n",
      "MAPE:  0.07986275371317156\n",
      "Delta:  0.007754249802406572\n",
      "GRAD\n",
      " tensor([-21.3352,   1.2712,   4.4288,  41.2580])\n",
      "0.0009763534788813644 0.0010208303419069198 -0.006790827701926405\n",
      "Epoch: 772\n",
      "Arb loss 0.009805255228551121\n",
      "Real arb loss 9.676318868574056e-06\n",
      "Bounds loss: 0.5512498421496054\n",
      "MAPE:  0.07981620098277244\n",
      "Delta:  0.007746678913635878\n",
      "GRAD\n",
      " tensor([-21.3344,   1.2710,   4.4285,  41.2648])\n",
      "0.0009633739080850967 0.0010082412669243368 -0.0061568122718178575\n",
      "Epoch: 773\n",
      "Arb loss 0.009865624344270572\n",
      "Real arb loss 9.73584756140361e-06\n",
      "Bounds loss: 0.5506940493103646\n",
      "MAPE:  0.07977097871112822\n",
      "Delta:  0.007739215965296168\n",
      "GRAD\n",
      " tensor([-21.3334,   1.2709,   4.4283,  41.2713])\n",
      "0.0009510465399519274 0.0009964007785240314 -0.0055742044718321004\n",
      "Epoch: 774\n",
      "Arb loss 0.00992061735160782\n",
      "Real arb loss 9.790076199217784e-06\n",
      "Bounds loss: 0.5501453373309032\n",
      "MAPE:  0.07972696763876397\n",
      "Delta:  0.0077318556107304325\n",
      "GRAD\n",
      " tensor([-21.3324,   1.2709,   4.4281,  41.2777])\n",
      "0.0009398898682196899 0.0009854964227351548 -0.005065276747378444\n",
      "Epoch: 775\n",
      "Arb loss 0.009970868023998557\n",
      "Real arb loss 9.83962966592794e-06\n",
      "Bounds loss: 0.5496031710689792\n",
      "MAPE:  0.07968401259068078\n",
      "Delta:  0.007724588517979369\n",
      "GRAD\n",
      " tensor([-21.3314,   1.2709,   4.4279,  41.2840])\n",
      "0.0009295146976532331 0.000975343811625784 -0.00460229220826891\n",
      "Epoch: 776\n",
      "Arb loss 0.010016756872215083\n",
      "Real arb loss 9.88488330437691e-06\n",
      "Bounds loss: 0.5490671190172272\n",
      "MAPE:  0.07964198748516596\n",
      "Delta:  0.007717408399418584\n",
      "GRAD\n",
      " tensor([-21.3303,   1.2709,   4.4278,  41.2901])\n",
      "0.0009193184543795363 0.0009656247838624177 -0.004153232632698289\n",
      "Epoch: 777\n",
      "Arb loss 0.01005835879373057\n",
      "Real arb loss 9.925911450735375e-06\n",
      "Bounds loss: 0.5485369261991002\n",
      "MAPE:  0.0796008232821769\n",
      "Delta:  0.007710313643457015\n",
      "GRAD\n",
      " tensor([-21.3291,   1.2710,   4.4276,  41.2961])\n",
      "0.000909454477521221 0.0009563323256501777 -0.003728714964666091\n",
      "Epoch: 778\n",
      "Arb loss 0.010095863546684736\n",
      "Real arb loss 9.962901440414251e-06\n",
      "Bounds loss: 0.5480123426047632\n",
      "MAPE:  0.07956045332219351\n",
      "Delta:  0.007703301464190879\n",
      "GRAD\n",
      " tensor([-21.3279,   1.2711,   4.4275,  41.3019])\n",
      "0.0008926311254007224 0.0009858028081158876 -0.0062878310883425215\n",
      "arb imp changed to 1005.9116122376411\n",
      "Epoch: 779\n",
      "Arb loss 0.010164424303672922\n",
      "Real arb loss 1.0025450524516409e-05\n",
      "Bounds loss: 0.5474721104985413\n",
      "MAPE:  0.07951879162914693\n",
      "Delta:  0.0076964252575355985\n",
      "GRAD\n",
      " tensor([-21.3374,   1.2669,   4.4256,  41.3162])\n",
      "0.0008905553197925409 0.0009732398020042554 -0.005961150543268179\n",
      "Epoch: 780\n",
      "Arb loss 0.01022501596713277\n",
      "Real arb loss 1.0085119720009098e-05\n",
      "Bounds loss: 0.5469392888501168\n",
      "MAPE:  0.07947815464311017\n",
      "Delta:  0.007689571165079114\n",
      "GRAD\n",
      " tensor([-21.3361,   1.2670,   4.4256,  41.3218])\n",
      "0.0008880648996414386 0.0009642786068737585 -0.005711448279485332\n",
      "Epoch: 781\n",
      "Arb loss 0.010283415616985961\n",
      "Real arb loss 1.0142626493781427e-05\n",
      "Bounds loss: 0.5464118869946198\n",
      "MAPE:  0.07943814293699694\n",
      "Delta:  0.007682742326834112\n",
      "GRAD\n",
      " tensor([-21.3348,   1.2672,   4.4255,  41.3275])\n",
      "0.0008816949530336959 0.0009549066628867786 -0.005207077754153966\n",
      "Epoch: 782\n",
      "Arb loss 0.010336962161681888\n",
      "Real arb loss 1.019535353405903e-05\n",
      "Bounds loss: 0.5458901146430483\n",
      "MAPE:  0.07939880872553591\n",
      "Delta:  0.007675968491699084\n",
      "GRAD\n",
      " tensor([-21.3334,   1.2675,   4.4255,  41.3331])\n",
      "0.0008743364539774978 0.0009457064291024109 -0.004660273972051154\n",
      "Epoch: 783\n",
      "Arb loss 0.01038513523739405\n",
      "Real arb loss 1.0242789688845315e-05\n",
      "Bounds loss: 0.5453738628520468\n",
      "MAPE:  0.0793601299111423\n",
      "Delta:  0.007669257112627209\n",
      "GRAD\n",
      " tensor([-21.3320,   1.2677,   4.4254,  41.3386])\n",
      "0.0008668256558830301 0.0009368217561438463 -0.004129310797134966\n",
      "Epoch: 784\n",
      "Arb loss 0.010428018688459531\n",
      "Real arb loss 1.028501811393176e-05\n",
      "Bounds loss: 0.5448629447520948\n",
      "MAPE:  0.07932206637679287\n",
      "Delta:  0.00766260920380042\n",
      "GRAD\n",
      " tensor([-21.3306,   1.2680,   4.4254,  41.3440])\n",
      "0.0008593962327416715 0.0009282700764799978 -0.0036279838270842912\n",
      "Epoch: 785\n",
      "Arb loss 0.010465851371609795\n",
      "Real arb loss 1.0322274335961417e-05\n",
      "Bounds loss: 0.5443571647846986\n",
      "MAPE:  0.07928457612996878\n",
      "Delta:  0.0076560239863177025\n",
      "GRAD\n",
      " tensor([-21.3291,   1.2683,   4.4254,  41.3493])\n",
      "0.0008521059520989471 0.0009200341441304438 -0.003157502850602123\n",
      "Epoch: 786\n",
      "Arb loss 0.010498897327149632\n",
      "Real arb loss 1.0354818544349061e-05\n",
      "Bounds loss: 0.5438563376064947\n",
      "MAPE:  0.07924761969305871\n",
      "Delta:  0.007649500242709549\n",
      "GRAD\n",
      " tensor([-21.3276,   1.2687,   4.4255,  41.3545])\n",
      "0.0008449619880990245 0.0009120887813002243 -0.002715742902452911\n",
      "Epoch: 787\n",
      "Arb loss 0.01052740963304942\n",
      "Real arb loss 1.0382900049888941e-05\n",
      "Bounds loss: 0.5433602923423247\n",
      "MAPE:  0.07921116107668268\n",
      "Delta:  0.007643036705776505\n",
      "GRAD\n",
      " tensor([-21.3261,   1.2690,   4.4255,  41.3596])\n",
      "0.0008379576685780821 0.0009044085238530952 -0.002299899092160329\n",
      "Epoch: 788\n",
      "Arb loss 0.01055162161290727\n",
      "Real arb loss 1.0406748650714928e-05\n",
      "Bounds loss: 0.542868872662407\n",
      "MAPE:  0.07917516778085297\n",
      "Delta:  0.007636632164557676\n",
      "GRAD\n",
      " tensor([-21.3245,   1.2694,   4.4255,  41.3646])\n",
      "0.0008310831739066771 0.0008969696599785415 -0.0019072229033303412\n",
      "Epoch: 789\n",
      "Arb loss 0.010571745907314682\n",
      "Real arb loss 1.0426573731174323e-05\n",
      "Bounds loss: 0.5423819357542822\n",
      "MAPE:  0.07913999210809508\n",
      "Delta:  0.0076302854880603965\n",
      "GRAD\n",
      " tensor([-21.3230,   1.2698,   4.4256,  41.3695])\n",
      "0.0008243285889553142 0.0008897506435142644 -0.0031315233263147224\n",
      "arb imp changed to 1006.4145680437598\n",
      "Epoch: 790\n",
      "Arb loss 0.01061015400201142\n",
      "Real arb loss 1.045934189569879e-05\n",
      "Bounds loss: 0.5418993510779142\n",
      "MAPE:  0.0791060370018829\n",
      "Delta:  0.007623995625590698\n",
      "GRAD\n",
      " tensor([-35.3534,   1.5436,   5.0886,  67.7294])\n",
      "-0.008914009460496475 -0.012680799769952289 0.835554843453777\n",
      "Delta imp changed to 0.018621531184890325\n",
      "Epoch: 791\n",
      "Arb loss 0.0017447884358403032\n",
      "Real arb loss 1.7238900861673984e-06\n",
      "Bounds loss: 0.5487710682444004\n",
      "MAPE:  0.0804867462656487\n",
      "Delta:  0.007504347311925851\n",
      "GRAD\n",
      " tensor([-7.1349,  1.0812,  1.8060, 13.7840])\n",
      "0.014703309633218642 0.017263496062008832 -8.716454557639704\n",
      "Epoch: 792\n",
      "Arb loss 0.016953157549537565\n",
      "Real arb loss 1.6696108987700193e-05\n",
      "Bounds loss: 0.5392973610688188\n",
      "MAPE:  0.07867609870619538\n",
      "Delta:  0.007394008569803393\n",
      "GRAD\n",
      " tensor([-35.3458,   1.5375,   5.0823,  68.9290])\n",
      "-0.013156549067161238 -0.01533801631173537 0.8875687000964032\n",
      "Epoch: 793\n",
      "Arb loss 0.0019060655407649842\n",
      "Real arb loss 1.8831797619146897e-06\n",
      "Bounds loss: 0.5475691127897682\n",
      "MAPE:  0.08033299241915329\n",
      "Delta:  0.007491288206355023\n",
      "GRAD\n",
      " tensor([-7.1382,  1.0794,  1.8050, 13.7914])\n",
      "0.01466466818422707 0.017192645587270183 -8.184704262170603\n",
      "Epoch: 794\n",
      "Arb loss 0.017506648296240667\n",
      "Real arb loss 1.723975063321094e-05\n",
      "Bounds loss: 0.5381549510990377\n",
      "MAPE:  0.07854275134584833\n",
      "Delta:  0.007381430950536414\n",
      "GRAD\n",
      " tensor([-35.3465,   1.5350,   5.0804,  68.9536])\n",
      "-0.01302452595673631 -0.015044809513153456 0.8974678228489975\n",
      "Epoch: 795\n",
      "Arb loss 0.0017949947644304435\n",
      "Real arb loss 1.772918356424763e-06\n",
      "Bounds loss: 0.5462513898268831\n",
      "MAPE:  0.0801606401247809\n",
      "Delta:  0.007477570589549532\n",
      "GRAD\n",
      " tensor([-0.0062, -0.0025, -0.0010,  0.0050])\n",
      "0.01956869074001666 0.0237739706994492 -15.091000957048681\n",
      "Epoch: 796\n",
      "Arb loss 0.028883262472347637\n",
      "Real arb loss 2.839732458279235e-05\n",
      "Bounds loss: 0.5332648252906055\n",
      "MAPE:  0.07774639378701974\n",
      "Delta:  0.007331244323195993\n",
      "GRAD\n",
      " tensor([-49.2783,   1.8282,   7.7428,  92.4934])\n",
      "-0.024042229512174496 -0.029238839121098925 0.98914918730995\n",
      "Epoch: 797\n",
      "Arb loss 0.00031340687096499475\n",
      "Real arb loss 3.097346989528668e-07\n",
      "Bounds loss: 0.5488568697262184\n",
      "MAPE:  0.08076741975923717\n",
      "Delta:  0.007507503781824099\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.022160944214810407 0.025445774533637833 -70.7106423177057\n",
      "Epoch: 798\n",
      "Arb loss 0.02247460802368208\n",
      "Real arb loss 2.211511754022882e-05\n",
      "Bounds loss: 0.5348907815679268\n",
      "MAPE:  0.07810763002254091\n",
      "Delta:  0.007341130409322617\n",
      "GRAD\n",
      " tensor([-49.2273,   1.8669,   7.7659,  92.3992])\n",
      "-0.023042082519937557 -0.02811394924358468 0.9958491747425362\n",
      "Epoch: 799\n",
      "Arb loss 9.328817063629857e-05\n",
      "Real arb loss 9.197579158338326e-08\n",
      "Bounds loss: 0.5499286738517889\n",
      "MAPE:  0.08105768610021796\n",
      "Delta:  0.007510285342003852\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.021643866165816705 0.02567830594979681 -203.85486015371967\n",
      "Epoch: 800\n",
      "Arb loss 0.019110535149695282\n",
      "Real arb loss 1.8814446132748663e-05\n",
      "Bounds loss: 0.5358074371140565\n",
      "MAPE:  0.07833705914030598\n",
      "Delta:  0.007347733731194425\n",
      "GRAD\n",
      " tensor([-49.1973,   1.8921,   7.7815,  92.3493])\n",
      "-0.02335723103934506 -0.02841408770386522 0.9999890281847048\n",
      "arb imp changed to 1006.9177753277817\n",
      "Epoch: 801\n",
      "Arb loss 2.0978210048565792e-07\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 0.5510319166245986\n",
      "MAPE:  0.08133974081697169\n",
      "Delta:  0.007519356445569523\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.02217018982214114 0.026465106932027083 -81329.85831680427\n",
      "Delta imp changed to 0.018167347497453978\n",
      "Epoch: 802\n",
      "Arb loss 0.01706175829200064\n",
      "Real arb loss 1.679522221154805e-05\n",
      "Bounds loss: 0.5364487980281688\n",
      "MAPE:  0.0785183661194527\n",
      "Delta:  0.0071733179373960065\n",
      "GRAD\n",
      " tensor([-35.3093,   1.5583,   5.0933,  69.0286])\n",
      "-0.01435736890918693 -0.015218528966742362 0.928194176965032\n",
      "Epoch: 803\n",
      "Arb loss 0.0012251335965807947\n",
      "Real arb loss 1.2097907878006882e-06\n",
      "Bounds loss: 0.5446127596001346\n",
      "MAPE:  0.0801618895829202\n",
      "Delta:  0.0072763079093260885\n",
      "GRAD\n",
      " tensor([-0.0046, -0.0019, -0.0008,  0.0037])\n",
      "0.019257474307305733 0.024007873792902812 -20.478890180551712\n",
      "Epoch: 804\n",
      "Arb loss 0.02631450997746323\n",
      "Real arb loss 2.5869333268835474e-05\n",
      "Bounds loss: 0.5315377652016501\n",
      "MAPE:  0.07771758272659866\n",
      "Delta:  0.007136184596710196\n",
      "GRAD\n",
      " tensor([-49.2458,   1.8528,   7.7574,  92.5014])\n",
      "-0.024112081275913022 -0.029501769802291467 0.9966504845324752\n",
      "Epoch: 805\n",
      "Arb loss 8.814085818984949e-05\n",
      "Real arb loss 8.683148678979153e-08\n",
      "Bounds loss: 0.5472190699918537\n",
      "MAPE:  0.08075186239237292\n",
      "Delta:  0.00730825285970599\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.02219464489157119 0.02577319853653759 -186.37352052439533\n",
      "Epoch: 806\n",
      "Arb loss 0.01651526290107358\n",
      "Real arb loss 1.6251539421883816e-05\n",
      "Bounds loss: 0.5331154842579741\n",
      "MAPE:  0.07806220736689407\n",
      "Delta:  0.007146048782707006\n",
      "GRAD\n",
      " tensor([-35.0047,   1.7082,   5.1649,  67.6753])\n",
      "-0.013425566163107305 -0.014705604319484422 0.8757343257131397\n",
      "Epoch: 807\n",
      "Arb loss 0.002052280280426677\n",
      "Real arb loss 2.025216255498251e-06\n",
      "Bounds loss: 0.5409552696260622\n",
      "MAPE:  0.0796179524297342\n",
      "Delta:  0.007241988533444032\n",
      "GRAD\n",
      " tensor([-0.0129, -0.0053, -0.0022,  0.0105])\n",
      "0.019107824192114098 0.02354840134051761 -14.06079191902032\n",
      "Epoch: 808\n",
      "Arb loss 0.03090896626301485\n",
      "Real arb loss 3.0366195916823733e-05\n",
      "Bounds loss: 0.5282166378296398\n",
      "MAPE:  0.07727949621153257\n",
      "Delta:  0.007103609889745678\n",
      "GRAD\n",
      " tensor([-49.2594,   1.8332,   7.7436,  92.6192])\n",
      "-0.02415947981724509 -0.029683188933072424 0.9898476917366034\n",
      "Epoch: 809\n",
      "Arb loss 0.0003137973536050545\n",
      "Real arb loss 3.0995689916048927e-07\n",
      "Bounds loss: 0.5438957920879294\n",
      "MAPE:  0.08027801707838425\n",
      "Delta:  0.00727522940950657\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.021985685188473103 0.025400435790407405 -60.88867847784418\n",
      "Epoch: 810\n",
      "Arb loss 0.019420503524461598\n",
      "Real arb loss 1.9102305174667046e-05\n",
      "Bounds loss: 0.530080601944327\n",
      "MAPE:  0.07768824372820382\n",
      "Delta:  0.007115278506035237\n",
      "GRAD\n",
      " tensor([-35.0096,   1.6979,   5.1573,  67.7494])\n",
      "-0.013503015084054715 -0.014922916130394981 0.8525245530122644\n",
      "Epoch: 811\n",
      "Arb loss 0.002864047437996869\n",
      "Real arb loss 2.825962823467733e-06\n",
      "Bounds loss: 0.5379909503094916\n",
      "MAPE:  0.07922730078551805\n",
      "Delta:  0.007211356219029481\n",
      "GRAD\n",
      " tensor([-7.0702,  1.1117,  1.8200, 13.7480])\n",
      "0.012977476116517228 0.01581552323129609 -4.832771886512574\n",
      "arb imp changed to 1007.4212342154455\n",
      "Epoch: 812\n",
      "Arb loss 0.016713688045675492\n",
      "Real arb loss 1.643957256060244e-05\n",
      "Bounds loss: 0.5294823419366448\n",
      "MAPE:  0.07768446975074038\n",
      "Delta:  0.0071177710159293275\n",
      "GRAD\n",
      " tensor([-35.0362,   1.6872,   5.1530,  67.6928])\n",
      "-0.012097168903015598 -0.014835257155559445 0.8574619138794719\n",
      "Epoch: 813\n",
      "Arb loss 0.0023823371060461332\n",
      "Real arb loss 2.3495581902566523e-06\n",
      "Bounds loss: 0.5373373486386027\n",
      "MAPE:  0.07918658799994568\n",
      "Delta:  0.007203875894122014\n",
      "GRAD\n",
      " tensor([-7.0739,  1.1100,  1.8193, 13.7489])\n",
      "0.014438985906139346 0.01680469941823115 -6.609624408589999\n",
      "Epoch: 814\n",
      "Arb loss 0.01812869059165832\n",
      "Real arb loss 1.78279872786453e-05\n",
      "Bounds loss: 0.5283075560085417\n",
      "MAPE:  0.07755031565961985\n",
      "Delta:  0.007099859231617209\n",
      "GRAD\n",
      " tensor([-35.0295,   1.6874,   5.1520,  67.7495])\n",
      "-0.012673009412576874 -0.014970603818272199 0.8569970677535366\n",
      "Epoch: 815\n",
      "Arb loss 0.002592455912396014\n",
      "Real arb loss 2.5566196420001577e-06\n",
      "Bounds loss: 0.5362166391237453\n",
      "MAPE:  0.07906443985126536\n",
      "Delta:  0.007189835814487466\n",
      "GRAD\n",
      " tensor([-7.0732,  1.1099,  1.8191, 13.7554])\n",
      "0.013174271509001745 0.015900569716334467 -5.387238657154375\n",
      "Epoch: 816\n",
      "Arb loss 0.01655863462062424\n",
      "Real arb loss 1.628861138756783e-05\n",
      "Bounds loss: 0.5276904890702996\n",
      "MAPE:  0.07752871860776452\n",
      "Delta:  0.007095114965362263\n",
      "GRAD\n",
      " tensor([-35.0293,   1.6875,   5.1521,  67.7233])\n",
      "-0.012065706738661142 -0.01493384650238827 0.8603805392992934\n",
      "Epoch: 817\n",
      "Arb loss 0.0023119076356716063\n",
      "Real arb loss 2.2804603642956613e-06\n",
      "Bounds loss: 0.5355709378348457\n",
      "MAPE:  0.07902664140396136\n",
      "Delta:  0.0071807225418114105\n",
      "GRAD\n",
      " tensor([-7.0724,  1.1102,  1.8192, 13.7554])\n",
      "0.01440209833830064 0.016836958974617455 -6.807410412730365\n",
      "Delta imp changed to 0.017724241460930712\n",
      "Epoch: 818\n",
      "Arb loss 0.018050011748013337\n",
      "Real arb loss 1.775197857657058e-05\n",
      "Bounds loss: 0.526553551926523\n",
      "MAPE:  0.07740075435034786\n",
      "Delta:  0.006904687872804088\n",
      "GRAD\n",
      " tensor([-35.0221,   1.6881,   5.1514,  67.7831])\n",
      "-0.012703951796775081 -0.015074094228584078 0.8601769659605123\n",
      "Epoch: 819\n",
      "Arb loss 0.002523807407055621\n",
      "Real arb loss 2.4892974343827605e-06\n",
      "Bounds loss: 0.5344908697846591\n",
      "MAPE:  0.07891222602353852\n",
      "Delta:  0.006992404694711969\n",
      "GRAD\n",
      " tensor([-7.0732,  1.1095,  1.8188, 13.7632])\n",
      "0.014181235301075401 0.016744620730234194 -6.363341809228631\n",
      "Epoch: 820\n",
      "Arb loss 0.018583656598813555\n",
      "Real arb loss 1.827550672530292e-05\n",
      "Bounds loss: 0.525541022886342\n",
      "MAPE:  0.07730337080589803\n",
      "Delta:  0.006893243758415914\n",
      "GRAD\n",
      " tensor([-35.0188,   1.6879,   5.1507,  67.8070])\n",
      "-0.01277376061391311 -0.015143943350999445 0.8584264008619646\n",
      "Epoch: 821\n",
      "Arb loss 0.002630955149839336\n",
      "Real arb loss 2.5948888915999644e-06\n",
      "Bounds loss: 0.5334997863655591\n",
      "MAPE:  0.07881618075453899\n",
      "Delta:  0.0069812964040392705\n",
      "GRAD\n",
      " tensor([-7.0748,  1.1086,  1.8183, 13.7692])\n",
      "0.01413613331536967 0.016717582493198546 -6.201940404908426\n",
      "Epoch: 822\n",
      "Arb loss 0.018947982197129818\n",
      "Real arb loss 1.8632943420134312e-05\n",
      "Bounds loss: 0.524580959676889\n",
      "MAPE:  0.07721579411273258\n",
      "Delta:  0.00688260786735766\n",
      "GRAD\n",
      " tensor([-35.0153,   1.6880,   5.1502,  67.8264])\n",
      "-0.012794128786268733 -0.015205457683084456 0.8568704442406246\n",
      "arb imp changed to 1007.9249448325531\n",
      "Epoch: 823\n",
      "Arb loss 0.00271337228254895\n",
      "Real arb loss 2.6748230029806088e-06\n",
      "Bounds loss: 0.5325574532606078\n",
      "MAPE:  0.07872887876677623\n",
      "Delta:  0.00697066483879802\n",
      "GRAD\n",
      " tensor([-7.0794,  1.1064,  1.8173, 13.7772])\n",
      "0.013043591034508695 0.01587866060497789 -5.303099672026945\n",
      "Epoch: 824\n",
      "Arb loss 0.01710265594422129\n",
      "Real arb loss 1.681587561824445e-05\n",
      "Bounds loss: 0.5241011542076313\n",
      "MAPE:  0.07721859921128511\n",
      "Delta:  0.006879742337402109\n",
      "GRAD\n",
      " tensor([-35.0314,   1.6822,   5.1481,  67.8068])\n",
      "-0.012144983780371765 -0.01516364910291812 0.8621586521933874\n",
      "Epoch: 825\n",
      "Arb loss 0.002357453146424238\n",
      "Real arb loss 2.3246123464439467e-06\n",
      "Bounds loss: 0.5320484402044702\n",
      "MAPE:  0.07871567902350467\n",
      "Delta:  0.006963296696502995\n",
      "GRAD\n",
      " tensor([-7.0757,  1.1080,  1.8180, 13.7739])\n",
      "0.014306138566141713 0.01685949140730547 -6.8107571372948605\n",
      "Epoch: 826\n",
      "Arb loss 0.01841349398927134\n",
      "Real arb loss 1.8101052691774394e-05\n",
      "Bounds loss: 0.5230783740985726\n",
      "MAPE:  0.07710924363746766\n",
      "Delta:  0.006863678809085666\n",
      "GRAD\n",
      " tensor([-35.0224,   1.6842,   5.1483,  67.8621])\n",
      "-0.012768426945580114 -0.015295137007765414 0.863037642791977\n",
      "Epoch: 827\n",
      "Arb loss 0.002521955541206365\n",
      "Real arb loss 2.4866247172074255e-06\n",
      "Bounds loss: 0.5310789294962095\n",
      "MAPE:  0.07861968744750909\n",
      "Delta:  0.006951317190537403\n",
      "GRAD\n",
      " tensor([-7.0776,  1.1070,  1.8175, 13.7821])\n",
      "0.014097356105771341 0.01678527720050782 -6.455733366729435\n",
      "Epoch: 828\n",
      "Arb loss 0.018803028077980486\n",
      "Real arb loss 1.8482980198625964e-05\n",
      "Bounds loss: 0.5221646224492666\n",
      "MAPE:  0.07702696847123004\n",
      "Delta:  0.006853321996698227\n",
      "GRAD\n",
      " tensor([-35.0178,   1.6850,   5.1481,  67.8825])\n",
      "-0.01283415339087246 -0.015359268578282181 0.8623015463185624\n",
      "Epoch: 829\n",
      "Arb loss 0.0025891478908665676\n",
      "Real arb loss 2.552810877772399e-06\n",
      "Bounds loss: 0.5301846891275422\n",
      "MAPE:  0.07853992012289779\n",
      "Delta:  0.006941278582440893\n",
      "GRAD\n",
      " tensor([-7.0785,  1.1064,  1.8172, 13.7870])\n",
      "0.01406070700720885 0.016773066162983685 -6.3556485937347125\n",
      "Epoch: 830\n",
      "Arb loss 0.019044862042423866\n",
      "Real arb loss 1.872016135090479e-05\n",
      "Bounds loss: 0.521291866258205\n",
      "MAPE:  0.07695200601632797\n",
      "Delta:  0.006843679298037778\n",
      "GRAD\n",
      " tensor([-35.0132,   1.6860,   5.1482,  68.8989])\n",
      "-0.013204017989440375 -0.01594767087681137 0.8712630022289612\n",
      "Epoch: 831\n",
      "Arb loss 0.0024517783623052626\n",
      "Real arb loss 2.4176942145144456e-06\n",
      "Bounds loss: 0.5296052573720497\n",
      "MAPE:  0.07851643541277688\n",
      "Delta:  0.006934043362603029\n",
      "GRAD\n",
      " tensor([-7.0765,  1.1074,  1.8176, 13.7874])\n",
      "0.014091059183420351 0.01684320763307101 -6.628483114441045\n",
      "Epoch: 832\n",
      "Arb loss 0.018703349837197614\n",
      "Real arb loss 1.838604212402096e-05\n",
      "Bounds loss: 0.5206850060585663\n",
      "MAPE:  0.07692286206074928\n",
      "Delta:  0.006836335347200187\n",
      "GRAD\n",
      " tensor([-35.0054,   1.6897,   5.1499,  68.9046])\n",
      "-0.013198353475190272 -0.015983430477167326 0.8751408993143154\n",
      "Delta imp changed to 0.017291942888712893\n",
      "Epoch: 833\n",
      "Arb loss 0.0023352834404822393\n",
      "Real arb loss 2.303075387636501e-06\n",
      "Bounds loss: 0.5290073386534068\n",
      "MAPE:  0.07848715406603478\n",
      "Delta:  0.00675762313910973\n",
      "GRAD\n",
      " tensor([-7.0748,  1.1082,  1.8180, 13.7885])\n",
      "0.014095331680964218 0.016899062472202075 -6.880829263823374\n",
      "arb imp changed to 1008.4289073049694\n",
      "Epoch: 834\n",
      "Arb loss 0.0184131720621131\n",
      "Real arb loss 1.8093107478906933e-05\n",
      "Bounds loss: 0.5200676105892494\n",
      "MAPE:  0.07688961587407454\n",
      "Delta:  0.0066623721995890195\n",
      "GRAD\n",
      " tensor([-35.0155,   1.6860,   5.1485,  68.9258])\n",
      "-0.013209784842111327 -0.016030135677149948 0.8791164860788144\n",
      "Epoch: 835\n",
      "Arb loss 0.0022258489413036348\n",
      "Real arb loss 2.194272630666523e-06\n",
      "Bounds loss: 0.5284043649482862\n",
      "MAPE:  0.07845493048393123\n",
      "Delta:  0.006750380702883654\n",
      "GRAD\n",
      " tensor([-7.0767,  1.1075,  1.8177, 13.7925])\n",
      "0.014098739238517233 0.016949882085108836 -7.145383503714884\n",
      "Epoch: 836\n",
      "Arb loss 0.018130393248255865\n",
      "Real arb loss 1.7816501506183786e-05\n",
      "Bounds loss: 0.519447973269156\n",
      "MAPE:  0.07685406319500933\n",
      "Delta:  0.006655208845592979\n",
      "GRAD\n",
      " tensor([-35.0083,   1.6893,   5.1500,  68.9327])\n",
      "-0.01321032220461893 -0.016068980319791315 0.8828889089954884\n",
      "Epoch: 837\n",
      "Arb loss 0.002123270133644074\n",
      "Real arb loss 2.0933315687879788e-06\n",
      "Bounds loss: 0.5277949725287736\n",
      "MAPE:  0.07841962697910015\n",
      "Delta:  0.006743126298782292\n",
      "GRAD\n",
      " tensor([-7.0753,  1.1081,  1.8180, 13.7939])\n",
      "0.014098419439595 0.01699620757354836 -7.416184380126278\n",
      "Epoch: 838\n",
      "Arb loss 0.01786983293356389\n",
      "Real arb loss 1.7561588484311046e-05\n",
      "Bounds loss: 0.5188244596193993\n",
      "MAPE:  0.07681601155391603\n",
      "Delta:  0.006648058875887896\n",
      "GRAD\n",
      " tensor([-35.0014,   1.6924,   5.1514,  68.9399])\n",
      "-0.013213329321327016 -0.016109046348147915 0.9042836666025388\n",
      "Epoch: 839\n",
      "Arb loss 0.001710434886825933\n",
      "Real arb loss 1.6862048433462647e-06\n",
      "Bounds loss: 0.527182226885961\n",
      "MAPE:  0.07838197684110672\n",
      "Delta:  0.006735901867162573\n",
      "GRAD\n",
      " tensor([-0.0038, -0.0015, -0.0006,  0.0031])\n",
      "0.019000414034724633 0.023882625934609214 -15.368325250703865\n",
      "Epoch: 840\n",
      "Arb loss 0.027996954547717726\n",
      "Real arb loss 2.747459628327879e-05\n",
      "Bounds loss: 0.5145917309618693\n",
      "MAPE:  0.07613925452677182\n",
      "Delta:  0.00660791694278921\n",
      "GRAD\n",
      " tensor([-48.7756,   2.0604,   6.8486,  92.4413])\n",
      "-0.023500313292663666 -0.029636608983121482 0.9900483297156911\n",
      "Epoch: 841\n",
      "Arb loss 0.00027861646062366825\n",
      "Real arb loss 2.7479122300052424e-07\n",
      "Bounds loss: 0.5298424848783339\n",
      "MAPE:  0.07897072552977213\n",
      "Delta:  0.0067632050611566566\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.021501308133037078 0.025630510061457112 -76.38800471540709\n",
      "Epoch: 842\n",
      "Arb loss 0.021561571968534473\n",
      "Real arb loss 2.1175390784593324e-05\n",
      "Bounds loss: 0.5162623517386723\n",
      "MAPE:  0.076495925712525\n",
      "Delta:  0.006617787305169811\n",
      "GRAD\n",
      " tensor([-48.7356,   2.0946,   6.8699,  92.3543])\n",
      "-0.0229555417648315 -0.029526944239477215 0.9999797732675056\n",
      "Epoch: 843\n",
      "Arb loss 4.361201483658338e-07\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 0.5315060014114015\n",
      "MAPE:  0.07936902869982695\n",
      "Delta:  0.006769702198044408\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.021441305904127517 0.026421568248788274 -42370.846119432696\n",
      "Delta imp changed to 0.01687018818411014\n",
      "Epoch: 844\n",
      "Arb loss 0.018479215816141266\n",
      "Real arb loss 1.8159152480156143e-05\n",
      "Bounds loss: 0.5174627793204696\n",
      "MAPE:  0.07675875623156875\n",
      "Delta:  0.0064629765291085795\n",
      "GRAD\n",
      " tensor([-34.9570,   1.7150,   5.1625,  69.0115])\n",
      "-0.014487398180346167 -0.016276482963019312 0.92258006005726\n",
      "arb imp changed to 1008.9331217586218\n",
      "Epoch: 845\n",
      "Arb loss 0.0014313751085639262\n",
      "Real arb loss 1.4106349801876126e-06\n",
      "Bounds loss: 0.5258852534320758\n",
      "MAPE:  0.07835400136128474\n",
      "Delta:  0.006556608243516008\n",
      "GRAD\n",
      " tensor([-0.0037, -0.0015, -0.0006,  0.0031])\n",
      "0.018668281503581574 0.024004706589170866 -17.677845603244297\n",
      "Epoch: 846\n",
      "Arb loss 0.026735003278084053\n",
      "Real arb loss 2.6228940225189284e-05\n",
      "Bounds loss: 0.5132615322238671\n",
      "MAPE:  0.0760991687729143\n",
      "Delta:  0.0064342076351173475\n",
      "GRAD\n",
      " tensor([-48.7580,   2.0741,   7.8568,  92.4661])\n",
      "-0.023848484441720386 -0.030105284720889358 0.995094284823822\n",
      "Epoch: 847\n",
      "Arb loss 0.00013115431131646618\n",
      "Real arb loss 1.2915903033283022e-07\n",
      "Bounds loss: 0.5287134167877466\n",
      "MAPE:  0.07900256415220039\n",
      "Delta:  0.006587653735798242\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.021561554704377484 0.025901264801874713 -152.69661394926112\n",
      "Epoch: 848\n",
      "Arb loss 0.02015797355418811\n",
      "Real arb loss 1.979266862317997e-05\n",
      "Bounds loss: 0.5150190705752232\n",
      "MAPE:  0.07646896833841346\n",
      "Delta:  0.006445613679400332\n",
      "GRAD\n",
      " tensor([-48.7216,   2.1074,   6.8780,  92.3681])\n",
      "-0.02292754685360099 -0.029723048809601194 0.9999895892219127\n",
      "Epoch: 849\n",
      "Arb loss 2.0986018936089474e-07\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 0.530327007547806\n",
      "MAPE:  0.0793773789595046\n",
      "Delta:  0.006593395789034995\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.021493872366975864 0.026679995942339163 -66699.18914004121\n",
      "Epoch: 850\n",
      "Arb loss 0.013997714323336543\n",
      "Real arb loss 1.3752321327859682e-05\n",
      "Bounds loss: 0.5161778851383176\n",
      "MAPE:  0.07671612131832486\n",
      "Delta:  0.0064516781814805205\n",
      "GRAD\n",
      " tensor([-20.8928,   1.4748,   4.5213,  41.3108])\n",
      "-0.0043741842522733165 -0.0015907266470618353 0.3973168880649782\n",
      "Epoch: 851\n",
      "Arb loss 0.008436186028365896\n",
      "Real arb loss 8.296162824075047e-06\n",
      "Bounds loss: 0.5169989830548313\n",
      "MAPE:  0.07694947751645184\n",
      "Delta:  0.006479899010582687\n",
      "GRAD\n",
      " tensor([-20.9010,   1.4749,   4.5228,  41.1796])\n",
      "-0.00012162587873043584 -0.0001245720306861653 0.12104945471913164\n",
      "Epoch: 852\n",
      "Arb loss 0.007414990309723047\n",
      "Real arb loss 7.292893906247744e-06\n",
      "Bounds loss: 0.5170633866680131\n",
      "MAPE:  0.07700403424887808\n",
      "Delta:  0.006480687133993935\n",
      "GRAD\n",
      " tensor([-7.0332,  1.1270,  1.8264, 13.7955])\n",
      "0.010499846502424082 0.014353504088042146 -2.6433306878372225\n",
      "Epoch: 853\n",
      "Arb loss 0.02701526174542961\n",
      "Real arb loss 2.6503858851847558e-05\n",
      "Bounds loss: 0.5096417152336968\n",
      "MAPE:  0.07572073029528822\n",
      "Delta:  0.0064126409138567635\n",
      "GRAD\n",
      " tensor([-48.7769,   2.0570,   7.8460,  92.4452])\n",
      "-0.022257813074055166 -0.030230065184351895 0.9920627882209517\n",
      "Epoch: 854\n",
      "Arb loss 0.00021442585373989664\n",
      "Real arb loss 2.1135637684763925e-07\n",
      "Bounds loss: 0.5250482175058765\n",
      "MAPE:  0.07861177565058516\n",
      "Delta:  0.006555372276628426\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.021926911565028018 0.02589388009532745 -85.24540600883023\n",
      "Epoch: 855\n",
      "Arb loss 0.018493244814587435\n",
      "Real arb loss 1.815550475254501e-05\n",
      "Bounds loss: 0.5114526819175139\n",
      "MAPE:  0.07609170509192774\n",
      "Delta:  0.006411633208442958\n",
      "GRAD\n",
      " tensor([-34.6418,   1.8666,   5.2337,  67.7064])\n",
      "-0.013448098824763832 -0.01593352366385714 0.8747418436695451\n",
      "arb imp changed to 1009.4375883195011\n",
      "Delta imp changed to 0.016458720179619652\n",
      "Epoch: 856\n",
      "Arb loss 0.002317587964917989\n",
      "Real arb loss 2.2807739579512876e-06\n",
      "Bounds loss: 0.5196019253277898\n",
      "MAPE:  0.07761929862933815\n",
      "Delta:  0.0063393731565446225\n",
      "GRAD\n",
      " tensor([-7.0058,  1.1419,  1.8340, 13.7458])\n",
      "0.013674592759561066 0.01672002743238077 -6.44632201649557\n",
      "Epoch: 857\n",
      "Arb loss 0.017257506288333984\n",
      "Real arb loss 1.6937881547202085e-05\n",
      "Bounds loss: 0.5109141668823913\n",
      "MAPE:  0.076070982735576\n",
      "Delta:  0.0062526848102779815\n",
      "GRAD\n",
      " tensor([-34.6631,   1.8582,   5.2305,  67.6987])\n",
      "-0.012907990289442228 -0.015937788313597823 0.8781385970352106\n",
      "Epoch: 858\n",
      "Arb loss 0.0021030239279700544\n",
      "Real arb loss 2.069920855614249e-06\n",
      "Bounds loss: 0.5190570087205811\n",
      "MAPE:  0.07758999668599871\n",
      "Delta:  0.006333394405091993\n",
      "GRAD\n",
      " tensor([-7.0052,  1.1422,  1.8342, 13.7456])\n",
      "0.013842984645567435 0.016827806339813622 -6.994929128551708\n",
      "Epoch: 859\n",
      "Arb loss 0.016813527259769017\n",
      "Real arb loss 1.6503912927820797e-05\n",
      "Bounds loss: 0.5103224178985082\n",
      "MAPE:  0.07603397937223162\n",
      "Delta:  0.006245721323587982\n",
      "GRAD\n",
      " tensor([-34.6583,   1.8602,   5.2313,  67.7048])\n",
      "-0.012865580298168311 -0.015971387853044083 0.8824627534257501\n",
      "Epoch: 860\n",
      "Arb loss 0.001976215699314344\n",
      "Real arb loss 1.9453480358141635e-06\n",
      "Bounds loss: 0.5184729751648686\n",
      "MAPE:  0.07755513638591392\n",
      "Delta:  0.006326076152796584\n",
      "GRAD\n",
      " tensor([-0.0138, -0.0056, -0.0023,  0.0113])\n",
      "0.018701610169699512 0.02375297626465067 -12.316209907675912\n",
      "Epoch: 861\n",
      "Arb loss 0.026315703074914352\n",
      "Real arb loss 2.5795335260911033e-05\n",
      "Bounds loss: 0.5061576988919146\n",
      "MAPE:  0.07536909081848878\n",
      "Delta:  0.006207768342683151\n",
      "GRAD\n",
      " tensor([-34.6824,   1.8315,   4.2118,  67.8777])\n",
      "-0.014049404401730081 -0.016221897343464464 0.8265078361659095\n",
      "Epoch: 862\n",
      "Arb loss 0.004565568269282321\n",
      "Real arb loss 4.4926972618427735e-06\n",
      "Bounds loss: 0.5143685371229435\n",
      "MAPE:  0.07688931210582553\n",
      "Delta:  0.006294983790561764\n",
      "GRAD\n",
      " tensor([-7.0222,  1.1316,  1.8284, 13.7780])\n",
      "0.012913686736632513 0.015378102390857795 -3.528611554404561\n",
      "Epoch: 863\n",
      "Arb loss 0.020675685216694755\n",
      "Real arb loss 2.028486723225365e-05\n",
      "Bounds loss: 0.5064585250924311\n",
      "MAPE:  0.07551422165596057\n",
      "Delta:  0.00621369234187827\n",
      "GRAD\n",
      " tensor([-34.6847,   1.8347,   5.2148,  67.7782])\n",
      "-0.012914889673359298 -0.016314744487836874 0.8558021513850435\n",
      "Epoch: 864\n",
      "Arb loss 0.0029813893268874465\n",
      "Real arb loss 2.9348416067314297e-06\n",
      "Bounds loss: 0.5147212665230009\n",
      "MAPE:  0.07705486906109428\n",
      "Delta:  0.006293941492937825\n",
      "GRAD\n",
      " tensor([-7.0100,  1.1374,  1.8311, 13.7604])\n",
      "0.013430748343602139 0.0158454867860629 -4.96908998492558\n",
      "Epoch: 865\n",
      "Arb loss 0.017796181172287873\n",
      "Real arb loss 1.7467588395120645e-05\n",
      "Bounds loss: 0.5065652574958052\n",
      "MAPE:  0.07561110729843037\n",
      "Delta:  0.006209409148656822\n",
      "GRAD\n",
      " tensor([-34.6711,   1.8436,   5.2198,  67.7539])\n",
      "-0.012102872941622822 -0.016112549725106895 0.863532041711642\n",
      "Epoch: 866\n",
      "Arb loss 0.002428608509911843\n",
      "Real arb loss 2.3906528904609967e-06\n",
      "Bounds loss: 0.5147273153962179\n",
      "MAPE:  0.07712868347009648\n",
      "Delta:  0.006284560838625566\n",
      "GRAD\n",
      " tensor([-7.0046,  1.1402,  1.8324, 13.7635])\n",
      "0.01394259567845968 0.016773856202605186 -6.547117353673055\n",
      "arb imp changed to 1009.9423071136607\n",
      "Epoch: 867\n",
      "Arb loss 0.01833815792714894\n",
      "Real arb loss 1.79896363231956e-05\n",
      "Bounds loss: 0.5060933534242087\n",
      "MAPE:  0.07559494762545103\n",
      "Delta:  0.006196937747835928\n",
      "GRAD\n",
      " tensor([-34.6679,   1.8458,   5.2211,  67.8173])\n",
      "-0.012922925217396797 -0.016246652902714986 0.8736197803443554\n",
      "Delta imp changed to 0.016057287980116734\n",
      "Epoch: 868\n",
      "Arb loss 0.0023175804269129846\n",
      "Real arb loss 2.280496219734307e-06\n",
      "Bounds loss: 0.5143156764736628\n",
      "MAPE:  0.07713012626762054\n",
      "Delta:  0.006123922254563976\n",
      "GRAD\n",
      " tensor([-7.0055,  1.1401,  1.8325, 13.7694])\n",
      "0.013699237878518566 0.01679398454518699 -6.690499745150722\n",
      "Epoch: 869\n",
      "Arb loss 0.01782335168254061\n",
      "Real arb loss 1.7486744013718874e-05\n",
      "Bounds loss: 0.5056782669516168\n",
      "MAPE:  0.07559124785127536\n",
      "Delta:  0.0060400291868491504\n",
      "GRAD\n",
      " tensor([-34.6570,   1.8515,   5.2239,  67.8221])\n",
      "-0.012991670895018848 -0.016280715184898265 0.8803961945528351\n",
      "Epoch: 870\n",
      "Arb loss 0.0021317406870549863\n",
      "Real arb loss 2.097931900356835e-06\n",
      "Bounds loss: 0.5139110707910489\n",
      "MAPE:  0.0771342053533704\n",
      "Delta:  0.006118499258241002\n",
      "GRAD\n",
      " tensor([-7.0038,  1.1410,  1.8330, 13.7700])\n",
      "0.01369369604677484 0.016877660569587172 -7.1127984706677925\n",
      "Epoch: 871\n",
      "Arb loss 0.0172943825858\n",
      "Real arb loss 1.6969796567694448e-05\n",
      "Bounds loss: 0.5052374541752845\n",
      "MAPE:  0.07558108426609587\n",
      "Delta:  0.006034714389136232\n",
      "GRAD\n",
      " tensor([-34.6477,   1.8563,   5.2263,  67.8241])\n",
      "-0.01299407583215939 -0.016310415918650456 0.8866336981866458\n",
      "Epoch: 872\n",
      "Arb loss 0.0019606001958974197\n",
      "Real arb loss 1.929731250767147e-06\n",
      "Bounds loss: 0.5134780871905635\n",
      "MAPE:  0.077130453691051\n",
      "Delta:  0.006113129925534092\n",
      "GRAD\n",
      " tensor([-7.0023,  1.1419,  1.8334, 13.7706])\n",
      "0.013704556223463893 0.01695538300821775 -7.5821691113230685\n",
      "Epoch: 873\n",
      "Arb loss 0.016826202440884792\n",
      "Real arb loss 1.6512149636984817e-05\n",
      "Bounds loss: 0.5047718695559205\n",
      "MAPE:  0.07556437871137975\n",
      "Delta:  0.006029352192768271\n",
      "GRAD\n",
      " tensor([-34.6392,   1.8606,   5.2284,  67.8270])\n",
      "-0.012992457881998876 -0.01634213473193391 0.8925967248930974\n",
      "Epoch: 874\n",
      "Arb loss 0.001807189249762786\n",
      "Real arb loss 1.7788959519763961e-06\n",
      "Bounds loss: 0.5130209194570935\n",
      "MAPE:  0.07711965142306479\n",
      "Delta:  0.00610768829718855\n",
      "GRAD\n",
      " tensor([-7.0008,  1.1426,  1.8338, 13.7713])\n",
      "0.013713326403806514 0.01702349626379729 -8.08121640614789\n",
      "Epoch: 875\n",
      "Arb loss 0.016411476663959913\n",
      "Real arb loss 1.610667639651622e-05\n",
      "Bounds loss: 0.5042875097514657\n",
      "MAPE:  0.0755424097917233\n",
      "Delta:  0.006023931573996493\n",
      "GRAD\n",
      " tensor([-34.6312,   1.8646,   5.2304,  67.8306])\n",
      "-0.012991951900212628 -0.016375896251960897 0.8983629027960093\n",
      "Epoch: 876\n",
      "Arb loss 0.0016680148489559195\n",
      "Real arb loss 1.6420080523982043e-06\n",
      "Bounds loss: 0.5125456696923155\n",
      "MAPE:  0.0771040546967242\n",
      "Delta:  0.006102194203256028\n",
      "GRAD\n",
      " tensor([-6.9994,  1.1434,  1.8341, 13.7721])\n",
      "0.013718974881448909 0.017083429989890875 -8.615210202225784\n",
      "Epoch: 877\n",
      "Arb loss 0.016038313393145057\n",
      "Real arb loss 1.5741773325694595e-05\n",
      "Bounds loss: 0.5037896316275051\n",
      "MAPE:  0.07551631923059147\n",
      "Delta:  0.006018478354259835\n",
      "GRAD\n",
      " tensor([-34.6236,   1.8684,   5.2322,  67.8350])\n",
      "-0.012992717425277522 -0.016411311821463048 0.9039955918615256\n",
      "arb imp changed to 1010.4472782672175\n",
      "Epoch: 878\n",
      "Arb loss 0.0015405186592406834\n",
      "Real arb loss 1.5158051470260046e-06\n",
      "Bounds loss: 0.512057480364564\n",
      "MAPE:  0.07708746028618968\n",
      "Delta:  0.006096674742846883\n",
      "GRAD\n",
      " tensor([-7.0015,  1.1426,  1.8339, 13.7760])\n",
      "0.013719973767490012 0.01713540381037948 -9.192775273133941\n",
      "Delta imp changed to 0.015665646809869985\n",
      "Epoch: 879\n",
      "Arb loss 0.015702160497709887\n",
      "Real arb loss 1.5405324911901894e-05\n",
      "Bounds loss: 0.5032831686643918\n",
      "MAPE:  0.07548715924829938\n",
      "Delta:  0.005866369292981566\n",
      "GRAD\n",
      " tensor([-34.6337,   1.8648,   5.2309,  67.8542])\n",
      "-0.012997440927694504 -0.01645284118708168 0.9096542345840063\n",
      "Epoch: 880\n",
      "Arb loss 0.0014186237088503809\n",
      "Real arb loss 1.3958885294252932e-06\n",
      "Bounds loss: 0.5115636067105582\n",
      "MAPE:  0.07706772193161703\n",
      "Delta:  0.005942617081327134\n",
      "GRAD\n",
      " tensor([-7.0002,  1.1432,  1.8342, 13.7770])\n",
      "0.013719854608755466 0.017183446768785693 -9.839878723427963\n",
      "Epoch: 881\n",
      "Arb loss 0.015377708958117709\n",
      "Real arb loss 1.508809005784239e-05\n",
      "Bounds loss: 0.5027731807057993\n",
      "MAPE:  0.07545588187494255\n",
      "Delta:  0.005861085238975819\n",
      "GRAD\n",
      " tensor([-34.6269,   1.8681,   5.2325,  67.8594])\n",
      "-0.012991279855147253 -0.016485412615980355 0.9150888451993943\n",
      "Epoch: 882\n",
      "Arb loss 0.0013057390258213947\n",
      "Real arb loss 1.28480016418326e-06\n",
      "Bounds loss: 0.5110616040419833\n",
      "MAPE:  0.07704435636946756\n",
      "Delta:  0.005937228237570227\n",
      "GRAD\n",
      " tensor([-6.9990,  1.1439,  1.8345, 13.7781])\n",
      "0.013714811117871428 0.017225626068727684 -10.546309582158793\n",
      "Epoch: 883\n",
      "Arb loss 0.015076467025640257\n",
      "Real arb loss 1.4793497251255727e-05\n",
      "Bounds loss: 0.5022582479526719\n",
      "MAPE:  0.07542231651986878\n",
      "Delta:  0.005855800273728258\n",
      "GRAD\n",
      " tensor([-34.6203,   1.8712,   5.2339,  67.8650])\n",
      "-0.012988043302371022 -0.016519200779910426 0.9266796396170501\n",
      "Epoch: 884\n",
      "Arb loss 0.0011054119956216038\n",
      "Real arb loss 1.087824363897455e-06\n",
      "Bounds loss: 0.5105551527939681\n",
      "MAPE:  0.07701836809648822\n",
      "Delta:  0.005931855661253477\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.018545979146539993 0.024298441766549272 -21.11786386470775\n",
      "Epoch: 885\n",
      "Arb loss 0.02444935203357355\n",
      "Real arb loss 2.3955422459752073e-05\n",
      "Bounds loss: 0.4981494581451923\n",
      "MAPE:  0.0747548470553033\n",
      "Delta:  0.005821843589859585\n",
      "GRAD\n",
      " tensor([-48.2467,   2.3090,   6.9634,  92.3404])\n",
      "-0.023562983713228736 -0.031094722361178162 0.999952237469437\n",
      "Epoch: 886\n",
      "Arb loss 1.1677629237501499e-06\n",
      "Real arb loss 6.543786478033221e-10\n",
      "Bounds loss: 0.5136392772405884\n",
      "MAPE:  0.07773293270209844\n",
      "Delta:  0.005959023595548411\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.02107135113593528 0.02625455365135332 -15449.845381769204\n",
      "Epoch: 887\n",
      "Arb loss 0.018042924377426307\n",
      "Real arb loss 1.7696424179187246e-05\n",
      "Bounds loss: 0.500153907278833\n",
      "MAPE:  0.07516426197159284\n",
      "Delta:  0.005833458916939287\n",
      "GRAD\n",
      " tensor([-34.6073,   1.8722,   4.2326,  67.9559])\n",
      "-0.0135642509530578 -0.01647041753652556 0.9151059040745642\n",
      "Epoch: 888\n",
      "Arb loss 0.0015317377528726145\n",
      "Real arb loss 1.5072444893843019e-06\n",
      "Bounds loss: 0.5083916509642401\n",
      "MAPE:  0.07674295986125076\n",
      "Delta:  0.005912585417613005\n",
      "GRAD\n",
      " tensor([-0.0020, -0.0008, -0.0003,  0.0017])\n",
      "0.01823341171607229 0.024024228384920354 -16.428385228180854\n",
      "arb imp changed to 1010.952501906351\n",
      "Epoch: 889\n",
      "Arb loss 0.026709063483424812\n",
      "Real arb loss 2.615033241589706e-05\n",
      "Bounds loss: 0.4961779338324885\n",
      "MAPE:  0.07453015507481824\n",
      "Delta:  0.005804778813387221\n",
      "GRAD\n",
      " tensor([-48.2527,   2.3011,   6.9580,  92.4207])\n",
      "-0.02368104521429748 -0.03125639650563139 0.9967497247342769\n",
      "Delta imp changed to 0.015283557863287792\n",
      "Epoch: 890\n",
      "Arb loss 8.681180841080384e-05\n",
      "Real arb loss 8.517033690338266e-08\n",
      "Bounds loss: 0.5116866680697018\n",
      "MAPE:  0.0775101343992904\n",
      "Delta:  0.005797309310171746\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.02096386687569507 0.026101412578102057 -221.19651380183691\n",
      "Epoch: 891\n",
      "Arb loss 0.019289281185713596\n",
      "Real arb loss 1.890530408040907e-05\n",
      "Bounds loss: 0.49833092323570005\n",
      "MAPE:  0.0749640728313012\n",
      "Delta:  0.005675775289556079\n",
      "GRAD\n",
      " tensor([-34.6194,   1.8642,   4.2280,  69.0106])\n",
      "-0.013963526712904795 -0.01717202266500406 0.9188139379633539\n",
      "Epoch: 892\n",
      "Arb loss 0.001566020778985655\n",
      "Real arb loss 1.540150532555927e-06\n",
      "Bounds loss: 0.506888273144176\n",
      "MAPE:  0.0766100975655746\n",
      "Delta:  0.00575502912942824\n",
      "GRAD\n",
      " tensor([-0.0038, -0.0015, -0.0006,  0.0031])\n",
      "0.0182255134011714 0.02401327575858303 -16.425278381441878\n",
      "Epoch: 893\n",
      "Arb loss 0.027288348024947503\n",
      "Real arb loss 2.671648397408438e-05\n",
      "Bounds loss: 0.4947162252623729\n",
      "MAPE:  0.074394776447667\n",
      "Delta:  0.005650140768905714\n",
      "GRAD\n",
      " tensor([-48.2363,   2.3060,   6.9592,  92.4555])\n",
      "-0.02369182172198747 -0.03140533133557555 0.9968587859218093\n",
      "Epoch: 894\n",
      "Arb loss 8.571854298653171e-05\n",
      "Real arb loss 8.409173308818879e-08\n",
      "Bounds loss: 0.5102529522338229\n",
      "MAPE:  0.07738599482968914\n",
      "Delta:  0.005784002896706762\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.020911927641174888 0.02610577134690306 -226.92218423546603\n",
      "Epoch: 895\n",
      "Arb loss 0.019537157546971995\n",
      "Real arb loss 1.9147740606725684e-05\n",
      "Bounds loss: 0.4969324053337245\n",
      "MAPE:  0.07483672612121102\n",
      "Delta:  0.005663048246654484\n",
      "GRAD\n",
      " tensor([-34.6096,   1.8672,   4.2289,  69.0347])\n",
      "-0.013963448994835925 -0.017274934725818536 0.9212979641893005\n",
      "Epoch: 896\n",
      "Arb loss 0.001537614072901067\n",
      "Real arb loss 1.5122107507533277e-06\n",
      "Bounds loss: 0.5055168801990086\n",
      "MAPE:  0.07649851090098429\n",
      "Delta:  0.005742123932001938\n",
      "GRAD\n",
      " tensor([-0.0051, -0.0021, -0.0008,  0.0042])\n",
      "0.018199105181172293 0.0240304809943227 -16.910720528630172\n",
      "Epoch: 897\n",
      "Arb loss 0.027539775940619793\n",
      "Real arb loss 2.696268695171734e-05\n",
      "Bounds loss: 0.49336906641707706\n",
      "MAPE:  0.07427652214615668\n",
      "Delta:  0.005637622414600108\n",
      "GRAD\n",
      " tensor([-48.2202,   2.3115,   6.9610,  92.4874])\n",
      "-0.023706822341859723 -0.03155420566015499 0.9976270731949103\n",
      "Epoch: 898\n",
      "Arb loss 6.534987253566202e-05\n",
      "Real arb loss 6.399748949335871e-08\n",
      "Bounds loss: 0.5089369354051602\n",
      "MAPE:  0.0772809659779671\n",
      "Delta:  0.00577127252761352\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.02086110888881032 0.026138336273262675 -244.78149797077907\n",
      "Epoch: 899\n",
      "Arb loss 0.016061789564014484\n",
      "Real arb loss 1.5742465709183758e-05\n",
      "Bounds loss: 0.4956341706456564\n",
      "MAPE:  0.07472420439984523\n",
      "Delta:  0.005650877382987974\n",
      "GRAD\n",
      " tensor([-20.6841,   1.5630,   4.5586,  41.3316])\n",
      "-0.004281539608941065 -0.0025082812126371312 0.38859320013752796\n",
      "arb imp changed to 1011.4579781573042\n",
      "Epoch: 900\n",
      "Arb loss 0.009825197501077245\n",
      "Real arb loss 9.635561481057224e-06\n",
      "Bounds loss: 0.4968773605242278\n",
      "MAPE:  0.07503443708503393\n",
      "Delta:  0.005675071838328507\n",
      "GRAD\n",
      " tensor([-20.6979,   1.5620,   4.5601,  41.2117])\n",
      "-0.0003850965870868528 -0.0008790867995762675 0.14990578359548778\n",
      "Epoch: 901\n",
      "Arb loss 0.008352343570697833\n",
      "Real arb loss 8.193392716240831e-06\n",
      "Bounds loss: 0.497314158852873\n",
      "MAPE:  0.07515846323558549\n",
      "Delta:  0.005677257289124921\n",
      "GRAD\n",
      " tensor([-20.6951,   1.5655,   4.5624,  41.1953])\n",
      "-0.00016813144808303093 -0.0007161048102244383 0.13174080521003007\n",
      "Epoch: 902\n",
      "Arb loss 0.007251999103303282\n",
      "Real arb loss 7.115824900953305e-06\n",
      "Bounds loss: 0.49767028791422024\n",
      "MAPE:  0.0752632233875504\n",
      "Delta:  0.005678211814614081\n",
      "GRAD\n",
      " tensor([-6.9612,  1.1590,  1.8405, 13.7998])\n",
      "0.01006714283817245 0.014183259488380173 -2.043275905228908\n",
      "Epoch: 903\n",
      "Arb loss 0.022069834135824522\n",
      "Real arb loss 2.1603801657488618e-05\n",
      "Bounds loss: 0.490611701081076\n",
      "MAPE:  0.07401233212427649\n",
      "Delta:  0.005621048445210963\n",
      "GRAD\n",
      " tensor([-34.3284,   1.9950,   4.2864,  67.7160])\n",
      "-0.012690385575369056 -0.017072991253995307 0.8457469357414482\n",
      "Epoch: 904\n",
      "Arb loss 0.0034043395431289183\n",
      "Real arb loss 3.344276131337643e-06\n",
      "Bounds loss: 0.4989879103627409\n",
      "MAPE:  0.0756318238515176\n",
      "Delta:  0.0056923817173185195\n",
      "GRAD\n",
      " tensor([-6.9424,  1.1682,  1.8449, 13.7503])\n",
      "0.013022627340566473 0.01568651893190165 -4.3022646674061304\n",
      "Epoch: 905\n",
      "Arb loss 0.018050709275385993\n",
      "Real arb loss 1.767826572476925e-05\n",
      "Bounds loss: 0.49116052706004576\n",
      "MAPE:  0.07418828193768366\n",
      "Delta:  0.0056182519515336265\n",
      "GRAD\n",
      " tensor([-34.3173,   2.0048,   4.2925,  67.6935])\n",
      "-0.012663772528345385 -0.01701935962582768 0.884932592487219\n",
      "Epoch: 906\n",
      "Arb loss 0.002077048320085575\n",
      "Real arb loss 2.0403466987714212e-06\n",
      "Bounds loss: 0.4995197647040917\n",
      "MAPE:  0.07582145842714964\n",
      "Delta:  0.00568940021625478\n",
      "GRAD\n",
      " tensor([-0.0132, -0.0054, -0.0022,  0.0109])\n",
      "0.01894926607448255 0.02397568841485387 -12.279819887888127\n",
      "Epoch: 907\n",
      "Arb loss 0.02758282758917704\n",
      "Real arb loss 2.6979214367931846e-05\n",
      "Bounds loss: 0.48754343446848525\n",
      "MAPE:  0.07362029231890219\n",
      "Delta:  0.00558159025775275\n",
      "GRAD\n",
      " tensor([-34.3170,   1.9885,   4.2791,  67.8827])\n",
      "-0.015205914433201961 -0.018540845840136377 0.8637509619985118\n",
      "Epoch: 908\n",
      "Arb loss 0.0037581337243862804\n",
      "Real arb loss 3.691861596133744e-06\n",
      "Bounds loss: 0.49658290212733613\n",
      "MAPE:  0.07535476792929205\n",
      "Delta:  0.005666463441613332\n",
      "GRAD\n",
      " tensor([-6.9459,  1.1652,  1.8430, 13.7637])\n",
      "0.013096769650723483 0.01564399553319784 -4.130267178373541\n",
      "Epoch: 909\n",
      "Arb loss 0.01928023009815765\n",
      "Real arb loss 1.8881559580370597e-05\n",
      "Bounds loss: 0.48881436142459367\n",
      "MAPE:  0.0739388634764743\n",
      "Delta:  0.005592251075184276\n",
      "GRAD\n",
      " tensor([-34.3140,   1.9988,   4.2870,  67.7518])\n",
      "-0.01267125979451622 -0.01717929019572595 0.8790342337188697\n",
      "Delta imp changed to 0.014910788159305164\n",
      "Epoch: 910\n",
      "Arb loss 0.0023322478079001517\n",
      "Real arb loss 2.2909682298652632e-06\n",
      "Bounds loss: 0.4972118451913452\n",
      "MAPE:  0.07556655487018935\n",
      "Delta:  0.005524987259896683\n",
      "GRAD\n",
      " tensor([-6.9397,  1.1689,  1.8450, 13.7585])\n",
      "0.014043961704574337 0.016873453627330504 -6.8477521596293585\n",
      "arb imp changed to 1011.9637071463828\n",
      "Epoch: 911\n",
      "Arb loss 0.01831205422262487\n",
      "Real arb loss 1.792685870535345e-05\n",
      "Bounds loss: 0.48882216417854957\n",
      "MAPE:  0.07400654131739799\n",
      "Delta:  0.005447394550400432\n",
      "GRAD\n",
      " tensor([-34.3065,   2.0049,   4.2908,  67.7947])\n",
      "-0.013368710573895104 -0.017265738402534758 0.8973204460100672\n",
      "Epoch: 912\n",
      "Arb loss 0.0018802735602185881\n",
      "Real arb loss 1.8465130006299625e-06\n",
      "Bounds loss: 0.49726203979061734\n",
      "MAPE:  0.07565931587897884\n",
      "Delta:  0.00552021919152655\n",
      "GRAD\n",
      " tensor([-6.9402,  1.1693,  1.8454, 13.7617])\n",
      "0.013855120179536051 0.01701175020265333 -7.909470796776896\n",
      "Epoch: 913\n",
      "Arb loss 0.016752242374719235\n",
      "Real arb loss 1.6404503315229197e-05\n",
      "Bounds loss: 0.4888027421844375\n",
      "MAPE:  0.0740734556113616\n",
      "Delta:  0.005443735891210568\n",
      "GRAD\n",
      " tensor([-34.2959,   2.0121,   4.2949,  67.7895])\n",
      "-0.012705793678513988 -0.0169800833108249 0.8933843093961246\n",
      "Epoch: 914\n",
      "Arb loss 0.001786051889944197\n",
      "Real arb loss 1.7541546895539216e-06\n",
      "Bounds loss: 0.49710265346928884\n",
      "MAPE:  0.07569272017431805\n",
      "Delta:  0.005512902876284611\n",
      "GRAD\n",
      " tensor([-6.9358,  1.1715,  1.8465, 13.7675])\n",
      "0.013259487233579392 0.016952044999816396 -7.935623444799354\n",
      "Epoch: 915\n",
      "Arb loss 0.015959487141413563\n",
      "Real arb loss 1.5630680259105808e-05\n",
      "Bounds loss: 0.4886757469181493\n",
      "MAPE:  0.07411067609262574\n",
      "Delta:  0.005439804610976552\n",
      "GRAD\n",
      " tensor([-34.2819,   2.0202,   4.2992,  67.7940])\n",
      "-0.012885372031856024 -0.017003272328326213 0.9053214645317532\n",
      "Epoch: 916\n",
      "Arb loss 0.0015110208693733522\n",
      "Real arb loss 1.48420941368705e-06\n",
      "Bounds loss: 0.49698483372324687\n",
      "MAPE:  0.07574221660566607\n",
      "Delta:  0.00550989851716959\n",
      "GRAD\n",
      " tensor([-0.0133, -0.0054, -0.0022,  0.0110])\n",
      "0.01799102156060617 0.02419262507001707 -15.450575416693255\n",
      "Epoch: 917\n",
      "Arb loss 0.024857162767823737\n",
      "Real arb loss 2.4314044462858957e-05\n",
      "Bounds loss: 0.48496146597549555\n",
      "MAPE:  0.07350960602374516\n",
      "Delta:  0.00541076981415044\n",
      "GRAD\n",
      " tensor([-34.2914,   1.9998,   4.2841,  67.9467])\n",
      "-0.014353750022436218 -0.017660589356613077 0.8612265344979783\n",
      "Epoch: 918\n",
      "Arb loss 0.003449514619838727\n",
      "Real arb loss 3.38751182160596e-06\n",
      "Bounds loss: 0.4935261712798699\n",
      "MAPE:  0.07517495538861485\n",
      "Delta:  0.0054884346514916995\n",
      "GRAD\n",
      " tensor([-6.9447,  1.1654,  1.8430, 13.7884])\n",
      "0.01230899258628726 0.015606870582046684 -4.280960758900533\n",
      "Epoch: 919\n",
      "Arb loss 0.018216751344622008\n",
      "Real arb loss 1.7835783653169172e-05\n",
      "Bounds loss: 0.485823772195852\n",
      "MAPE:  0.07376383337236628\n",
      "Delta:  0.005420877550056166\n",
      "GRAD\n",
      " tensor([-34.2921,   2.0067,   4.2899,  67.8251])\n",
      "-0.012188175024755665 -0.0171249820627577 0.8747929981563736\n",
      "Epoch: 920\n",
      "Arb loss 0.0022808648191909725\n",
      "Real arb loss 2.2400949513378954e-06\n",
      "Bounds loss: 0.4941434955803672\n",
      "MAPE:  0.07537237400712489\n",
      "Delta:  0.005486948154424019\n",
      "GRAD\n",
      " tensor([-6.9339,  1.1710,  1.8458, 13.7789])\n",
      "0.013288214437993107 0.016828848050406964 -6.7772526305975065\n",
      "Delta imp changed to 0.014547110399322112\n",
      "Epoch: 921\n",
      "Arb loss 0.017738861915090297\n",
      "Real arb loss 1.7370100262300356e-05\n",
      "Bounds loss: 0.48582762977814825\n",
      "MAPE:  0.07381951109491548\n",
      "Delta:  0.0052819867421833\n",
      "GRAD\n",
      " tensor([-34.2661,   2.0205,   4.2967,  67.8520])\n",
      "-0.012866046120271868 -0.01720444951533251 0.8912759868716615\n",
      "arb imp changed to 1012.469688999956\n",
      "Epoch: 922\n",
      "Arb loss 0.001929604575865929\n",
      "Real arb loss 1.8945756029305483e-06\n",
      "Bounds loss: 0.4941860267078201\n",
      "MAPE:  0.0754517076511341\n",
      "Delta:  0.005349945027214895\n",
      "GRAD\n",
      " tensor([-6.9344,  1.1714,  1.8462, 13.7820])\n",
      "0.013103439528141414 0.016937577688741157 -7.559665200154692\n",
      "Epoch: 923\n",
      "Arb loss 0.016516769138098845\n",
      "Real arb loss 1.6169186564452195e-05\n",
      "Bounds loss: 0.48581571248776606\n",
      "MAPE:  0.07387730173380706\n",
      "Delta:  0.0052798423460719045\n",
      "GRAD\n",
      " tensor([-34.2722,   2.0209,   4.2982,  67.8602])\n",
      "-0.012903123430094032 -0.017209637753499152 0.9060171917595312\n",
      "Epoch: 924\n",
      "Arb loss 0.0015522923466580374\n",
      "Real arb loss 1.5242614696538218e-06\n",
      "Bounds loss: 0.49417642491463865\n",
      "MAPE:  0.0755204338817833\n",
      "Delta:  0.005347968803554708\n",
      "GRAD\n",
      " tensor([-6.9324,  1.1728,  1.8470, 13.7804])\n",
      "0.013108364591174704 0.01708287084729676 -8.907685399479076\n",
      "Epoch: 925\n",
      "Arb loss 0.01537962421870695\n",
      "Real arb loss 1.5059002710932372e-05\n",
      "Bounds loss: 0.485734472872043\n",
      "MAPE:  0.07392008714182612\n",
      "Delta:  0.005277865678655484\n",
      "GRAD\n",
      " tensor([-34.2633,   2.0271,   4.3017,  67.8528])\n",
      "-0.012869457119208949 -0.017205558693027534 0.9205795792527989\n",
      "Epoch: 926\n",
      "Arb loss 0.0012214562263835502\n",
      "Real arb loss 1.1992710929670108e-06\n",
      "Bounds loss: 0.4940918058542697\n",
      "MAPE:  0.07557066841950058\n",
      "Delta:  0.005345788944687886\n",
      "GRAD\n",
      " tensor([-6.9306,  1.1740,  1.8477, 13.7791])\n",
      "0.013122411567419112 0.017207525912241617 -10.786911676472664\n",
      "Epoch: 927\n",
      "Arb loss 0.014397196657060508\n",
      "Real arb loss 1.4099290278393358e-05\n",
      "Bounds loss: 0.4855897083020061\n",
      "MAPE:  0.07394856788256725\n",
      "Delta:  0.005275639302003132\n",
      "GRAD\n",
      " tensor([-34.2553,   2.0326,   4.3048,  67.8472])\n",
      "-0.012835552887553447 -0.01720719391703507 0.9342008701862935\n",
      "Epoch: 928\n",
      "Arb loss 0.0009473230117913851\n",
      "Real arb loss 9.303075403733624e-07\n",
      "Bounds loss: 0.4939453445768752\n",
      "MAPE:  0.07560536276186582\n",
      "Delta:  0.005343355049279649\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.01790539370426092 0.024541835684706803 -23.414064808529517\n",
      "Epoch: 929\n",
      "Arb loss 0.023128005404486247\n",
      "Real arb loss 2.2619880672865005e-05\n",
      "Bounds loss: 0.4818230190930437\n",
      "MAPE:  0.07333089820515715\n",
      "Delta:  0.005247680173420646\n",
      "GRAD\n",
      " tensor([-34.2667,   2.0110,   4.2891,  68.0010])\n",
      "-0.01430908493327765 -0.017912219462236312 0.8879218198720362\n",
      "Epoch: 930\n",
      "Arb loss 0.0025921447557245283\n",
      "Real arb loss 2.5444096902478913e-06\n",
      "Bounds loss: 0.4904535387529955\n",
      "MAPE:  0.07502234058703594\n",
      "Delta:  0.0053227696747248\n",
      "GRAD\n",
      " tensor([-6.9409,  1.1672,  1.8439, 13.8002])\n",
      "0.01335766723223164 0.016762262660907634 -6.344670268123717\n",
      "Epoch: 931\n",
      "Arb loss 0.01903844851804276\n",
      "Real arb loss 1.8631153817483295e-05\n",
      "Bounds loss: 0.48223242771344615\n",
      "MAPE:  0.07348610831700732\n",
      "Delta:  0.005251669888656012\n",
      "GRAD\n",
      " tensor([-34.2616,   2.0180,   4.2940,  67.9334])\n",
      "-0.012811840236301109 -0.017476753272238188 0.9016811280500642\n",
      "Epoch: 932\n",
      "Arb loss 0.0018718387819708917\n",
      "Real arb loss 1.8377074773400087e-06\n",
      "Bounds loss: 0.49066028487246643\n",
      "MAPE:  0.07512785128205879\n",
      "Delta:  0.005318953444243266\n",
      "GRAD\n",
      " tensor([-0.0024, -0.0010, -0.0004,  0.0020])\n",
      "0.01776721848343832 0.024051310354471167 -13.916849438591347\n",
      "arb imp changed to 1012.9759238444559\n",
      "Epoch: 933\n",
      "Arb loss 0.027935898252617993\n",
      "Real arb loss 2.7290471791871813e-05\n",
      "Bounds loss: 0.4788592620823855\n",
      "MAPE:  0.07293572271817512\n",
      "Delta:  0.005224450436296159\n",
      "GRAD\n",
      " tensor([-47.7346,   2.5230,   7.0528,  92.4208])\n",
      "-0.02367503452399311 -0.03273919300974648 0.9959802048418293\n",
      "Delta imp changed to 0.01419230282860694\n",
      "Epoch: 934\n",
      "Arb loss 0.00011229658853502333\n",
      "Real arb loss 1.1007454978496228e-07\n",
      "Bounds loss: 0.49453672788820546\n",
      "MAPE:  0.07598344687224708\n",
      "Delta:  0.0052176970543847435\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.020241533149576885 0.026270576286359537 -169.14582642630387\n",
      "Epoch: 935\n",
      "Arb loss 0.019106795861146143\n",
      "Real arb loss 1.8689337670438696e-05\n",
      "Bounds loss: 0.4815449630518117\n",
      "MAPE:  0.07347607868862488\n",
      "Delta:  0.005112082866493965\n",
      "GRAD\n",
      " tensor([-34.2444,   2.0278,   4.2991,  67.9882])\n",
      "-0.013586424330052305 -0.01761757048444279 0.9149230699511148\n",
      "Epoch: 936\n",
      "Arb loss 0.0016255475349370595\n",
      "Real arb loss 1.5954648860038656e-06\n",
      "Bounds loss: 0.4900286153798054\n",
      "MAPE:  0.0751489854531991\n",
      "Delta:  0.005181537793528543\n",
      "GRAD\n",
      " tensor([-0.0019, -0.0008, -0.0003,  0.0015])\n",
      "0.01759843450262688 0.024186470811442762 -15.51263142997561\n",
      "Epoch: 937\n",
      "Arb loss 0.026842067316321064\n",
      "Real arb loss 2.622708566313183e-05\n",
      "Bounds loss: 0.47817655257715\n",
      "MAPE:  0.07293451093257075\n",
      "Delta:  0.005090350840046245\n",
      "GRAD\n",
      " tensor([-47.7066,   2.5383,   7.0606,  92.4231])\n",
      "-0.023721659555090424 -0.032883720676461614 0.9995257862033351\n",
      "Epoch: 938\n",
      "Arb loss 1.2728878652408179e-05\n",
      "Real arb loss 1.2041163173430458e-08\n",
      "Bounds loss: 0.49390077676613037\n",
      "MAPE:  0.07600055784413941\n",
      "Delta:  0.00521110240968979\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.02025964515839318 0.026458981315205077 -1429.0235893342171\n",
      "Epoch: 939\n",
      "Arb loss 0.018202596738716437\n",
      "Real arb loss 1.7808742274848818e-05\n",
      "Bounds loss: 0.48083266534211005\n",
      "MAPE:  0.07346478514596926\n",
      "Delta:  0.005105527323985428\n",
      "GRAD\n",
      " tensor([-34.2258,   2.0378,   4.3042,  67.9872])\n",
      "-0.013560124249268668 -0.017667317990336384 0.9256395831138917\n",
      "Epoch: 940\n",
      "Arb loss 0.0013535526819006688\n",
      "Real arb loss 1.3287170747441832e-06\n",
      "Bounds loss: 0.4893276889408501\n",
      "MAPE:  0.0751492211072443\n",
      "Delta:  0.005174758908856706\n",
      "GRAD\n",
      " tensor([-0.0011, -0.0005, -0.0002,  0.0010])\n",
      "0.01761535235974865 0.02433857344763568 -18.090684247808106\n",
      "Epoch: 941\n",
      "Arb loss 0.025840246862939516\n",
      "Real arb loss 2.5252706302235653e-05\n",
      "Bounds loss: 0.4774181510436014\n",
      "MAPE:  0.07291150166423477\n",
      "Delta:  0.005083603707300446\n",
      "GRAD\n",
      " tensor([-47.6840,   2.5503,   7.0667,  92.4257])\n",
      "-0.023691955057911773 -0.03301486619421001 0.9999858941091919\n",
      "Epoch: 942\n",
      "Arb loss 3.644997007010365e-07\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 0.49318004741899313\n",
      "MAPE:  0.07599104444867838\n",
      "Delta:  0.0052040442178660435\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.02071388240326444 0.027085698900233268 -42137.53006966254\n",
      "Epoch: 943\n",
      "Arb loss 0.015359481598373621\n",
      "Real arb loss 1.5026180500661311e-05\n",
      "Bounds loss: 0.47982192115099953\n",
      "MAPE:  0.07338740065406267\n",
      "Delta:  0.0050962482579157775\n",
      "GRAD\n",
      " tensor([-20.4425,   1.6707,   4.6062,  41.3025])\n",
      "-0.004681167491305871 -0.0030760686204791554 0.43056169056450944\n",
      "arb imp changed to 1013.4824118063781\n",
      "Epoch: 944\n",
      "Arb loss 0.008750650373800992\n",
      "Real arb loss 8.565484150236564e-06\n",
      "Bounds loss: 0.4812978863060702\n",
      "MAPE:  0.07373767127759433\n",
      "Delta:  0.0051201046495883565\n",
      "GRAD\n",
      " tensor([-6.8900,  1.1899,  1.8539, 13.8013])\n",
      "0.009398052404091528 0.013761069829694161 -2.1963945280360897\n",
      "Epoch: 945\n",
      "Arb loss 0.027970530971574457\n",
      "Real arb loss 2.731368725620907e-05\n",
      "Bounds loss: 0.4746747124837281\n",
      "MAPE:  0.0725727845480935\n",
      "Delta:  0.005071985637777093\n",
      "GRAD\n",
      " tensor([-47.7372,   2.5163,   7.0478,  92.4332])\n",
      "-0.022223120726600376 -0.03300016259457417 0.995373661378572\n",
      "Delta imp changed to 0.013846149101079943\n",
      "Epoch: 946\n",
      "Arb loss 0.0001294011476956449\n",
      "Real arb loss 1.2683487212557242e-07\n",
      "Bounds loss: 0.49033905517522386\n",
      "MAPE:  0.07561682958284084\n",
      "Delta:  0.005058244865296583\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.02047372919725088 0.026371541638215534 -129.7858547679015\n",
      "Epoch: 947\n",
      "Arb loss 0.016923839709322385\n",
      "Real arb loss 1.654358186348641e-05\n",
      "Bounds loss: 0.4774080583648272\n",
      "MAPE:  0.07310592342966325\n",
      "Delta:  0.004954683729711116\n",
      "GRAD\n",
      " tensor([-20.4601,   1.6592,   4.5998,  41.3392])\n",
      "-0.0052111683718985 -0.0037994012402720045 0.4717745304989175\n",
      "Epoch: 948\n",
      "Arb loss 0.008939603176217881\n",
      "Real arb loss 8.750231240809225e-06\n",
      "Bounds loss: 0.4792219231338944\n",
      "MAPE:  0.07351732304088998\n",
      "Delta:  0.004980503420856147\n",
      "GRAD\n",
      " tensor([-20.4770,   1.6583,   4.6019,  41.1910])\n",
      "2.8219579015331675e-05 -0.0012830953669991096 0.1251828160258185\n",
      "Epoch: 949\n",
      "Arb loss 0.007820518476465576\n",
      "Real arb loss 7.6576401771047e-06\n",
      "Bounds loss: 0.4798368105632319\n",
      "MAPE:  0.07367371164711933\n",
      "Delta:  0.0049803628731463255\n",
      "GRAD\n",
      " tensor([-6.8859,  1.1913,  1.8544, 13.8003])\n",
      "0.009718122232431847 0.013944978526533092 -1.8936066751974705\n",
      "Epoch: 950\n",
      "Arb loss 0.022629504467005943\n",
      "Real arb loss 2.2105008076817135e-05\n",
      "Bounds loss: 0.4731454965436875\n",
      "MAPE:  0.07248303597609451\n",
      "Delta:  0.004931963097983224\n",
      "GRAD\n",
      " tensor([-33.9347,   2.1652,   4.3597,  67.7087])\n",
      "-0.012743718485627387 -0.018183557753809865 0.8519586616607564\n",
      "Epoch: 951\n",
      "Arb loss 0.00335010212724945\n",
      "Real arb loss 3.2844116979318657e-06\n",
      "Bounds loss: 0.4817489650060447\n",
      "MAPE:  0.07416531525789788\n",
      "Delta:  0.004994814647285425\n",
      "GRAD\n",
      " tensor([-6.8684,  1.2006,  1.8591, 13.7511])\n",
      "0.012198036739772378 0.015323254962985144 -4.082094901734732\n",
      "Epoch: 952\n",
      "Arb loss 0.01702553694118511\n",
      "Real arb loss 1.6643107281561652e-05\n",
      "Bounds loss: 0.4743670027871028\n",
      "MAPE:  0.07277895646901343\n",
      "Delta:  0.004933887714709484\n",
      "GRAD\n",
      " tensor([-20.4782,   1.6457,   4.5917,  41.3449])\n",
      "-0.0038060090098019916 -0.003836392872109684 0.40711663239143203\n",
      "Epoch: 953\n",
      "Arb loss 0.010094157677033904\n",
      "Real arb loss 9.879376985068516e-06\n",
      "Bounds loss: 0.4761868609753592\n",
      "MAPE:  0.07316895080398106\n",
      "Delta:  0.0049526661358050205\n",
      "GRAD\n",
      " tensor([-20.4768,   1.6523,   4.5969,  41.2281])\n",
      "0.00023596611265930267 -0.0014041672281930317 0.11649336403799981\n",
      "Epoch: 954\n",
      "Arb loss 0.008918255292106223\n",
      "Real arb loss 8.730900739245587e-06\n",
      "Bounds loss: 0.4768555069600369\n",
      "MAPE:  0.07333238322920745\n",
      "Delta:  0.004951497474429655\n",
      "GRAD\n",
      " tensor([-20.4634,   1.6610,   4.6018,  41.2306])\n",
      "-0.00028828949216541666 -0.001385150795493395 0.1563985971769345\n",
      "arb imp changed to 1013.9891530122812\n",
      "Epoch: 955\n",
      "Arb loss 0.007527214401492615\n",
      "Real arb loss 7.367473014261549e-06\n",
      "Bounds loss: 0.477516023744838\n",
      "MAPE:  0.07350079315541966\n",
      "Delta:  0.004952924939122017\n",
      "GRAD\n",
      " tensor([-6.8882,  1.1895,  1.8532, 13.8167])\n",
      "0.009556716632666218 0.013987387813941599 -1.9661676577737368\n",
      "Epoch: 956\n",
      "Arb loss 0.02232697991083609\n",
      "Real arb loss 2.1801796953897864e-05\n",
      "Bounds loss: 0.47083682193334764\n",
      "MAPE:  0.07230679958963374\n",
      "Delta:  0.004905591238975962\n",
      "GRAD\n",
      " tensor([-33.9325,   2.1616,   4.3564,  67.7741])\n",
      "-0.012833237225886585 -0.018342251945657972 0.8601774526978023\n",
      "Delta imp changed to 0.013508438147395068\n",
      "Epoch: 957\n",
      "Arb loss 0.003121815204698096\n",
      "Real arb loss 3.059422965206421e-06\n",
      "Bounds loss: 0.479473029546542\n",
      "MAPE:  0.07400333978358693\n",
      "Delta:  0.004847361809833144\n",
      "GRAD\n",
      " tensor([-6.8680,  1.1999,  1.8584, 13.7638])\n",
      "0.012112597253002622 0.015403878258960613 -4.343482819665485\n",
      "Epoch: 958\n",
      "Arb loss 0.016681365912474762\n",
      "Real arb loss 1.6300188366303044e-05\n",
      "Bounds loss: 0.472087285370952\n",
      "MAPE:  0.07260823063928055\n",
      "Delta:  0.004788647668491049\n",
      "GRAD\n",
      " tensor([-20.4785,   1.6431,   4.5897,  41.3838])\n",
      "-0.003000193335926493 -0.003316504865827241 0.3293562071986118\n",
      "Epoch: 959\n",
      "Arb loss 0.011187254504649864\n",
      "Real arb loss 1.094357844710791e-05\n",
      "Bounds loss: 0.4736529651499799\n",
      "MAPE:  0.07294791980999496\n",
      "Delta:  0.004803014537314155\n",
      "GRAD\n",
      " tensor([-20.4700,   1.6522,   4.5957,  41.2916])\n",
      "-0.0015934480734103307 -0.002782914409668047 0.30919048704937835\n",
      "Epoch: 960\n",
      "Arb loss 0.007728261835611822\n",
      "Real arb loss 7.564499351066719e-06\n",
      "Bounds loss: 0.4749711008118778\n",
      "MAPE:  0.07325055157056268\n",
      "Delta:  0.004810667891575201\n",
      "GRAD\n",
      " tensor([-20.4669,   1.6582,   4.6001,  41.2467])\n",
      "8.618437930285605e-05 -0.0012698959997681225 0.13142118400300407\n",
      "Epoch: 961\n",
      "Arb loss 0.006712604514890487\n",
      "Real arb loss 6.571634323174167e-06\n",
      "Bounds loss: 0.4755742647128043\n",
      "MAPE:  0.0734007045072258\n",
      "Delta:  0.0048102532871489335\n",
      "GRAD\n",
      " tensor([-6.8841,  1.1907,  1.8535, 13.8220])\n",
      "0.009654543803028992 0.014147415780486061 -2.176820242878983\n",
      "Epoch: 962\n",
      "Arb loss 0.02132473790534495\n",
      "Real arb loss 2.082791910359914e-05\n",
      "Bounds loss: 0.4688461178554133\n",
      "MAPE:  0.07218244996181948\n",
      "Delta:  0.00476381248608449\n",
      "GRAD\n",
      " tensor([-33.9120,   2.1675,   4.3578,  67.8077])\n",
      "-0.01297642240872321 -0.018759520381728123 0.8819391294457039\n",
      "Epoch: 963\n",
      "Arb loss 0.0025176171214472236\n",
      "Real arb loss 2.4672680982156874e-06\n",
      "Bounds loss: 0.477641446159216\n",
      "MAPE:  0.07391722913362525\n",
      "Delta:  0.0048256297291798715\n",
      "GRAD\n",
      " tensor([-6.8639,  1.2012,  1.8588, 13.7700])\n",
      "0.0121123272010224 0.015584133843414838 -5.256795379504159\n",
      "Epoch: 964\n",
      "Arb loss 0.01575221517283155\n",
      "Real arb loss 1.5396515212082442e-05\n",
      "Bounds loss: 0.47019781793310855\n",
      "MAPE:  0.07249798405843404\n",
      "Delta:  0.004767180122949064\n",
      "GRAD\n",
      " tensor([-20.4652,   1.6474,   4.5910,  41.4031])\n",
      "-0.0030150493058296313 -0.003331520462337645 0.3417289232663858\n",
      "Epoch: 965\n",
      "Arb loss 0.0103692276427594\n",
      "Real arb loss 1.0145426261904971e-05\n",
      "Bounds loss: 0.4717642915848992\n",
      "MAPE:  0.07284823909904688\n",
      "Delta:  0.004781553406069526\n",
      "GRAD\n",
      " tensor([-20.4567,   1.6564,   4.5969,  41.3112])\n",
      "-0.00045222833307145827 -0.001648644719927983 0.15796680615213898\n",
      "arb imp changed to 1014.4961475887873\n",
      "Epoch: 966\n",
      "Arb loss 0.008735599486703107\n",
      "Real arb loss 8.546120697226725e-06\n",
      "Bounds loss: 0.47254206329327125\n",
      "MAPE:  0.0730328447476159\n",
      "Delta:  0.004783715759995845\n",
      "GRAD\n",
      " tensor([-20.4544,   1.6608,   4.6001,  41.3038])\n",
      "-0.0005825066256799349 -0.0015156807542469064 0.1862397191926971\n",
      "Epoch: 967\n",
      "Arb loss 0.007108683891319651\n",
      "Real arb loss 6.9561272479109e-06\n",
      "Bounds loss: 0.473258286204177\n",
      "MAPE:  0.07320980866068472\n",
      "Delta:  0.004786502306121413\n",
      "GRAD\n",
      " tensor([-20.4485,   1.6664,   4.6037,  41.2884])\n",
      "-0.000578052300020726 -0.0013613410997852515 0.19552553611271228\n",
      "Delta imp changed to 0.013178964046239092\n",
      "Epoch: 968\n",
      "Arb loss 0.005718754662413575\n",
      "Real arb loss 5.596855534285093e-06\n",
      "Bounds loss: 0.47390255216000066\n",
      "MAPE:  0.07337241352372904\n",
      "Delta:  0.0046724577119888\n",
      "GRAD\n",
      " tensor([-6.8789,  1.1930,  1.8546, 13.8299])\n",
      "0.00943607445555017 0.01432537137963208 -2.4379496845051833\n",
      "Epoch: 969\n",
      "Arb loss 0.019660790787407297\n",
      "Real arb loss 1.9198952151421592e-05\n",
      "Bounds loss: 0.4671137221025532\n",
      "MAPE:  0.07212443446115586\n",
      "Delta:  0.004628368053128064\n",
      "GRAD\n",
      " tensor([-33.8944,   2.1757,   4.3615,  67.8431])\n",
      "-0.013087501531218404 -0.01893818394854474 0.9011997639849286\n",
      "Epoch: 970\n",
      "Arb loss 0.0019424907700387826\n",
      "Real arb loss 1.903192298891396e-06\n",
      "Bounds loss: 0.4759600076966208\n",
      "MAPE:  0.07388286617611849\n",
      "Delta:  0.00468894182711042\n",
      "GRAD\n",
      " tensor([-6.8614,  1.2025,  1.8594, 13.7765])\n",
      "0.013438776897071847 0.017123121610480685 -7.74159445452575\n",
      "Epoch: 971\n",
      "Arb loss 0.016980466543338475\n",
      "Real arb loss 1.658750453060283e-05\n",
      "Bounds loss: 0.4678100866031062\n",
      "MAPE:  0.07230611371234345\n",
      "Delta:  0.004625928184012534\n",
      "GRAD\n",
      " tensor([-33.8693,   2.1923,   4.3709,  67.8456])\n",
      "-0.012766150843147583 -0.018314237041939352 0.9087358461904126\n",
      "Epoch: 972\n",
      "Arb loss 0.001549707910369795\n",
      "Real arb loss 1.518550479720535e-06\n",
      "Bounds loss: 0.47637767141976567\n",
      "MAPE:  0.07401015823953405\n",
      "Delta:  0.004684983480999206\n",
      "GRAD\n",
      " tensor([-6.8557,  1.2058,  1.8611, 13.7805])\n",
      "0.012742106681926435 0.017141978704335203 -8.786092288088243\n",
      "Epoch: 973\n",
      "Arb loss 0.015165584630459198\n",
      "Real arb loss 1.4819307069686359e-05\n",
      "Bounds loss: 0.46821161552106727\n",
      "MAPE:  0.07242456489582062\n",
      "Delta:  0.0046252869216812514\n",
      "GRAD\n",
      " tensor([-33.8535,   2.2035,   4.3774,  67.8380])\n",
      "-0.01301988595714021 -0.018314385254503573 0.9334122253545046\n",
      "Epoch: 974\n",
      "Arb loss 0.0010098425317402054\n",
      "Real arb loss 9.894354028187892e-07\n",
      "Bounds loss: 0.47678662342835354\n",
      "MAPE:  0.07414026551047367\n",
      "Delta:  0.004685507629920593\n",
      "GRAD\n",
      " tensor([-0.0119, -0.0048, -0.0020,  0.0100])\n",
      "0.01744727292942383 0.02478146614386667 -21.869542468721026\n",
      "Epoch: 975\n",
      "Arb loss 0.023094636666353387\n",
      "Real arb loss 2.2542829792783844e-05\n",
      "Bounds loss: 0.4649711518620153\n",
      "MAPE:  0.07187869302049782\n",
      "Delta:  0.004603758299488471\n",
      "GRAD\n",
      " tensor([-33.8502,   1.1905,   4.3663,  66.9685])\n",
      "-0.014734820997876152 -0.019074183023357394 0.8988868467050265\n",
      "Epoch: 976\n",
      "Arb loss 0.0023351715375367066\n",
      "Real arb loss 2.2878183479254564e-06\n",
      "Bounds loss: 0.4738400967132127\n",
      "MAPE:  0.07366507009427159\n",
      "Delta:  0.00467159385394892\n",
      "GRAD\n",
      " tensor([-6.8568,  1.2038,  1.8597, 13.7878])\n",
      "0.01309715972718517 0.016918945745182712 -6.72894085889977\n",
      "arb imp changed to 1015.0033956625816\n",
      "Epoch: 977\n",
      "Arb loss 0.01805742691036175\n",
      "Real arb loss 1.762922504902774e-05\n",
      "Bounds loss: 0.4658232218250297\n",
      "MAPE:  0.07211031719837536\n",
      "Delta:  0.004610409243063215\n",
      "GRAD\n",
      " tensor([-33.8605,   1.1936,   4.3706,  67.8990])\n",
      "-0.014287114543737767 -0.01951709367530241 0.9372643045693158\n",
      "Epoch: 978\n",
      "Arb loss 0.0011328452349102958\n",
      "Real arb loss 1.1098762369204581e-06\n",
      "Bounds loss: 0.47491473728152\n",
      "MAPE:  0.07394154531195898\n",
      "Delta:  0.0046762786880123666\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.01810099774063001 0.024848129940812202 -20.710076563601707\n",
      "Delta imp changed to 0.012857525898769847\n",
      "Epoch: 979\n",
      "Arb loss 0.02459415678461388\n",
      "Real arb loss 2.3989110559942623e-05\n",
      "Bounds loss: 0.4631139941787421\n",
      "MAPE:  0.07167545176616047\n",
      "Delta:  0.004479642320044974\n",
      "GRAD\n",
      " tensor([-33.8625,   1.1814,   4.3609,  67.0118])\n",
      "-0.014527558657857265 -0.019231159781933238 0.8858985421132788\n",
      "Epoch: 980\n",
      "Arb loss 0.0028062291446190393\n",
      "Real arb loss 2.747922631933235e-06\n",
      "Bounds loss: 0.47202021339804273\n",
      "MAPE:  0.07346291047858852\n",
      "Delta:  0.004544720586615648\n",
      "GRAD\n",
      " tensor([-6.8645,  1.1999,  1.8578, 13.8029])\n",
      "0.011794173419846121 0.015496291474758617 -4.949003387218692\n",
      "Epoch: 981\n",
      "Arb loss 0.01669426668665048\n",
      "Real arb loss 1.6303006555559724e-05\n",
      "Bounds loss: 0.4647056505892489\n",
      "MAPE:  0.07204432940233935\n",
      "Delta:  0.004491119363872358\n",
      "GRAD\n",
      " tensor([-33.8630,   2.1920,   4.3696,  67.8794])\n",
      "-0.012213178292835636 -0.018500486537767813 0.9187700086113538\n",
      "Epoch: 982\n",
      "Arb loss 0.0013560751391963808\n",
      "Real arb loss 1.3285448464456366e-06\n",
      "Bounds loss: 0.47330293122199996\n",
      "MAPE:  0.07376064877993634\n",
      "Delta:  0.004545970205397738\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.017547281549645688 0.024624365257082115 -17.75453161438667\n",
      "Epoch: 983\n",
      "Arb loss 0.025432554069542326\n",
      "Real arb loss 2.4803858306447698e-05\n",
      "Bounds loss: 0.4616481469663418\n",
      "MAPE:  0.07152932903217385\n",
      "Delta:  0.004466200786287323\n",
      "GRAD\n",
      " tensor([-33.8493,   1.1840,   4.3608,  67.0551])\n",
      "-0.014767998418751649 -0.01938547859827877 0.9031830621249075\n",
      "Epoch: 984\n",
      "Arb loss 0.0024623020073558104\n",
      "Real arb loss 2.410678834472414e-06\n",
      "Bounds loss: 0.4705974172392929\n",
      "MAPE:  0.0733242597764978\n",
      "Delta:  0.004532157632437041\n",
      "GRAD\n",
      " tensor([-0.0055, -0.0022, -0.0009,  0.0046])\n",
      "0.016405222598511737 0.02286622612109923 -10.153807670914738\n",
      "Epoch: 985\n",
      "Arb loss 0.027464043017753993\n",
      "Real arb loss 2.6777878593253504e-05\n",
      "Bounds loss: 0.4598366302846939\n",
      "MAPE:  0.07128505831732158\n",
      "Delta:  0.004457806577625368\n",
      "GRAD\n",
      " tensor([-47.1518,   1.7684,   7.1560,  91.3777])\n",
      "-0.02422442320799223 -0.03588951793860207 0.9999897256737287\n",
      "Epoch: 986\n",
      "Arb loss 2.821745386931027e-07\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 0.4763399452761228\n",
      "MAPE:  0.0745189772427038\n",
      "Delta:  0.004565794370741136\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.021048706905123726 0.027787442416517982 -65247.0023623413\n",
      "Epoch: 987\n",
      "Arb loss 0.01841132496724013\n",
      "Real arb loss 1.7975910687979837e-05\n",
      "Bounds loss: 0.4631036764760752\n",
      "MAPE:  0.07190900200228509\n",
      "Delta:  0.004469690303242342\n",
      "GRAD\n",
      " tensor([-33.8044,   1.2160,   4.3795,  66.9786])\n",
      "-0.013841427072420753 -0.018569303937116866 0.9284534758240078\n",
      "arb imp changed to 1015.5108973604129\n",
      "Epoch: 988\n",
      "Arb loss 0.0013179249400341346\n",
      "Real arb loss 1.2905425766350926e-06\n",
      "Bounds loss: 0.47170318939895567\n",
      "MAPE:  0.07365455018244145\n",
      "Delta:  0.004531557195610977\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.017256462405643602 0.024622084186313065 -18.270525547494856\n",
      "Epoch: 989\n",
      "Arb loss 0.025397106226608415\n",
      "Real arb loss 2.4757868509064973e-05\n",
      "Bounds loss: 0.4600888737586222\n",
      "MAPE:  0.07141906301714508\n",
      "Delta:  0.004453358549225892\n",
      "GRAD\n",
      " tensor([-33.8374,   1.1894,   4.3632,  68.0934])\n",
      "-0.015258930595473785 -0.02013872707320119 0.919697872076659\n",
      "Delta imp changed to 0.012543927706116925\n",
      "Epoch: 990\n",
      "Arb loss 0.0020394416730917892\n",
      "Real arb loss 1.995822199098926e-06\n",
      "Bounds loss: 0.4693544780166636\n",
      "MAPE:  0.07328650032507689\n",
      "Delta:  0.0044110361348734545\n",
      "GRAD\n",
      " tensor([-0.0052, -0.0021, -0.0009,  0.0044])\n",
      "0.017755078664248747 0.024305263030584112 -13.752376972324784\n",
      "Epoch: 991\n",
      "Arb loss 0.030086612374518845\n",
      "Real arb loss 2.931463955455026e-05\n",
      "Bounds loss: 0.45794669397388604\n",
      "MAPE:  0.07110493380075446\n",
      "Delta:  0.004332717841307932\n",
      "GRAD\n",
      " tensor([-47.1087,   1.7843,   7.1618,  91.4815])\n",
      "-0.02500018951676508 -0.03621909131001089 0.9999894497367356\n",
      "Epoch: 992\n",
      "Arb loss 3.1742168128494395e-07\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 0.4745331070980438\n",
      "MAPE:  0.07436629873952681\n",
      "Delta:  0.0044410366084632995\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.0209076868640371 0.027741600780873177 -49719.46488375963\n",
      "Epoch: 993\n",
      "Arb loss 0.015782353557671998\n",
      "Real arb loss 1.5400207494596827e-05\n",
      "Bounds loss: 0.46136879908362255\n",
      "MAPE:  0.07175911716754328\n",
      "Delta:  0.0043481848057018236\n",
      "GRAD\n",
      " tensor([-20.1945,   0.7747,   4.6498,  41.3054])\n",
      "-0.006200488398641291 -0.004825593107002257 0.5209949379976102\n",
      "Epoch: 994\n",
      "Arb loss 0.007559827244436312\n",
      "Real arb loss 7.388616484478908e-06\n",
      "Bounds loss: 0.4635951771802663\n",
      "MAPE:  0.07230524794778904\n",
      "Delta:  0.004375145675144726\n",
      "GRAD\n",
      " tensor([-6.7987,  1.2289,  1.8705, 13.7805])\n",
      "0.009804581215495212 0.013870323512813254 -2.4219231018704273\n",
      "Epoch: 995\n",
      "Arb loss 0.02586914749388607\n",
      "Real arb loss 2.5217771583911678e-05\n",
      "Bounds loss: 0.4571649620937961\n",
      "MAPE:  0.07110364430269232\n",
      "Delta:  0.004332249204043148\n",
      "GRAD\n",
      " tensor([-47.1366,   1.7749,   7.1588,  91.3800])\n",
      "-0.022233072689061606 -0.03477301447926173 0.9999847205452398\n",
      "Epoch: 996\n",
      "Arb loss 3.9526646881682576e-07\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 0.4730619659400948\n",
      "MAPE:  0.0742336176705071\n",
      "Delta:  0.004428568415503768\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.020667013661531675 0.02764687939506083 -41336.49714074313\n",
      "Epoch: 997\n",
      "Arb loss 0.016339326524547167\n",
      "Real arb loss 1.594317485756796e-05\n",
      "Bounds loss: 0.45998327882135864\n",
      "MAPE:  0.07163868212641042\n",
      "Delta:  0.004337043131559523\n",
      "GRAD\n",
      " tensor([-20.1843,   0.7780,   4.6508,  40.3234])\n",
      "-0.006002978929363856 -0.0043677918149194195 0.5062409396364118\n",
      "Epoch: 998\n",
      "Arb loss 0.008067690511734261\n",
      "Real arb loss 7.88374476436874e-06\n",
      "Bounds loss: 0.46199239002159437\n",
      "MAPE:  0.07214756904890453\n",
      "Delta:  0.0043630783100940184\n",
      "GRAD\n",
      " tensor([-6.8001,  0.2278,  1.8698, 13.7907])\n",
      "0.009343438297277462 0.013495365400908566 -1.79829168164106\n",
      "arb imp changed to 1016.018652809093\n",
      "Epoch: 999\n",
      "Arb loss 0.022587039124665007\n",
      "Real arb loss 2.2007138801652932e-05\n",
      "Bounds loss: 0.4557576339058139\n",
      "MAPE:  0.07098139594078368\n",
      "Delta:  0.004322312157117465\n",
      "GRAD\n",
      " tensor([-33.5126,   1.3468,   4.4376,  66.6814])\n",
      "-0.013029772789007854 -0.019486986847180088 0.8676889393297706\n",
      "Epoch: 1000\n",
      "Arb loss 0.0029885151039843972\n",
      "Real arb loss 2.922555079827048e-06\n",
      "Bounds loss: 0.4646389769232384\n",
      "MAPE:  0.07276594977673889\n",
      "Delta:  0.004378630902447871\n",
      "GRAD\n",
      " tensor([-0.0133, -0.0054, -0.0022,  0.0112])\n",
      "0.016695938571408497 0.022815801851721162 -7.886428504246609\n",
      "Epoch: 1001\n",
      "Arb loss 0.02655722580541847\n",
      "Real arb loss 2.5864956449625705e-05\n",
      "Bounds loss: 0.45403786609317137\n",
      "MAPE:  0.07073757988626565\n",
      "Delta:  0.004305525549873731\n",
      "GRAD\n",
      " tensor([-33.4927,   1.3479,   4.4352,  66.7698])\n",
      "-0.015069739315121122 -0.021075973894930877 0.8924028185192225\n",
      "Epoch: 1002\n",
      "Arb loss 0.002857482644611598\n",
      "Real arb loss 2.794438611954518e-06\n",
      "Bounds loss: 0.46360715630626115\n",
      "MAPE:  0.07264829993058848\n",
      "Delta:  0.004370408697524922\n",
      "GRAD\n",
      " tensor([-6.7907,  1.2338,  1.8732, 13.7470])\n",
      "0.012421880875706948 0.01551675337511993 -4.754540320419844\n",
      "Epoch: 1003\n",
      "Arb loss 0.01644349909331737\n",
      "Real arb loss 1.6037180060762435e-05\n",
      "Bounds loss: 0.4564134783989162\n",
      "MAPE:  0.07124779945941932\n",
      "Delta:  0.004316120001306114\n",
      "GRAD\n",
      " tensor([-20.2187,   0.7566,   4.6390,  40.3333])\n",
      "-0.004196174322958379 -0.004473956157619252 0.4411003310768101\n",
      "Epoch: 1004\n",
      "Arb loss 0.009190266199193851\n",
      "Real arb loss 8.97346956329903e-06\n",
      "Bounds loss: 0.4584554522910194\n",
      "MAPE:  0.07172877960585576\n",
      "Delta:  0.004334231193230401\n",
      "GRAD\n",
      " tensor([-20.2281,   1.7596,   4.6431,  41.2172])\n",
      "0.00015624660285151748 -0.0019173547677411307 0.13801034764971942\n",
      "Delta imp changed to 0.012237978249870171\n",
      "Epoch: 1005\n",
      "Arb loss 0.007921914366049642\n",
      "Real arb loss 7.737924689335375e-06\n",
      "Bounds loss: 0.45933447403826655\n",
      "MAPE:  0.07192970489042198\n",
      "Delta:  0.004227857545688279\n",
      "GRAD\n",
      " tensor([-6.8021,  0.2258,  1.8686, 12.8127])\n",
      "0.009238136151271226 0.013978213877768542 -1.9046221421701528\n",
      "Epoch: 1006\n",
      "Arb loss 0.023010167876003622\n",
      "Real arb loss 2.2421142346248782e-05\n",
      "Bounds loss: 0.4529137985187274\n",
      "MAPE:  0.07072736090070895\n",
      "Delta:  0.004188800022053032\n",
      "GRAD\n",
      " tensor([-33.4853,   1.3512,   4.4366,  66.7496])\n",
      "-0.013383638843962986 -0.020020683712955956 0.879106891590206\n",
      "Epoch: 1007\n",
      "Arb loss 0.0027817707195612654\n",
      "Real arb loss 2.720670880470115e-06\n",
      "Bounds loss: 0.46198144242810424\n",
      "MAPE:  0.07254638626752631\n",
      "Delta:  0.004244861408737774\n",
      "GRAD\n",
      " tensor([-6.7842,  1.2361,  1.8740, 13.7574])\n",
      "0.011968498399592131 0.015471900347735157 -4.753927838137889\n",
      "Epoch: 1008\n",
      "Arb loss 0.01600610798260043\n",
      "Real arb loss 1.5612205011620597e-05\n",
      "Bounds loss: 0.4548337115883537\n",
      "MAPE:  0.07115489234612862\n",
      "Delta:  0.004194056791760805\n",
      "GRAD\n",
      " tensor([-20.2038,   0.7616,   4.6407,  40.3554])\n",
      "-0.003410660636034901 -0.003835414540521276 0.36960661251838467\n",
      "Epoch: 1009\n",
      "Arb loss 0.01009014463154801\n",
      "Real arb loss 9.851969882313232e-06\n",
      "Bounds loss: 0.4565781874192989\n",
      "MAPE:  0.07156558030843907\n",
      "Delta:  0.0042083612961657585\n",
      "GRAD\n",
      " tensor([-20.2038,   0.7677,   4.6456,  41.2597])\n",
      "-0.0021253701690611138 -0.003743551581933291 0.3560611580277876\n",
      "arb imp changed to 1016.5266621354975\n",
      "Epoch: 1010\n",
      "Arb loss 0.006500684767395846\n",
      "Real arb loss 6.34930456825232e-06\n",
      "Bounds loss: 0.45828741141508866\n",
      "MAPE:  0.07194071578476034\n",
      "Delta:  0.004217305621725261\n",
      "GRAD\n",
      " tensor([-6.7980,  0.2276,  1.8694, 13.8083])\n",
      "0.0093990530867204 0.013774791538557096 -2.1614730292753013\n",
      "Epoch: 1011\n",
      "Arb loss 0.020551739563942753\n",
      "Real arb loss 2.002420080991147e-05\n",
      "Bounds loss: 0.4519745978581009\n",
      "MAPE:  0.07074657543333057\n",
      "Delta:  0.004177666942303741\n",
      "GRAD\n",
      " tensor([-33.4828,   1.3539,   4.4384,  66.7607])\n",
      "-0.013071685682210177 -0.019828816807378802 0.9004796138242652\n",
      "Epoch: 1012\n",
      "Arb loss 0.0020453170579867092\n",
      "Real arb loss 1.9991336214540274e-06\n",
      "Bounds loss: 0.4609367193606178\n",
      "MAPE:  0.07254931537526624\n",
      "Delta:  0.004232276091458495\n",
      "GRAD\n",
      " tensor([-6.7832,  1.2367,  1.8743, 13.7618])\n",
      "0.01336292934070804 0.017083153671955897 -7.410748509143332\n",
      "Epoch: 1013\n",
      "Arb loss 0.017202647396187137\n",
      "Real arb loss 1.676839660617941e-05\n",
      "Bounds loss: 0.4530624665507332\n",
      "MAPE:  0.07099912344586365\n",
      "Delta:  0.004175720485097968\n",
      "GRAD\n",
      " tensor([-20.1948,   0.7638,   4.6410,  40.4081])\n",
      "-0.005170815594933487 -0.004754362209231644 0.4744060412483634\n",
      "Epoch: 1014\n",
      "Arb loss 0.009041607545970531\n",
      "Real arb loss 8.82624462804877e-06\n",
      "Bounds loss: 0.4552164896201233\n",
      "MAPE:  0.07151303981002605\n",
      "Delta:  0.004197312365702395\n",
      "GRAD\n",
      " tensor([-20.2075,   0.7658,   4.6447,  41.2627])\n",
      "-0.0004338732358608599 -0.0023440864086254898 0.1891339624193139\n",
      "Epoch: 1015\n",
      "Arb loss 0.007331532484160756\n",
      "Real arb loss 7.159055435985509e-06\n",
      "Bounds loss: 0.45628355640642404\n",
      "MAPE:  0.07175223716920229\n",
      "Delta:  0.004199133467200422\n",
      "GRAD\n",
      " tensor([-6.7984,  0.2268,  1.8688, 12.8271])\n",
      "0.009151137758344863 0.014094889946429712 -2.0406730011129897\n",
      "Delta imp changed to 0.011939490975483096\n",
      "Epoch: 1016\n",
      "Arb loss 0.022292792881370458\n",
      "Real arb loss 2.171680008336257e-05\n",
      "Bounds loss: 0.4498522898945099\n",
      "MAPE:  0.07053703070099411\n",
      "Delta:  0.004059225969147703\n",
      "GRAD\n",
      " tensor([-33.4519,   1.3623,   4.4402,  66.8057])\n",
      "-0.013419026839629256 -0.02031547037906023 0.8971781701836523\n",
      "Epoch: 1017\n",
      "Arb loss 0.0022921857557793614\n",
      "Real arb loss 2.2407003969775185e-06\n",
      "Bounds loss: 0.45899125076481423\n",
      "MAPE:  0.07237421831645617\n",
      "Delta:  0.004113696831375816\n",
      "GRAD\n",
      " tensor([-6.7784,  1.2380,  1.8746, 13.7687])\n",
      "0.011996624114238186 0.015667982893468935 -5.698172529068348\n",
      "Epoch: 1018\n",
      "Arb loss 0.015353455660883086\n",
      "Real arb loss 1.4971774525298014e-05\n",
      "Bounds loss: 0.45179978369957924\n",
      "MAPE:  0.07096940741346162\n",
      "Delta:  0.004064346356769868\n",
      "GRAD\n",
      " tensor([-20.1870,   0.7670,   4.6422,  40.3927])\n",
      "-0.0034783074955280213 -0.003930292398185209 0.3816818619197051\n",
      "Epoch: 1019\n",
      "Arb loss 0.009493320117335594\n",
      "Real arb loss 9.267308586729266e-06\n",
      "Bounds loss: 0.4535754889549554\n",
      "MAPE:  0.07138323359056391\n",
      "Delta:  0.004078483403167042\n",
      "GRAD\n",
      " tensor([-20.1856,   0.7737,   4.6475,  41.2935])\n",
      "-0.000994550276566697 -0.0025474538789291845 0.23019799830745968\n",
      "Epoch: 1020\n",
      "Arb loss 0.007307976829033001\n",
      "Real arb loss 7.136757077122782e-06\n",
      "Bounds loss: 0.45473095159368093\n",
      "MAPE:  0.07164177280779568\n",
      "Delta:  0.004082539659963635\n",
      "GRAD\n",
      " tensor([-20.1760,   0.7823,   4.6529,  41.2739])\n",
      "-0.001148305603005051 -0.00235820333067549 0.25546299325700983\n",
      "arb imp changed to 1017.0349254665653\n",
      "Epoch: 1021\n",
      "Arb loss 0.005443779723232177\n",
      "Real arb loss 5.315343099949562e-06\n",
      "Bounds loss: 0.4558032996382904\n",
      "MAPE:  0.07187978557242002\n",
      "Delta:  0.004087227663129661\n",
      "GRAD\n",
      " tensor([-6.7872,  0.2325,  1.8716, 12.8219])\n",
      "0.008879408952444767 0.014189727407502906 -2.4332539947359306\n",
      "Epoch: 1022\n",
      "Arb loss 0.018689878481249332\n",
      "Real arb loss 1.8207924659222017e-05\n",
      "Bounds loss: 0.44933557506498273\n",
      "MAPE:  0.07065124701428513\n",
      "Delta:  0.004050935497226988\n",
      "GRAD\n",
      " tensor([-33.4373,   1.3740,   4.4473,  66.8021])\n",
      "-0.01339080115807878 -0.020394863619944026 0.9261591827774553\n",
      "Epoch: 1023\n",
      "Arb loss 0.0013800759008455027\n",
      "Real arb loss 1.3489296212180548e-06\n",
      "Bounds loss: 0.45849971283802216\n",
      "MAPE:  0.07249813621233485\n",
      "Delta:  0.004105180768974558\n",
      "GRAD\n",
      " tensor([-0.0124, -0.0051, -0.0021,  0.0106])\n",
      "0.018072202126932724 0.02502687827476735 -17.522807962924464\n",
      "Epoch: 1024\n",
      "Arb loss 0.025562880885621232\n",
      "Real arb loss 2.488036379113237e-05\n",
      "Bounds loss: 0.4470248963358092\n",
      "MAPE:  0.0702481305686373\n",
      "Delta:  0.004030991112350052\n",
      "GRAD\n",
      " tensor([-33.4056,   1.3770,   4.4444,  66.9462])\n",
      "-0.015975092720960538 -0.021913336250874327 0.925955583358629\n",
      "Epoch: 1025\n",
      "Arb loss 0.0018927886028486777\n",
      "Real arb loss 1.84994970502516e-06\n",
      "Bounds loss: 0.45682070320172796\n",
      "MAPE:  0.07223593188161183\n",
      "Delta:  0.004095386569127212\n",
      "GRAD\n",
      " tensor([-6.7769,  1.2383,  1.8746, 13.7746])\n",
      "0.01362237904102126 0.017296106427837743 -8.097671706842805\n",
      "Epoch: 1026\n",
      "Arb loss 0.017219969319170938\n",
      "Real arb loss 1.6779606430638544e-05\n",
      "Bounds loss: 0.4489194837007112\n",
      "MAPE:  0.07067886816195247\n",
      "Delta:  0.004039597660963053\n",
      "GRAD\n",
      " tensor([-33.4064,   1.3886,   4.4540,  66.8420])\n",
      "-0.014028658163580898 -0.020289142390596204 0.9473098265425093\n",
      "Delta imp changed to 0.011648283878520094\n",
      "Epoch: 1027\n",
      "Arb loss 0.0009073231703597847\n",
      "Real arb loss 8.870445182243628e-07\n",
      "Bounds loss: 0.4580276750274279\n",
      "MAPE:  0.072521307250516\n",
      "Delta:  0.003996358825041078\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.0178918280061815 0.025234713060065306 -24.947593196071306\n",
      "Epoch: 1028\n",
      "Arb loss 0.023542852521865394\n",
      "Real arb loss 2.2922364770806573e-05\n",
      "Bounds loss: 0.44646947807454196\n",
      "MAPE:  0.07025762031721415\n",
      "Delta:  0.003924856660292458\n",
      "GRAD\n",
      " tensor([-33.3899,   1.3847,   4.4481,  66.9519])\n",
      "-0.014977950388567196 -0.02085932864875284 0.915991086964259\n",
      "Epoch: 1029\n",
      "Arb loss 0.0019778094501226645\n",
      "Real arb loss 1.933240240561081e-06\n",
      "Bounds loss: 0.4557825316493359\n",
      "MAPE:  0.07214180390490908\n",
      "Delta:  0.003983642968632556\n",
      "GRAD\n",
      " tensor([-6.7712,  1.2405,  1.8754, 13.7848])\n",
      "0.013001541293414909 0.01710373667954368 -7.589751805237114\n",
      "Epoch: 1030\n",
      "Arb loss 0.01698889229460618\n",
      "Real arb loss 1.6555761077862848e-05\n",
      "Bounds loss: 0.44798694724486987\n",
      "MAPE:  0.07060889945541017\n",
      "Delta:  0.003931849470077658\n",
      "GRAD\n",
      " tensor([-33.3863,   1.3964,   4.4570,  66.8681])\n",
      "-0.013292613164139988 -0.019565338664647047 0.9336182024797081\n",
      "Epoch: 1031\n",
      "Arb loss 0.0011277532083945948\n",
      "Real arb loss 1.102697678006366e-06\n",
      "Bounds loss: 0.45675196358505715\n",
      "MAPE:  0.07237278935333126\n",
      "Delta:  0.003984114024103029\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.01716169706397641 0.024946023966309405 -20.38698121769022\n",
      "arb imp changed to 1017.5434429292985\n",
      "Epoch: 1032\n",
      "Arb loss 0.02413129630446814\n",
      "Real arb loss 2.3482137177011398e-05\n",
      "Bounds loss: 0.44535781815480546\n",
      "MAPE:  0.07014578956328936\n",
      "Delta:  0.003915739866153033\n",
      "GRAD\n",
      " tensor([-33.3891,   1.3837,   4.4472,  66.9999])\n",
      "-0.015245847338221541 -0.021005537855681045 0.9271176500950074\n",
      "Epoch: 1033\n",
      "Arb loss 0.0017587455809233044\n",
      "Real arb loss 1.718243790888238e-06\n",
      "Bounds loss: 0.45471279866337966\n",
      "MAPE:  0.07204014856464487\n",
      "Delta:  0.003975438638368589\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.017556610946016016 0.024641169008832398 -14.83688943349723\n",
      "Epoch: 1034\n",
      "Arb loss 0.027853059306734228\n",
      "Real arb loss 2.7089467077820043e-05\n",
      "Bounds loss: 0.4435081437410362\n",
      "MAPE:  0.06985454297450876\n",
      "Delta:  0.0039056434088549927\n",
      "GRAD\n",
      " tensor([-33.3950,   1.3737,   4.4400,  67.0537])\n",
      "-0.016263078149620025 -0.022304077140862688 0.9318044319626266\n",
      "Epoch: 1035\n",
      "Arb loss 0.0018994552010013887\n",
      "Real arb loss 1.8554476075776581e-06\n",
      "Bounds loss: 0.4534001835916371\n",
      "MAPE:  0.07185462365388212\n",
      "Delta:  0.00396916119283775\n",
      "GRAD\n",
      " tensor([-0.0008, -0.0003, -0.0001,  0.0007])\n",
      "0.018082148505990214 0.024671359621095124 -14.522462805260995\n",
      "Epoch: 1036\n",
      "Arb loss 0.0294842227078036\n",
      "Real arb loss 2.8671119367428028e-05\n",
      "Bounds loss: 0.44221418460997725\n",
      "MAPE:  0.06967777836519139\n",
      "Delta:  0.0038973902307046443\n",
      "GRAD\n",
      " tensor([-46.4925,   2.0461,   7.2729,  91.3961])\n",
      "-0.025005277941297033 -0.03799805317123339 0.999993723444523\n",
      "Epoch: 1037\n",
      "Arb loss 1.850593595229448e-07\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 0.4590174627098608\n",
      "MAPE:  0.07301029906416462\n",
      "Delta:  0.00399484555666911\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.02069628637348142 0.028298084317278427 -95874.82420442665\n",
      "Delta imp changed to 0.01136417939367814\n",
      "Epoch: 1038\n",
      "Arb loss 0.017742718621005644\n",
      "Real arb loss 1.7282098397704117e-05\n",
      "Bounds loss: 0.44602814784699396\n",
      "MAPE:  0.07044708888639342\n",
      "Delta:  0.0038167483795223966\n",
      "GRAD\n",
      " tensor([-33.3471,   1.4115,   4.4629,  66.9537])\n",
      "-0.01538516538953938 -0.020981654887473278 0.9725921406757758\n",
      "Epoch: 1039\n",
      "Arb loss 0.0004862899359938156\n",
      "Real arb loss 4.7469879352961264e-07\n",
      "Bounds loss: 0.4553865565152185\n",
      "MAPE:  0.07234731238308324\n",
      "Delta:  0.003875469684591605\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.01862249184415088 0.02641636789189039 -49.64939504739196\n",
      "Epoch: 1040\n",
      "Arb loss 0.02463029107572172\n",
      "Real arb loss 2.3967052772831003e-05\n",
      "Bounds loss: 0.44335689770529135\n",
      "MAPE:  0.0699915367276538\n",
      "Delta:  0.0038032987819980437\n",
      "GRAD\n",
      " tensor([-33.3458,   1.4007,   4.4538,  67.0556])\n",
      "-0.015782449912778107 -0.021250062819441418 0.9365685713907786\n",
      "Epoch: 1041\n",
      "Arb loss 0.0015623345499939838\n",
      "Real arb loss 1.5266098408343101e-06\n",
      "Bounds loss: 0.4527782596329615\n",
      "MAPE:  0.07189293152396943\n",
      "Delta:  0.0038633241545282583\n",
      "GRAD\n",
      " tensor([-5.6885e-04, -2.3128e-04, -9.4034e-05,  4.8536e-04])\n",
      "0.0173974727034214 0.02468867031579236 -16.452631100609878\n",
      "Epoch: 1042\n",
      "Arb loss 0.02726684855678234\n",
      "Real arb loss 2.652230071945545e-05\n",
      "Bounds loss: 0.44159976645472504\n",
      "MAPE:  0.06971203416455933\n",
      "Delta:  0.0037961120780053846\n",
      "GRAD\n",
      " tensor([-46.4437,   2.0724,   7.2862,  91.3963])\n",
      "-0.02523338916921891 -0.038259089942226154 0.9999988885183911\n",
      "arb imp changed to 1018.0522146507631\n",
      "Epoch: 1043\n",
      "Arb loss 3.032175400427141e-08\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 0.4584949716379824\n",
      "MAPE:  0.0730630006896591\n",
      "Delta:  0.0038919008513996663\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.020767580693088483 0.028639186739962574 -437512.2474949812\n",
      "Epoch: 1044\n",
      "Arb loss 0.013266169064152733\n",
      "Real arb loss 1.2918934807230817e-05\n",
      "Bounds loss: 0.4453640485259084\n",
      "MAPE:  0.07047181197192119\n",
      "Delta:  0.0038110754864187236\n",
      "GRAD\n",
      " tensor([-19.9131,   0.8974,   4.7031,  40.2658])\n",
      "-0.0053435159288359735 -0.0043071579203532995 0.48803893353918826\n",
      "Epoch: 1045\n",
      "Arb loss 0.006791762061933063\n",
      "Real arb loss 6.623245632648128e-06\n",
      "Bounds loss: 0.4472823018149574\n",
      "MAPE:  0.07092668896865156\n",
      "Delta:  0.0038314400289863985\n",
      "GRAD\n",
      " tensor([-6.7005,  0.2713,  1.8888, 12.7715])\n",
      "0.008455640218698157 0.013541316377361667 -1.8544030868976034\n",
      "Epoch: 1046\n",
      "Arb loss 0.019386426595055767\n",
      "Real arb loss 1.886070895786793e-05\n",
      "Bounds loss: 0.44122551065608645\n",
      "MAPE:  0.06978083881550079\n",
      "Delta:  0.0037990427505817715\n",
      "GRAD\n",
      " tensor([-19.9546,   0.8689,   4.6867,  40.2941])\n",
      "-0.004768102753488712 -0.005800335056387773 0.47512787113440236\n",
      "Epoch: 1047\n",
      "Arb loss 0.01017539499804356\n",
      "Real arb loss 9.913374518904846e-06\n",
      "Bounds loss: 0.4437847664533175\n",
      "MAPE:  0.0703409361728403\n",
      "Delta:  0.0038171569767814417\n",
      "GRAD\n",
      " tensor([-6.7238,  0.2585,  1.8822, 12.7965])\n",
      "0.008358322568961185 0.01213226811738044 -1.7082083045471887\n",
      "Epoch: 1048\n",
      "Arb loss 0.027557089235749496\n",
      "Real arb loss 2.6791542287561825e-05\n",
      "Bounds loss: 0.4384006506802968\n",
      "MAPE:  0.06933775707360491\n",
      "Delta:  0.0037852519474731415\n",
      "GRAD\n",
      " tensor([-46.5254,   2.0246,   7.2608,  91.3490])\n",
      "-0.02273874033960177 -0.03814413098067049 0.9999941130792411\n",
      "Delta imp changed to 0.01108700428651526\n",
      "Epoch: 1049\n",
      "Arb loss 1.622264006762098e-07\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 0.45512306252185725\n",
      "MAPE:  0.07263644647378052\n",
      "Delta:  0.003776901276708981\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.02118711486638547 0.028549336368185796 -96832.69261258705\n",
      "Epoch: 1050\n",
      "Arb loss 0.015708981416726484\n",
      "Real arb loss 1.5292749318542363e-05\n",
      "Bounds loss: 0.44212960112100186\n",
      "MAPE:  0.07008226423616254\n",
      "Delta:  0.0036968796355203496\n",
      "GRAD\n",
      " tensor([-19.9068,   0.8942,   4.6994,  40.3110])\n",
      "-0.006441778855679203 -0.005685796607299398 0.5593087645812445\n",
      "Epoch: 1051\n",
      "Arb loss 0.006922810427707468\n",
      "Real arb loss 6.751048340488169e-06\n",
      "Bounds loss: 0.4446434601070423\n",
      "MAPE:  0.07065303204398163\n",
      "Delta:  0.0037206941165884356\n",
      "GRAD\n",
      " tensor([-6.7040,  0.2685,  1.8870, 12.7795])\n",
      "0.009100697658015244 0.013575466098619815 -1.9412716817067452\n",
      "Epoch: 1052\n",
      "Arb loss 0.020361866268840137\n",
      "Real arb loss 1.9807060974628997e-05\n",
      "Bounds loss: 0.43860721788838614\n",
      "MAPE:  0.06950727445772313\n",
      "Delta:  0.003686833204355408\n",
      "GRAD\n",
      " tensor([-19.9477,   0.8676,   4.6845,  40.3280])\n",
      "-0.004662697424169915 -0.0059752005660771434 0.4618082604552801\n",
      "Epoch: 1053\n",
      "Arb loss 0.010958588227604028\n",
      "Real arb loss 1.0676406950889593e-05\n",
      "Bounds loss: 0.44122798398499835\n",
      "MAPE:  0.07007555507669465\n",
      "Delta:  0.0037040237920407003\n",
      "GRAD\n",
      " tensor([-19.9575,  -0.1279,   4.6898,  40.2004])\n",
      "-0.0017287543263984073 -0.00419895940102788 0.32904827912766754\n",
      "arb imp changed to 1018.5612407580884\n",
      "Epoch: 1054\n",
      "Arb loss 0.007356359971457027\n",
      "Real arb loss 7.1694090743360815e-06\n",
      "Bounds loss: 0.44308068237634873\n",
      "MAPE:  0.07048685205223713\n",
      "Delta:  0.0037104271391962735\n",
      "GRAD\n",
      " tensor([-6.7099,  0.2652,  1.8854, 12.7895])\n",
      "0.009367907726826386 0.013557864217382254 -1.9127518711885623\n",
      "Epoch: 1055\n",
      "Arb loss 0.021427251271998092\n",
      "Real arb loss 2.0829662809869317e-05\n",
      "Bounds loss: 0.43707345464734515\n",
      "MAPE:  0.06934522925231344\n",
      "Delta:  0.00367566820012917\n",
      "GRAD\n",
      " tensor([-33.0401,   0.5432,   4.5192,  66.6796])\n",
      "-0.013551533332246013 -0.02122725463559272 0.9028118074073885\n",
      "Epoch: 1056\n",
      "Arb loss 0.002082475823353231\n",
      "Real arb loss 2.0315039130546845e-06\n",
      "Bounds loss: 0.4463513241636025\n",
      "MAPE:  0.07120891041956949\n",
      "Delta:  0.0037254791402614976\n",
      "GRAD\n",
      " tensor([-0.0099, -0.0040, -0.0016,  0.0085])\n",
      "0.016387889275608303 0.023169878662547716 -10.558802707613546\n",
      "Epoch: 1057\n",
      "Arb loss 0.024070927185515074\n",
      "Real arb loss 2.3393937747178392e-05\n",
      "Bounds loss: 0.43600941814186434\n",
      "MAPE:  0.06919445325901011\n",
      "Delta:  0.003664426400612304\n",
      "GRAD\n",
      " tensor([-33.0042,   0.5545,   4.5225,  66.7497])\n",
      "-0.015911410625077504 -0.023384653107948683 0.9332901871473784\n",
      "Epoch: 1058\n",
      "Arb loss 0.00160576704773479\n",
      "Real arb loss 1.5672815901697917e-06\n",
      "Bounds loss: 0.4462053471369104\n",
      "MAPE:  0.07124821580382464\n",
      "Delta:  0.0037227325937778206\n",
      "GRAD\n",
      " tensor([-0.0072, -0.0029, -0.0012,  0.0062])\n",
      "0.01814857541408299 0.02494773635505232 -15.151404577427776\n",
      "Epoch: 1059\n",
      "Arb loss 0.02593539324506637\n",
      "Real arb loss 2.5201799316382744e-05\n",
      "Bounds loss: 0.4350735337763242\n",
      "MAPE:  0.06908107787730458\n",
      "Delta:  0.003655170300553179\n",
      "GRAD\n",
      " tensor([-32.9779,   1.5626,   4.5246,  66.7996])\n",
      "-0.015997272703459187 -0.02293565022177768 0.9283951157406255\n",
      "Delta imp changed to 0.010816589547819767\n",
      "Epoch: 1060\n",
      "Arb loss 0.0018571008315343407\n",
      "Real arb loss 1.812046530056441e-06\n",
      "Bounds loss: 0.44505222816777074\n",
      "MAPE:  0.07109131577855636\n",
      "Delta:  0.0036230663967109396\n",
      "GRAD\n",
      " tensor([-0.0102, -0.0041, -0.0017,  0.0087])\n",
      "0.017869223140170587 0.024725368180723906 -13.600736539434106\n",
      "Epoch: 1061\n",
      "Arb loss 0.027115039968396912\n",
      "Real arb loss 2.6345021798731334e-05\n",
      "Bounds loss: 0.43404814796667107\n",
      "MAPE:  0.06894939905742865\n",
      "Delta:  0.0035583250148164577\n",
      "GRAD\n",
      " tensor([-32.9736,   1.5607,   4.5224,  66.8333])\n",
      "-0.01594901011966421 -0.02261223619397912 0.9211580801708588\n",
      "Epoch: 1062\n",
      "Arb loss 0.0021378018073523104\n",
      "Real arb loss 2.085363836690363e-06\n",
      "Bounds loss: 0.44386294720805264\n",
      "MAPE:  0.07092965882046476\n",
      "Delta:  0.0036150767764868193\n",
      "GRAD\n",
      " tensor([-0.0129, -0.0053, -0.0021,  0.0111])\n",
      "0.016458840358970384 0.023145916902601038 -10.679633943702598\n",
      "Epoch: 1063\n",
      "Arb loss 0.024968742554060806\n",
      "Real arb loss 2.4266447639726455e-05\n",
      "Bounds loss: 0.4335893323158315\n",
      "MAPE:  0.06893096772309193\n",
      "Delta:  0.0035555768049372015\n",
      "GRAD\n",
      " tensor([-32.9860,   1.5549,   4.5197,  66.8070])\n",
      "-0.015563371388716218 -0.02329456014246989 0.9324401632432907\n",
      "Epoch: 1064\n",
      "Arb loss 0.001686884170972648\n",
      "Real arb loss 1.6461675494627084e-06\n",
      "Bounds loss: 0.443689605094596\n",
      "MAPE:  0.0709629234590137\n",
      "Delta:  0.0036109135672535444\n",
      "GRAD\n",
      " tensor([-0.0108, -0.0044, -0.0018,  0.0093])\n",
      "0.017966063215736128 0.024845604489498796 -14.901162429892333\n",
      "arb imp changed to 1019.0705213784673\n",
      "Epoch: 1065\n",
      "Arb loss 0.026836830912651866\n",
      "Real arb loss 2.6064043035740393e-05\n",
      "Bounds loss: 0.43266586865031376\n",
      "MAPE:  0.06882120515041447\n",
      "Delta:  0.0035460396658377083\n",
      "GRAD\n",
      " tensor([-32.9812,   1.5540,   4.5182,  66.8810])\n",
      "-0.01596284763034861 -0.022769552101853385 0.9253212292732171\n",
      "Epoch: 1066\n",
      "Arb loss 0.0020041415427593683\n",
      "Real arb loss 1.9541652647567173e-06\n",
      "Bounds loss: 0.4425174766892407\n",
      "MAPE:  0.07080546855582838\n",
      "Delta:  0.0036026445567146482\n",
      "GRAD\n",
      " tensor([-6.6985,  0.2713,  1.8884, 13.7646])\n",
      "0.012956381316503118 0.017101983737285664 -7.774665055259872\n",
      "Epoch: 1067\n",
      "Arb loss 0.017585670761045235\n",
      "Real arb loss 1.710004976600995e-05\n",
      "Bounds loss: 0.43494954999943664\n",
      "MAPE:  0.06933585702342619\n",
      "Delta:  0.0035559673200900284\n",
      "GRAD\n",
      " tensor([-19.9153,   0.8792,   4.6886,  40.4094])\n",
      "-0.005622657738000969 -0.005791775605471061 0.5154520205115771\n",
      "Epoch: 1068\n",
      "Arb loss 0.008521101235213104\n",
      "Real arb loss 8.298510421971266e-06\n",
      "Bounds loss: 0.43746868019273394\n",
      "MAPE:  0.0698880476454346\n",
      "Delta:  0.0035759613072584118\n",
      "GRAD\n",
      " tensor([-19.9366,   0.8788,   4.6918,  40.2594])\n",
      "-0.0004117706758506312 -0.0024272405428380495 0.18321310326882978\n",
      "Epoch: 1069\n",
      "Arb loss 0.006959923834641852\n",
      "Real arb loss 6.780582222414296e-06\n",
      "Bounds loss: 0.43853052190951963\n",
      "MAPE:  0.07012911781829492\n",
      "Delta:  0.003577433783262717\n",
      "GRAD\n",
      " tensor([-6.7053,  0.2657,  1.8850, 12.8244])\n",
      "0.008625277044989943 0.013835098261000822 -2.0338189208672937\n",
      "Epoch: 1070\n",
      "Arb loss 0.0211151486173317\n",
      "Real arb loss 2.0522742017518573e-05\n",
      "Bounds loss: 0.43246340904845343\n",
      "MAPE:  0.06897949609782728\n",
      "Delta:  0.0035465774257719693\n",
      "GRAD\n",
      " tensor([-32.9832,   0.5591,   4.5227,  66.7860])\n",
      "-0.013888832426315112 -0.021747221999165678 0.9214178085533158\n",
      "Delta imp changed to 0.01055277029055587\n",
      "Epoch: 1071\n",
      "Arb loss 0.0016592746510723504\n",
      "Real arb loss 1.6183062048994724e-06\n",
      "Bounds loss: 0.4418682868115461\n",
      "MAPE:  0.0708690822279772\n",
      "Delta:  0.0035081319466589932\n",
      "GRAD\n",
      " tensor([-0.0129, -0.0053, -0.0021,  0.0111])\n",
      "0.017708404795662602 0.025240306725561656 -15.461008595199871\n",
      "Epoch: 1072\n",
      "Arb loss 0.02731333429309923\n",
      "Real arb loss 2.652668532356373e-05\n",
      "Bounds loss: 0.43071539572012424\n",
      "MAPE:  0.06870251175083872\n",
      "Delta:  0.00344600852607096\n",
      "GRAD\n",
      " tensor([-32.9341,   1.5727,   4.5256,  66.9067])\n",
      "-0.01622802776489607 -0.023274080421789467 0.930139360182278\n",
      "Epoch: 1073\n",
      "Arb loss 0.0019081270092712376\n",
      "Real arb loss 1.8609618834195333e-06\n",
      "Bounds loss: 0.4407399004790173\n",
      "MAPE:  0.07071343149784873\n",
      "Delta:  0.0035019304481101084\n",
      "GRAD\n",
      " tensor([-6.6901,  0.2747,  1.8898, 12.7675])\n",
      "0.013304246898503402 0.01777677130922728 -8.428351069758428\n",
      "Epoch: 1074\n",
      "Arb loss 0.01799049132909742\n",
      "Real arb loss 1.7493707675963958e-05\n",
      "Bounds loss: 0.4329049680613502\n",
      "MAPE:  0.06919314941937707\n",
      "Delta:  0.003455339900807065\n",
      "GRAD\n",
      " tensor([-32.9384,   0.5849,   4.5363,  66.7935])\n",
      "-0.014708018088789299 -0.02187591421884405 0.9550336762178819\n",
      "Epoch: 1075\n",
      "Arb loss 0.0008089662581035814\n",
      "Real arb loss 7.89034955576709e-07\n",
      "Bounds loss: 0.44237516000757177\n",
      "MAPE:  0.07108490765376939\n",
      "Delta:  0.0035061611025710504\n",
      "GRAD\n",
      " tensor([-0.0080, -0.0033, -0.0013,  0.0069])\n",
      "0.017493568350792632 0.025365051667992744 -26.974531060041723\n",
      "arb imp changed to 1019.5800566391565\n",
      "Epoch: 1076\n",
      "Arb loss 0.02264176693970129\n",
      "Real arb loss 2.1992671182846547e-05\n",
      "Bounds loss: 0.43115429121734317\n",
      "MAPE:  0.06891159985094117\n",
      "Delta:  0.0034448258336743334\n",
      "GRAD\n",
      " tensor([-32.9223,   1.5848,   4.5335,  66.8813])\n",
      "-0.015008848925506912 -0.02177458674695254 0.9308340354180358\n",
      "Epoch: 1077\n",
      "Arb loss 0.001566039650224469\n",
      "Real arb loss 1.526833441922608e-06\n",
      "Bounds loss: 0.44054249773277604\n",
      "MAPE:  0.07078576226706268\n",
      "Delta:  0.0034965287041866353\n",
      "GRAD\n",
      " tensor([-6.6857,  0.2774,  1.8913, 12.7736])\n",
      "0.012710347898546637 0.01777858690753986 -9.362653194760389\n",
      "Epoch: 1078\n",
      "Arb loss 0.016228325784520038\n",
      "Real arb loss 1.5776264848500542e-05\n",
      "Bounds loss: 0.4327102746503692\n",
      "MAPE:  0.06926786996618962\n",
      "Delta:  0.0034520866079191686\n",
      "GRAD\n",
      " tensor([-19.8839,   0.8936,   3.6952,  40.4283])\n",
      "-0.005553638749419054 -0.00562386657007985 0.531004781530786\n",
      "Epoch: 1079\n",
      "Arb loss 0.007611007196700554\n",
      "Real arb loss 7.411136949115543e-06\n",
      "Bounds loss: 0.43514377949850547\n",
      "MAPE:  0.06978708642775423\n",
      "Delta:  0.003471258249871259\n",
      "GRAD\n",
      " tensor([-19.9099,   0.8907,   4.6971,  40.2772])\n",
      "-0.0004235702768216054 -0.0024586463131566205 0.21631253877944168\n",
      "Epoch: 1080\n",
      "Arb loss 0.005964650907313656\n",
      "Real arb loss 5.809372984592554e-06\n",
      "Bounds loss: 0.4362136441476625\n",
      "MAPE:  0.07002491483345781\n",
      "Delta:  0.003472728571689076\n",
      "GRAD\n",
      " tensor([-6.6977,  0.2691,  1.8865, 12.8310])\n",
      "0.008629415677201435 0.013986060890318619 -2.303981201670034\n",
      "Epoch: 1081\n",
      "Arb loss 0.01970709447228843\n",
      "Real arb loss 1.915105954762917e-05\n",
      "Bounds loss: 0.4301127335594255\n",
      "MAPE:  0.06885911673588564\n",
      "Delta:  0.003442760953309877\n",
      "GRAD\n",
      " tensor([-32.9402,   0.5780,   4.5310,  66.8153])\n",
      "-0.01387703177846178 -0.022034340373537686 0.9402736592366158\n",
      "Delta imp changed to 0.010295385649322801\n",
      "Epoch: 1082\n",
      "Arb loss 0.0011770326399081039\n",
      "Real arb loss 1.148021166855029e-06\n",
      "Bounds loss: 0.43958998392966664\n",
      "MAPE:  0.07076250110390236\n",
      "Delta:  0.0034054012258191275\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.017768956018289983 0.025574321072872386 -20.842912095699536\n",
      "Epoch: 1083\n",
      "Arb loss 0.025709820487281876\n",
      "Real arb loss 2.4964101796836053e-05\n",
      "Bounds loss: 0.42834776854023054\n",
      "MAPE:  0.06858152331603053\n",
      "Delta:  0.0033448908012129164\n",
      "GRAD\n",
      " tensor([-32.8928,   1.5905,   4.5333,  66.9400])\n",
      "-0.016300055606094155 -0.023610772667819857 0.9474431539691751\n",
      "Epoch: 1084\n",
      "Arb loss 0.0013512270768302212\n",
      "Real arb loss 1.3178600678708034e-06\n",
      "Bounds loss: 0.4384613903260018\n",
      "MAPE:  0.07059973773372337\n",
      "Delta:  0.003399412707269\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.017956669342333087 0.025493856214370614 -19.003148072097463\n",
      "Epoch: 1085\n",
      "Arb loss 0.02702879529686233\n",
      "Real arb loss 2.6240696090924437e-05\n",
      "Bounds loss: 0.42728331868547764\n",
      "MAPE:  0.06843031922318092\n",
      "Delta:  0.003338370577326445\n",
      "GRAD\n",
      " tensor([-32.8918,   1.5871,   4.5303,  66.9692])\n",
      "-0.016274323563123527 -0.023711259357894976 0.9432273608205447\n",
      "Epoch: 1086\n",
      "Arb loss 0.001534496042844124\n",
      "Real arb loss 1.4964361158012544e-06\n",
      "Bounds loss: 0.43741474427413113\n",
      "MAPE:  0.07045454920325621\n",
      "Delta:  0.0033927003002754675\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.01789963680227269 0.02535551453451179 -17.315136923909204\n",
      "arb imp changed to 1020.0898466674761\n",
      "Epoch: 1087\n",
      "Arb loss 0.02811855738645392\n",
      "Real arb loss 2.7281295104182117e-05\n",
      "Bounds loss: 0.4263238683680786\n",
      "MAPE:  0.06830670819705292\n",
      "Delta:  0.0033319721971215746\n",
      "GRAD\n",
      " tensor([-32.9045,   1.5786,   4.5255,  67.0120])\n",
      "-0.016316936008275107 -0.023818901446045926 0.9408568982346763\n",
      "Epoch: 1088\n",
      "Arb loss 0.0016630187010011376\n",
      "Real arb loss 1.6207907485752683e-06\n",
      "Bounds loss: 0.436478434572835\n",
      "MAPE:  0.07033225604186077\n",
      "Delta:  0.003386339774243359\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.017847616564192537 0.025259469901430354 -16.38752116797703\n",
      "Epoch: 1089\n",
      "Arb loss 0.02891577286639894\n",
      "Real arb loss 2.8051812237697924e-05\n",
      "Bounds loss: 0.425453220692119\n",
      "MAPE:  0.06820214459321873\n",
      "Delta:  0.0033259016803965894\n",
      "GRAD\n",
      " tensor([-32.8996,   1.5778,   4.5240,  67.0370])\n",
      "-0.016350194832433385 -0.023910741079115283 0.9395535868861409\n",
      "Epoch: 1090\n",
      "Arb loss 0.001747854752188869\n",
      "Real arb loss 1.7033376699922415e-06\n",
      "Bounds loss: 0.43562612249336397\n",
      "MAPE:  0.07022731508222088\n",
      "Delta:  0.003380280820864591\n",
      "GRAD\n",
      " tensor([-1.5025e-04, -6.1091e-05, -2.4840e-05,  1.2964e-04])\n",
      "0.017802076091625207 0.02519425499256811 -15.877801440721015\n",
      "Epoch: 1091\n",
      "Arb loss 0.029499945454664365\n",
      "Real arb loss 2.8616278010403312e-05\n",
      "Bounds loss: 0.42465084688184246\n",
      "MAPE:  0.06811123570878795\n",
      "Delta:  0.003320104804480498\n",
      "GRAD\n",
      " tensor([-32.8940,   1.5776,   4.5230,  67.0594])\n",
      "-0.01638200453121419 -0.023998024428795395 0.9390445433146235\n",
      "Epoch: 1092\n",
      "Arb loss 0.0017981826473827628\n",
      "Real arb loss 1.7522899853384122e-06\n",
      "Bounds loss: 0.43484162827902156\n",
      "MAPE:  0.07013629032757515\n",
      "Delta:  0.003374494776431604\n",
      "GRAD\n",
      " tensor([-0.0014, -0.0006, -0.0002,  0.0012])\n",
      "0.017764095218084308 0.02515413540791145 -15.683390119143812\n",
      "Delta imp changed to 0.010044278682266148\n",
      "Epoch: 1093\n",
      "Arb loss 0.02999978261176145\n",
      "Real arb loss 2.9100379739971675e-05\n",
      "Bounds loss: 0.42390356308029437\n",
      "MAPE:  0.06803121606548264\n",
      "Delta:  0.0032337072486928247\n",
      "GRAD\n",
      " tensor([-45.7744,   1.3421,   7.3949,  90.3917])\n",
      "-0.02523392173916328 -0.03991641672609214 0.999997288238856\n",
      "Epoch: 1094\n",
      "Arb loss 8.135224481422282e-08\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 0.4408242743558827\n",
      "MAPE:  0.07135011340540068\n",
      "Delta:  0.0033153063643337043\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.020669750914839913 0.028982869806771228 -179201.53947632495\n",
      "Epoch: 1095\n",
      "Arb loss 0.014578528862808417\n",
      "Real arb loss 1.4165538779810355e-05\n",
      "Bounds loss: 0.4280479218045617\n",
      "MAPE:  0.06888170401113439\n",
      "Delta:  0.0032467798075765434\n",
      "GRAD\n",
      " tensor([-1.9611e+01,  2.0894e-02,  4.7535e+00,  4.0260e+01])\n",
      "-0.007391702440424419 -0.0064815336012946645 0.6047857688422984\n",
      "Epoch: 1096\n",
      "Arb loss 0.0057616420759251915\n",
      "Real arb loss 5.608844113137537e-06\n",
      "Bounds loss: 0.43082232879270227\n",
      "MAPE:  0.0694478212362729\n",
      "Delta:  0.0032707790378037277\n",
      "GRAD\n",
      " tensor([-6.6021, -0.6876,  1.9059, 12.7509])\n",
      "0.008504087515439518 0.013517564433905171 -2.1461287925527577\n",
      "Epoch: 1097\n",
      "Arb loss 0.018126868027451688\n",
      "Real arb loss 1.7604738031768345e-05\n",
      "Bounds loss: 0.4249986602036819\n",
      "MAPE:  0.06834937496834563\n",
      "Delta:  0.0032429640466225796\n",
      "GRAD\n",
      " tensor([-1.9647e+01, -2.1041e-03,  3.7409e+00,  4.0244e+01])\n",
      "-0.004903776364063361 -0.006425668761134373 0.49538495236556046\n",
      "arb imp changed to 1020.5998915908098\n",
      "Epoch: 1098\n",
      "Arb loss 0.0091516639183223\n",
      "Real arb loss 8.89655291735357e-06\n",
      "Bounds loss: 0.4277295608180766\n",
      "MAPE:  0.06893238782308482\n",
      "Delta:  0.0032588668170639144\n",
      "GRAD\n",
      " tensor([-6.6203,  0.3022,  1.9007, 12.7785])\n",
      "0.008137323820608056 0.012166605322556201 -1.3738005546343954\n",
      "Epoch: 1099\n",
      "Arb loss 0.021724224885141058\n",
      "Real arb loss 2.107494980962076e-05\n",
      "Bounds loss: 0.42252554406681275\n",
      "MAPE:  0.06793659065294622\n",
      "Delta:  0.0032323483624852314\n",
      "GRAD\n",
      " tensor([-1.9675e+01, -2.0190e-02,  3.7307e+00,  4.0285e+01])\n",
      "-0.005541267986124199 -0.008107435779094452 0.5365063706930653\n",
      "Epoch: 1100\n",
      "Arb loss 0.010069039835894055\n",
      "Real arb loss 9.786655930402003e-06\n",
      "Bounds loss: 0.4259511427803614\n",
      "MAPE:  0.06867432085860947\n",
      "Delta:  0.0032502596709862715\n",
      "GRAD\n",
      " tensor([-6.6290,  0.2970,  1.8979, 12.7854])\n",
      "0.008893341956771605 0.012191038882447658 -1.3834276949928093\n",
      "Epoch: 1101\n",
      "Arb loss 0.023998828406855743\n",
      "Real arb loss 2.327475039529161e-05\n",
      "Bounds loss: 0.42075835583670296\n",
      "MAPE:  0.06768908325390471\n",
      "Delta:  0.0032213540002838867\n",
      "GRAD\n",
      " tensor([-32.5853,   0.7264,   4.5930,  66.6110])\n",
      "-0.014190991617875959 -0.024080029644979684 0.9188223413779388\n",
      "Epoch: 1102\n",
      "Arb loss 0.0019481686997411603\n",
      "Real arb loss 1.8970910609711552e-06\n",
      "Bounds loss: 0.4308902295186237\n",
      "MAPE:  0.06973143045617375\n",
      "Delta:  0.003267068207900127\n",
      "GRAD\n",
      " tensor([-0.0062, -0.0025, -0.0010,  0.0053])\n",
      "0.01833371049358723 0.02532799881157155 -13.427388966639912\n",
      "Epoch: 1103\n",
      "Arb loss 0.02810698760379884\n",
      "Real arb loss 2.7247936263393276e-05\n",
      "Bounds loss: 0.41997664229745824\n",
      "MAPE:  0.06764153721766565\n",
      "Delta:  0.003207170725213683\n",
      "GRAD\n",
      " tensor([-32.4979,   0.7606,   4.6064,  66.7391])\n",
      "-0.016593596904932673 -0.024576912323990285 0.9269838314184776\n",
      "Epoch: 1104\n",
      "Arb loss 0.0020522645451977357\n",
      "Real arb loss 1.998270112300346e-06\n",
      "Bounds loss: 0.43029837141332666\n",
      "MAPE:  0.06968297715405275\n",
      "Delta:  0.003260389223433179\n",
      "GRAD\n",
      " tensor([-0.0078, -0.0032, -0.0013,  0.0068])\n",
      "0.016371357966917355 0.023613264902552444 -10.88079176528658\n",
      "Epoch: 1105\n",
      "Arb loss 0.024382527708774866\n",
      "Real arb loss 2.3648558938039517e-05\n",
      "Bounds loss: 0.4201376219820069\n",
      "MAPE:  0.0677301405577311\n",
      "Delta:  0.0032070122243448747\n",
      "GRAD\n",
      " tensor([-32.5118,   0.7577,   4.6063,  66.7023])\n",
      "-0.016030701861278862 -0.024545537642227888 0.9380228060170926\n",
      "Delta imp changed to 0.009799296275381609\n",
      "Epoch: 1106\n",
      "Arb loss 0.001511160649600354\n",
      "Real arb loss 1.4721608624679999e-06\n",
      "Bounds loss: 0.4304501257972823\n",
      "MAPE:  0.06977587515595812\n",
      "Delta:  0.003178949152369585\n",
      "GRAD\n",
      " tensor([-0.0048, -0.0020, -0.0008,  0.0042])\n",
      "0.017923625100139118 0.025492304141847777 -16.074786551397402\n",
      "Epoch: 1107\n",
      "Arb loss 0.02580274553679709\n",
      "Real arb loss 2.5023115976054072e-05\n",
      "Bounds loss: 0.41947696027256137\n",
      "MAPE:  0.06767373353335891\n",
      "Delta:  0.0031219708595501077\n",
      "GRAD\n",
      " tensor([-32.4785,   0.7700,   4.6108,  66.7467])\n",
      "-0.016725268656899273 -0.024698093700146417 0.9399904150732595\n",
      "Epoch: 1108\n",
      "Arb loss 0.0015484120496334988\n",
      "Real arb loss 1.508375487145601e-06\n",
      "Bounds loss: 0.42983724154242564\n",
      "MAPE:  0.06971736153324987\n",
      "Delta:  0.0031741866609150933\n",
      "GRAD\n",
      " tensor([-0.0060, -0.0024, -0.0010,  0.0052])\n",
      "0.017741657079152984 0.025425142644451837 -15.75283816077048\n",
      "arb imp changed to 1021.1101915366052\n",
      "Epoch: 1109\n",
      "Arb loss 0.025953266621933757\n",
      "Real arb loss 2.5156854553012294e-05\n",
      "Bounds loss: 0.4189085683623118\n",
      "MAPE:  0.06762529886774371\n",
      "Delta:  0.0031178713296719164\n",
      "GRAD\n",
      " tensor([-32.4824,   0.7676,   4.6095,  66.7726])\n",
      "-0.01679234440793609 -0.024784136072610652 0.9415380478533214\n",
      "Epoch: 1110\n",
      "Arb loss 0.001517278631301481\n",
      "Real arb loss 1.4773215544683775e-06\n",
      "Bounds loss: 0.4292908553225858\n",
      "MAPE:  0.06967072557033213\n",
      "Delta:  0.003170227698859397\n",
      "GRAD\n",
      " tensor([-0.0065, -0.0026, -0.0011,  0.0057])\n",
      "0.01772912588790887 0.02544710781011361 -16.09763170915875\n",
      "Epoch: 1111\n",
      "Arb loss 0.02594187123816919\n",
      "Real arb loss 2.514656409313701e-05\n",
      "Bounds loss: 0.41836664464529605\n",
      "MAPE:  0.06758074142675048\n",
      "Delta:  0.0031140223328929833\n",
      "GRAD\n",
      " tensor([-32.4717,   0.7712,   4.6107,  66.7815])\n",
      "-0.016809069562003343 -0.024855458731845914 0.9432350906233393\n",
      "Epoch: 1112\n",
      "Arb loss 0.001472587969895675\n",
      "Real arb loss 1.433831042760847e-06\n",
      "Bounds loss: 0.42876533951605805\n",
      "MAPE:  0.06962733019367556\n",
      "Delta:  0.003166366150904213\n",
      "GRAD\n",
      " tensor([-0.0070, -0.0028, -0.0012,  0.0061])\n",
      "0.017725265690547554 0.025477809494484305 -16.57226845969382\n",
      "Epoch: 1113\n",
      "Arb loss 0.025876711137522324\n",
      "Real arb loss 2.5084299708768693e-05\n",
      "Bounds loss: 0.4178413378780301\n",
      "MAPE:  0.06753859912523581\n",
      "Delta:  0.0031102414696058795\n",
      "GRAD\n",
      " tensor([-32.4612,   0.7748,   4.6119,  66.7900])\n",
      "-0.016824469634693084 -0.024925996794540772 0.9451591872286611\n",
      "Epoch: 1114\n",
      "Arb loss 0.001419099870630882\n",
      "Real arb loss 1.3817756777649085e-06\n",
      "Bounds loss: 0.4282564497266044\n",
      "MAPE:  0.06958633858537457\n",
      "Delta:  0.0031625696327678273\n",
      "GRAD\n",
      " tensor([-0.0074, -0.0030, -0.0012,  0.0064])\n",
      "0.017722445467150516 0.02551314246091496 -17.158764673514952\n",
      "Epoch: 1115\n",
      "Arb loss 0.025769100599001695\n",
      "Real arb loss 2.4980988781336588e-05\n",
      "Bounds loss: 0.4173302819149239\n",
      "MAPE:  0.06749841459937836\n",
      "Delta:  0.003106521164915033\n",
      "GRAD\n",
      " tensor([-32.4508,   0.7785,   4.6131,  66.7981])\n",
      "-0.016839629591186567 -0.02499597533155029 0.947284585397311\n",
      "Epoch: 1116\n",
      "Arb loss 0.0013584288220147768\n",
      "Real arb loss 1.3227219105056004e-06\n",
      "Bounds loss: 0.4277618593467783\n",
      "MAPE:  0.06954728764299631\n",
      "Delta:  0.0031588338306493837\n",
      "GRAD\n",
      " tensor([-0.0077, -0.0031, -0.0013,  0.0067])\n",
      "0.01772020735763602 0.025551974796766297 -17.86476810044853\n",
      "Delta imp changed to 0.00956028904915279\n",
      "Epoch: 1117\n",
      "Arb loss 0.025626444708274236\n",
      "Real arb loss 2.4843780045476043e-05\n",
      "Bounds loss: 0.41683169909773155\n",
      "MAPE:  0.06745983748377828\n",
      "Delta:  0.003027179161133621\n",
      "GRAD\n",
      " tensor([-32.4406,   0.7821,   4.6143,  66.8059])\n",
      "-0.016855302178874654 -0.025065848343648556 0.9495955853410267\n",
      "Epoch: 1118\n",
      "Arb loss 0.001291685945311106\n",
      "Real arb loss 1.2577469390117405e-06\n",
      "Bounds loss: 0.4272799392521407\n",
      "MAPE:  0.06950985717877076\n",
      "Delta:  0.00307820318064412\n",
      "GRAD\n",
      " tensor([-0.0080, -0.0033, -0.0013,  0.0070])\n",
      "0.017718017430283117 0.02559340647809505 -18.70582958341433\n",
      "Epoch: 1119\n",
      "Arb loss 0.025453743113592095\n",
      "Real arb loss 2.467749732096919e-05\n",
      "Bounds loss: 0.41634439008692486\n",
      "MAPE:  0.06742263041677143\n",
      "Delta:  0.003023663523035515\n",
      "GRAD\n",
      " tensor([-32.4305,   0.7857,   4.6156,  66.8135])\n",
      "-0.016728788564417618 -0.024688129768723588 0.9473657537593975\n",
      "arb imp changed to 1021.6207466323734\n",
      "Epoch: 1120\n",
      "Arb loss 0.001340408452077239\n",
      "Real arb loss 1.3044632030176225e-06\n",
      "Bounds loss: 0.42662315441787096\n",
      "MAPE:  0.06943801953347183\n",
      "Delta:  0.003074245750802318\n",
      "GRAD\n",
      " tensor([-0.0091, -0.0037, -0.0015,  0.0079])\n",
      "0.01770033303257601 0.0255591516052448 -18.280022039751824\n",
      "Epoch: 1121\n",
      "Arb loss 0.025843104498318798\n",
      "Real arb loss 2.5041903063842618e-05\n",
      "Bounds loss: 0.41571902853579684\n",
      "MAPE:  0.06735861216365706\n",
      "Delta:  0.0030198305771891353\n",
      "GRAD\n",
      " tensor([-32.4354,   0.7825,   4.6138,  66.8392])\n",
      "-0.016896682052639056 -0.02522201499828447 0.9521515909204942\n",
      "Epoch: 1122\n",
      "Arb loss 0.001236551435919975\n",
      "Real arb loss 1.2034144841934285e-06\n",
      "Bounds loss: 0.42620430010859894\n",
      "MAPE:  0.06941173045428443\n",
      "Delta:  0.0030708556943047373\n",
      "GRAD\n",
      " tensor([-0.0092, -0.0037, -0.0015,  0.0080])\n",
      "0.017707245296571306 0.025625473137610766 -19.619184723236632\n",
      "Epoch: 1123\n",
      "Arb loss 0.02549668247701747\n",
      "Real arb loss 2.4707857520764896e-05\n",
      "Bounds loss: 0.41528261326503185\n",
      "MAPE:  0.06733006830888524\n",
      "Delta:  0.0030164792992553105\n",
      "GRAD\n",
      " tensor([-32.4261,   0.7860,   4.6151,  66.8457])\n",
      "-0.01676880640157652 -0.024840788160744864 0.950736131729931\n",
      "Epoch: 1124\n",
      "Arb loss 0.001256065206871567\n",
      "Real arb loss 1.222352303235641e-06\n",
      "Bounds loss: 0.42559856068798907\n",
      "MAPE:  0.0693485078366983\n",
      "Delta:  0.003067062056638886\n",
      "GRAD\n",
      " tensor([-0.0101, -0.0041, -0.0017,  0.0088])\n",
      "0.017693747805238802 0.025608078516244248 -19.489168095123677\n",
      "Epoch: 1125\n",
      "Arb loss 0.025735731162027833\n",
      "Real arb loss 2.4939318315633617e-05\n",
      "Bounds loss: 0.4146997993294905\n",
      "MAPE:  0.0672729442371895\n",
      "Delta:  0.0030127942341057\n",
      "GRAD\n",
      " tensor([-32.4164,   0.7890,   4.6159,  66.8572])\n",
      "-0.016786325314030348 -0.02491625526943042 0.9513662883363704\n",
      "Epoch: 1126\n",
      "Arb loss 0.0012516241287867484\n",
      "Real arb loss 1.2179860804997777e-06\n",
      "Bounds loss: 0.42503256538976564\n",
      "MAPE:  0.06929257683725015\n",
      "Delta:  0.003063367978223633\n",
      "GRAD\n",
      " tensor([-0.0108, -0.0044, -0.0018,  0.0094])\n",
      "0.01768376411223027 0.025606456934101685 -19.661477482081185\n",
      "Epoch: 1127\n",
      "Arb loss 0.025860403752956885\n",
      "Real arb loss 2.506025870898922e-05\n",
      "Bounds loss: 0.41414898730852184\n",
      "MAPE:  0.06722153062529337\n",
      "Delta:  0.003009196101507767\n",
      "GRAD\n",
      " tensor([-32.4068,   0.7920,   4.6169,  66.8676])\n",
      "-0.016803119850373305 -0.0249898896516898 0.9525143390923928\n",
      "Delta imp changed to 0.009327111267466139\n",
      "Epoch: 1128\n",
      "Arb loss 0.001227998363546723\n",
      "Real arb loss 1.1953313080144411e-06\n",
      "Bounds loss: 0.42449852480072087\n",
      "MAPE:  0.06924234048143724\n",
      "Delta:  0.002985131691955784\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.017680165650006185 0.025623042224391934 -20.09476578730717\n",
      "Epoch: 1129\n",
      "Arb loss 0.025904337866214606\n",
      "Real arb loss 2.510318662644116e-05\n",
      "Bounds loss: 0.4136215811755599\n",
      "MAPE:  0.06717410461194194\n",
      "Delta:  0.0029323540691549225\n",
      "GRAD\n",
      " tensor([-32.3973,   0.7952,   4.6178,  66.8774])\n",
      "-0.016820227183422576 -0.02506228664131016 0.9540137711206866\n",
      "Epoch: 1130\n",
      "Arb loss 0.0011912428100828078\n",
      "Real arb loss 1.159561214812893e-06\n",
      "Bounds loss: 0.4239878838040137\n",
      "MAPE:  0.06919605662807277\n",
      "Delta:  0.0029816769307803416\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.01767418858059322 0.025641943785066457 -20.720415798654116\n",
      "arb imp changed to 1022.1315570056895\n",
      "Epoch: 1131\n",
      "Arb loss 0.025887226296731815\n",
      "Real arb loss 2.5074630255484477e-05\n",
      "Bounds loss: 0.41311601032196194\n",
      "MAPE:  0.06713030522982891\n",
      "Delta:  0.0029289782104193257\n",
      "GRAD\n",
      " tensor([-32.4040,   0.7918,   4.6162,  66.9009])\n",
      "-0.01684484913539097 -0.02514288184962954 0.9559500103424067\n",
      "Epoch: 1132\n",
      "Arb loss 0.0011403320506348153\n",
      "Real arb loss 1.1094534606039263e-06\n",
      "Bounds loss: 0.4235029373596773\n",
      "MAPE:  0.06915414867787867\n",
      "Delta:  0.0029783164064946864\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.017672349035708246 0.025671033296616574 -21.615214172685754\n",
      "Epoch: 1133\n",
      "Arb loss 0.025788853553084284\n",
      "Real arb loss 2.4980098491511823e-05\n",
      "Bounds loss: 0.41263117935350213\n",
      "MAPE:  0.06708986997047567\n",
      "Delta:  0.0029256825594203358\n",
      "GRAD\n",
      " tensor([-32.3946,   0.7951,   4.6173,  66.9093])\n",
      "-0.016858195321437286 -0.025212254980530258 0.9581008527249782\n",
      "Epoch: 1134\n",
      "Arb loss 0.0010805309730746472\n",
      "Real arb loss 1.0512653647902285e-06\n",
      "Bounds loss: 0.4230345418602795\n",
      "MAPE:  0.06911476785210376\n",
      "Delta:  0.002975004287455566\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.01766906933024881 0.025703604696314497 -22.735845216986654\n",
      "Epoch: 1135\n",
      "Arb loss 0.0256473159290598\n",
      "Real arb loss 2.4843859441068232e-05\n",
      "Bounds loss: 0.41216102922341635\n",
      "MAPE:  0.06705160867615846\n",
      "Delta:  0.002922438730442726\n",
      "GRAD\n",
      " tensor([-32.3852,   0.7984,   4.6184,  66.9173])\n",
      "-0.01687261572208243 -0.025281130818365805 0.9604957674171785\n",
      "Epoch: 1136\n",
      "Arb loss 0.0010131775335866832\n",
      "Real arb loss 9.857145537642623e-07\n",
      "Bounds loss: 0.4225809261214458\n",
      "MAPE:  0.06907754076531247\n",
      "Delta:  0.0029717479161128165\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.017666204465674795 0.025740114070860742 -24.137449512419654\n",
      "Epoch: 1137\n",
      "Arb loss 0.025468699097653116\n",
      "Real arb loss 2.467177989106473e-05\n",
      "Bounds loss: 0.4117036448789098\n",
      "MAPE:  0.06701512008015996\n",
      "Delta:  0.0029192484098063244\n",
      "GRAD\n",
      " tensor([-32.3759,   0.8017,   4.6196,  66.9249])\n",
      "-0.016886949768742054 -0.025349510401162734 0.9631103229347814\n",
      "Epoch: 1138\n",
      "Arb loss 0.0009395320849836469\n",
      "Real arb loss 9.140230391778832e-07\n",
      "Bounds loss: 0.4221401307069644\n",
      "MAPE:  0.0690420714204732\n",
      "Delta:  0.002968545611065204\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.017663885623069864 0.025779779510146206 -25.885016909702376\n",
      "Delta imp changed to 0.009099620748747454\n",
      "Epoch: 1139\n",
      "Arb loss 0.025259335991993277\n",
      "Real arb loss 2.4469965720161305e-05\n",
      "Bounds loss: 0.41125745121495455\n",
      "MAPE:  0.06698008783034962\n",
      "Delta:  0.0028449849374873\n",
      "GRAD\n",
      " tensor([-32.3666,   0.8051,   4.6208,  66.9321])\n",
      "-0.01690176190739301 -0.02541780081473677 0.9659308503216437\n",
      "Epoch: 1140\n",
      "Arb loss 0.0008605640986871123\n",
      "Real arb loss 8.371303244558218e-07\n",
      "Bounds loss: 0.42171071119351256\n",
      "MAPE:  0.06900807215970316\n",
      "Delta:  0.00289307019553083\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.01766164091504263 0.02582178450721806 -28.078129738568002\n",
      "Epoch: 1141\n",
      "Arb loss 0.025023594509977688\n",
      "Real arb loss 2.4242625886640807e-05\n",
      "Bounds loss: 0.41082138808468804\n",
      "MAPE:  0.06694629867632275\n",
      "Delta:  0.0028419738285953523\n",
      "GRAD\n",
      " tensor([-32.3574,   0.8085,   4.6221,  66.9391])\n",
      "-0.01691547646890501 -0.025485359135779984 0.9689401021355181\n",
      "arb imp changed to 1022.6426227841923\n",
      "Epoch: 1142\n",
      "Arb loss 0.0007776189048269601\n",
      "Real arb loss 7.559641752952901e-07\n",
      "Bounds loss: 0.4212913187006859\n",
      "MAPE:  0.06897527601304913\n",
      "Delta:  0.002890047170018201\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.017659567679158883 0.025866110695158095 -30.86476269824343\n",
      "Epoch: 1143\n",
      "Arb loss 0.02477864187197903\n",
      "Real arb loss 2.399437247477557e-05\n",
      "Bounds loss: 0.4103941508162649\n",
      "MAPE:  0.06691349728792009\n",
      "Delta:  0.0028390101864233033\n",
      "GRAD\n",
      " tensor([-32.3644,   0.8053,   4.6206,  66.9602])\n",
      "-0.016938537325551284 -0.0255629776308135 0.9722442155262246\n",
      "Epoch: 1144\n",
      "Arb loss 0.0006877506433515143\n",
      "Real arb loss 6.68451518920074e-07\n",
      "Bounds loss: 0.42088504731339776\n",
      "MAPE:  0.06894430987662326\n",
      "Delta:  0.0028870988664336547\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.017662235479064092 0.025914575117240823 -29.382239601656522\n",
      "Epoch: 1145\n",
      "Arb loss 0.02089540483249913\n",
      "Real arb loss 2.0234457683976137e-05\n",
      "Bounds loss: 0.4099779901390712\n",
      "MAPE:  0.06688212605523432\n",
      "Delta:  0.0028361062464033644\n",
      "GRAD\n",
      " tensor([-19.3271,   0.1294,   3.7949,  40.2715])\n",
      "-0.008115514090361264 -0.009042312635308747 0.6342474269814338\n",
      "Epoch: 1146\n",
      "Arb loss 0.00764254808175114\n",
      "Real arb loss 7.418057881398998e-06\n",
      "Bounds loss: 0.41368513929950423\n",
      "MAPE:  0.06759118355214051\n",
      "Delta:  0.002859122706607812\n",
      "GRAD\n",
      " tensor([-6.5134, -0.6529,  1.9195, 12.7497])\n",
      "0.008761908297467924 0.012722818370815014 -1.7712519302191678\n",
      "Epoch: 1147\n",
      "Arb loss 0.021179426123345644\n",
      "Real arb loss 2.0508745084511566e-05\n",
      "Bounds loss: 0.40842189840949134\n",
      "MAPE:  0.06662849812489613\n",
      "Delta:  0.002834071335641306\n",
      "GRAD\n",
      " tensor([-19.3536,   0.1147,   3.7873,  39.2448])\n",
      "-0.006088784756063337 -0.0084141683612593 0.5615629000083346\n",
      "Epoch: 1148\n",
      "Arb loss 0.009285846169007383\n",
      "Real arb loss 9.009698795081227e-06\n",
      "Bounds loss: 0.4118584290251339\n",
      "MAPE:  0.06730758647258808\n",
      "Delta:  0.0028513273859873548\n",
      "GRAD\n",
      " tensor([-6.5216, -0.6578,  1.9169, 12.7633])\n",
      "0.007773427678560707 0.011223661927046269 -1.301854518103117\n",
      "Epoch: 1149\n",
      "Arb loss 0.021374666958540164\n",
      "Real arb loss 2.06975445585784e-05\n",
      "Bounds loss: 0.40723586925595145\n",
      "MAPE:  0.06646411299576688\n",
      "Delta:  0.0028291627987644826\n",
      "GRAD\n",
      " tensor([-19.3625,   0.1083,   3.7835,  39.2404])\n",
      "-0.005291930843424053 -0.008362636571267013 0.5358275641202368\n",
      "Epoch: 1150\n",
      "Arb loss 0.009921531228264278\n",
      "Real arb loss 9.62533037833132e-06\n",
      "Bounds loss: 0.410641434829323\n",
      "MAPE:  0.06715328960748396\n",
      "Delta:  0.0028441345326403323\n",
      "GRAD\n",
      " tensor([-6.5240, -0.6597,  1.9157, 12.7714])\n",
      "0.007908234425443195 0.011169486716985144 -1.2681151152196861\n",
      "Epoch: 1151\n",
      "Arb loss 0.022503174944950344\n",
      "Real arb loss 2.1787389587241746e-05\n",
      "Bounds loss: 0.4060547807775532\n",
      "MAPE:  0.0663215187599604\n",
      "Delta:  0.002821642450018714\n",
      "GRAD\n",
      " tensor([-19.3579,   0.1076,   3.7822,  40.2605])\n",
      "-0.005597718884452485 -0.009058680752677128 0.5519202861301675\n",
      "Epoch: 1152\n",
      "Arb loss 0.010083216190496132\n",
      "Real arb loss 9.781890907973598e-06\n",
      "Bounds loss: 0.40973310140471536\n",
      "MAPE:  0.06706379473361912\n",
      "Delta:  0.0028374372112463567\n",
      "GRAD\n",
      " tensor([-6.5235, -0.6600,  1.9153, 12.7774])\n",
      "0.007892243358738948 0.011150138823727174 -1.260605347997826\n",
      "arb imp changed to 1023.1539440955844\n",
      "Epoch: 1153\n",
      "Arb loss 0.022805569531476447\n",
      "Real arb loss 2.2068597461327986e-05\n",
      "Bounds loss: 0.4051645204433765\n",
      "MAPE:  0.06623792207509037\n",
      "Delta:  0.002815043466260059\n",
      "GRAD\n",
      " tensor([-19.3606,   0.1049,   3.7805,  40.2827])\n",
      "-0.005636815190368516 -0.009138186502240409 0.5530206195289357\n",
      "Epoch: 1154\n",
      "Arb loss 0.010193619340469123\n",
      "Real arb loss 9.883848552069671e-06\n",
      "Bounds loss: 0.4088669893952789\n",
      "MAPE:  0.06698252692003001\n",
      "Delta:  0.002830911346032221\n",
      "GRAD\n",
      " tensor([-6.5259, -0.6615,  1.9145, 12.7859])\n",
      "0.007864834204004967 0.011135984438568225 -1.2565074992521885\n",
      "Epoch: 1155\n",
      "Arb loss 0.023001978486290726\n",
      "Real arb loss 2.2258376212510823e-05\n",
      "Bounds loss: 0.4043138529639288\n",
      "MAPE:  0.06616168797918195\n",
      "Delta:  0.002808646697649441\n",
      "GRAD\n",
      " tensor([-19.3533,   0.1065,   3.7805,  40.2952])\n",
      "-0.005668913081158022 -0.009207271420330176 0.5544375688656404\n",
      "Epoch: 1156\n",
      "Arb loss 0.010248817455251932\n",
      "Real arb loss 9.937258069565682e-06\n",
      "Bounds loss: 0.4080364803471672\n",
      "MAPE:  0.06690785939720396\n",
      "Delta:  0.002824568671654097\n",
      "GRAD\n",
      " tensor([-6.5248, -0.6615,  1.9143, 12.7910])\n",
      "0.007842132643751665 0.011131417402906574 -1.2568693593976517\n",
      "Epoch: 1157\n",
      "Arb loss 0.0231302420848179\n",
      "Real arb loss 2.2382395952486676e-05\n",
      "Bounds loss: 0.40349445596881\n",
      "MAPE:  0.06609102292190576\n",
      "Delta:  0.0028024180294696\n",
      "GRAD\n",
      " tensor([-19.3456,   0.1083,   3.7807,  40.3069])\n",
      "-0.0057022543201359355 -0.009273353669971618 0.5563176855387736\n",
      "Delta imp changed to 0.00887767877926581\n",
      "Epoch: 1158\n",
      "Arb loss 0.01026247934224047\n",
      "Real arb loss 9.950473881530978e-06\n",
      "Bounds loss: 0.4072362027628816\n",
      "MAPE:  0.06683852876762227\n",
      "Delta:  0.0027496567119853366\n",
      "GRAD\n",
      " tensor([-6.5234, -0.6614,  1.9142, 12.7957])\n",
      "0.00775827686950048 0.011107291789756113 -1.2559887801473657\n",
      "Epoch: 1159\n",
      "Arb loss 0.023152038252588616\n",
      "Real arb loss 2.2403712799826913e-05\n",
      "Bounds loss: 0.402712911431442\n",
      "MAPE:  0.06602765789337411\n",
      "Delta:  0.002728324113917674\n",
      "GRAD\n",
      " tensor([-19.3376,   0.1104,   3.7811,  40.3163])\n",
      "-0.005708409323306629 -0.009329051866911353 0.5580900601594239\n",
      "Epoch: 1160\n",
      "Arb loss 0.010231115831388152\n",
      "Real arb loss 9.92012676723225e-06\n",
      "Bounds loss: 0.4064698410696608\n",
      "MAPE:  0.06677642182737065\n",
      "Delta:  0.002743898504726564\n",
      "GRAD\n",
      " tensor([-6.5217, -0.6610,  1.9142, 12.7997])\n",
      "0.00775180181707269 0.011120666080035924 -1.264354408620329\n",
      "Epoch: 1161\n",
      "Arb loss 0.023166872237909007\n",
      "Real arb loss 2.2418294991479162e-05\n",
      "Bounds loss: 0.4019496256955198\n",
      "MAPE:  0.06596752846192723\n",
      "Delta:  0.0027226283473117618\n",
      "GRAD\n",
      " tensor([-19.3291,   0.1128,   3.7816,  40.3259])\n",
      "-0.005736873322327529 -0.009388963140979811 0.5593278214994215\n",
      "Epoch: 1162\n",
      "Arb loss 0.010208996058123934\n",
      "Real arb loss 9.89901102510525e-06\n",
      "Bounds loss: 0.4057235159157057\n",
      "MAPE:  0.06671727791531\n",
      "Delta:  0.002738247721244067\n",
      "GRAD\n",
      " tensor([-19.3525,   0.1153,   3.7876,  39.1814])\n",
      "-0.0010299490152734236 -0.004702171753315776 0.3118845309912103\n",
      "Epoch: 1163\n",
      "Arb loss 0.007024968110644836\n",
      "Real arb loss 6.8174762682439966e-06\n",
      "Bounds loss: 0.40763129757190053\n",
      "MAPE:  0.06715975591327594\n",
      "Delta:  0.002741067976788137\n",
      "GRAD\n",
      " tensor([-6.4999, -0.6501,  1.9195, 12.7862])\n",
      "0.008501130952964009 0.013311542818466804 -1.964379319056932\n",
      "arb imp changed to 1023.6655210676321\n",
      "Epoch: 1164\n",
      "Arb loss 0.020835082519322114\n",
      "Real arb loss 2.015895287403699e-05\n",
      "Bounds loss: 0.40220509610012495\n",
      "MAPE:  0.06615912025729524\n",
      "Delta:  0.002717765798966485\n",
      "GRAD\n",
      " tensor([-19.3025,   0.1272,   3.7889,  40.3410])\n",
      "-0.006779442457508944 -0.00952339523507817 0.6100265408494477\n",
      "Epoch: 1165\n",
      "Arb loss 0.008125129201747247\n",
      "Real arb loss 7.878123809702577e-06\n",
      "Bounds loss: 0.406035454195849\n",
      "MAPE:  0.0669000612856521\n",
      "Delta:  0.002736190735813564\n",
      "GRAD\n",
      " tensor([-6.5103, -0.6556,  1.9168, 12.7953])\n",
      "0.009170926544196156 0.013254416644270739 -1.9147591937467867\n",
      "Epoch: 1166\n",
      "Arb loss 0.023682795041173283\n",
      "Real arb loss 2.2906933912638352e-05\n",
      "Bounds loss: 0.4006536911135915\n",
      "MAPE:  0.06592728839298674\n",
      "Delta:  0.002711097331564508\n",
      "GRAD\n",
      " tensor([-31.9466,   0.9811,   4.6945,  66.6858])\n",
      "-0.015245659025476144 -0.026247962774975653 0.9492230743370929\n",
      "Epoch: 1167\n",
      "Arb loss 0.0012025395232955216\n",
      "Real arb loss 1.1681077271079553e-06\n",
      "Bounds loss: 0.41117003428359766\n",
      "MAPE:  0.06797870314451958\n",
      "Delta:  0.0027524297970664183\n",
      "GRAD\n",
      " tensor([-0.0061, -0.0025, -0.0010,  0.0053])\n",
      "0.017954842387821968 0.02633367300080347 -20.48961542317512\n",
      "Epoch: 1168\n",
      "Arb loss 0.025842111886789098\n",
      "Real arb loss 2.4990753880157515e-05\n",
      "Bounds loss: 0.40034241705304424\n",
      "MAPE:  0.06594845884422686\n",
      "Delta:  0.002703010353876546\n",
      "GRAD\n",
      " tensor([-31.8699,   1.0131,   4.7078,  66.7728])\n",
      "-0.017245509805507986 -0.026850133774884988 0.9599313183445297\n",
      "Delta imp changed to 0.00866115002855201\n",
      "Epoch: 1169\n",
      "Arb loss 0.001035459354496798\n",
      "Real arb loss 1.0057974181179423e-06\n",
      "Bounds loss: 0.4110916645066793\n",
      "MAPE:  0.06801413145813015\n",
      "Delta:  0.002682561117501184\n",
      "GRAD\n",
      " tensor([-0.0058, -0.0024, -0.0010,  0.0051])\n",
      "0.01757037114475568 0.026319368559626688 -22.85254104437552\n",
      "Epoch: 1170\n",
      "Arb loss 0.02469833675291746\n",
      "Real arb loss 2.388867867517825e-05\n",
      "Bounds loss: 0.4002719914767376\n",
      "MAPE:  0.06598173415985203\n",
      "Delta:  0.002635427523048198\n",
      "GRAD\n",
      " tensor([-31.8571,   1.0199,   4.7113,  66.7719])\n",
      "-0.017351212824144202 -0.026915615662007397 0.9684194770257714\n",
      "Epoch: 1171\n",
      "Arb loss 0.0007799863912507444\n",
      "Real arb loss 7.57457310815033e-07\n",
      "Bounds loss: 0.4110455585595918\n",
      "MAPE:  0.06805517188380157\n",
      "Delta:  0.0026811553868832144\n",
      "GRAD\n",
      " tensor([-0.0047, -0.0019, -0.0008,  0.0042])\n",
      "0.01758513876516432 0.026484553276317713 -29.228934326072682\n",
      "Epoch: 1172\n",
      "Arb loss 0.023578157396349185\n",
      "Real arb loss 2.2808729414701093e-05\n",
      "Bounds loss: 0.4001592005649265\n",
      "MAPE:  0.06600315545819392\n",
      "Delta:  0.0026340068973539055\n",
      "GRAD\n",
      " tensor([-31.8477,   1.0251,   4.7140,  66.7677])\n",
      "-0.01736230684109663 -0.026973661137040583 0.9767064608780675\n",
      "Epoch: 1173\n",
      "Arb loss 0.0005492187317349433\n",
      "Real arb loss 5.329389711254857e-07\n",
      "Bounds loss: 0.4109529592418339\n",
      "MAPE:  0.0680841383758889\n",
      "Delta:  0.002679739333327329\n",
      "GRAD\n",
      " tensor([-0.0038, -0.0016, -0.0006,  0.0034])\n",
      "0.01761660589083247 0.026633397404747572 -40.15124384303134\n",
      "Epoch: 1174\n",
      "Arb loss 0.022601033952785066\n",
      "Real arb loss 2.1866297918864278e-05\n",
      "Bounds loss: 0.40000788576368906\n",
      "MAPE:  0.06601503959402016\n",
      "Delta:  0.002632531421601939\n",
      "GRAD\n",
      " tensor([-31.8383,   1.0301,   4.7165,  66.7645])\n",
      "-0.017227368605455373 -0.026759346559556807 0.9798159686756639\n",
      "arb imp changed to 1024.177353828166\n",
      "Epoch: 1175\n",
      "Arb loss 0.0004564080672540293\n",
      "Real arb loss 4.425577955386867e-07\n",
      "Bounds loss: 0.41071183540539524\n",
      "MAPE:  0.06808002532821336\n",
      "Delta:  0.0026778830107673196\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.018679342602356264 0.027483013716477767 -52.73361805196127\n",
      "Epoch: 1176\n",
      "Arb loss 0.024524456761661862\n",
      "Real arb loss 2.3711241165354685e-05\n",
      "Bounds loss: 0.399424236399429\n",
      "MAPE:  0.06594367034175029\n",
      "Delta:  0.0026278619165601676\n",
      "GRAD\n",
      " tensor([-31.8144,   1.0387,   4.7195,  66.8221])\n",
      "-0.01809496162366786 -0.027152947718869447 0.9808532098142754\n",
      "Epoch: 1177\n",
      "Arb loss 0.0004695646280344153\n",
      "Real arb loss 4.552787975215175e-07\n",
      "Bounds loss: 0.41026978180803203\n",
      "MAPE:  0.06803177544826422\n",
      "Delta:  0.002675412977092622\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.018508434656950512 0.02737761408399364 -51.49965332845837\n",
      "Epoch: 1178\n",
      "Arb loss 0.02465198018711331\n",
      "Real arb loss 2.3834728715468948e-05\n",
      "Bounds loss: 0.3990375740513674\n",
      "MAPE:  0.06590362846112793\n",
      "Delta:  0.0026258952708257456\n",
      "GRAD\n",
      " tensor([-31.8015,   1.0439,   4.7216,  66.8278])\n",
      "-0.01814254521928227 -0.027217527935311292 0.981423388765128\n",
      "Epoch: 1179\n",
      "Arb loss 0.0004579502521057712\n",
      "Real arb loss 4.4404414111713294e-07\n",
      "Bounds loss: 0.4098983903703494\n",
      "MAPE:  0.06799663315448581\n",
      "Delta:  0.002673535694517801\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.018497908191402956 0.027370352727041136 -52.72065848723742\n",
      "Delta imp changed to 0.00844990246688001\n",
      "Epoch: 1180\n",
      "Arb loss 0.024601389097518415\n",
      "Real arb loss 2.37864861082221e-05\n",
      "Bounds loss: 0.3986793268436666\n",
      "MAPE:  0.06586836525771304\n",
      "Delta:  0.002560078904091875\n",
      "GRAD\n",
      " tensor([-31.7905,   1.0483,   4.7233,  66.8312])\n",
      "-0.018154122002470352 -0.02728034471735019 0.9821470079844478\n",
      "Epoch: 1181\n",
      "Arb loss 0.0004392084031294892\n",
      "Real arb loss 4.2591078859388967e-07\n",
      "Bounds loss: 0.40955543631164293\n",
      "MAPE:  0.06796640753400464\n",
      "Delta:  0.0026065548888527094\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.018497883254890324 0.027379742891909253 -54.69297648605707\n",
      "Epoch: 1182\n",
      "Arb loss 0.024460823267969316\n",
      "Real arb loss 2.3651482918473725e-05\n",
      "Bounds loss: 0.3983419137654465\n",
      "MAPE:  0.06583665547932896\n",
      "Delta:  0.0025583391408212485\n",
      "GRAD\n",
      " tensor([-31.7803,   1.0525,   4.7251,  66.8343])\n",
      "-0.01816287937857819 -0.02734209683486677 0.9830079572351088\n",
      "Epoch: 1183\n",
      "Arb loss 0.000415639355033779\n",
      "Real arb loss 4.030992556148388e-07\n",
      "Bounds loss: 0.4092334169450075\n",
      "MAPE:  0.06793970986229356\n",
      "Delta:  0.00260480594604548\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.018499524148983038 0.027398556806530694 -57.35161826677009\n",
      "Epoch: 1184\n",
      "Arb loss 0.0242532289815776\n",
      "Real arb loss 2.3451823705064565e-05\n",
      "Bounds loss: 0.39802101192370903\n",
      "MAPE:  0.0658076527012614\n",
      "Delta:  0.0025566182755431973\n",
      "GRAD\n",
      " tensor([-31.7704,   1.0566,   4.7267,  66.8371])\n",
      "-0.018171950020521965 -0.027403328951431716 0.9839902349957671\n",
      "Epoch: 1185\n",
      "Arb loss 0.0003882884965889075\n",
      "Real arb loss 3.7661771870825187e-07\n",
      "Bounds loss: 0.40892811264303613\n",
      "MAPE:  0.06791568643566373\n",
      "Delta:  0.0026030770150679214\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.018501575185845054 0.027424182794754892 -60.78988555840643\n",
      "arb imp changed to 1024.68944250508\n",
      "Epoch: 1186\n",
      "Arb loss 0.02400429791875822\n",
      "Real arb loss 2.3200693330134216e-05\n",
      "Bounds loss: 0.3977135933319994\n",
      "MAPE:  0.0657807524038537\n",
      "Delta:  0.002554915989959097\n",
      "GRAD\n",
      " tensor([-31.7768,   1.0541,   4.7258,  66.8543])\n",
      "-0.018190977903257632 -0.02747501115947748 0.9851215672011843\n",
      "Epoch: 1187\n",
      "Arb loss 0.00035714633346699764\n",
      "Real arb loss 3.462795027552139e-07\n",
      "Bounds loss: 0.40864077874707194\n",
      "MAPE:  0.06789460297440358\n",
      "Delta:  0.0026013924102771223\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.01850745722233338 0.02745834045179718 -65.33246905930253\n",
      "Epoch: 1188\n",
      "Arb loss 0.023690398114342964\n",
      "Real arb loss 2.289856860025491e-05\n",
      "Bounds loss: 0.3974201811217473\n",
      "MAPE:  0.06575605928517765\n",
      "Delta:  0.0025532472515254158\n",
      "GRAD\n",
      " tensor([-31.7676,   1.0580,   4.7274,  66.8567])\n",
      "-0.018199371802781306 -0.027535375680928675 0.9863295154740466\n",
      "Epoch: 1189\n",
      "Arb loss 0.0003238592208358021\n",
      "Real arb loss 3.1403704921409426e-07\n",
      "Bounds loss: 0.4083632951121174\n",
      "MAPE:  0.06787483894106813\n",
      "Delta:  0.0025997147475603564\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.018510505129303745 0.02749441039827305 -71.08578007644572\n",
      "Epoch: 1190\n",
      "Arb loss 0.023345644568898694\n",
      "Real arb loss 2.256662600200929e-05\n",
      "Bounds loss: 0.39713558708471375\n",
      "MAPE:  0.06573254111436413\n",
      "Delta:  0.002551592714390914\n",
      "GRAD\n",
      " tensor([-31.7586,   1.0618,   4.7291,  66.8591])\n",
      "-0.01820880673683578 -0.02759550094683183 0.9876321348377558\n",
      "Delta imp changed to 0.008243807284760986\n",
      "Epoch: 1191\n",
      "Arb loss 0.0002887357841538172\n",
      "Real arb loss 2.7999844015994674e-07\n",
      "Bounds loss: 0.4080947425541306\n",
      "MAPE:  0.06785618092255695\n",
      "Delta:  0.0025346869980471965\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.018512728080519625 0.02753290631848504 -78.56763669517443\n",
      "Epoch: 1192\n",
      "Arb loss 0.02297402397444723\n",
      "Real arb loss 2.2208693582410897e-05\n",
      "Bounds loss: 0.3968587082383214\n",
      "MAPE:  0.0657099799632332\n",
      "Delta:  0.0024877630268831203\n",
      "GRAD\n",
      " tensor([-31.7499,   1.0655,   4.7307,  66.8613])\n",
      "-0.018218740866098537 -0.027655690451142467 0.9890285988860384\n",
      "Epoch: 1193\n",
      "Arb loss 0.0002520572322254295\n",
      "Real arb loss 2.4443352739198997e-07\n",
      "Bounds loss: 0.40783410982620066\n",
      "MAPE:  0.06783844048663396\n",
      "Delta:  0.002533086936806165\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.01865317939224509 0.027981781650566973 -77.99874787439762\n",
      "Epoch: 1194\n",
      "Arb loss 0.019912205738495194\n",
      "Real arb loss 1.924745255340616e-05\n",
      "Bounds loss: 0.3964221848153906\n",
      "MAPE:  0.06565525228207733\n",
      "Delta:  0.002485836811757767\n",
      "GRAD\n",
      " tensor([-18.9530,   0.2874,   3.8615,  39.2093])\n",
      "-0.009224185890496006 -0.010030676212477108 0.6959369175493956\n",
      "Epoch: 1195\n",
      "Arb loss 0.006054566655237463\n",
      "Real arb loss 5.8674342908613084e-06\n",
      "Bounds loss: 0.4003985673947165\n",
      "MAPE:  0.06640007332808116\n",
      "Delta:  0.002508766632602859\n",
      "GRAD\n",
      " tensor([-6.3992, -0.6042,  1.9402, 12.7222])\n",
      "0.008496376583447263 0.012899885604890304 -2.0198848546939354\n",
      "Epoch: 1196\n",
      "Arb loss 0.018284094143886532\n",
      "Real arb loss 1.767745410483416e-05\n",
      "Bounds loss: 0.3952334716789627\n",
      "MAPE:  0.06544758955165118\n",
      "Delta:  0.002487451206532278\n",
      "GRAD\n",
      " tensor([-18.9989,   0.2658,   3.8515,  39.1541])\n",
      "-0.005161519847833418 -0.007896716593144726 0.5348650544748217\n",
      "arb imp changed to 1025.2017872263325\n",
      "Epoch: 1197\n",
      "Arb loss 0.008508823419160691\n",
      "Real arb loss 8.236957582987653e-06\n",
      "Bounds loss: 0.3983545183929361\n",
      "MAPE:  0.06605775458966329\n",
      "Delta:  0.0025002902353053118\n",
      "GRAD\n",
      " tensor([-6.3998, -0.6062,  1.9387, 12.7400])\n",
      "0.006737964715046285 0.0104855463273964 -1.184386266536094\n",
      "Epoch: 1198\n",
      "Arb loss 0.018586557021195303\n",
      "Real arb loss 1.7960475848871507e-05\n",
      "Bounds loss: 0.3941775536355993\n",
      "MAPE:  0.06529193114929809\n",
      "Delta:  0.0024834433679224496\n",
      "GRAD\n",
      " tensor([-19.0137,   0.2573,   3.8470,  39.1593])\n",
      "-0.0045050164279543115 -0.007869002629259159 0.510078923248674\n",
      "Epoch: 1199\n",
      "Arb loss 0.009105946028923922\n",
      "Real arb loss 8.814295260923545e-06\n",
      "Bounds loss: 0.3972793378415528\n",
      "MAPE:  0.0659149005336947\n",
      "Delta:  0.0024946313210928344\n",
      "GRAD\n",
      " tensor([-6.4017, -0.6078,  1.9377, 12.7476])\n",
      "0.006850398312700845 0.010394385083445146 -1.1441839398175935\n",
      "Epoch: 1200\n",
      "Arb loss 0.019524823232064465\n",
      "Real arb loss 1.8865127689523854e-05\n",
      "Bounds loss: 0.3931498634183316\n",
      "MAPE:  0.06516028073055957\n",
      "Delta:  0.0024775421029000094\n",
      "GRAD\n",
      " tensor([-19.0064,   0.2580,   3.8464,  39.1758])\n",
      "-0.0060548981007142455 -0.010031262634077054 0.6151973171291896\n",
      "Epoch: 1201\n",
      "Arb loss 0.0075132043622767345\n",
      "Real arb loss 7.2750788569755655e-06\n",
      "Bounds loss: 0.3970936529528324\n",
      "MAPE:  0.06593115326913473\n",
      "Delta:  0.002492543367873298\n",
      "GRAD\n",
      " tensor([-6.3994, -0.6068,  1.9381, 12.7359])\n",
      "0.009126404603411298 0.012721458259414509 -1.8682988574390933\n",
      "Epoch: 1202\n",
      "Arb loss 0.021550115488024768\n",
      "Real arb loss 2.081753547548137e-05\n",
      "Bounds loss: 0.39204204262171455\n",
      "MAPE:  0.06502770500125726\n",
      "Delta:  0.002469795408606537\n",
      "GRAD\n",
      " tensor([-18.9894,   0.2625,   3.8473,  39.2144])\n",
      "-0.00667602069319484 -0.010296235153972377 0.6250846944593711\n",
      "Epoch: 1203\n",
      "Arb loss 0.008079468132628644\n",
      "Real arb loss 7.822058013029848e-06\n",
      "Bounds loss: 0.39607859968279135\n",
      "MAPE:  0.06580866606224099\n",
      "Delta:  0.002486283813862352\n",
      "GRAD\n",
      " tensor([-6.3998, -0.6077,  1.9375, 12.7464])\n",
      "0.007409463658201165 0.01068688031411591 -1.3382890244055692\n",
      "Epoch: 1204\n",
      "Arb loss 0.018892131657560117\n",
      "Real arb loss 1.8256716984834387e-05\n",
      "Bounds loss: 0.3918457550929988\n",
      "MAPE:  0.06505152751373665\n",
      "Delta:  0.0024678617842995645\n",
      "GRAD\n",
      " tensor([-18.9943,   0.2607,   3.8466,  39.1900])\n",
      "-0.004444104401829074 -0.008027499585742115 0.5125331233201551\n",
      "Epoch: 1205\n",
      "Arb loss 0.009209288412935251\n",
      "Real arb loss 8.914436255231282e-06\n",
      "Bounds loss: 0.39499129672968264\n",
      "MAPE:  0.06568859689446363\n",
      "Delta:  0.0024788292197182762\n",
      "GRAD\n",
      " tensor([-6.3990, -0.6081,  1.9370, 12.7627])\n",
      "0.0067988270899289605 0.010334897186237146 -1.1513533966197556\n",
      "Epoch: 1206\n",
      "Arb loss 0.019812433907619213\n",
      "Real arb loss 1.9143924619609165e-05\n",
      "Bounds loss: 0.3909091022885229\n",
      "MAPE:  0.06494211539950605\n",
      "Delta:  0.002461976088467948\n",
      "GRAD\n",
      " tensor([-18.9849,   0.2627,   3.8467,  39.2102])\n",
      "-0.006160602426658945 -0.010249399230533252 0.6215580787141799\n",
      "Delta imp changed to 0.008042738814400962\n",
      "Epoch: 1207\n",
      "Arb loss 0.007497855553347745\n",
      "Real arb loss 7.260720523857813e-06\n",
      "Bounds loss: 0.39491568574072733\n",
      "MAPE:  0.06572401325453373\n",
      "Delta:  0.002416725213983356\n",
      "GRAD\n",
      " tensor([-6.3958, -0.6066,  1.9377, 12.7498])\n",
      "0.009060967221544036 0.01271314596712203 -1.8849164356678547\n",
      "arb imp changed to 1025.7143881199456\n",
      "Epoch: 1208\n",
      "Arb loss 0.021641502061475464\n",
      "Real arb loss 2.0896493157185303e-05\n",
      "Bounds loss: 0.38989506498319937\n",
      "MAPE:  0.06482754965677684\n",
      "Delta:  0.0023948273460359737\n",
      "GRAD\n",
      " tensor([-18.9761,   0.2643,   3.8465,  39.2547])\n",
      "-0.006795370606278661 -0.010514499996511217 0.6323386486666502\n",
      "Epoch: 1209\n",
      "Arb loss 0.007956743892805542\n",
      "Real arb loss 7.700104064100027e-06\n",
      "Bounds loss: 0.393994616642605\n",
      "MAPE:  0.0656210358472193\n",
      "Delta:  0.002411101085390339\n",
      "GRAD\n",
      " tensor([-6.3986, -0.6083,  1.9367, 12.7618])\n",
      "0.00888046337677817 0.012562574685840877 -1.801257788525271\n",
      "Epoch: 1210\n",
      "Arb loss 0.022288890801022407\n",
      "Real arb loss 2.1519955429839098e-05\n",
      "Bounds loss: 0.38904502984521305\n",
      "MAPE:  0.06473162362440693\n",
      "Delta:  0.0023896893905038198\n",
      "GRAD\n",
      " tensor([-18.9677,   0.2662,   3.8466,  39.2696])\n",
      "-0.006864300459035633 -0.0106187578107515 0.6324831334552239\n",
      "Epoch: 1211\n",
      "Arb loss 0.008191543305950438\n",
      "Real arb loss 7.926766699007784e-06\n",
      "Bounds loss: 0.3931762047946159\n",
      "MAPE:  0.06553296154266472\n",
      "Delta:  0.002406092936484008\n",
      "GRAD\n",
      " tensor([-6.3979, -0.6086,  1.9364, 12.7679])\n",
      "0.007307909996315476 0.010615019054074248 -1.3419974505385057\n",
      "Epoch: 1212\n",
      "Arb loss 0.01918457353851169\n",
      "Real arb loss 1.853119501807332e-05\n",
      "Bounds loss: 0.38900263188911244\n",
      "MAPE:  0.0647846838810108\n",
      "Delta:  0.0023885094258614126\n",
      "GRAD\n",
      " tensor([-18.9726,   0.2649,   3.8464,  39.2398])\n",
      "0.0017592237753445428 -6.301932615374758 -172.1466857304156\n",
      "Epoch: 1213\n",
      "Arb loss 3.321745325344731\n",
      "Real arb loss 0.0031237579735825857\n",
      "Bounds loss: 2.840471005257731\n",
      "MAPE:  0.20536026310854452\n",
      "Delta:  0.0023843075032918028\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.2444127401162719 0.3410555581397995 0.9031126940838817\n",
      "Epoch: 1214\n",
      "Arb loss 0.32183495551211067\n",
      "Real arb loss 0.0003105090280761962\n",
      "Bounds loss: 1.8717125811796382\n",
      "MAPE:  0.1852924065822439\n",
      "Delta:  0.001801552373132466\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.0016033491933666877 0.38415207005827934 1.0\n",
      "Epoch: 1215\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.152690318565355\n",
      "MAPE:  0.16008674987824567\n",
      "Delta:  0.0017986638555881963\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.03980754833492928 0.282975192259307 -inf\n",
      "Epoch: 1216\n",
      "Arb loss 0.0009120901615024167\n",
      "Real arb loss 8.842001902036011e-07\n",
      "Bounds loss: 0.8265075540538819\n",
      "MAPE:  0.13538277885173947\n",
      "Delta:  0.001727063457218579\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.040362872830473795 0.23930577548762788 -69.24337650175623\n",
      "Epoch: 1217\n",
      "Arb loss 0.0640682926179619\n",
      "Real arb loss 6.163923533892315e-05\n",
      "Bounds loss: 0.6287195228846352\n",
      "MAPE:  0.1170985728709694\n",
      "Delta:  0.001657354214524707\n",
      "GRAD\n",
      " tensor([-34.6295,   3.5917,   8.0051, 105.5739])\n",
      "-0.03311262207900567 0.04788476556111665 0.979109694474877\n",
      "Delta imp changed to 0.00784657445307411\n",
      "Epoch: 1218\n",
      "Arb loss 0.0013384062072622108\n",
      "Real arb loss 1.2976026771661723e-06\n",
      "Bounds loss: 0.5986134359276073\n",
      "MAPE:  0.11668697782851967\n",
      "Delta:  0.0016704717641768888\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.06195245434697538 0.19730678375561628 -105.19482251478415\n",
      "arb imp changed to 1026.1246328507204\n",
      "Epoch: 1219\n",
      "Arb loss 0.1422028755377123\n",
      "Real arb loss 0.00013619332701035662\n",
      "Bounds loss: 0.4805029441718325\n",
      "MAPE:  0.10125334377489775\n",
      "Delta:  0.0015669819384688088\n",
      "GRAD\n",
      " tensor([-59.3194,   3.0371,   9.4949, 161.7433])\n",
      "-0.0656100589039359 -0.1273506394685071 1.0\n",
      "Epoch: 1220\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 0.5416953013786157\n",
      "MAPE:  0.10991645559969929\n",
      "Delta:  0.0016697917157531509\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.071083187010898 0.20097537100673268 -inf\n",
      "Epoch: 1221\n",
      "Arb loss 0.12110335132420891\n",
      "Real arb loss 0.00011603198198716185\n",
      "Bounds loss: 0.4328278872114445\n",
      "MAPE:  0.09404257037772713\n",
      "Delta:  0.0015510975989530213\n",
      "GRAD\n",
      " tensor([-61.0217,   3.2325,   9.1190, 159.8535])\n",
      "-0.058702298809533815 -0.1348398436375391 0.9999992514815623\n",
      "Epoch: 1222\n",
      "Arb loss 9.064809132858709e-08\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 0.4911903318450021\n",
      "MAPE:  0.10233804736091631\n",
      "Delta:  0.001642150593689512\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.0632875479626932 0.1829331445841067 -1478427.326070517\n",
      "Epoch: 1223\n",
      "Arb loss 0.13401670592441037\n",
      "Real arb loss 0.00012836355118947334\n",
      "Bounds loss: 0.401335339851285\n",
      "MAPE:  0.0882028246337563\n",
      "Delta:  0.001538222909229422\n",
      "GRAD\n",
      " tensor([-73.1252,   4.0283,   9.8819, 190.0406])\n",
      "-0.07643801129817063 -0.20670550971286872 1.0\n",
      "Epoch: 1224\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 0.4842935658410323\n",
      "MAPE:  0.10023233631494871\n",
      "Delta:  0.0016558016093442052\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.05351569770136777 0.1581247518137724 -inf\n",
      "Epoch: 1225\n",
      "Arb loss 0.04875048744460701\n",
      "Real arb loss 4.693795848741664e-05\n",
      "Bounds loss: 0.4077147659374122\n",
      "MAPE:  0.08828823391345145\n",
      "Delta:  0.0015671902309651025\n",
      "GRAD\n",
      " tensor([-40.7438,   1.7530,   6.6992, 103.2601])\n",
      "-0.017629573627347295 -0.02739689696712655 0.7450641014698027\n",
      "Epoch: 1226\n",
      "Arb loss 0.012428249320475992\n",
      "Real arb loss 1.2012766516782587e-05\n",
      "Bounds loss: 0.41888488537177554\n",
      "MAPE:  0.08992082766911606\n",
      "Delta:  0.0015948191265299613\n",
      "GRAD\n",
      " tensor([-5.9862, -0.5323,  1.9288, 14.5953])\n",
      "0.024802922949841877 0.08892773968011114 -4.975447992931709\n",
      "Epoch: 1227\n",
      "Arb loss 0.07426435745769314\n",
      "Real arb loss 7.13207307155314e-05\n",
      "Bounds loss: 0.3816343993295011\n",
      "MAPE:  0.08351469087890653\n",
      "Delta:  0.0015552629506157046\n",
      "GRAD\n",
      " tensor([-52.3794,   1.7804,   6.5742, 132.1478])\n",
      "-0.03076061787129425 -0.0742024560462915 0.881734322531786\n",
      "Epoch: 1228\n",
      "Arb loss 0.008782924546475696\n",
      "Real arb loss 8.497025706475492e-06\n",
      "Bounds loss: 0.4099526090715013\n",
      "MAPE:  0.08798734611387066\n",
      "Delta:  0.0016031037999289757\n",
      "GRAD\n",
      " tensor([-6.0378, -0.5552,  1.9186, 14.5528])\n",
      "0.026695205271422662 0.08996058108845062 -6.555770710345422\n",
      "Epoch: 1229\n",
      "Arb loss 0.06636176403943492\n",
      "Real arb loss 6.375539416677862e-05\n",
      "Bounds loss: 0.3730730341407026\n",
      "MAPE:  0.08141349314097265\n",
      "Delta:  0.001560308614918474\n",
      "GRAD\n",
      " tensor([-40.7684,   1.7174,   6.6735, 101.6584])\n",
      "-0.02038196234856482 -0.04237863289280308 0.6576211356149307\n",
      "arb imp changed to 1026.432398423137\n",
      "Epoch: 1230\n",
      "Arb loss 0.022732225843116856\n",
      "Real arb loss 2.1934201891311832e-05\n",
      "Bounds loss: 0.38888335929675555\n",
      "MAPE:  0.08398718932407714\n",
      "Delta:  0.0015921107663598836\n",
      "GRAD\n",
      " tensor([-29.7468,   1.4154,   4.6759,  71.3375])\n",
      "-4.256160189397562e-05 0.012069210220779114 -0.14999685523187334\n",
      "Epoch: 1231\n",
      "Arb loss 0.026141988232005104\n",
      "Real arb loss 2.52165287032749e-05\n",
      "Bounds loss: 0.3841898442820402\n",
      "MAPE:  0.08287180751954007\n",
      "Delta:  0.0015921785291444926\n",
      "GRAD\n",
      " tensor([-29.7295,   1.4193,   4.6762,  71.4070])\n",
      "-0.0015682390940519042 0.008609584263877146 -0.029875101344769783\n",
      "Epoch: 1232\n",
      "Arb loss 0.026922982779790036\n",
      "Real arb loss 2.596879966550136e-05\n",
      "Bounds loss: 0.38088212944436817\n",
      "MAPE:  0.0820112637650276\n",
      "Delta:  0.0015946754457586072\n",
      "GRAD\n",
      " tensor([-29.7555,   1.4076,   4.6710,  71.4167])\n",
      "-0.0024104319070439306 0.006336245605124247 0.02212565771980357\n",
      "Epoch: 1233\n",
      "Arb loss 0.026327294078008236\n",
      "Real arb loss 2.539756369814836e-05\n",
      "Bounds loss: 0.3784687667256059\n",
      "MAPE:  0.08131844579198785\n",
      "Delta:  0.0015985193023344434\n",
      "GRAD\n",
      " tensor([-29.7980,   1.3908,   4.6643,  71.3984])\n",
      "-0.0029377964475685303 0.004661896049165559 0.1841503850416517\n",
      "Epoch: 1234\n",
      "Arb loss 0.02147911273643822\n",
      "Real arb loss 2.072417645581672e-05\n",
      "Bounds loss: 0.3767043846772753\n",
      "MAPE:  0.08074843512472313\n",
      "Delta:  0.0016032154266622115\n",
      "GRAD\n",
      " tensor([-17.8225,   0.4682,   3.8171,  44.2972])\n",
      "0.006037090851684579 0.03177270305740809 -1.0143101940635608\n",
      "Epoch: 1235\n",
      "Arb loss 0.04326559574444797\n",
      "Real arb loss 4.165784329702341e-05\n",
      "Bounds loss: 0.3647354681225006\n",
      "MAPE:  0.0783752228346848\n",
      "Delta:  0.0015935366694766293\n",
      "GRAD\n",
      " tensor([-41.4164,   1.4689,   6.5792, 101.1882])\n",
      "-0.018868568349094117 -0.0429960181226674 0.7739813788307259\n",
      "Epoch: 1236\n",
      "Arb loss 0.009778830294227344\n",
      "Real arb loss 9.453736833038609e-06\n",
      "Bounds loss: 0.3804176409198752\n",
      "MAPE:  0.08100535197221445\n",
      "Delta:  0.0016236044250414368\n",
      "GRAD\n",
      " tensor([-6.0351, -0.5501,  1.9225, 14.4455])\n",
      "0.020919104505699115 0.07094806205473836 -5.433537842555031\n",
      "Epoch: 1237\n",
      "Arb loss 0.06291247475383517\n",
      "Real arb loss 6.0447915554867474e-05\n",
      "Bounds loss: 0.3534277465251747\n",
      "MAPE:  0.07574321033354217\n",
      "Delta:  0.0015896400743980795\n",
      "GRAD\n",
      " tensor([-52.7794,   2.6590,   6.5432, 129.9213])\n",
      "-0.03281419498703686 -0.08589826919623 0.9492187758639927\n",
      "Epoch: 1238\n",
      "Arb loss 0.003194772481425406\n",
      "Real arb loss 3.0930706078329644e-06\n",
      "Bounds loss: 0.3837865782376111\n",
      "MAPE:  0.08113495971071788\n",
      "Delta:  0.001641802833758586\n",
      "GRAD\n",
      " tensor([-0.0114, -0.0048, -0.0020,  0.0120])\n",
      "0.02997715438533144 0.09297320576354218 -19.39782068951339\n",
      "Epoch: 1239\n",
      "Arb loss 0.06516639621990718\n",
      "Real arb loss 6.260475481479244e-05\n",
      "Bounds loss: 0.3481047097298399\n",
      "MAPE:  0.07409926643356106\n",
      "Delta:  0.00159258625674073\n",
      "GRAD\n",
      " tensor([-40.8217,   1.7368,   6.6995,  99.8455])\n",
      "-0.02633711687711182 -0.06140171438959685 0.8422467684478656\n",
      "Epoch: 1240\n",
      "Arb loss 0.010280209592297154\n",
      "Real arb loss 9.937117814635152e-06\n",
      "Bounds loss: 0.36947893569434503\n",
      "MAPE:  0.07810467334286453\n",
      "Delta:  0.0016345303871213926\n",
      "GRAD\n",
      " tensor([-6.0810, -0.5705,  1.9134, 14.4395])\n",
      "0.019265907347564504 0.06370349870168435 -4.5074991907651984\n",
      "arb imp changed to 1026.9456146223486\n",
      "Epoch: 1241\n",
      "Arb loss 0.05664655513347844\n",
      "Real arb loss 5.442974015489714e-05\n",
      "Bounds loss: 0.3459418347940406\n",
      "MAPE:  0.07327867769049048\n",
      "Delta:  0.0016030396761263332\n",
      "GRAD\n",
      " tensor([-41.0868,   1.6293,   6.6560,  99.6276])\n",
      "-0.024103979990517832 -0.05829343566558487 0.8210655207246144\n",
      "Epoch: 1242\n",
      "Arb loss 0.01013602184555339\n",
      "Real arb loss 9.794250000643381e-06\n",
      "Bounds loss: 0.36610797288464136\n",
      "MAPE:  0.07709181933889436\n",
      "Delta:  0.0016416793124036885\n",
      "GRAD\n",
      " tensor([-18.0895,   0.3667,   3.7790,  44.0405])\n",
      "0.008770597050823281 0.032426344770657756 -1.9604706770222906\n",
      "Epoch: 1243\n",
      "Arb loss 0.030007395455418175\n",
      "Real arb loss 2.8915456287173277e-05\n",
      "Bounds loss: 0.3542364295325974\n",
      "MAPE:  0.07454585240637426\n",
      "Delta:  0.0016272808046679233\n",
      "GRAD\n",
      " tensor([-29.7173,   1.4538,   4.7032,  69.8258])\n",
      "-0.008066111743851856 -0.011477520936733487 0.35218356433634024\n",
      "Epoch: 1244\n",
      "Arb loss 0.019439283967478904\n",
      "Real arb loss 1.875666873791063e-05\n",
      "Bounds loss: 0.35830218556911153\n",
      "MAPE:  0.07522366691057525\n",
      "Delta:  0.0016404066334769999\n",
      "GRAD\n",
      " tensor([-18.0160,   0.3944,   3.7892,  44.1426])\n",
      "0.003973749824134565 0.02161496469745039 -0.7087161757364169\n",
      "Epoch: 1245\n",
      "Arb loss 0.033216218959964794\n",
      "Real arb loss 3.1995009671548137e-05\n",
      "Bounds loss: 0.35055749647701584\n",
      "MAPE:  0.07349704700417713\n",
      "Delta:  0.0016338880679057117\n",
      "GRAD\n",
      " tensor([-29.7123,   1.4588,   4.7065,  69.7820])\n",
      "-0.008831524782533684 -0.01385157326921016 0.38037244262116054\n",
      "Epoch: 1246\n",
      "Arb loss 0.020581684619523682\n",
      "Real arb loss 1.9855507098524195e-05\n",
      "Bounds loss: 0.35541326932453815\n",
      "MAPE:  0.07436906524267212\n",
      "Delta:  0.001648317790869307\n",
      "GRAD\n",
      " tensor([-29.8370,   1.4248,   4.7000,  69.5680])\n",
      "-0.006465864209876715 -0.00927063536624706 0.30236226241850506\n",
      "Epoch: 1247\n",
      "Arb loss 0.014358559893580354\n",
      "Real arb loss 1.386701340955895e-05\n",
      "Bounds loss: 0.3587081761487717\n",
      "MAPE:  0.07486497136910787\n",
      "Delta:  0.001658975589879792\n",
      "GRAD\n",
      " tensor([-18.0401,   0.3962,   3.7951,  44.0190])\n",
      "0.004081853308975036 0.021371396665475273 -0.8826262240450418\n",
      "Epoch: 1248\n",
      "Arb loss 0.027031801395175758\n",
      "Real arb loss 2.6060870913507772e-05\n",
      "Bounds loss: 0.3510420814291471\n",
      "MAPE:  0.07313791353399554\n",
      "Delta:  0.0016522038948787324\n",
      "GRAD\n",
      " tensor([-29.7535,   1.4612,   4.7158,  69.5950])\n",
      "-0.008150424131034173 -0.012696059198783693 0.3804429139837491\n",
      "Epoch: 1249\n",
      "Arb loss 0.01674774410216512\n",
      "Real arb loss 1.6168744727928626e-05\n",
      "Bounds loss: 0.3554989324762359\n",
      "MAPE:  0.0739325108767204\n",
      "Delta:  0.0016656700573729406\n",
      "GRAD\n",
      " tensor([-18.0317,   0.4022,   3.7986,  44.0042])\n",
      "0.002952099320652102 0.01796161562369969 -0.6309817954285823\n",
      "Epoch: 1250\n",
      "Arb loss 0.027315265745127718\n",
      "Real arb loss 2.6330916609253265e-05\n",
      "Bounds loss: 0.34911359729646213\n",
      "MAPE:  0.07244901162873431\n",
      "Delta:  0.0016607528339281394\n",
      "GRAD\n",
      " tensor([-29.7541,   1.4675,   4.7212,  69.5233])\n",
      "-0.007685195585696247 -0.011929360283814194 0.4372662510090425\n",
      "Epoch: 1251\n",
      "Arb loss 0.015371221897440002\n",
      "Real arb loss 1.4834610422127237e-05\n",
      "Bounds loss: 0.3532782991785901\n",
      "MAPE:  0.07319957349973376\n",
      "Delta:  0.0016735160442763765\n",
      "GRAD\n",
      " tensor([-6.0037, -0.5265,  1.9368, 14.3124])\n",
      "0.011910717844335839 0.04362435853451152 -2.5022323959168657\n",
      "arb imp changed to 1027.4590874296596\n",
      "Epoch: 1252\n",
      "Arb loss 0.0538605080896881\n",
      "Real arb loss 5.177050571816647e-05\n",
      "Bounds loss: 0.33786675999276083\n",
      "MAPE:  0.06971912139570269\n",
      "Delta:  0.0016535832668650315\n",
      "GRAD\n",
      " tensor([-41.2248,   1.6279,   6.6794,  99.0194])\n",
      "-0.024854851616662677 -0.06258887094273491 0.9169857045560534\n",
      "Epoch: 1253\n",
      "Arb loss 0.004471192131318441\n",
      "Real arb loss 4.322525136327026e-06\n",
      "Bounds loss: 0.35901345902978776\n",
      "MAPE:  0.07402806826112818\n",
      "Delta:  0.0016946828335987583\n",
      "GRAD\n",
      " tensor([-0.0104, -0.0044, -0.0018,  0.0107])\n",
      "0.023181801563038396 0.0687131875950937 -13.145113263629915\n",
      "Epoch: 1254\n",
      "Arb loss 0.0632455191209502\n",
      "Real arb loss 6.078284146797159e-05\n",
      "Bounds loss: 0.33434449987031045\n",
      "MAPE:  0.06840748908507834\n",
      "Delta:  0.001655397032437984\n",
      "GRAD\n",
      " tensor([-41.2300,   1.6193,   6.6730,  99.0800])\n",
      "-0.027276109273804083 -0.06860884245133114 0.9429353955618945\n",
      "Epoch: 1255\n",
      "Arb loss 0.0036090805311196567\n",
      "Real arb loss 3.49020743280723e-06\n",
      "Bounds loss: 0.3572834889863817\n",
      "MAPE:  0.07324467420619096\n",
      "Delta:  0.0017005498227862935\n",
      "GRAD\n",
      " tensor([-0.0098, -0.0041, -0.0017,  0.0100])\n",
      "0.024241643927252587 0.06944650607648184 -17.339020992567395\n",
      "Epoch: 1256\n",
      "Arb loss 0.06618700362406967\n",
      "Real arb loss 6.361579632792926e-05\n",
      "Bounds loss: 0.3324713989974623\n",
      "MAPE:  0.06745406519821646\n",
      "Delta:  0.0016593256995017557\n",
      "GRAD\n",
      " tensor([-52.7642,   1.7816,   6.6440, 126.2679])\n",
      "-0.03763409336412371 -0.10117572284365894 0.9999929025917237\n",
      "Epoch: 1257\n",
      "Arb loss 4.697561873044859e-07\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 0.3661094331158731\n",
      "MAPE:  0.07460982300420345\n",
      "Delta:  0.0017217729177982945\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.029710255371257044 0.08145234689729686 -90953.14596315887\n",
      "Epoch: 1258\n",
      "Arb loss 0.0427262728271892\n",
      "Real arb loss 4.1098389605901135e-05\n",
      "Bounds loss: 0.33628896056734625\n",
      "MAPE:  0.0677251901897235\n",
      "Delta:  0.001670618604719193\n",
      "GRAD\n",
      " tensor([-29.3880,   0.6413,   4.8027,  69.2671])\n",
      "-0.017137807029810048 -0.033085832395312265 0.7492920525317839\n",
      "Epoch: 1259\n",
      "Arb loss 0.010711816163471622\n",
      "Real arb loss 1.034316087080987e-05\n",
      "Bounds loss: 0.3474153607530712\n",
      "MAPE:  0.07025138925882667\n",
      "Delta:  0.001699249343987281\n",
      "GRAD\n",
      " tensor([-6.0575, -0.5476,  1.9285, 14.2737])\n",
      "0.012341922617138845 0.04052126432973391 -2.89418534143245\n",
      "Epoch: 1260\n",
      "Arb loss 0.04171379748391038\n",
      "Real arb loss 4.0124468342051295e-05\n",
      "Bounds loss: 0.3333376510877862\n",
      "MAPE:  0.06690266824303749\n",
      "Delta:  0.001678277340076566\n",
      "GRAD\n",
      " tensor([-29.4975,   0.5932,   4.7816,  69.1063])\n",
      "-0.015280445951231902 -0.03332254310606131 0.7066877135500085\n",
      "Epoch: 1261\n",
      "Arb loss 0.012235169316517658\n",
      "Real arb loss 1.1811524230110416e-05\n",
      "Bounds loss: 0.34444530933503215\n",
      "MAPE:  0.06933173683191703\n",
      "Delta:  0.0017039221662627833\n",
      "GRAD\n",
      " tensor([-18.0073,   0.4370,   3.8236,  42.5450])\n",
      "0.0033246400851263402 0.013844484750588526 -0.7758477683094764\n",
      "Epoch: 1262\n",
      "Arb loss 0.021727798125626464\n",
      "Real arb loss 2.093740664627552e-05\n",
      "Bounds loss: 0.3396766415025316\n",
      "MAPE:  0.06813102769067986\n",
      "Delta:  0.0016982572383268909\n",
      "GRAD\n",
      " tensor([-17.9094,   0.4738,   3.8372,  42.6608])\n",
      "-0.0002679597972272685 0.007363431732384629 -0.2536353760124299\n",
      "arb imp changed to 1027.9728169733744\n",
      "Epoch: 1263\n",
      "Arb loss 0.027252355741328473\n",
      "Real arb loss 2.622596509734774e-05\n",
      "Bounds loss: 0.33717545574174196\n",
      "MAPE:  0.06751320004463714\n",
      "Delta:  0.0016987123029921125\n",
      "GRAD\n",
      " tensor([-29.5947,   0.5772,   4.7853,  67.8765])\n",
      "-0.010662501413748249 -0.021532847984203407 0.5207679800113654\n",
      "Delta imp changed to 0.007655194588364986\n",
      "Epoch: 1264\n",
      "Arb loss 0.013060201491365709\n",
      "Real arb loss 1.2600500799115042e-05\n",
      "Bounds loss: 0.3444358035742334\n",
      "MAPE:  0.0691122362058335\n",
      "Delta:  0.0016749510490968954\n",
      "GRAD\n",
      " tensor([-17.9528,   0.4704,   3.8420,  42.5125])\n",
      "0.00114870680749235 0.009708040766438275 -0.47352970039116893\n",
      "Epoch: 1265\n",
      "Arb loss 0.01924459479062041\n",
      "Real arb loss 1.8546324418990127e-05\n",
      "Bounds loss: 0.3410920067517138\n",
      "MAPE:  0.06826886697071316\n",
      "Delta:  0.0016730270214245812\n",
      "GRAD\n",
      " tensor([-17.8933,   0.4930,   3.8505,  42.5668])\n",
      "-0.0003006280895059277 0.007053471178713577 -0.23439506703531765\n",
      "Epoch: 1266\n",
      "Arb loss 0.023755432876635407\n",
      "Real arb loss 2.2871989307969992e-05\n",
      "Bounds loss: 0.338686124112801\n",
      "MAPE:  0.06765633697789454\n",
      "Delta:  0.0016735299803417238\n",
      "GRAD\n",
      " tensor([-29.5745,   0.6060,   4.8060,  67.7155])\n",
      "-0.010714177632540789 -0.021962990924363046 0.5763848354842298\n",
      "Epoch: 1267\n",
      "Arb loss 0.010063161606179243\n",
      "Real arb loss 9.71377428320628e-06\n",
      "Bounds loss: 0.34612468438289823\n",
      "MAPE:  0.06928261595565283\n",
      "Delta:  0.0016914604778244873\n",
      "GRAD\n",
      " tensor([-6.0449, -0.5351,  1.9368, 14.2168])\n",
      "0.011218118745061179 0.03633607983812881 -3.1901924494386478\n",
      "Epoch: 1268\n",
      "Arb loss 0.042166583779693165\n",
      "Real arb loss 4.0581669773694714e-05\n",
      "Bounds loss: 0.3335478702172141\n",
      "MAPE:  0.06625082518806685\n",
      "Delta:  0.0016724854733316742\n",
      "GRAD\n",
      " tensor([-29.4554,   0.6484,   4.8206,  67.7834])\n",
      "-0.016720331963608448 -0.037813511676961564 0.836520846287353\n",
      "Epoch: 1269\n",
      "Arb loss 0.006893357431257669\n",
      "Real arb loss 6.659401634142762e-06\n",
      "Bounds loss: 0.3461604865024983\n",
      "MAPE:  0.06899221954843412\n",
      "Delta:  0.001700449985650093\n",
      "GRAD\n",
      " tensor([-6.0630, -0.5422,  1.9341, 14.1728])\n",
      "0.014197271593159755 0.040549675923321704 -4.9193467277105585\n",
      "Epoch: 1270\n",
      "Arb loss 0.04080417275365434\n",
      "Real arb loss 3.927037283003504e-05\n",
      "Bounds loss: 0.33212379095736266\n",
      "MAPE:  0.06561542409643271\n",
      "Delta:  0.001676308235373234\n",
      "GRAD\n",
      " tensor([-29.4958,   1.6304,   4.8126,  67.7587])\n",
      "-0.01472933477970817 -0.033807518039896234 0.7850310257181422\n",
      "Epoch: 1271\n",
      "Arb loss 0.0087716311632728\n",
      "Real arb loss 8.46911432511904e-06\n",
      "Bounds loss: 0.34335207201163237\n",
      "MAPE:  0.06800844111809087\n",
      "Delta:  0.0017009991405660281\n",
      "GRAD\n",
      " tensor([-6.0721, -0.5469,  1.9317, 14.1940])\n",
      "0.01242840917349286 0.036402179347888475 -3.931311868552009\n",
      "Epoch: 1272\n",
      "Arb loss 0.04325564886200782\n",
      "Real arb loss 4.163433677791221e-05\n",
      "Bounds loss: 0.3308533083067958\n",
      "MAPE:  0.06504591226222076\n",
      "Delta:  0.0016798584272433139\n",
      "GRAD\n",
      " tensor([-29.5283,   1.6160,   4.8062,  67.7411])\n",
      "-0.015567914231239266 -0.03627454408829256 0.8207624095810826\n",
      "Epoch: 1273\n",
      "Arb loss 0.007753038274033068\n",
      "Real arb loss 7.487879410407484e-06\n",
      "Bounds loss: 0.3428548612257281\n",
      "MAPE:  0.06760961089388423\n",
      "Delta:  0.0017060103191592624\n",
      "GRAD\n",
      " tensor([-6.0816, -0.5506,  1.9303, 14.1819])\n",
      "0.013100208734015295 0.03693673639060424 -4.670448480977028\n",
      "arb imp changed to 1028.4868033818611\n",
      "Epoch: 1274\n",
      "Arb loss 0.04398518570599955\n",
      "Real arb loss 4.2320511079511693e-05\n",
      "Bounds loss: 0.33019092159639624\n",
      "MAPE:  0.06462826235650052\n",
      "Delta:  0.001683661227875892\n",
      "GRAD\n",
      " tensor([-29.5691,   1.5997,   4.7997,  67.7431])\n",
      "-0.016522840642006376 -0.03891803754597323 0.8746441008549144\n",
      "Epoch: 1275\n",
      "Arb loss 0.00551380250323914\n",
      "Real arb loss 5.324478872699715e-06\n",
      "Bounds loss: 0.3430413042804243\n",
      "MAPE:  0.06735846992347659\n",
      "Delta:  0.00171148009403921\n",
      "GRAD\n",
      " tensor([-0.0085, -0.0036, -0.0015,  0.0086])\n",
      "0.017858011559086506 0.04837140507953963 -10.281392394429934\n",
      "Epoch: 1276\n",
      "Arb loss 0.06220336962443077\n",
      "Real arb loss 5.982678338110463e-05\n",
      "Bounds loss: 0.3264479143920622\n",
      "MAPE:  0.06350435979709555\n",
      "Delta:  0.0016809164627367113\n",
      "GRAD\n",
      " tensor([-41.1096,   1.7652,   6.7745,  95.8070])\n",
      "-0.028378793020214177 -0.07318837590162963 0.9944201417035567\n",
      "Epoch: 1277\n",
      "Arb loss 0.0003470859880656062\n",
      "Real arb loss 3.352426001845023e-07\n",
      "Bounds loss: 0.35034010706289154\n",
      "MAPE:  0.06868438513027503\n",
      "Delta:  0.0017286188431169872\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.02475612793256421 0.06213531320041088 -144.8055687427153\n",
      "Epoch: 1278\n",
      "Arb loss 0.050607069892533\n",
      "Real arb loss 4.8691299137363546e-05\n",
      "Bounds loss: 0.3285716147838733\n",
      "MAPE:  0.06362893484227114\n",
      "Delta:  0.0016858249338901417\n",
      "GRAD\n",
      " tensor([-41.1399,   1.7644,   6.7791,  95.8557])\n",
      "-0.02813792992654185 -0.06883969562280523 0.996229687874389\n",
      "Delta imp changed to 0.007468482525234133\n",
      "Epoch: 1279\n",
      "Arb loss 0.00019080444925746116\n",
      "Real arb loss 1.8428291226285297e-07\n",
      "Bounds loss: 0.3511903847358887\n",
      "MAPE:  0.06855017652654623\n",
      "Delta:  0.0016909859099983999\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.023702246436200558 0.06037041430369394 -224.76039677477027\n",
      "Epoch: 1280\n",
      "Arb loss 0.04307608817075595\n",
      "Real arb loss 4.14547236081128e-05\n",
      "Bounds loss: 0.3299888757099094\n",
      "MAPE:  0.0636758098314665\n",
      "Delta:  0.0016509057452394748\n",
      "GRAD\n",
      " tensor([-41.1808,   1.7579,   6.7808,  95.8352])\n",
      "-0.027281674608009565 -0.0647597096845216 0.996459010404595\n",
      "Epoch: 1281\n",
      "Arb loss 0.00015253198002339747\n",
      "Real arb loss 1.472579217728226e-07\n",
      "Bounds loss: 0.35135885950000484\n",
      "MAPE:  0.06833907211461637\n",
      "Delta:  0.0016959452185895917\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.022801126125590376 0.058638959690621606 -231.59340227583897\n",
      "Epoch: 1282\n",
      "Arb loss 0.03547793218951232\n",
      "Real arb loss 3.415109604554346e-05\n",
      "Bounds loss: 0.3307555415008413\n",
      "MAPE:  0.06363391564078374\n",
      "Delta:  0.0016572757577584384\n",
      "GRAD\n",
      " tensor([-17.6864,   0.5983,   3.9024,  42.3758])\n",
      "-0.010940853200884781 -0.016712916348288864 0.6920458217394624\n",
      "Epoch: 1283\n",
      "Arb loss 0.010925577453804342\n",
      "Real arb loss 1.0536490665277689e-05\n",
      "Bounds loss: 0.3362834311976779\n",
      "MAPE:  0.06473033537142159\n",
      "Delta:  0.0016754077685374588\n",
      "GRAD\n",
      " tensor([-6.0174, -0.5189,  1.9456, 14.1105])\n",
      "0.008742802966103969 0.026730967648003867 -3.5815891198151544\n",
      "Epoch: 1284\n",
      "Arb loss 0.05005650679004773\n",
      "Real arb loss 4.817667845603446e-05\n",
      "Bounds loss: 0.32729424967777304\n",
      "MAPE:  0.06277289340285305\n",
      "Delta:  0.0016607600085292557\n",
      "GRAD\n",
      " tensor([-41.3115,   1.7001,   6.7553,  95.6282])\n",
      "-0.027180979250251536 -0.06867494077482061 0.9984645654873446\n",
      "arb imp changed to 1029.001046783552\n",
      "Epoch: 1285\n",
      "Arb loss 7.689691735246373e-05\n",
      "Real arb loss 7.399148310069728e-08\n",
      "Bounds loss: 0.34977116289033344\n",
      "MAPE:  0.06763711274571205\n",
      "Delta:  0.001705901091860737\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.023491361253362153 0.05785758105304828 -490.5846257134863\n",
      "Epoch: 1286\n",
      "Arb loss 0.03780134233523177\n",
      "Real arb loss 3.6377900689111795e-05\n",
      "Bounds loss: 0.32953424948338705\n",
      "MAPE:  0.0630440940325665\n",
      "Delta:  0.0016658271530493316\n",
      "GRAD\n",
      " tensor([-29.3453,   0.7368,   4.8752,  66.2979])\n",
      "-0.018789231651315408 -0.04020659657037351 0.9324172955492686\n",
      "Epoch: 1287\n",
      "Arb loss 0.002554716946882892\n",
      "Real arb loss 2.467919127694302e-06\n",
      "Bounds loss: 0.34278370010848636\n",
      "MAPE:  0.06584879753549613\n",
      "Delta:  0.0016971267653190269\n",
      "GRAD\n",
      " tensor([-0.0061, -0.0026, -0.0011,  0.0061])\n",
      "0.017244062176435482 0.04502027867600977 -15.573801035204461\n",
      "Epoch: 1288\n",
      "Arb loss 0.04234137037890205\n",
      "Real arb loss 4.074553680946273e-05\n",
      "Bounds loss: 0.3273514824040086\n",
      "MAPE:  0.062420368079588416\n",
      "Delta:  0.0016678614058565726\n",
      "GRAD\n",
      " tensor([-29.3668,   0.7225,   4.8671,  66.2641])\n",
      "-0.018209707385725027 -0.041243109834325775 0.9232636051712164\n",
      "Epoch: 1289\n",
      "Arb loss 0.0032491241149871877\n",
      "Real arb loss 3.1381246959971407e-06\n",
      "Bounds loss: 0.3408524755472264\n",
      "MAPE:  0.06522213305188784\n",
      "Delta:  0.0016982326740171648\n",
      "GRAD\n",
      " tensor([-0.0100, -0.0042, -0.0018,  0.0100])\n",
      "0.017076024710634297 0.043608267565257375 -13.822927224446753\n",
      "Epoch: 1290\n",
      "Arb loss 0.04816153029965004\n",
      "Real arb loss 4.63430991128077e-05\n",
      "Bounds loss: 0.32598848959328264\n",
      "MAPE:  0.061936331997200375\n",
      "Delta:  0.001669233610911241\n",
      "GRAD\n",
      " tensor([-29.3832,   0.7119,   4.8611,  66.2597])\n",
      "-0.01882772934408128 -0.043232723517969696 0.934679327765306\n",
      "Epoch: 1291\n",
      "Arb loss 0.0031459435350247224\n",
      "Real arb loss 3.038513839065407e-06\n",
      "Bounds loss: 0.34008185983390954\n",
      "MAPE:  0.06485029806376573\n",
      "Delta:  0.0017006614895495216\n",
      "GRAD\n",
      " tensor([-0.0108, -0.0045, -0.0019,  0.0107])\n",
      "0.01720168791596255 0.04303449563302364 -14.758868180325843\n",
      "Epoch: 1292\n",
      "Arb loss 0.049576509471202894\n",
      "Real arb loss 4.770658956932209e-05\n",
      "Bounds loss: 0.3254466085220166\n",
      "MAPE:  0.06165041953251431\n",
      "Delta:  0.0016714072413555946\n",
      "GRAD\n",
      " tensor([-29.4115,   0.6990,   4.8553,  66.2489])\n",
      "-0.018789486235717856 -0.043392196823920814 0.938348412438647\n",
      "Delta imp changed to 0.00728632441486257\n",
      "Epoch: 1293\n",
      "Arb loss 0.003056470514650113\n",
      "Real arb loss 2.95210706673165e-06\n",
      "Bounds loss: 0.3395684518146814\n",
      "MAPE:  0.0645634690389283\n",
      "Delta:  0.0016612801216695854\n",
      "GRAD\n",
      " tensor([-0.0116, -0.0049, -0.0020,  0.0116])\n",
      "0.017055744373560167 0.04231072449261197 -15.383977479245765\n",
      "Epoch: 1294\n",
      "Arb loss 0.05007714407800617\n",
      "Real arb loss 4.819152815579151e-05\n",
      "Bounds loss: 0.3252010646035677\n",
      "MAPE:  0.06144485860161988\n",
      "Delta:  0.001632945752581512\n",
      "GRAD\n",
      " tensor([-29.4324,   0.6905,   4.8518,  66.2397])\n",
      "-0.018835403713879373 -0.04352068934049336 0.9436397396857394\n",
      "Epoch: 1295\n",
      "Arb loss 0.002822360876031161\n",
      "Real arb loss 2.726109433272835e-06\n",
      "Bounds loss: 0.3393540391093772\n",
      "MAPE:  0.06436620449579168\n",
      "Delta:  0.0016637029450742495\n",
      "GRAD\n",
      " tensor([-0.0118, -0.0049, -0.0021,  0.0118])\n",
      "0.016905186681086093 0.04172813600074099 -16.539197154864645\n",
      "arb imp changed to 1029.5155473069437\n",
      "Epoch: 1296\n",
      "Arb loss 0.04952669481881046\n",
      "Real arb loss 4.7643136116295336e-05\n",
      "Bounds loss: 0.3251934276130204\n",
      "MAPE:  0.06130185287498345\n",
      "Delta:  0.0016355777362058966\n",
      "GRAD\n",
      " tensor([-29.4660,   0.6778,   4.8470,  66.2404])\n",
      "-0.018888684776800835 -0.04362946152924363 0.9504451740615921\n",
      "Epoch: 1297\n",
      "Arb loss 0.002454286741050801\n",
      "Real arb loss 2.369480434317565e-06\n",
      "Bounds loss: 0.3393814417526255\n",
      "MAPE:  0.0642305126976588\n",
      "Delta:  0.0016664716484930432\n",
      "GRAD\n",
      " tensor([-0.0114, -0.0048, -0.0020,  0.0113])\n",
      "0.016793298055680084 0.04130340960311729 -18.60063340570749\n",
      "Epoch: 1298\n",
      "Arb loss 0.0481055746838253\n",
      "Real arb loss 4.6282636426273594e-05\n",
      "Bounds loss: 0.3253638310522204\n",
      "MAPE:  0.0612069329473008\n",
      "Delta:  0.001638486093398559\n",
      "GRAD\n",
      " tensor([-29.4838,   0.6725,   4.8457,  66.2213])\n",
      "-0.018915409853302867 -0.04368673701982484 0.9585769619886298\n",
      "Epoch: 1299\n",
      "Arb loss 0.001992679048686903\n",
      "Real arb loss 1.923643398268282e-06\n",
      "Bounds loss: 0.33957791517516145\n",
      "MAPE:  0.06413931897657124\n",
      "Delta:  0.00166947872939413\n",
      "GRAD\n",
      " tensor([-0.0106, -0.0044, -0.0018,  0.0105])\n",
      "0.01670763632111183 0.04098755770562745 -22.136114699277666\n",
      "Epoch: 1300\n",
      "Arb loss 0.04610285102926769\n",
      "Real arb loss 4.4362961901930754e-05\n",
      "Bounds loss: 0.32565944578136286\n",
      "MAPE:  0.06114982239886698\n",
      "Delta:  0.0016415856859375811\n",
      "GRAD\n",
      " tensor([-29.5011,   0.6680,   4.8450,  66.1998])\n",
      "-0.01893887170518216 -0.04373044371829993 0.9650868795460471\n",
      "Epoch: 1301\n",
      "Arb loss 0.0016095943912554699\n",
      "Real arb loss 1.5540629092738804e-06\n",
      "Bounds loss: 0.3399006778464375\n",
      "MAPE:  0.06408266611336927\n",
      "Delta:  0.0016726754666366163\n",
      "GRAD\n",
      " tensor([-0.0094, -0.0039, -0.0016,  0.0093])\n",
      "0.018541002982008448 0.043938006188652845 -31.89283174044033\n",
      "Epoch: 1302\n",
      "Arb loss 0.052944117481922646\n",
      "Real arb loss 5.093508080634856e-05\n",
      "Bounds loss: 0.3249661197596934\n",
      "MAPE:  0.06088338620314003\n",
      "Delta:  0.0016416623858217744\n",
      "GRAD\n",
      " tensor([-29.4690,   0.6802,   4.8496,  66.2500])\n",
      "-0.02033323861715597 -0.04603097453691429 0.9737527065488498\n",
      "Epoch: 1303\n",
      "Arb loss 0.0013896397880601924\n",
      "Real arb loss 1.3419038239233932e-06\n",
      "Bounds loss: 0.3399246269437117\n",
      "MAPE:  0.06394642177274788\n",
      "Delta:  0.001675042698841498\n",
      "GRAD\n",
      " tensor([-0.0090, -0.0038, -0.0016,  0.0089])\n",
      "0.018445299952622896 0.043546785796307774 -35.79823498951766\n",
      "Delta imp changed to 0.007108609185231776\n",
      "Epoch: 1304\n",
      "Arb loss 0.051136291471822484\n",
      "Real arb loss 4.9202213548030815e-05\n",
      "Bounds loss: 0.32512200202730407\n",
      "MAPE:  0.060785875310502654\n",
      "Delta:  0.001604044911051625\n",
      "GRAD\n",
      " tensor([-29.4931,   0.6715,   4.8465,  66.2380])\n",
      "-0.020360480028908112 -0.04608518001484563 0.9780061228891914\n",
      "Epoch: 1305\n",
      "Arb loss 0.0011246853105337526\n",
      "Real arb loss 1.086374055362247e-06\n",
      "Bounds loss: 0.34010530801751937\n",
      "MAPE:  0.06385228050319698\n",
      "Delta:  0.0016367040354285634\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.018359760388198088 0.04324375748488973 -42.39174245152982\n",
      "Epoch: 1306\n",
      "Arb loss 0.04880205533369944\n",
      "Real arb loss 4.696303633370819e-05\n",
      "Bounds loss: 0.32539787655828606\n",
      "MAPE:  0.06072212986404549\n",
      "Delta:  0.0016066545415116982\n",
      "GRAD\n",
      " tensor([-29.5150,   0.6642,   4.8442,  66.2229])\n",
      "-0.020389569742867097 -0.046124569041190666 0.9831332802774165\n",
      "arb imp changed to 1030.0303050805971\n",
      "Epoch: 1307\n",
      "Arb loss 0.0008235421544941201\n",
      "Real arb loss 7.949525726974119e-07\n",
      "Bounds loss: 0.3404067133814555\n",
      "MAPE:  0.06379112316384518\n",
      "Delta:  0.0016394135363385451\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.01828920886728913 0.04301232076150574 -49.57491693658015\n",
      "Epoch: 1308\n",
      "Arb loss 0.041650576057312386\n",
      "Real arb loss 4.007557977335659e-05\n",
      "Bounds loss: 0.3257650306361224\n",
      "MAPE:  0.060684804241001644\n",
      "Delta:  0.0016094299597525885\n",
      "GRAD\n",
      " tensor([-29.5502,   1.6519,   4.8401,  66.2199])\n",
      "-0.01490774637500869 -0.033238926667470414 0.9232401272159724\n",
      "Epoch: 1309\n",
      "Arb loss 0.0031970929195407664\n",
      "Real arb loss 3.084627172135382e-06\n",
      "Bounds loss: 0.3365931106002627\n",
      "MAPE:  0.06290205042926135\n",
      "Delta:  0.0016334229334009206\n",
      "GRAD\n",
      " tensor([-0.0010, -0.0004, -0.0002,  0.0010])\n",
      "0.013186703371909747 0.03256590087706612 -11.910125153536375\n",
      "Epoch: 1310\n",
      "Arb loss 0.04127486971875629\n",
      "Real arb loss 3.9716065768092385e-05\n",
      "Bounds loss: 0.3256316527245512\n",
      "MAPE:  0.06056120249148467\n",
      "Delta:  0.0016118834696972882\n",
      "GRAD\n",
      " tensor([-29.5790,   1.6402,   4.8353,  66.1911])\n",
      "-0.014665074747574947 -0.0332534273216496 0.9245736842402542\n",
      "Epoch: 1311\n",
      "Arb loss 0.003113211356349281\n",
      "Real arb loss 3.0038432368796366e-06\n",
      "Bounds loss: 0.3364600212220557\n",
      "MAPE:  0.06278712548293466\n",
      "Delta:  0.0016355218612647794\n",
      "GRAD\n",
      " tensor([-0.0011, -0.0005, -0.0002,  0.0011])\n",
      "0.013273343575979535 0.032400220583574946 -12.366670883205835\n",
      "Epoch: 1312\n",
      "Arb loss 0.04161327159017968\n",
      "Real arb loss 4.0042467515938554e-05\n",
      "Bounds loss: 0.3255586423169068\n",
      "MAPE:  0.060462586276219\n",
      "Delta:  0.0016138130176741863\n",
      "GRAD\n",
      " tensor([-29.5915,   1.6356,   4.8337,  66.1795])\n",
      "-0.014639962137988904 -0.033301606694017494 0.9270520979018354\n",
      "Epoch: 1313\n",
      "Arb loss 0.003035600861944763\n",
      "Real arb loss 2.9290875141457954e-06\n",
      "Bounds loss: 0.3364002681791827\n",
      "MAPE:  0.0626929380225434\n",
      "Delta:  0.0016374391791507301\n",
      "GRAD\n",
      " tensor([-0.0013, -0.0005, -0.0002,  0.0013])\n",
      "0.013255495904698655 0.032166679037070045 -12.722890696673785\n",
      "Epoch: 1314\n",
      "Arb loss 0.04165721882719671\n",
      "Real arb loss 4.0085987329227815e-05\n",
      "Bounds loss: 0.3255793887246787\n",
      "MAPE:  0.060392178308594544\n",
      "Delta:  0.0016157341108173045\n",
      "GRAD\n",
      " tensor([-29.6006,   1.6329,   4.8330,  66.1696])\n",
      "-0.014657197170852676 -0.03334766343278028 0.9300287285080195\n",
      "Epoch: 1315\n",
      "Arb loss 0.00291480856815862\n",
      "Real arb loss 2.8127191998190555e-06\n",
      "Bounds loss: 0.3364367006005196\n",
      "MAPE:  0.06262288094939282\n",
      "Delta:  0.001639416244255226\n",
      "GRAD\n",
      " tensor([-0.0013, -0.0005, -0.0002,  0.0013])\n",
      "0.013223305746287939 0.03196022624886896 -13.162814115446364\n",
      "Epoch: 1316\n",
      "Arb loss 0.04128189193294091\n",
      "Real arb loss 3.972673940886083e-05\n",
      "Bounds loss: 0.32568410753090404\n",
      "MAPE:  0.06034281251715871\n",
      "Delta:  0.001617737742012008\n",
      "GRAD\n",
      " tensor([-29.6091,   1.6308,   4.8328,  66.1584])\n",
      "-0.014679396874137662 -0.033384965316764825 0.9333943046307996\n",
      "Epoch: 1317\n",
      "Arb loss 0.002749609118349712\n",
      "Real arb loss 2.653528162931545e-06\n",
      "Bounds loss: 0.3365570601650448\n",
      "MAPE:  0.06257367141842182\n",
      "Delta:  0.0016414851563652736\n",
      "GRAD\n",
      " tensor([-0.0010, -0.0004, -0.0002,  0.0010])\n",
      "0.013194817229677969 0.03179329830709221 -13.74263790801114\n",
      "arb imp changed to 1030.5453202331373\n",
      "Epoch: 1318\n",
      "Arb loss 0.040556759866205744\n",
      "Real arb loss 3.9011898789581473e-05\n",
      "Bounds loss: 0.32585680115385957\n",
      "MAPE:  0.06031051899214176\n",
      "Delta:  0.0016198260597418044\n",
      "GRAD\n",
      " tensor([-29.6324,   1.6229,   4.8302,  66.1607])\n",
      "-0.014717964709252795 -0.03366422179538109 0.9386371213429399\n",
      "Epoch: 1319\n",
      "Arb loss 0.002488679534393508\n",
      "Real arb loss 2.400786422823178e-06\n",
      "Bounds loss: 0.3368265167814365\n",
      "MAPE:  0.06255677163355719\n",
      "Delta:  0.0016436666025242124\n",
      "GRAD\n",
      " tensor([-2.6424e-04, -1.1009e-04, -4.5863e-05,  2.6151e-04])\n",
      "0.01317561674852441 0.03169910084320393 -14.679258911950432\n",
      "Epoch: 1320\n",
      "Arb loss 0.03902065076862807\n",
      "Real arb loss 3.753774260643895e-05\n",
      "Bounds loss: 0.3261494190593166\n",
      "MAPE:  0.06030429234999297\n",
      "Delta:  0.0016220102813070043\n",
      "GRAD\n",
      " tensor([-29.6425,   1.6208,   4.8303,  66.1461])\n",
      "-0.014734133302873209 -0.033679144560643914 0.9434557813821345\n",
      "Delta imp changed to 0.0069352284733968554\n",
      "Epoch: 1321\n",
      "Arb loss 0.002206392207672686\n",
      "Real arb loss 2.128645251765007e-06\n",
      "Bounds loss: 0.33713385249218536\n",
      "MAPE:  0.0625500144927148\n",
      "Delta:  0.0016057650702540611\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.013163419396050702 0.03162756222015828 -15.943452990170371\n",
      "Epoch: 1322\n",
      "Arb loss 0.037383902648580374\n",
      "Real arb loss 3.5966846985722336e-05\n",
      "Bounds loss: 0.3264711305959671\n",
      "MAPE:  0.060306051403573493\n",
      "Delta:  0.0015846277111827782\n",
      "GRAD\n",
      " tensor([-29.6533,   1.6187,   4.8303,  66.1313])\n",
      "-0.014218058762945462 -0.03215992487852448 0.937004546863374\n",
      "Epoch: 1323\n",
      "Arb loss 0.0023550158873628362\n",
      "Real arb loss 2.271947259358937e-06\n",
      "Bounds loss: 0.3369704176309403\n",
      "MAPE:  0.06246080570450848\n",
      "Delta:  0.0016071580410977665\n",
      "GRAD\n",
      " tensor([-0.0006, -0.0003, -0.0001,  0.0006])\n",
      "0.01290182362477188 0.03111777988936537 -15.331626039236863\n",
      "Epoch: 1324\n",
      "Arb loss 0.0384612387888714\n",
      "Real arb loss 3.70028880916889e-05\n",
      "Bounds loss: 0.3264846463458732\n",
      "MAPE:  0.06025604933904203\n",
      "Delta:  0.0015864227715143891\n",
      "GRAD\n",
      " tensor([-29.6459,   1.6235,   4.8330,  66.1252])\n",
      "-0.012625338692904275 -0.02833860176986347 0.9163920621425756\n",
      "Epoch: 1325\n",
      "Arb loss 0.0032156648625795204\n",
      "Real arb loss 3.1008205479513863e-06\n",
      "Bounds loss: 0.33573676472264363\n",
      "MAPE:  0.062150530760097036\n",
      "Delta:  0.0016064518963148941\n",
      "GRAD\n",
      " tensor([-0.0053, -0.0022, -0.0009,  0.0053])\n",
      "0.010589849796594497 0.025832980576622866 -9.572609136265445\n",
      "Epoch: 1326\n",
      "Arb loss 0.033997967705276\n",
      "Real arb loss 3.271572103703677e-05\n",
      "Bounds loss: 0.32706368340070535\n",
      "MAPE:  0.060319956244576464\n",
      "Delta:  0.001589439812027465\n",
      "GRAD\n",
      " tensor([-29.6834,   1.6108,   4.8290,  66.0839])\n",
      "-0.011907935103729228 -0.02700811832599248 0.9090351551973868\n",
      "Epoch: 1327\n",
      "Arb loss 0.003092619855914688\n",
      "Real arb loss 2.9824019256377325e-06\n",
      "Bounds loss: 0.33589705806212655\n",
      "MAPE:  0.06214184334182821\n",
      "Delta:  0.0016083667581603717\n",
      "GRAD\n",
      " tensor([-0.0050, -0.0021, -0.0009,  0.0050])\n",
      "0.010573591197007515 0.025740837601303745 -9.843644124805865\n",
      "Epoch: 1328\n",
      "Arb loss 0.03353526913084726\n",
      "Real arb loss 3.227203844696367e-05\n",
      "Bounds loss: 0.32725078643979366\n",
      "MAPE:  0.06031686355227441\n",
      "Delta:  0.0015913605455647277\n",
      "GRAD\n",
      " tensor([-29.6855,   1.6121,   4.8304,  66.0697])\n",
      "-0.011476627535412787 -0.025959172046003065 0.9024204315236564\n",
      "arb imp changed to 1031.060592893254\n",
      "Epoch: 1329\n",
      "Arb loss 0.0032739932690713865\n",
      "Real arb loss 3.1552776860445457e-06\n",
      "Bounds loss: 0.3357459459071741\n",
      "MAPE:  0.06207882421862208\n",
      "Delta:  0.0016096239978207255\n",
      "GRAD\n",
      " tensor([-0.0062, -0.0026, -0.0011,  0.0061])\n",
      "0.010381715596693764 0.025370550490738886 -9.68809235710895\n",
      "Epoch: 1330\n",
      "Arb loss 0.03499274243638803\n",
      "Real arb loss 3.365717035393202e-05\n",
      "Bounds loss: 0.32722788643447526\n",
      "MAPE:  0.06027869181280255\n",
      "Delta:  0.0015929133392577376\n",
      "GRAD\n",
      " tensor([-29.6876,   1.6129,   4.8315,  66.0786])\n",
      "-0.012025185478882205 -0.027080732724856782 0.9151562495853134\n",
      "Epoch: 1331\n",
      "Arb loss 0.0029689155055983188\n",
      "Real arb loss 2.8618655073555446e-06\n",
      "Bounds loss: 0.3360894573671271\n",
      "MAPE:  0.062106330010506874\n",
      "Delta:  0.0016120684176140975\n",
      "GRAD\n",
      " tensor([-0.0049, -0.0020, -0.0009,  0.0049])\n",
      "0.010510371765476312 0.02548467877308569 -9.190545744215806\n",
      "Epoch: 1332\n",
      "Arb loss 0.030254869270511263\n",
      "Real arb loss 2.9104917431982466e-05\n",
      "Bounds loss: 0.3275243255071052\n",
      "MAPE:  0.06029722739468896\n",
      "Delta:  0.0015951249792335903\n",
      "GRAD\n",
      " tensor([-17.7343,   0.6102,   2.9207,  40.9197])\n",
      "-0.006743959823030998 -0.013572625438393882 0.7521139080906812\n",
      "Epoch: 1333\n",
      "Arb loss 0.00749976130469438\n",
      "Real arb loss 7.2174334168820135e-06\n",
      "Bounds loss: 0.3319696904991757\n",
      "MAPE:  0.061162750777418534\n",
      "Delta:  0.0016058824380062548\n",
      "GRAD\n",
      " tensor([-6.0013, -0.5019,  1.9570, 12.9838])\n",
      "0.005208894817635645 0.013047490144497687 -2.557608394996396\n",
      "Epoch: 1334\n",
      "Arb loss 0.02668121377804985\n",
      "Real arb loss 2.5671452217036585e-05\n",
      "Bounds loss: 0.32763831923411574\n",
      "MAPE:  0.060240239198111695\n",
      "Delta:  0.001597517565297192\n",
      "GRAD\n",
      " tensor([-17.7759,   0.5926,   2.9132,  40.8878])\n",
      "-0.005730489943040817 -0.012424656663701406 0.713554944998271\n",
      "Epoch: 1335\n",
      "Arb loss 0.0076427017481663796\n",
      "Real arb loss 7.355551739128812e-06\n",
      "Bounds loss: 0.3317091128604719\n",
      "MAPE:  0.0610448003613396\n",
      "Delta:  0.0016066721236389584\n",
      "GRAD\n",
      " tensor([-6.0053, -0.5038,  1.9561, 12.9814])\n",
      "0.004178946243591275 0.010179166300119613 -1.774087660028247\n",
      "Epoch: 1336\n",
      "Arb loss 0.021201524608864666\n",
      "Real arb loss 2.040313226429781e-05\n",
      "Bounds loss: 0.32833259063739995\n",
      "MAPE:  0.060329108576121955\n",
      "Delta:  0.0015999579272031946\n",
      "GRAD\n",
      " tensor([-17.8135,   0.5780,   2.9076,  40.8614])\n",
      "-0.0037694469307885115 -0.008423990521623681 0.5557175174270554\n",
      "Epoch: 1337\n",
      "Arb loss 0.00941946598755777\n",
      "Real arb loss 9.066887316068675e-06\n",
      "Bounds loss: 0.3310984612688696\n",
      "MAPE:  0.06088327556086117\n",
      "Delta:  0.0016059888837012815\n",
      "GRAD\n",
      " tensor([-6.0030, -0.5031,  1.9562, 12.9889])\n",
      "0.0035747268020841494 0.008976575945798038 -1.340086760610407\n",
      "Epoch: 1338\n",
      "Arb loss 0.02204236764950397\n",
      "Real arb loss 2.1212689323719273e-05\n",
      "Bounds loss: 0.3281263307857527\n",
      "MAPE:  0.0602399607742138\n",
      "Delta:  0.0016002479121948654\n",
      "GRAD\n",
      " tensor([-17.8159,   0.5765,   2.9068,  40.8627])\n",
      "-0.003784798238024134 -0.008489245965084269 0.5553172991152155\n",
      "Epoch: 1339\n",
      "Arb loss 0.009801859580276824\n",
      "Real arb loss 9.435602048430165e-06\n",
      "Bounds loss: 0.3309118759154136\n",
      "MAPE:  0.0608014754125166\n",
      "Delta:  0.0016063045276733423\n",
      "GRAD\n",
      " tensor([-6.0050, -0.5041,  1.9558, 12.9905])\n",
      "0.0035568369793965715 0.008874739092710526 -1.3138412894306155\n",
      "arb imp changed to 1031.5761231897004\n",
      "Epoch: 1340\n",
      "Arb loss 0.022691287383750577\n",
      "Real arb loss 2.1826583187037613e-05\n",
      "Bounds loss: 0.3279751193539849\n",
      "MAPE:  0.06016478911030366\n",
      "Delta:  0.0016005911643291416\n",
      "GRAD\n",
      " tensor([-17.8271,   0.5715,   2.9046,  40.8726])\n",
      "-0.004177571220049581 -0.009409545443853418 0.6047657421440573\n",
      "Epoch: 1341\n",
      "Arb loss 0.008968374128912576\n",
      "Real arb loss 8.629147762677299e-06\n",
      "Bounds loss: 0.33106121614399947\n",
      "MAPE:  0.06078350675851724\n",
      "Delta:  0.0016072777479123087\n",
      "GRAD\n",
      " tensor([-6.0109, -0.5065,  1.9548, 12.9890])\n",
      "0.003669304317486577 0.00896401656329493 -1.4107259073400846\n",
      "Epoch: 1342\n",
      "Arb loss 0.02162029185928811\n",
      "Real arb loss 2.0797919588681486e-05\n",
      "Bounds loss: 0.3280935779190201\n",
      "MAPE:  0.060143766030992724\n",
      "Delta:  0.001601380156732494\n",
      "GRAD\n",
      " tensor([-17.8380,   0.5672,   2.9028,  40.8678])\n",
      "-0.0037292784382996214 -0.008517069447181225 0.559671107832385\n",
      "Epoch: 1343\n",
      "Arb loss 0.00952003916274084\n",
      "Real arb loss 9.160642990066119e-06\n",
      "Bounds loss: 0.3308879737073306\n",
      "MAPE:  0.06071113579635962\n",
      "Delta:  0.0016073521492225174\n",
      "GRAD\n",
      " tensor([-6.0116, -0.5069,  1.9546, 12.9927])\n",
      "0.0035624241471429174 0.008792054025830054 -1.3465862148068362\n",
      "Epoch: 1344\n",
      "Arb loss 0.022339592663708864\n",
      "Real arb loss 2.149008742200017e-05\n",
      "Bounds loss: 0.3279787887659983\n",
      "MAPE:  0.06008092802241336\n",
      "Delta:  0.0016016260791131651\n",
      "GRAD\n",
      " tensor([-17.8367,   0.5676,   2.9030,  40.8712])\n",
      "-0.0037985672036375817 -0.008595032212250775 0.5628586065182597\n",
      "Epoch: 1345\n",
      "Arb loss 0.009765560666828155\n",
      "Real arb loss 9.397380110406765e-06\n",
      "Bounds loss: 0.33079777702037705\n",
      "MAPE:  0.06065623921796366\n",
      "Delta:  0.0016077099634097748\n",
      "GRAD\n",
      " tensor([-6.0126, -0.5073,  1.9544, 12.9942])\n",
      "0.0035133111032207287 0.008689205133317723 -1.3245978215189464\n",
      "Epoch: 1346\n",
      "Arb loss 0.022701001052019838\n",
      "Real arb loss 2.183831218560088e-05\n",
      "Bounds loss: 0.3279234072782015\n",
      "MAPE:  0.06003211991185247\n",
      "Delta:  0.0016020615781445688\n",
      "GRAD\n",
      " tensor([-17.8377,   0.5672,   2.9028,  40.8720])\n",
      "-0.003572846770142357 -0.00804737446435877 0.5454112132666387\n",
      "Epoch: 1347\n",
      "Arb loss 0.010319620525870458\n",
      "Real arb loss 9.930973937097256e-06\n",
      "Bounds loss: 0.3305623297321976\n",
      "MAPE:  0.06056872410729557\n",
      "Delta:  0.0016077854986796117\n",
      "GRAD\n",
      " tensor([-6.0146, -0.5083,  1.9539, 12.9965])\n",
      "0.0026474668221767583 0.00649414217865929 -0.5390168655407848\n",
      "Epoch: 1348\n",
      "Arb loss 0.015882070035295497\n",
      "Real arb loss 1.5285307915366893e-05\n",
      "Bounds loss: 0.3284156109640079\n",
      "MAPE:  0.06009652081675371\n",
      "Delta:  0.0016035289399146807\n",
      "GRAD\n",
      " tensor([-6.0161, -0.5105,  1.9523, 13.0294])\n",
      "0.0016824193189652892 0.004103145204981673 -0.36613660493269173\n",
      "Epoch: 1349\n",
      "Arb loss 0.021697077237321827\n",
      "Real arb loss 2.087896790056633e-05\n",
      "Bounds loss: 0.3270680740246398\n",
      "MAPE:  0.05977196591615138\n",
      "Delta:  0.0016008311318476483\n",
      "GRAD\n",
      " tensor([-17.8512,   0.5583,   2.8977,  40.8812])\n",
      "-0.0026764569815973527 -0.006624840608204119 0.48316055706625993\n",
      "Delta imp changed to 0.006766076559411567\n",
      "Epoch: 1350\n",
      "Arb loss 0.011213905312627746\n",
      "Real arb loss 1.0793740769647086e-05\n",
      "Bounds loss: 0.3292348478830853\n",
      "MAPE:  0.06020056180434925\n",
      "Delta:  0.0015659665243969174\n",
      "GRAD\n",
      " tensor([-6.0222, -0.5129,  1.9514, 13.0157])\n",
      "0.002943857963323193 0.006781773067645491 -0.9543967920086169\n",
      "arb imp changed to 1032.0919112512952\n",
      "Epoch: 1351\n",
      "Arb loss 0.021927378779172495\n",
      "Real arb loss 2.1090055537228573e-05\n",
      "Bounds loss: 0.3270020518587815\n",
      "MAPE:  0.059717096268503245\n",
      "Delta:  0.0015613565413737738\n",
      "GRAD\n",
      " tensor([-17.8614,   0.5535,   3.8955,  40.9019])\n",
      "-0.002885291855534655 -0.006860354574352634 0.49699884980546116\n",
      "Epoch: 1352\n",
      "Arb loss 0.011029496746675088\n",
      "Real arb loss 1.0610998195239976e-05\n",
      "Bounds loss: 0.3292454018810736\n",
      "MAPE:  0.060159007781033134\n",
      "Delta:  0.0015658615106861854\n",
      "GRAD\n",
      " tensor([-6.0269, -0.5150,  1.9505, 13.0218])\n",
      "0.002868528532859793 0.00669658481393709 -0.9503293576381151\n",
      "Epoch: 1353\n",
      "Arb loss 0.021511151305014506\n",
      "Real arb loss 2.0690330341854816e-05\n",
      "Bounds loss: 0.3270405821227782\n",
      "MAPE:  0.05968605997175664\n",
      "Delta:  0.0015613697922642752\n",
      "GRAD\n",
      " tensor([-17.8663,   0.5512,   3.8944,  40.9077])\n",
      "-0.0029349147911956752 -0.006895790651249456 0.5040361537855655\n",
      "Epoch: 1354\n",
      "Arb loss 0.010668753337735645\n",
      "Real arb loss 1.0264030294483278e-05\n",
      "Bounds loss: 0.32929578551155964\n",
      "MAPE:  0.06013033836586224\n",
      "Delta:  0.0015659522795621176\n",
      "GRAD\n",
      " tensor([-6.0288, -0.5158,  1.9501, 13.0233])\n",
      "0.0028299707220732495 0.006649763007648191 -0.9610841254962033\n",
      "Epoch: 1355\n",
      "Arb loss 0.020922322809468007\n",
      "Real arb loss 2.0124653824874944e-05\n",
      "Bounds loss: 0.3271060465784904\n",
      "MAPE:  0.05966158964795376\n",
      "Delta:  0.001561520680458793\n",
      "GRAD\n",
      " tensor([-17.8724,   0.5485,   3.8932,  40.9116])\n",
      "-0.002961983371834176 -0.0069160054649315406 0.5108925903619845\n",
      "Epoch: 1356\n",
      "Arb loss 0.01023326311294926\n",
      "Real arb loss 9.845083379139776e-06\n",
      "Bounds loss: 0.32936831378423936\n",
      "MAPE:  0.06010844782454188\n",
      "Delta:  0.001566145878749087\n",
      "GRAD\n",
      " tensor([-6.0307, -0.5166,  1.9498, 13.0242])\n",
      "0.0028059950404366596 0.00661918573450726 -0.9792022140420147\n",
      "Epoch: 1357\n",
      "Arb loss 0.020253697010023657\n",
      "Real arb loss 1.948214978089218e-05\n",
      "Bounds loss: 0.32718816374024007\n",
      "MAPE:  0.059641788728193736\n",
      "Delta:  0.0015617512811807168\n",
      "GRAD\n",
      " tensor([-17.8788,   0.5457,   3.8921,  40.9143])\n",
      "-0.0029793552545345214 -0.0069291853997288655 0.5180014139375654\n",
      "Epoch: 1358\n",
      "Arb loss 0.009762253321368363\n",
      "Real arb loss 9.391856210096958e-06\n",
      "Bounds loss: 0.329455311187393\n",
      "MAPE:  0.060090666820322526\n",
      "Delta:  0.0015664042930665788\n",
      "GRAD\n",
      " tensor([-6.0324, -0.5174,  1.9495, 13.0246])\n",
      "0.0027886530445597746 0.006596800814922532 -1.002165990351351\n",
      "Epoch: 1359\n",
      "Arb loss 0.019545651589238253\n",
      "Real arb loss 1.8801597328266648e-05\n",
      "Bounds loss: 0.3272819601220715\n",
      "MAPE:  0.059625659701142406\n",
      "Delta:  0.0015620361349657072\n",
      "GRAD\n",
      " tensor([-17.8851,   0.5430,   3.8909,  40.9165])\n",
      "-0.0029912607779192246 -0.006937510630234955 0.5250734866839339\n",
      "Epoch: 1360\n",
      "Arb loss 0.009282748159767549\n",
      "Real arb loss 8.930391147311119e-06\n",
      "Bounds loss: 0.3295524821995025\n",
      "MAPE:  0.0600761290027804\n",
      "Delta:  0.0015667085923899227\n",
      "GRAD\n",
      " tensor([-6.0341, -0.5181,  1.9492, 13.0248])\n",
      "0.003090094427875889 0.007258405671383916 -1.2032114355018932\n",
      "Delta imp changed to 0.006601050301864943\n",
      "Epoch: 1361\n",
      "Arb loss 0.020451856898484017\n",
      "Real arb loss 1.9672965546402896e-05\n",
      "Bounds loss: 0.327160456593687\n",
      "MAPE:  0.05957137468891766\n",
      "Delta:  0.001523772990144852\n",
      "GRAD\n",
      " tensor([-17.8812,   0.5444,   3.8914,  40.9255])\n",
      "-0.0031022460921106276 -0.007021523212305869 0.528151603548335\n",
      "arb imp changed to 1032.6079572069207\n",
      "Epoch: 1362\n",
      "Arb loss 0.009655000969949609\n",
      "Real arb loss 9.284042388576632e-06\n",
      "Bounds loss: 0.3294576213338082\n",
      "MAPE:  0.060029145374076776\n",
      "Delta:  0.0015285001089487926\n",
      "GRAD\n",
      " tensor([-6.0379, -0.5198,  1.9484, 13.0312])\n",
      "0.002693226117033265 0.006467498939662031 -0.9892143630364318\n",
      "Epoch: 1363\n",
      "Arb loss 0.019205866604554443\n",
      "Real arb loss 1.8465953493098994e-05\n",
      "Bounds loss: 0.3273268545171682\n",
      "MAPE:  0.05957144584582248\n",
      "Delta:  0.0015243835125354835\n",
      "GRAD\n",
      " tensor([-17.9005,   0.5365,   3.8881,  40.9314])\n",
      "-0.0025945625674876904 -0.0059291297473220705 0.46936223663428267\n",
      "Epoch: 1364\n",
      "Arb loss 0.010191358098541093\n",
      "Real arb loss 9.799971616727337e-06\n",
      "Bounds loss: 0.3292676179073833\n",
      "MAPE:  0.059959474279657136\n",
      "Delta:  0.0015283386209356035\n",
      "GRAD\n",
      " tensor([-6.0398, -0.5208,  1.9479, 14.0348])\n",
      "0.0021350613051805967 0.005145452163610176 -0.7432578292487368\n",
      "Epoch: 1365\n",
      "Arb loss 0.01776616479595928\n",
      "Real arb loss 1.7082695246365412e-05\n",
      "Bounds loss: 0.32757338713041495\n",
      "MAPE:  0.059595811295361165\n",
      "Delta:  0.001525075524284831\n",
      "GRAD\n",
      " tensor([-17.9098,   0.5330,   3.8869,  40.9275])\n",
      "-0.00228925581217454 -0.005299160309067519 0.4285186669384219\n",
      "Epoch: 1366\n",
      "Arb loss 0.010153031540986488\n",
      "Real arb loss 9.7631326811938e-06\n",
      "Bounds loss: 0.32930925102180325\n",
      "MAPE:  0.05994734720568938\n",
      "Delta:  0.001528566812292805\n",
      "GRAD\n",
      " tensor([-6.0400, -0.5208,  1.9479, 14.0362])\n",
      "0.002085005839189802 0.005092677074912233 -0.7352187919633701\n",
      "Epoch: 1367\n",
      "Arb loss 0.01761773112531657\n",
      "Real arb loss 1.6940160259479336e-05\n",
      "Bounds loss: 0.327632185348568\n",
      "MAPE:  0.05958632311155942\n",
      "Delta:  0.0015253797415635828\n",
      "GRAD\n",
      " tensor([-17.9105,   0.5329,   3.8869,  40.9295])\n",
      "-0.0023239687580447477 -0.005322882311797006 0.4335605625522283\n",
      "Epoch: 1368\n",
      "Arb loss 0.009979377707730415\n",
      "Real arb loss 9.596153327760447e-06\n",
      "Bounds loss: 0.32937613291273526\n",
      "MAPE:  0.05993991280910263\n",
      "Delta:  0.0015289246764271308\n",
      "GRAD\n",
      " tensor([-6.0405, -0.5209,  1.9479, 14.0366])\n",
      "0.002058596527239276 0.00506306836721826 -0.7366516838963504\n",
      "Epoch: 1369\n",
      "Arb loss 0.017330703100367727\n",
      "Real arb loss 1.6664399642586146e-05\n",
      "Bounds loss: 0.3277084790332681\n",
      "MAPE:  0.05958046374116722\n",
      "Delta:  0.0015257772373978274\n",
      "GRAD\n",
      " tensor([-17.9125,   0.5323,   3.8867,  40.9301])\n",
      "-0.0023419062457519235 -0.005335796712109486 0.43817192310764497\n",
      "Epoch: 1370\n",
      "Arb loss 0.009736875594071975\n",
      "Real arb loss 9.362939794734194e-06\n",
      "Bounds loss: 0.32945706485822424\n",
      "MAPE:  0.05993537876957193\n",
      "Delta:  0.0015293504646397154\n",
      "GRAD\n",
      " tensor([-6.0410, -0.5211,  1.9479, 14.0364])\n",
      "0.002043681281716503 0.005044850672198287 -0.7430543478697773\n",
      "Epoch: 1371\n",
      "Arb loss 0.01697190333891428\n",
      "Real arb loss 1.6319614064939567e-05\n",
      "Bounds loss: 0.3277950031631138\n",
      "MAPE:  0.05957696034315449\n",
      "Delta:  0.0015262249597219467\n",
      "GRAD\n",
      " tensor([-17.9150,   0.5315,   3.8865,  40.9299])\n",
      "-0.0023516967011596446 -0.005343400354779426 0.4427270271395467\n",
      "Epoch: 1372\n",
      "Arb loss 0.009457983028777012\n",
      "Real arb loss 9.09469069275147e-06\n",
      "Bounds loss: 0.3295465430993105\n",
      "MAPE:  0.059932822174727035\n",
      "Delta:  0.0015298141779249523\n",
      "GRAD\n",
      " tensor([-6.0416, -0.5212,  1.9479, 14.0359])\n",
      "0.0020344449696455547 0.0050325015376241344 -0.7524034781825275\n",
      "arb imp changed to 1033.1242611855241\n",
      "Delta imp changed to 0.006440049074990189\n",
      "Epoch: 1373\n",
      "Arb loss 0.016582489457398264\n",
      "Real arb loss 1.5937382388520472e-05\n",
      "Bounds loss: 0.32788809961444443\n",
      "MAPE:  0.059575142044936455\n",
      "Delta:  0.0014894652245523712\n",
      "GRAD\n",
      " tensor([-17.9268,   0.5269,   3.8847,  40.9381])\n",
      "-0.0023605876464571907 -0.005351795119760361 0.44648874328496857\n",
      "Epoch: 1374\n",
      "Arb loss 0.009178594579028273\n",
      "Real arb loss 8.821639267137743e-06\n",
      "Bounds loss: 0.3296428895457885\n",
      "MAPE:  0.05993197474695288\n",
      "Delta:  0.0014929812377612772\n",
      "GRAD\n",
      " tensor([-6.0451, -0.5226,  1.9473, 14.0382])\n",
      "0.001951546787408942 0.004769620675235342 -0.7403531927295006\n",
      "Epoch: 1375\n",
      "Arb loss 0.015973996380381543\n",
      "Real arb loss 1.5352779193027918e-05\n",
      "Bounds loss: 0.3280706180043666\n",
      "MAPE:  0.059598666895635984\n",
      "Delta:  0.0014900676150230623\n",
      "GRAD\n",
      " tensor([-17.9276,   0.5272,   3.8851,  40.9370])\n",
      "-0.0017965216857156463 -0.00395191887337365 0.34146516594037\n",
      "Epoch: 1376\n",
      "Arb loss 0.01051943305562369\n",
      "Real arb loss 1.0110613254781763e-05\n",
      "Bounds loss: 0.3293671264714574\n",
      "MAPE:  0.0598668537800054\n",
      "Delta:  0.0014927445538066339\n",
      "GRAD\n",
      " tensor([-6.0442, -0.5223,  1.9474, 14.0444])\n",
      "0.0016210015423291368 0.00414475143951587 -0.5699861423524328\n",
      "Epoch: 1377\n",
      "Arb loss 0.0165153641227333\n",
      "Real arb loss 1.587306670342578e-05\n",
      "Bounds loss: 0.3280019815998856\n",
      "MAPE:  0.0595700543203332\n",
      "Delta:  0.0014903248125826098\n",
      "GRAD\n",
      " tensor([-17.9254,   0.5282,   3.8855,  40.9382])\n",
      "-0.0020495904838750967 -0.004572253765689149 0.3962211445901681\n",
      "Epoch: 1378\n",
      "Arb loss 0.009971627646700516\n",
      "Real arb loss 9.584141217422311e-06\n",
      "Bounds loss: 0.3295016898954092\n",
      "MAPE:  0.05987600010900222\n",
      "Delta:  0.001493379368136362\n",
      "GRAD\n",
      " tensor([-6.0452, -0.5226,  1.9473, 14.0417])\n",
      "0.0016545211793097536 0.00417430869262192 -0.5900952116083444\n",
      "Epoch: 1379\n",
      "Arb loss 0.015855837372959876\n",
      "Real arb loss 1.5239457117138725e-05\n",
      "Bounds loss: 0.32812624812704516\n",
      "MAPE:  0.0595778244250945\n",
      "Delta:  0.0014909085403430361\n",
      "GRAD\n",
      " tensor([-17.9306,   0.5263,   3.8849,  40.9345])\n",
      "-0.0017930352520103554 -0.0039632227280022025 0.34364059865084284\n",
      "Epoch: 1380\n",
      "Arb loss 0.010407127926005535\n",
      "Real arb loss 1.0002798123258955e-05\n",
      "Bounds loss: 0.32942668553127635\n",
      "MAPE:  0.05984755682736865\n",
      "Delta:  0.0014935817919133944\n",
      "GRAD\n",
      " tensor([-6.0452, -0.5226,  1.9474, 14.0435])\n",
      "0.0016194629996673093 0.0041221945095165635 -0.57143179928604\n",
      "Epoch: 1381\n",
      "Arb loss 0.016354091762162872\n",
      "Real arb loss 1.571826924258175e-05\n",
      "Bounds loss: 0.3280687246568911\n",
      "MAPE:  0.059552113405145865\n",
      "Delta:  0.001491162991464414\n",
      "GRAD\n",
      " tensor([-17.9282,   0.5274,   3.8854,  40.9359])\n",
      "-0.002048898139819011 -0.0045834914767428625 0.39882199242751015\n",
      "Epoch: 1382\n",
      "Arb loss 0.009831720301234744\n",
      "Real arb loss 9.449756407968327e-06\n",
      "Bounds loss: 0.3295724248601419\n",
      "MAPE:  0.05985959567689198\n",
      "Delta:  0.001494218232543792\n",
      "GRAD\n",
      " tensor([-6.0460, -0.5228,  1.9473, 14.0409])\n",
      "0.0016512566832647124 0.004152311409861054 -0.5936436060105323\n",
      "Epoch: 1383\n",
      "Arb loss 0.015668258194146693\n",
      "Real arb loss 1.5059434453584278e-05\n",
      "Bounds loss: 0.32820393752001953\n",
      "MAPE:  0.05956271671885577\n",
      "Delta:  0.0014917508947010483\n",
      "GRAD\n",
      " tensor([-17.9333,   0.5256,   3.8848,  40.9322])\n",
      "-0.0017938611176580022 -0.003974515176656812 0.3466041439791284\n",
      "arb imp changed to 1033.640823316117\n",
      "Epoch: 1384\n",
      "Arb loss 0.010242693762608075\n",
      "Real arb loss 9.839949243896115e-06\n",
      "Bounds loss: 0.3295083890507314\n",
      "MAPE:  0.05983389639245134\n",
      "Delta:  0.0014944268886282841\n",
      "GRAD\n",
      " tensor([-6.0490, -0.5240,  1.9468, 14.0456])\n",
      "0.001614045374402573 0.004100321991506228 -0.5735514442408027\n",
      "Epoch: 1385\n",
      "Arb loss 0.016117405563068198\n",
      "Real arb loss 1.548325662344988e-05\n",
      "Bounds loss: 0.3281572985567209\n",
      "MAPE:  0.05953973203868355\n",
      "Delta:  0.0014920148158213107\n",
      "GRAD\n",
      " tensor([-17.9399,   0.5230,   3.8837,  40.9424])\n",
      "-0.0015505177919912239 -0.00347898561631399 0.31038388809382855\n",
      "Epoch: 1386\n",
      "Arb loss 0.011114822558417989\n",
      "Real arb loss 1.067764327416143e-05\n",
      "Bounds loss: 0.32929895307828816\n",
      "MAPE:  0.05977741841678145\n",
      "Delta:  0.0014943282113391563\n",
      "GRAD\n",
      " tensor([-6.0493, -0.5242,  1.9467, 14.0492])\n",
      "0.0013337662148901197 0.003426171098267039 -0.45655211655319383\n",
      "Epoch: 1387\n",
      "Arb loss 0.016189318322576907\n",
      "Real arb loss 1.55524006019977e-05\n",
      "Bounds loss: 0.32817071852256174\n",
      "MAPE:  0.059530909177920685\n",
      "Delta:  0.0014923351268569152\n",
      "GRAD\n",
      " tensor([-17.9398,   0.5232,   3.8839,  40.9421])\n",
      "-0.0017513623423410785 -0.003909295838330218 0.3518947508989011\n",
      "Epoch: 1388\n",
      "Arb loss 0.010492382184230691\n",
      "Real arb loss 1.0079916675226394e-05\n",
      "Bounds loss: 0.32945363494674385\n",
      "MAPE:  0.05979444013695646\n",
      "Delta:  0.001494948746400245\n",
      "GRAD\n",
      " tensor([-6.0501, -0.5244,  1.9466, 14.0462])\n",
      "0.0013657849496800933 0.0034582814136695506 -0.4726891173300656\n",
      "Epoch: 1389\n",
      "Arb loss 0.015452017057584401\n",
      "Real arb loss 1.4844499853343653e-05\n",
      "Bounds loss: 0.3283142915643416\n",
      "MAPE:  0.059546336964019994\n",
      "Delta:  0.0014929069679018687\n",
      "GRAD\n",
      " tensor([-17.9452,   0.5213,   3.8833,  40.9378])\n",
      "-0.0015318319367372268 -0.003469376314623407 0.31225413788404666\n",
      "Epoch: 1390\n",
      "Arb loss 0.0106270607926988\n",
      "Real arb loss 1.0209319389280433e-05\n",
      "Bounds loss: 0.3294533373912473\n",
      "MAPE:  0.059783703011382236\n",
      "Delta:  0.001495193850473878\n",
      "GRAD\n",
      " tensor([-6.0500, -0.5244,  1.9467, 14.0469])\n",
      "0.0013465082688720598 0.003433522399521327 -0.46670179533421563\n",
      "Epoch: 1391\n",
      "Arb loss 0.015586729143777182\n",
      "Real arb loss 1.4973940069023939e-05\n",
      "Bounds loss: 0.3283221519777174\n",
      "MAPE:  0.05953686453620351\n",
      "Delta:  0.0014931805595906483\n",
      "GRAD\n",
      " tensor([-17.9442,   0.5219,   3.8836,  40.9382])\n",
      "-0.001546529598781765 -0.0034829456904057476 0.31389282353363634\n",
      "Epoch: 1392\n",
      "Arb loss 0.010694166723182944\n",
      "Real arb loss 1.0273818914529678e-05\n",
      "Bounds loss: 0.32946568020201294\n",
      "MAPE:  0.059775372607052506\n",
      "Delta:  0.0014954898075223808\n",
      "GRAD\n",
      " tensor([-6.0500, -0.5243,  1.9468, 14.0472])\n",
      "0.0013342683364919727 0.0034155884426060323 -0.46321421798403595\n",
      "Epoch: 1393\n",
      "Arb loss 0.01564785679885303\n",
      "Real arb loss 1.5032714040194518e-05\n",
      "Bounds loss: 0.3283403610324796\n",
      "MAPE:  0.05952946592593578\n",
      "Delta:  0.0014934944228246572\n",
      "GRAD\n",
      " tensor([-17.9438,   0.5223,   3.8838,  40.9380])\n",
      "-0.0015556038794233285 -0.0034926559170607163 0.3152232096974382\n",
      "Epoch: 1394\n",
      "Arb loss 0.010715289153832698\n",
      "Real arb loss 1.0294155621507712e-05\n",
      "Bounds loss: 0.32948714093724957\n",
      "MAPE:  0.05976885273480356\n",
      "Delta:  0.0014958177085427004\n",
      "GRAD\n",
      " tensor([-6.0501, -0.5243,  1.9468, 14.0471])\n",
      "0.001326330267234388 0.003401967965343089 -0.4612825159071574\n",
      "arb imp changed to 1034.157643727775\n",
      "Epoch: 1395\n",
      "Arb loss 0.015665893725732013\n",
      "Real arb loss 1.5042590858029087e-05\n",
      "Bounds loss: 0.3283662362387886\n",
      "MAPE:  0.05952366200705987\n",
      "Delta:  0.001493833760241595\n",
      "GRAD\n",
      " tensor([-17.9529,   0.5187,   3.8824,  40.9463])\n",
      "-0.0015633406994377541 -0.003502347723883581 0.316616313112845\n",
      "Epoch: 1396\n",
      "Arb loss 0.010705816212673093\n",
      "Real arb loss 1.0279970920456983e-05\n",
      "Bounds loss: 0.32951628897887975\n",
      "MAPE:  0.05976391925328771\n",
      "Delta:  0.0014961691313571748\n",
      "GRAD\n",
      " tensor([-6.0532, -0.5255,  1.9463, 14.0499])\n",
      "0.001122347335023477 0.0028855436484531705 -0.38524670191130306\n",
      "Epoch: 1397\n",
      "Arb loss 0.014830196599873956\n",
      "Real arb loss 1.4240443444905613e-05\n",
      "Bounds loss: 0.3285654553441549\n",
      "MAPE:  0.05955602117452919\n",
      "Delta:  0.0014944899099198516\n",
      "GRAD\n",
      " tensor([-17.9565,   0.5178,   3.8823,  40.9419])\n",
      "-0.0013167527451485306 -0.002959989607187463 0.27792349481885437\n",
      "Epoch: 1398\n",
      "Arb loss 0.010708536531986296\n",
      "Real arb loss 1.0282625417693627e-05\n",
      "Bounds loss: 0.3295380056772544\n",
      "MAPE:  0.05975911420923782\n",
      "Delta:  0.0014964577836113354\n",
      "GRAD\n",
      " tensor([-6.0533, -0.5255,  1.9464, 14.0498])\n",
      "0.0011176222115297785 0.0028768090729852647 -0.38431354535374185\n",
      "Epoch: 1399\n",
      "Arb loss 0.014823972172144014\n",
      "Real arb loss 1.4234530861617973e-05\n",
      "Bounds loss: 0.3285899877526286\n",
      "MAPE:  0.0595516760259782\n",
      "Delta:  0.0014947853091537547\n",
      "GRAD\n",
      " tensor([-17.9567,   0.5179,   3.8824,  40.9412])\n",
      "-0.0013201656149757213 -0.0029647150023375257 0.2788169127699296\n",
      "Epoch: 1400\n",
      "Arb loss 0.010690798016119472\n",
      "Real arb loss 1.0265641303201311e-05\n",
      "Bounds loss: 0.32956416341893674\n",
      "MAPE:  0.059755238912237316\n",
      "Delta:  0.0014967586733206702\n",
      "GRAD\n",
      " tensor([-6.0534, -0.5254,  1.9464, 14.0495])\n",
      "0.0011142225071344436 0.0028695271527082733 -0.38379846888442337\n",
      "Epoch: 1401\n",
      "Arb loss 0.014793909925858757\n",
      "Real arb loss 1.4205731628015204e-05\n",
      "Bounds loss: 0.32861847010344647\n",
      "MAPE:  0.05954818562530724\n",
      "Delta:  0.0014950909511191077\n",
      "GRAD\n",
      " tensor([-17.9570,   0.5180,   3.8825,  40.9404])\n",
      "-0.0013224891346224066 -0.0029685939515282644 0.27963554404100643\n",
      "Epoch: 1402\n",
      "Arb loss 0.010657006875247597\n",
      "Real arb loss 1.0233247519182146e-05\n",
      "Bounds loss: 0.32959400490615604\n",
      "MAPE:  0.05975215518543064\n",
      "Delta:  0.001497068192657235\n",
      "GRAD\n",
      " tensor([-6.0535, -0.5254,  1.9464, 14.0492])\n",
      "0.0011117146155631419 0.0028633021379259604 -0.3835866949283826\n",
      "Epoch: 1403\n",
      "Arb loss 0.014744892920352873\n",
      "Real arb loss 1.415873328101857e-05\n",
      "Bounds loss: 0.32865027768726063\n",
      "MAPE:  0.05954543116921489\n",
      "Delta:  0.0014954038800669633\n",
      "GRAD\n",
      " tensor([-17.9574,   0.5180,   3.8826,  40.9395])\n",
      "-0.0013240857904002201 -0.0029718593747256605 0.28041252371511394\n",
      "Epoch: 1404\n",
      "Arb loss 0.010610240284647608\n",
      "Real arb loss 1.0188397075137371e-05\n",
      "Bounds loss: 0.3296269800960117\n",
      "MAPE:  0.059749759969423694\n",
      "Delta:  0.0014973839230954691\n",
      "GRAD\n",
      " tensor([-6.0536, -0.5254,  1.9465, 14.0488])\n",
      "0.0011098120041782567 0.002857868472044278 -0.3836028884855265\n",
      "Epoch: 1405\n",
      "Arb loss 0.014680359105363923\n",
      "Real arb loss 1.4096835722519186e-05\n",
      "Bounds loss: 0.3286849495420602\n",
      "MAPE:  0.05954332275997117\n",
      "Delta:  0.0014957221084427542\n",
      "GRAD\n",
      " tensor([-17.9579,   0.5180,   3.8827,  40.9384])\n",
      "-0.0013251946943235726 -0.00297466751327935 0.28116952494049097\n",
      "arb imp changed to 1034.6747225496388\n",
      "Epoch: 1406\n",
      "Arb loss 0.010557965854507814\n",
      "Real arb loss 1.0133192550856477e-05\n",
      "Bounds loss: 0.3296626779835668\n",
      "MAPE:  0.059747974112967284\n",
      "Delta:  0.0014977042314450449\n",
      "GRAD\n",
      " tensor([-6.0567, -0.5266,  1.9460, 14.0514])\n",
      "0.001105539923290877 0.002786020278083945 -0.3734877948796571\n",
      "Epoch: 1407\n",
      "Arb loss 0.014501237239922653\n",
      "Real arb loss 1.3917954121294942e-05\n",
      "Bounds loss: 0.3287442310777771\n",
      "MAPE:  0.059546176898329646\n",
      "Delta:  0.0014960484596239006\n",
      "GRAD\n",
      " tensor([-17.9679,   0.5141,   3.8812,  40.9463])\n",
      "-0.0011288087667133961 -0.0025287595906846594 0.24616066089617605\n",
      "Epoch: 1408\n",
      "Arb loss 0.010931603097131053\n",
      "Real arb loss 1.0491718959055693e-05\n",
      "Bounds loss: 0.3295755462049973\n",
      "MAPE:  0.05972037535933641\n",
      "Delta:  0.001497737212240552\n",
      "GRAD\n",
      " tensor([-6.0570, -0.5268,  1.9459, 14.0529])\n",
      "0.0009280014423637128 0.002349171219415136 -0.3081886327609691\n",
      "Epoch: 1409\n",
      "Arb loss 0.014300598909521449\n",
      "Real arb loss 1.3725443936973201e-05\n",
      "Bounds loss: 0.32880131681722946\n",
      "MAPE:  0.059550051654250404\n",
      "Delta:  0.0014963473099473112\n",
      "GRAD\n",
      " tensor([-17.9690,   0.5139,   3.8812,  40.9451])\n",
      "-0.0011277964839213617 -0.0025282150144427806 0.24639117492017837\n",
      "Epoch: 1410\n",
      "Arb loss 0.010777057542142237\n",
      "Real arb loss 1.0343484575378578e-05\n",
      "Bounds loss: 0.32963259724317534\n",
      "MAPE:  0.05972426280940461\n",
      "Delta:  0.001498034885182195\n",
      "GRAD\n",
      " tensor([-6.0571, -0.5267,  1.9460, 14.0522])\n",
      "0.0009286400100187997 0.002349450703564515 -0.3086625959886433\n",
      "Epoch: 1411\n",
      "Arb loss 0.014103532100218849\n",
      "Real arb loss 1.353634747076711e-05\n",
      "Bounds loss: 0.3288581417056646\n",
      "MAPE:  0.059553913793283196\n",
      "Delta:  0.0014966437500514107\n",
      "GRAD\n",
      " tensor([-17.9701,   0.5137,   3.8812,  40.9439])\n",
      "-0.0011270815520703081 -0.0025278343403023484 0.24666159747593452\n",
      "Epoch: 1412\n",
      "Arb loss 0.010624732342325745\n",
      "Real arb loss 1.019736788231897e-05\n",
      "Bounds loss: 0.3296894406093562\n",
      "MAPE:  0.0597281479918452\n",
      "Delta:  0.001498330589612115\n",
      "GRAD\n",
      " tensor([-6.0572, -0.5267,  1.9460, 14.0516])\n",
      "0.0009290406734762113 0.002349548239418131 -0.3091054272458962\n",
      "Epoch: 1413\n",
      "Arb loss 0.013908894772373639\n",
      "Real arb loss 1.3349569190024629e-05\n",
      "Bounds loss: 0.3289148193646177\n",
      "MAPE:  0.05955778217585913\n",
      "Delta:  0.0014969385795520517\n",
      "GRAD\n",
      " tensor([-17.9711,   0.5134,   3.8812,  40.9427])\n",
      "-0.0011265744396644628 -0.002527565914872909 0.24696290962324396\n",
      "Epoch: 1414\n",
      "Arb loss 0.010473913649744716\n",
      "Real arb loss 1.005268449878216e-05\n",
      "Bounds loss: 0.3297461732509403\n",
      "MAPE:  0.059732046292450706\n",
      "Delta:  0.0014986249922935228\n",
      "GRAD\n",
      " tensor([-6.0572, -0.5267,  1.9460, 14.0509])\n",
      "0.00092927591639691 0.0023495232833611324 -0.30952897890345343\n",
      "Epoch: 1415\n",
      "Arb loss 0.013715893446873142\n",
      "Real arb loss 1.316434785698432e-05\n",
      "Bounds loss: 0.328971426939288\n",
      "MAPE:  0.05956166925580027\n",
      "Delta:  0.0014972323561804738\n",
      "GRAD\n",
      " tensor([-17.9721,   0.5132,   3.8812,  40.9415])\n",
      "-0.0011262121330914976 -0.0025273734221733513 0.24728879553817817\n",
      "Epoch: 1416\n",
      "Arb loss 0.010324106676665891\n",
      "Real arb loss 9.90896001027022e-06\n",
      "Bounds loss: 0.3298028605803888\n",
      "MAPE:  0.05973596773891451\n",
      "Delta:  0.0014989185574260614\n",
      "GRAD\n",
      " tensor([-6.0573, -0.5266,  1.9461, 14.0502])\n",
      "0.0009293967113073176 0.002349417462292447 -0.30994186008332303\n",
      "arb imp changed to 1035.1920599109135\n",
      "Epoch: 1417\n",
      "Arb loss 0.013530741493482235\n",
      "Real arb loss 1.2980157094637249e-05\n",
      "Bounds loss: 0.32902801598062725\n",
      "MAPE:  0.05956558301728353\n",
      "Delta:  0.0014975254674482721\n",
      "GRAD\n",
      " tensor([-17.9821,   0.5093,   3.8796,  40.9493])\n",
      "-0.001127459591552471 -0.00252896723503504 0.2478184179667242\n",
      "Epoch: 1418\n",
      "Arb loss 0.010177574542650756\n",
      "Real arb loss 9.763485370097746e-06\n",
      "Bounds loss: 0.3298601170524509\n",
      "MAPE:  0.05974003766552596\n",
      "Delta:  0.0014992138669001405\n",
      "GRAD\n",
      " tensor([-6.0604, -0.5278,  1.9456, 14.0526])\n",
      "0.0007895345323274405 0.001998170669185506 -0.26092380816947447\n",
      "Delta imp changed to 0.006282974707307502\n",
      "Epoch: 1419\n",
      "Arb loss 0.012833146050247888\n",
      "Real arb loss 1.231105232595718e-05\n",
      "Bounds loss: 0.3292010002416226\n",
      "MAPE:  0.059595230744295076\n",
      "Delta:  0.0014614928641764671\n",
      "GRAD\n",
      " tensor([-17.9854,   0.5085,   3.8795,  40.9457])\n",
      "-0.0008300986250235898 -0.00183355362011417 0.1795065225845961\n",
      "Epoch: 1420\n",
      "Arb loss 0.010529512628947645\n",
      "Real arb loss 1.0101086107472495e-05\n",
      "Bounds loss: 0.32980460792736077\n",
      "MAPE:  0.05972412501870432\n",
      "Delta:  0.0014627060473935017\n",
      "GRAD\n",
      " tensor([-6.0601, -0.5277,  1.9457, 14.0540])\n",
      "0.000774382950216923 0.001979198089688161 -0.25569599639742413\n",
      "Epoch: 1421\n",
      "Arb loss 0.013221866852185673\n",
      "Real arb loss 1.2683955954792224e-05\n",
      "Bounds loss: 0.32915185927738055\n",
      "MAPE:  0.05958030354685093\n",
      "Delta:  0.001461573352769221\n",
      "GRAD\n",
      " tensor([-17.9824,   0.5098,   3.8801,  40.9473])\n",
      "-0.0008429578575841479 -0.001845651041991525 0.18132156268344157\n",
      "Epoch: 1422\n",
      "Arb loss 0.01082445729295497\n",
      "Real arb loss 1.0383972843404334e-05\n",
      "Bounds loss: 0.3297593587494293\n",
      "MAPE:  0.059710102482838874\n",
      "Delta:  0.0014628053975113736\n",
      "GRAD\n",
      " tensor([-6.0598, -0.5275,  1.9458, 14.0551])\n",
      "0.0007629437418045226 0.0019637723951633212 -0.2527765554686403\n",
      "Epoch: 1423\n",
      "Arb loss 0.01356062632228553\n",
      "Real arb loss 1.3008966275380923e-05\n",
      "Bounds loss: 0.3291117864236704\n",
      "MAPE:  0.05956709311572191\n",
      "Delta:  0.0014616893592878644\n",
      "GRAD\n",
      " tensor([-17.9800,   0.5108,   3.8805,  40.9482])\n",
      "-0.0009730781301366953 -0.0021590787217986573 0.2174863417218481\n",
      "Epoch: 1424\n",
      "Arb loss 0.010611375311994652\n",
      "Real arb loss 1.0179667803276311e-05\n",
      "Bounds loss: 0.3298223646788309\n",
      "MAPE:  0.059716259740632514\n",
      "Delta:  0.001463111697236441\n",
      "GRAD\n",
      " tensor([-6.0600, -0.5276,  1.9458, 14.0539])\n",
      "0.0007686592397562197 0.001968745852282683 -0.25397998429425916\n",
      "Epoch: 1425\n",
      "Arb loss 0.013306452247075544\n",
      "Real arb loss 1.276516440133332e-05\n",
      "Bounds loss: 0.3291730282663794\n",
      "MAPE:  0.05957298503119379\n",
      "Delta:  0.0014619870629115647\n",
      "GRAD\n",
      " tensor([-17.9818,   0.5103,   3.8804,  40.9463])\n",
      "-0.0008473850379213665 -0.00185193369319947 0.18237408514556175\n",
      "Epoch: 1426\n",
      "Arb loss 0.010879700191982037\n",
      "Real arb loss 1.0437016934189594e-05\n",
      "Bounds loss: 0.3297826348883184\n",
      "MAPE:  0.05970333840507955\n",
      "Delta:  0.0014632259288743107\n",
      "GRAD\n",
      " tensor([-6.0598, -0.5274,  1.9458, 14.0548])\n",
      "0.0007584966109505098 0.00195469277825977 -0.25206744197185627\n",
      "Epoch: 1427\n",
      "Arb loss 0.013622118388795661\n",
      "Real arb loss 1.3068061393611478e-05\n",
      "Bounds loss: 0.3291380111535067\n",
      "MAPE:  0.059560806105440414\n",
      "Delta:  0.0014621160769662045\n",
      "GRAD\n",
      " tensor([-17.9796,   0.5113,   3.8808,  40.9470])\n",
      "-0.0009763802041935499 -0.002164152252885243 0.21860555455431008\n",
      "arb imp changed to 1035.709655940869\n",
      "Epoch: 1428\n",
      "Arb loss 0.010649569768030626\n",
      "Real arb loss 1.0211265668710309e-05\n",
      "Bounds loss: 0.32985031592185476\n",
      "MAPE:  0.059710471206450635\n",
      "Delta:  0.0014635436581599875\n",
      "GRAD\n",
      " tensor([-6.0631, -0.5287,  1.9453, 14.0566])\n",
      "0.0007644490797996673 0.0019601532506897668 -0.25283943340957427\n",
      "Epoch: 1429\n",
      "Arb loss 0.013342200954235219\n",
      "Real arb loss 1.2793136873279462e-05\n",
      "Bounds loss: 0.3292037587528595\n",
      "MAPE:  0.05956765342244352\n",
      "Delta:  0.0014624248535572604\n",
      "GRAD\n",
      " tensor([-17.9906,   0.5069,   3.8791,  40.9539])\n",
      "-0.0007232772130376652 -0.0015784610722873182 0.15869219644279264\n",
      "Epoch: 1430\n",
      "Arb loss 0.011224897779426507\n",
      "Real arb loss 1.0762781569360991e-05\n",
      "Bounds loss: 0.32972339407090157\n",
      "MAPE:  0.059678910483795616\n",
      "Delta:  0.0014634825921296184\n",
      "GRAD\n",
      " tensor([-6.0630, -0.5288,  1.9453, 14.0587])\n",
      "0.0005366227308297722 0.0014328955301491364 -0.17137473894454303\n",
      "Epoch: 1431\n",
      "Arb loss 0.013148561706054905\n",
      "Real arb loss 1.2607541530438826e-05\n",
      "Bounds loss: 0.3292509348933518\n",
      "MAPE:  0.05957181328104126\n",
      "Delta:  0.001462697254104508\n",
      "GRAD\n",
      " tensor([-17.9923,   0.5064,   3.8790,  40.9518])\n",
      "-0.0007179257174294573 -0.0015753204557042988 0.15895003644422556\n",
      "Epoch: 1432\n",
      "Arb loss 0.01105859734368833\n",
      "Real arb loss 1.0603358096636386e-05\n",
      "Bounds loss: 0.32976961062614907\n",
      "MAPE:  0.05968289179427397\n",
      "Delta:  0.001463747362080043\n",
      "GRAD\n",
      " tensor([-6.0632, -0.5288,  1.9453, 14.0577])\n",
      "0.0006425141432996329 0.0016511919762484117 -0.2106154329465204\n",
      "Epoch: 1433\n",
      "Arb loss 0.013387708611010485\n",
      "Real arb loss 1.2836827642664556e-05\n",
      "Bounds loss: 0.3292250976910726\n",
      "MAPE:  0.059562400618877534\n",
      "Delta:  0.0014628068836976891\n",
      "GRAD\n",
      " tensor([-17.9904,   0.5072,   3.8794,  40.9525])\n",
      "-0.0007243076656142655 -0.0015816619998594295 0.1589024479376675\n",
      "Epoch: 1434\n",
      "Arb loss 0.01126036894044473\n",
      "Real arb loss 1.0796868836840636e-05\n",
      "Bounds loss: 0.3297458205174906\n",
      "MAPE:  0.0596739710302863\n",
      "Delta:  0.0014638664059368647\n",
      "GRAD\n",
      " tensor([-6.0631, -0.5287,  1.9454, 14.0583])\n",
      "0.0005353353943854389 0.0014278018035158713 -0.17049577718148812\n",
      "Epoch: 1435\n",
      "Arb loss 0.013180214294296142\n",
      "Real arb loss 1.2637953753266345e-05\n",
      "Bounds loss: 0.3292750088402539\n",
      "MAPE:  0.059567154166953885\n",
      "Delta:  0.001463082746437115\n",
      "GRAD\n",
      " tensor([-17.9922,   0.5067,   3.8792,  40.9504])\n",
      "-0.0007187373370014516 -0.0015782834735060813 0.15945637829839698\n",
      "Epoch: 1436\n",
      "Arb loss 0.011078545057730918\n",
      "Real arb loss 1.0622539452069179e-05\n",
      "Bounds loss: 0.3297946981449451\n",
      "MAPE:  0.05967852662263641\n",
      "Delta:  0.0014641343186341017\n",
      "GRAD\n",
      " tensor([-6.0632, -0.5287,  1.9454, 14.0573])\n",
      "0.0005400715450796234 0.0014311496096117704 -0.1727770484579676\n",
      "Epoch: 1437\n",
      "Arb loss 0.012992663374014269\n",
      "Real arb loss 1.2458183107102943e-05\n",
      "Bounds loss: 0.3293227125914429\n",
      "MAPE:  0.05957152138749504\n",
      "Delta:  0.0014633435813504328\n",
      "GRAD\n",
      " tensor([-17.9937,   0.5062,   3.8791,  40.9486])\n",
      "-0.0007143798544682056 -0.0015756249117007126 0.1588627034500908\n",
      "Epoch: 1438\n",
      "Arb loss 0.010928613745401383\n",
      "Real arb loss 1.0478884274022108e-05\n",
      "Bounds loss: 0.3298416016613908\n",
      "MAPE:  0.05968274348343176\n",
      "Delta:  0.001464388964525115\n",
      "GRAD\n",
      " tensor([-6.0634, -0.5287,  1.9454, 14.0564])\n",
      "0.0006451108925322746 0.0016490720900357303 -0.21102179949106414\n",
      "arb imp changed to 1036.2275107688392\n",
      "Epoch: 1439\n",
      "Arb loss 0.01324140687864071\n",
      "Real arb loss 1.2690340265554406e-05\n",
      "Bounds loss: 0.32929766908195834\n",
      "MAPE:  0.05956236106129261\n",
      "Delta:  0.0014634442712531958\n",
      "GRAD\n",
      " tensor([-18.0007,   0.5034,   3.8779,  40.9584])\n",
      "-0.0007225822414627103 -0.0015835917369220187 0.16001203463199287\n",
      "Epoch: 1440\n",
      "Arb loss 0.011122622422599343\n",
      "Real arb loss 1.0659548581819044e-05\n",
      "Bounds loss: 0.32981914214970426\n",
      "MAPE:  0.05967418156564847\n",
      "Delta:  0.0014645017300949736\n",
      "GRAD\n",
      " tensor([-6.0662, -0.5299,  1.9449, 14.0600])\n",
      "0.00045621906573090065 0.001211738580083943 -0.1452418031494076\n",
      "Epoch: 1441\n",
      "Arb loss 0.012738092159007704\n",
      "Real arb loss 1.2208058901404793e-05\n",
      "Bounds loss: 0.32941948757071127\n",
      "MAPE:  0.05958351902719326\n",
      "Delta:  0.0014638335964839084\n",
      "GRAD\n",
      " tensor([-18.0034,   0.5026,   3.8778,  40.9551])\n",
      "-0.0006077685946024314 -0.0013391843283736549 0.13789956597911268\n",
      "Epoch: 1442\n",
      "Arb loss 0.010981514778878603\n",
      "Real arb loss 1.0524380553818827e-05\n",
      "Bounds loss: 0.3298606409859268\n",
      "MAPE:  0.059678082181503646\n",
      "Delta:  0.0014647232685715754\n",
      "GRAD\n",
      " tensor([-6.0664, -0.5299,  1.9449, 14.0592])\n",
      "0.0005454095439951789 0.0013970108253196223 -0.1777411750336464\n",
      "Epoch: 1443\n",
      "Arb loss 0.01293338211932584\n",
      "Real arb loss 1.2395238776435231e-05\n",
      "Bounds loss: 0.3293998220996226\n",
      "MAPE:  0.05957604826927435\n",
      "Delta:  0.0014639243945215846\n",
      "GRAD\n",
      " tensor([-18.0018,   0.5034,   3.8781,  40.9557])\n",
      "-0.0006126009457985138 -0.001343795556486782 0.1386254559013732\n",
      "Epoch: 1444\n",
      "Arb loss 0.011140486126687627\n",
      "Real arb loss 1.0676730390848003e-05\n",
      "Bounds loss: 0.3298424681168677\n",
      "MAPE:  0.05967096481655099\n",
      "Delta:  0.0014648211959902462\n",
      "GRAD\n",
      " tensor([-6.0662, -0.5298,  1.9450, 14.0597])\n",
      "0.0004547324175125933 0.0012080114485384374 -0.14466582622017965\n",
      "Epoch: 1445\n",
      "Arb loss 0.012752133756699343\n",
      "Real arb loss 1.222157379613851e-05\n",
      "Bounds loss: 0.32944401463916834\n",
      "MAPE:  0.059580505022712574\n",
      "Delta:  0.00146415509430657\n",
      "GRAD\n",
      " tensor([-18.0032,   0.5029,   3.8780,  40.9540])\n",
      "-0.0006088848659548951 -0.0013414421638238139 0.13837453405094124\n",
      "Epoch: 1446\n",
      "Arb loss 0.01098756318996079\n",
      "Real arb loss 1.0530226923380403e-05\n",
      "Bounds loss: 0.32988594473102467\n",
      "MAPE:  0.059675281175089946\n",
      "Delta:  0.0014650465961849038\n",
      "GRAD\n",
      " tensor([-6.0664, -0.5298,  1.9450, 14.0589])\n",
      "0.0005441624493343067 0.001393443712648601 -0.17742606276964001\n",
      "Epoch: 1447\n",
      "Arb loss 0.01293704326618816\n",
      "Real arb loss 1.2398804914398941e-05\n",
      "Bounds loss: 0.32942626723544804\n",
      "MAPE:  0.05957343210939161\n",
      "Delta:  0.0014642493728407348\n",
      "GRAD\n",
      " tensor([-18.0018,   0.5036,   3.8783,  40.9545])\n",
      "-0.0006135059209306792 -0.0013458573357256753 0.13897405259847873\n",
      "Epoch: 1448\n",
      "Arb loss 0.011139129934844132\n",
      "Real arb loss 1.067548974079035e-05\n",
      "Bounds loss: 0.3298696279937876\n",
      "MAPE:  0.05966854773911736\n",
      "Delta:  0.0014651476985006917\n",
      "GRAD\n",
      " tensor([-6.0662, -0.5297,  1.9451, 14.0593])\n",
      "0.00045367531570417174 0.0012047895362378158 -0.14428476903468157\n",
      "Epoch: 1449\n",
      "Arb loss 0.012746336724740426\n",
      "Real arb loss 1.2216075991425883e-05\n",
      "Bounds loss: 0.3294722045176581\n",
      "MAPE:  0.05957826222850699\n",
      "Delta:  0.0014644829971560212\n",
      "GRAD\n",
      " tensor([-18.0033,   0.5031,   3.8782,  40.9528])\n",
      "-0.0006096148733396589 -0.0013433464229302139 0.13873857374885268\n",
      "arb imp changed to 1036.7456245242236\n",
      "Epoch: 1450\n",
      "Arb loss 0.010983417111100829\n",
      "Real arb loss 1.0521050574736076e-05\n",
      "Bounds loss: 0.3299147998250518\n",
      "MAPE:  0.0596732251494932\n",
      "Delta:  0.0014653757677728404\n",
      "GRAD\n",
      " tensor([-6.0694, -0.5310,  1.9446, 14.0614])\n",
      "0.0005427390038694746 0.0013899458587486313 -0.17707044618872048\n",
      "Epoch: 1451\n",
      "Arb loss 0.01292825567964028\n",
      "Real arb loss 1.2384250115812683e-05\n",
      "Bounds loss: 0.32945623611529506\n",
      "MAPE:  0.059571719097105666\n",
      "Delta:  0.001464580451188345\n",
      "GRAD\n",
      " tensor([-18.0108,   0.5001,   3.8769,  40.9622])\n",
      "-0.0005226611518420743 -0.001145874903626165 0.11970422782928836\n",
      "Epoch: 1452\n",
      "Arb loss 0.011380688816329329\n",
      "Real arb loss 1.0901622411522615e-05\n",
      "Bounds loss: 0.3298337517481027\n",
      "MAPE:  0.05965261888577242\n",
      "Delta:  0.0014653459304939283\n",
      "GRAD\n",
      " tensor([-6.0694, -0.5310,  1.9445, 14.0628])\n",
      "0.0003825579612778407 0.0010175806701905321 -0.12039287475972982\n",
      "Epoch: 1453\n",
      "Arb loss 0.012750842659673122\n",
      "Real arb loss 1.2214340632974242e-05\n",
      "Bounds loss: 0.3294981192979474\n",
      "MAPE:  0.059576289655976715\n",
      "Delta:  0.0014647853507421917\n",
      "GRAD\n",
      " tensor([-18.0122,   0.4996,   3.8768,  40.9607])\n",
      "-0.0005195688608796711 -0.0011438284649145647 0.11985382033978031\n",
      "Epoch: 1454\n",
      "Arb loss 0.011222605454359854\n",
      "Real arb loss 1.0750209823154162e-05\n",
      "Bounds loss: 0.3298750086259362\n",
      "MAPE:  0.05965721161156855\n",
      "Delta:  0.0014655464075983102\n",
      "GRAD\n",
      " tensor([-6.0695, -0.5310,  1.9445, 14.0620])\n",
      "0.00038530339928444235 0.0010198092901049227 -0.12142564452806393\n",
      "Epoch: 1455\n",
      "Arb loss 0.012585317554939666\n",
      "Real arb loss 1.205580648522255e-05\n",
      "Bounds loss: 0.32953859902756605\n",
      "MAPE:  0.05958074879591088\n",
      "Delta:  0.0014649817275856534\n",
      "GRAD\n",
      " tensor([-18.0134,   0.4993,   3.8767,  40.9592])\n",
      "-0.0005169674952463232 -0.0011420761602964902 0.12004998272248735\n",
      "Epoch: 1456\n",
      "Arb loss 0.011074450399912143\n",
      "Real arb loss 1.0608297087084533e-05\n",
      "Bounds loss: 0.3299149572054129\n",
      "MAPE:  0.05966156878861798\n",
      "Delta:  0.001465739075519945\n",
      "GRAD\n",
      " tensor([-6.0696, -0.5310,  1.9446, 14.0612])\n",
      "0.0003876052453536394 0.0010217161114053352 -0.12238842927460869\n",
      "Epoch: 1457\n",
      "Arb loss 0.012429834989436951\n",
      "Real arb loss 1.1906882162677458e-05\n",
      "Bounds loss: 0.32957787777824255\n",
      "MAPE:  0.05958499696779171\n",
      "Delta:  0.0014651709473659537\n",
      "GRAD\n",
      " tensor([-18.0145,   0.4989,   3.8766,  40.9579])\n",
      "-0.000514777578014769 -0.0011405742913306316 0.11943745037101483\n",
      "Epoch: 1458\n",
      "Arb loss 0.010945247189766171\n",
      "Real arb loss 1.0484600031803917e-05\n",
      "Bounds loss: 0.3299537858326277\n",
      "MAPE:  0.05966572505074566\n",
      "Delta:  0.0014659251845176165\n",
      "GRAD\n",
      " tensor([-6.0697, -0.5310,  1.9446, 14.0606])\n",
      "0.0004628458923947587 0.001179019872977194 -0.14960881365459655\n",
      "Epoch: 1459\n",
      "Arb loss 0.012582752636983396\n",
      "Real arb loss 1.2053398611732012e-05\n",
      "Bounds loss: 0.329564763761967\n",
      "MAPE:  0.05957986650435178\n",
      "Delta:  0.0014652466870674046\n",
      "GRAD\n",
      " tensor([-18.0132,   0.4996,   3.8769,  40.9585])\n",
      "-0.0005184634627404261 -0.0011438929184151014 0.12045881596275032\n",
      "Epoch: 1460\n",
      "Arb loss 0.011067049152780202\n",
      "Real arb loss 1.0601253918305995e-05\n",
      "Bounds loss: 0.3299417505613934\n",
      "MAPE:  0.05966046719123963\n",
      "Delta:  0.0014660063639385505\n",
      "GRAD\n",
      " tensor([-6.0696, -0.5309,  1.9446, 14.0610])\n",
      "0.0003860880254364929 0.0010191468613085508 -0.12206215132022402\n",
      "arb imp changed to 1037.2639973364855\n",
      "Epoch: 1461\n",
      "Arb loss 0.012424125939625783\n",
      "Real arb loss 1.1895513780818188e-05\n",
      "Bounds loss: 0.3296054914618941\n",
      "MAPE:  0.05958429941893063\n",
      "Delta:  0.00146544035643622\n",
      "GRAD\n",
      " tensor([-18.0234,   0.4954,   3.8753,  40.9660])\n",
      "-0.0005167781967190255 -0.0011431054105295324 0.11988074660547399\n",
      "Epoch: 1462\n",
      "Arb loss 0.010934712446063007\n",
      "Real arb loss 1.0469324506367808e-05\n",
      "Bounds loss: 0.32998226528252445\n",
      "MAPE:  0.05966496696853591\n",
      "Delta:  0.0014661976640610184\n",
      "GRAD\n",
      " tensor([-6.0727, -0.5322,  1.9441, 14.0633])\n",
      "0.00039200623409163526 0.0010002576407583952 -0.12585134914579466\n",
      "Epoch: 1463\n",
      "Arb loss 0.012310860759921351\n",
      "Real arb loss 1.1787074195636467e-05\n",
      "Bounds loss: 0.32965219800036083\n",
      "MAPE:  0.05959183076080901\n",
      "Delta:  0.0014656229054362958\n",
      "GRAD\n",
      " tensor([-18.0233,   0.4957,   3.8755,  40.9653])\n",
      "-0.00044034900486655815 -0.0009715459400203574 0.10377421682677457\n",
      "Epoch: 1464\n",
      "Arb loss 0.011033310826097043\n",
      "Real arb loss 1.0563692762487218e-05\n",
      "Bounds loss: 0.3299724702549469\n",
      "MAPE:  0.05966057245245746\n",
      "Delta:  0.0014662682910242144\n",
      "GRAD\n",
      " tensor([-6.0726, -0.5321,  1.9442, 14.0636])\n",
      "0.0003895914757464647 0.000997141869424012 -0.12605327765668317\n",
      "Epoch: 1465\n",
      "Arb loss 0.01242409581913154\n",
      "Real arb loss 1.1895524138751366e-05\n",
      "Bounds loss: 0.3296434408890984\n",
      "MAPE:  0.05958803267443261\n",
      "Delta:  0.001465697045396874\n",
      "GRAD\n",
      " tensor([-18.0223,   0.4962,   3.8757,  40.9656])\n",
      "-0.00044254316285186057 -0.0009736142385436963 0.10397159841836001\n",
      "Epoch: 1466\n",
      "Arb loss 0.01113234271791357\n",
      "Real arb loss 1.0658544341307674e-05\n",
      "Bounds loss: 0.3299643864367906\n",
      "MAPE:  0.05965649943712452\n",
      "Delta:  0.0014663456796031266\n",
      "GRAD\n",
      " tensor([-6.0725, -0.5321,  1.9442, 14.0639])\n",
      "0.00032514837291675036 0.0008622151675143908 -0.10229073401206157\n",
      "Epoch: 1467\n",
      "Arb loss 0.012271078225802779\n",
      "Real arb loss 1.1749020501196937e-05\n",
      "Bounds loss: 0.3296798861380652\n",
      "MAPE:  0.05959211574569289\n",
      "Delta:  0.00146586889969127\n",
      "GRAD\n",
      " tensor([-18.0234,   0.4958,   3.8756,  40.9643])\n",
      "-0.000440434372032783 -0.0009721749687967574 0.10372649944261514\n",
      "Epoch: 1468\n",
      "Arb loss 0.010998242237053759\n",
      "Real arb loss 1.0530173106226521e-05\n",
      "Bounds loss: 0.3300003926710844\n",
      "MAPE:  0.059660619878146845\n",
      "Delta:  0.0014665145187395879\n",
      "GRAD\n",
      " tensor([-6.0726, -0.5321,  1.9442, 14.0632])\n",
      "0.0003893994841961401 0.0009960308420871034 -0.12577430895930397\n",
      "Epoch: 1469\n",
      "Arb loss 0.012381538554186226\n",
      "Real arb loss 1.1854815259742216e-05\n",
      "Bounds loss: 0.3296717021020832\n",
      "MAPE:  0.05958843376564342\n",
      "Delta:  0.0014659434587424246\n",
      "GRAD\n",
      " tensor([-18.0225,   0.4963,   3.8758,  40.9646])\n",
      "-0.00044261168377657256 -0.0009742167640454102 0.10418080331107071\n",
      "Epoch: 1470\n",
      "Arb loss 0.011091619921384112\n",
      "Real arb loss 1.0619591520143114e-05\n",
      "Bounds loss: 0.32999287380090236\n",
      "MAPE:  0.059656667253748887\n",
      "Delta:  0.0014665923024450198\n",
      "GRAD\n",
      " tensor([-6.0725, -0.5320,  1.9442, 14.0634])\n",
      "0.00032497084762816986 0.0008611672591050112 -0.10225795093189194\n",
      "Epoch: 1471\n",
      "Arb loss 0.012225826247060203\n",
      "Real arb loss 1.1705728549292325e-05\n",
      "Bounds loss: 0.32970869474224707\n",
      "MAPE:  0.0595926304419657\n",
      "Delta:  0.0014661157027013694\n",
      "GRAD\n",
      " tensor([-18.0237,   0.4959,   3.8757,  40.9633])\n",
      "-0.0004404872496048817 -0.0009727539410144814 0.10364298936633598\n",
      "arb imp changed to 1037.7826293351538\n",
      "Epoch: 1472\n",
      "Arb loss 0.010964184419875142\n",
      "Real arb loss 1.0492376568755003e-05\n",
      "Bounds loss: 0.3300294201744443\n",
      "MAPE:  0.05966090540128608\n",
      "Delta:  0.0014667615079748547\n",
      "GRAD\n",
      " tensor([-6.0756, -0.5333,  1.9437, 14.0658])\n",
      "0.0003888567771859197 0.0009947092507620603 -0.12541533620858858\n",
      "Epoch: 1473\n",
      "Arb loss 0.01233926129514675\n",
      "Real arb loss 1.1808468862206643e-05\n",
      "Bounds loss: 0.32970113685717317\n",
      "MAPE:  0.0595890732429634\n",
      "Delta:  0.0014661911478219632\n",
      "GRAD\n",
      " tensor([-18.0317,   0.4926,   3.8743,  40.9725])\n",
      "-0.0003767609463014576 -0.0008289431521788515 0.08946479495541748\n",
      "Epoch: 1474\n",
      "Arb loss 0.011235331813475125\n",
      "Real arb loss 1.0751868083786792e-05\n",
      "Bounds loss: 0.3299744403568365\n",
      "MAPE:  0.05964676638196384\n",
      "Delta:  0.0014667435513862753\n",
      "GRAD\n",
      " tensor([-6.0756, -0.5333,  1.9437, 14.0667])\n",
      "0.00027474821677975214 0.0007289581623577401 -0.08584406610522843\n",
      "Epoch: 1475\n",
      "Arb loss 0.012199818380385261\n",
      "Real arb loss 1.1675022770248856e-05\n",
      "Bounds loss: 0.3297339027951689\n",
      "MAPE:  0.05959290765093274\n",
      "Delta:  0.001466340566211059\n",
      "GRAD\n",
      " tensor([-18.0328,   0.4923,   3.8743,  40.9713])\n",
      "-0.00037513319419724134 -0.0008278095997917845 0.0893562233683396\n",
      "Epoch: 1476\n",
      "Arb loss 0.01110968868413438\n",
      "Real arb loss 1.0631637332919257e-05\n",
      "Bounds loss: 0.3300068596852796\n",
      "MAPE:  0.059650662642917754\n",
      "Delta:  0.0014668906392314427\n",
      "GRAD\n",
      " tensor([-6.0757, -0.5333,  1.9437, 14.0661])\n",
      "0.0002762350582272699 0.0007302557395887366 -0.08616109346027212\n",
      "Epoch: 1477\n",
      "Arb loss 0.012066911609162612\n",
      "Real arb loss 1.1547825260356596e-05\n",
      "Bounds loss: 0.32976587028189075\n",
      "MAPE:  0.05959661417428832\n",
      "Delta:  0.0014664854326103015\n",
      "GRAD\n",
      " tensor([-18.0337,   0.4920,   3.8742,  40.9703])\n",
      "-0.0003736934687852411 -0.0008267894836222478 0.08903435555525907\n",
      "Epoch: 1478\n",
      "Arb loss 0.010992541910498544\n",
      "Real arb loss 1.051954992662366e-05\n",
      "Bounds loss: 0.3300385172354974\n",
      "MAPE:  0.0596544187184969\n",
      "Delta:  0.0014670334486385367\n",
      "GRAD\n",
      " tensor([-6.0758, -0.5333,  1.9437, 14.0655])\n",
      "0.00033057328028229804 0.0008438481324388736 -0.10592534203621029\n",
      "Epoch: 1479\n",
      "Arb loss 0.01215693067221548\n",
      "Real arb loss 1.163400778286702e-05\n",
      "Bounds loss: 0.3297600148490953\n",
      "MAPE:  0.05959373694862228\n",
      "Delta:  0.0014665484865791362\n",
      "GRAD\n",
      " tensor([-18.0329,   0.4924,   3.8744,  40.9705])\n",
      "-0.00037531268711354926 -0.0008282643239070353 0.08950627209801387\n",
      "Epoch: 1480\n",
      "Arb loss 0.01106880912759147\n",
      "Real arb loss 1.0592546370145802e-05\n",
      "Bounds loss: 0.33003314330484584\n",
      "MAPE:  0.059651299782010454\n",
      "Delta:  0.0014670989008324167\n",
      "GRAD\n",
      " tensor([-6.0757, -0.5332,  1.9438, 14.0657])\n",
      "0.000275990462261122 0.0007295116017520531 -0.08609549467825373\n",
      "Epoch: 1481\n",
      "Arb loss 0.012021783724930627\n",
      "Real arb loss 1.150466366068621e-05\n",
      "Bounds loss: 0.32979238029784225\n",
      "MAPE:  0.05959752201023663\n",
      "Delta:  0.0014666939955285932\n",
      "GRAD\n",
      " tensor([-18.0339,   0.4921,   3.8743,  40.9694])\n",
      "-0.0003738466338996105 -0.0008272212014786007 0.0888742269837487\n",
      "Epoch: 1482\n",
      "Arb loss 0.010953356989411607\n",
      "Real arb loss 1.0482102680890933e-05\n",
      "Bounds loss: 0.3300651915469107\n",
      "MAPE:  0.0596551380843722\n",
      "Delta:  0.0014672423141417824\n",
      "GRAD\n",
      " tensor([-6.0757, -0.5332,  1.9438, 14.0652])\n",
      "0.0003303556717562106 0.0008431140237746826 -0.10557132710945782\n",
      "arb imp changed to 1038.3015206498214\n",
      "Epoch: 1483\n",
      "Arb loss 0.01211577228179899\n",
      "Real arb loss 1.1588851711526842e-05\n",
      "Bounds loss: 0.32978690895515766\n",
      "MAPE:  0.05959471906121373\n",
      "Delta:  0.0014667576023214648\n",
      "GRAD\n",
      " tensor([-18.0421,   0.4887,   3.8729,  40.9786])\n",
      "-0.00037598910856817547 -0.0008293161499839385 0.08973680305585119\n",
      "Epoch: 1484\n",
      "Arb loss 0.011028541610677654\n",
      "Real arb loss 1.0548765282100036e-05\n",
      "Bounds loss: 0.3300604065648074\n",
      "MAPE:  0.05965214200496353\n",
      "Delta:  0.0014673090872048473\n",
      "GRAD\n",
      " tensor([-6.0787, -0.5344,  1.9433, 14.0684])\n",
      "0.00023415654527980667 0.0006194611266280292 -0.07236688126889779\n",
      "Epoch: 1485\n",
      "Arb loss 0.01182664277198666\n",
      "Real arb loss 1.131223593906699e-05\n",
      "Bounds loss: 0.32985594697350146\n",
      "MAPE:  0.05960637059571673\n",
      "Delta:  0.0014669655071781298\n",
      "GRAD\n",
      " tensor([-18.0436,   0.4883,   3.8728,  40.9769])\n",
      "-0.0003177498739084239 -0.0007028972669043121 0.07558731471128399\n",
      "Epoch: 1486\n",
      "Arb loss 0.010932698602802573\n",
      "Real arb loss 1.0457146673020854e-05\n",
      "Bounds loss: 0.33008780181710123\n",
      "MAPE:  0.059655432087440924\n",
      "Delta:  0.0014674316352830637\n",
      "GRAD\n",
      " tensor([-6.0787, -0.5344,  1.9433, 14.0679])\n",
      "0.00028023984194003315 0.0007159297641633477 -0.08848708041835485\n",
      "Epoch: 1487\n",
      "Arb loss 0.0119001011832584\n",
      "Real arb loss 1.1382536655812197e-05\n",
      "Bounds loss: 0.32985148213499316\n",
      "MAPE:  0.059604019044035984\n",
      "Delta:  0.0014670204024735342\n",
      "GRAD\n",
      " tensor([-18.0430,   0.4886,   3.8730,  40.9771])\n",
      "-0.00031887766077942636 -0.0007039292221455717 0.07639539588230193\n",
      "Epoch: 1488\n",
      "Arb loss 0.010990988242323925\n",
      "Real arb loss 1.0512882975218055e-05\n",
      "Bounds loss: 0.330083674232236\n",
      "MAPE:  0.05965286628561015\n",
      "Delta:  0.0014674882025077906\n",
      "GRAD\n",
      " tensor([-6.0787, -0.5344,  1.9433, 14.0681])\n",
      "0.00027914478791091213 0.0007145124550990145 -0.08888301174420454\n",
      "Epoch: 1489\n",
      "Arb loss 0.011967900379346816\n",
      "Real arb loss 1.1447420543117839e-05\n",
      "Bounds loss: 0.3298478253357722\n",
      "MAPE:  0.05960180363093432\n",
      "Delta:  0.0014670785608247399\n",
      "GRAD\n",
      " tensor([-18.0424,   0.4889,   3.8731,  40.9772])\n",
      "-0.00031989123153741694 -0.000704881494977716 0.07678595543767452\n",
      "Epoch: 1490\n",
      "Arb loss 0.011048933714135763\n",
      "Real arb loss 1.0568318289522676e-05\n",
      "Bounds loss: 0.3300803289640101\n",
      "MAPE:  0.05965044777820301\n",
      "Delta:  0.0014675478663923242\n",
      "GRAD\n",
      " tensor([-6.0786, -0.5343,  1.9434, 14.0682])\n",
      "0.00023305756437130842 0.0006177342432450716 -0.072119706386367\n",
      "Epoch: 1491\n",
      "Arb loss 0.011845779569481666\n",
      "Real arb loss 1.1330591442660287e-05\n",
      "Bounds loss: 0.3298764270417874\n",
      "MAPE:  0.05960521630250222\n",
      "Delta:  0.0014672058432609845\n",
      "GRAD\n",
      " tensor([-18.0433,   0.4886,   3.8730,  40.9762])\n",
      "-0.00031870956080504165 -0.0007040445464812084 0.07603126911161551\n",
      "Epoch: 1492\n",
      "Arb loss 0.010945129915197528\n",
      "Real arb loss 1.0469070661109596e-05\n",
      "Bounds loss: 0.3301086747412589\n",
      "MAPE:  0.05965392777982493\n",
      "Delta:  0.0014676734557909007\n",
      "GRAD\n",
      " tensor([-6.0787, -0.5343,  1.9434, 14.0677])\n",
      "0.00027924854180638725 0.0007142272395912475 -0.08844910013023966\n",
      "Epoch: 1493\n",
      "Arb loss 0.011913216807005316\n",
      "Real arb loss 1.1395130496921247e-05\n",
      "Bounds loss: 0.32987290213373327\n",
      "MAPE:  0.059603031860565925\n",
      "Delta:  0.001467263610118523\n",
      "GRAD\n",
      " tensor([-18.0427,   0.4889,   3.8732,  40.9763])\n",
      "-0.00031973702718923747 -0.0007050014016714012 0.07677091648784651\n",
      "arb imp changed to 1038.8206714101464\n",
      "Epoch: 1494\n",
      "Arb loss 0.011004127548530307\n",
      "Real arb loss 1.0520226449113282e-05\n",
      "Bounds loss: 0.33010546299211097\n",
      "MAPE:  0.059651540518011595\n",
      "Delta:  0.0014677327486233255\n",
      "GRAD\n",
      " tensor([-6.0816, -0.5356,  1.9429, 14.0709])\n",
      "0.0002779709682512177 0.0007126976223524872 -0.08876736000911811\n",
      "Epoch: 1495\n",
      "Arb loss 0.011980934900216953\n",
      "Real arb loss 1.1454207731172849e-05\n",
      "Bounds loss: 0.3298701976135109\n",
      "MAPE:  0.059600986994392355\n",
      "Delta:  0.0014673247615300568\n",
      "GRAD\n",
      " tensor([-18.0511,   0.4855,   3.8717,  40.9854])\n",
      "-0.0002729357014878975 -0.0006003317113500994 0.06582159561926426\n",
      "Epoch: 1496\n",
      "Arb loss 0.011192330648074143\n",
      "Real arb loss 1.0700188532113575e-05\n",
      "Bounds loss: 0.3300682291537676\n",
      "MAPE:  0.059641823395317636\n",
      "Delta:  0.0014677252468431555\n",
      "GRAD\n",
      " tensor([-6.0816, -0.5356,  1.9429, 14.0715])\n",
      "0.00019662598301140033 0.0005226236141288032 -0.06052064217822384\n",
      "Epoch: 1497\n",
      "Arb loss 0.011869697686366606\n",
      "Real arb loss 1.134784347069062e-05\n",
      "Bounds loss: 0.3298957277029382\n",
      "MAPE:  0.059604120747072734\n",
      "Delta:  0.0014674366539237042\n",
      "GRAD\n",
      " tensor([-18.0519,   0.4852,   3.8717,  40.9845])\n",
      "-0.0002719853502450853 -0.0005996587862411307 0.06555954902422723\n",
      "Epoch: 1498\n",
      "Arb loss 0.011091525658994498\n",
      "Real arb loss 1.060381941453168e-05\n",
      "Bounds loss: 0.33009355257459866\n",
      "MAPE:  0.05964503778696208\n",
      "Delta:  0.0014678357751959842\n",
      "GRAD\n",
      " tensor([-6.0817, -0.5356,  1.9429, 14.0710])\n",
      "0.00019751259980882452 0.0005234167630326914 -0.060482339514205785\n",
      "Epoch: 1499\n",
      "Arb loss 0.011762367079632328\n",
      "Real arb loss 1.1245210398549415e-05\n",
      "Bounds loss: 0.32992077607581205\n",
      "MAPE:  0.059607176125919786\n",
      "Delta:  0.001467545859135933\n",
      "GRAD\n",
      " tensor([-18.0527,   0.4849,   3.8716,  40.9836])\n",
      "-0.0002711149484000419 -0.0005990336746166669 0.06524232256260953\n",
      "Epoch: 1500\n",
      "Arb loss 0.010994962932523136\n",
      "Real arb loss 1.0511507239497228e-05\n",
      "Bounds loss: 0.33011840973063716\n",
      "MAPE:  0.059648165170572684\n",
      "Delta:  0.0014679437327558072\n",
      "GRAD\n",
      " tensor([-6.0818, -0.5356,  1.9429, 14.0705])\n",
      "0.00023667728376064456 0.0006053492884000589 -0.0746544430134306\n",
      "Epoch: 1501\n",
      "Arb loss 0.011815785766203964\n",
      "Real arb loss 1.1296310712213576e-05\n",
      "Bounds loss: 0.329918572786219\n",
      "MAPE:  0.05960548185604298\n",
      "Delta:  0.001467596303820425\n",
      "GRAD\n",
      " tensor([-18.0522,   0.4852,   3.8717,  40.9837])\n",
      "-0.0002718307494640193 -0.0005996971861881306 0.06551500486449746\n",
      "Epoch: 1502\n",
      "Arb loss 0.011041674504253252\n",
      "Real arb loss 1.0556179377436578e-05\n",
      "Bounds loss: 0.3301164240259901\n",
      "MAPE:  0.059646297903512724\n",
      "Delta:  0.0014679952416236032\n",
      "GRAD\n",
      " tensor([-6.0817, -0.5355,  1.9429, 14.0707])\n",
      "0.00019762049900473588 0.0005232762327471718 -0.06038166770119768\n",
      "Epoch: 1503\n",
      "Arb loss 0.011708389225033857\n",
      "Real arb loss 1.1193612280769172e-05\n",
      "Bounds loss: 0.3299436819472578\n",
      "MAPE:  0.0596085530803149\n",
      "Delta:  0.001467705135671417\n",
      "GRAD\n",
      " tensor([-18.0530,   0.4850,   3.8717,  40.9829])\n",
      "-0.00027097146450638654 -0.0005990763728846993 0.06480865378683831\n",
      "Epoch: 1504\n",
      "Arb loss 0.01094958428134709\n",
      "Real arb loss 1.0468170946455122e-05\n",
      "Bounds loss: 0.330141343411495\n",
      "MAPE:  0.05964944085334322\n",
      "Delta:  0.0014681028418814935\n",
      "GRAD\n",
      " tensor([-6.0818, -0.5355,  1.9429, 14.0702])\n",
      "0.00023677623344586785 0.000605206886438836 -0.07417087007649159\n",
      "arb imp changed to 1039.3400817458514\n",
      "Epoch: 1505\n",
      "Arb loss 0.011767605336707716\n",
      "Real arb loss 1.124463395186342e-05\n",
      "Bounds loss: 0.32994153959696415\n",
      "MAPE:  0.059606874355993815\n",
      "Delta:  0.0014677552300202815\n",
      "GRAD\n",
      " tensor([-18.0615,   0.4814,   3.8702,  40.9920])\n",
      "-0.0002717266211347269 -0.0005848707176683288 0.0637182398601206\n",
      "Epoch: 1506\n",
      "Arb loss 0.01101779423728414\n",
      "Real arb loss 1.0528107715179768e-05\n",
      "Bounds loss: 0.3301345127420168\n",
      "MAPE:  0.05964661309132165\n",
      "Delta:  0.0014681540581895879\n",
      "GRAD\n",
      " tensor([-6.0848, -0.5368,  1.9424, 14.0734])\n",
      "0.00016787527130679436 0.0004444886931161962 -0.05112466223166501\n",
      "Epoch: 1507\n",
      "Arb loss 0.011581075246203276\n",
      "Real arb loss 1.1066378616013587e-05\n",
      "Bounds loss: 0.32998777168389554\n",
      "MAPE:  0.05961459526414203\n",
      "Delta:  0.001467907591428749\n",
      "GRAD\n",
      " tensor([-6.0852, -0.5371,  1.9422, 14.0754])\n",
      "0.0001662261945390986 0.0004403424448329307 -0.05164390058131363\n",
      "Epoch: 1508\n",
      "Arb loss 0.012179167144842911\n",
      "Real arb loss 1.1638035883270728e-05\n",
      "Bounds loss: 0.3298424640617473\n",
      "MAPE:  0.05958331289717368\n",
      "Delta:  0.0014676635867358907\n",
      "GRAD\n",
      " tensor([-18.0606,   0.4816,   3.8702,  40.9933])\n",
      "-0.00023141712921392887 -0.0004987596652483717 0.05530195673939897\n",
      "Epoch: 1509\n",
      "Arb loss 0.0115056353702769\n",
      "Real arb loss 1.0994310321547827e-05\n",
      "Bounds loss: 0.33000697617870745\n",
      "MAPE:  0.059616834307590794\n",
      "Delta:  0.0014680032292297852\n",
      "GRAD\n",
      " tensor([-6.0852, -0.5371,  1.9422, 14.0749])\n",
      "0.00016690405837438416 0.0004408833334217377 -0.05153220113013046\n",
      "Epoch: 1510\n",
      "Arb loss 0.01209854608630795\n",
      "Real arb loss 1.1560993195185076e-05\n",
      "Bounds loss: 0.32986148160299733\n",
      "MAPE:  0.05958552526491453\n",
      "Delta:  0.00146775821353312\n",
      "GRAD\n",
      " tensor([-18.0612,   0.4814,   3.8701,  40.9925])\n",
      "-0.0002307463543227417 -0.0004983199230181867 0.0550380832447156\n",
      "Epoch: 1511\n",
      "Arb loss 0.011432665299669706\n",
      "Real arb loss 1.0924599193857757e-05\n",
      "Bounds loss: 0.3300258581511164\n",
      "MAPE:  0.05961902238573766\n",
      "Delta:  0.0014680968933899199\n",
      "GRAD\n",
      " tensor([-6.0853, -0.5371,  1.9422, 14.0745])\n",
      "0.00016753256691082186 0.0004413891908753298 -0.05142115694034888\n",
      "Epoch: 1512\n",
      "Arb loss 0.012020546176290501\n",
      "Real arb loss 1.1486453179397344e-05\n",
      "Bounds loss: 0.3298801883046192\n",
      "MAPE:  0.05958768835614209\n",
      "Delta:  0.0014678509393488966\n",
      "GRAD\n",
      " tensor([-18.0618,   0.4812,   3.8701,  40.9918])\n",
      "-0.00023012369192443316 -0.000497908538693359 0.05478585186498486\n",
      "Epoch: 1513\n",
      "Arb loss 0.01136199031414004\n",
      "Real arb loss 1.0857078539679248e-05\n",
      "Bounds loss: 0.33004443846712184\n",
      "MAPE:  0.05962116283759362\n",
      "Delta:  0.0014681887266262542\n",
      "GRAD\n",
      " tensor([-6.0853, -0.5371,  1.9423, 14.0742])\n",
      "0.000168115348436082 0.0004418623386783782 -0.05131070802438442\n",
      "Epoch: 1514\n",
      "Arb loss 0.011944982081724762\n",
      "Real arb loss 1.1414238936509832e-05\n",
      "Bounds loss: 0.329898604259673\n",
      "MAPE:  0.059589805388374203\n",
      "Delta:  0.0014679419015669075\n",
      "GRAD\n",
      " tensor([-18.0623,   0.4811,   3.8700,  40.9911])\n",
      "-0.0002295456040013466 -0.0004975236501956193 0.05454454627021266\n",
      "Delta imp changed to 0.006129731421763417\n",
      "Epoch: 1515\n",
      "Arb loss 0.011293448453871265\n",
      "Real arb loss 1.079159382830934e-05\n",
      "Bounds loss: 0.33006273661745866\n",
      "MAPE:  0.05962325876184034\n",
      "Delta:  0.001432467181636431\n",
      "GRAD\n",
      " tensor([-6.0854, -0.5371,  1.9423, 14.0738])\n",
      "0.00016864463902332982 0.00044229689591157584 -0.05119961883593649\n",
      "arb imp changed to 1039.8597517867242\n",
      "Epoch: 1516\n",
      "Arb loss 0.011877604544407795\n",
      "Real arb loss 1.1344173766054175e-05\n",
      "Bounds loss: 0.32991675089359673\n",
      "MAPE:  0.05959187989831352\n",
      "Delta:  0.001432225603725671\n",
      "GRAD\n",
      " tensor([-18.0719,   0.4771,   3.8684,  40.9994])\n",
      "-0.0002296623478121873 -0.000510579200174055 0.05590014839172397\n",
      "Epoch: 1517\n",
      "Arb loss 0.011213644687837185\n",
      "Real arb loss 1.070998830252206e-05\n",
      "Bounds loss: 0.33008519952439197\n",
      "MAPE:  0.0596261694148052\n",
      "Delta:  0.0014325545320204194\n",
      "GRAD\n",
      " tensor([-6.0885, -0.5383,  1.9417, 14.0765])\n",
      "0.0001435862792069642 0.0003763136232471931 -0.04285236498465461\n",
      "Epoch: 1518\n",
      "Arb loss 0.011694175882808617\n",
      "Real arb loss 1.1168932087997075e-05\n",
      "Bounds loss: 0.32996098396697865\n",
      "MAPE:  0.059599482085492046\n",
      "Delta:  0.0014323488368454056\n",
      "GRAD\n",
      " tensor([-18.0728,   0.4769,   3.8684,  40.9983])\n",
      "-0.0001945868411634688 -0.0004332433125908697 0.04712018820173247\n",
      "Epoch: 1519\n",
      "Arb loss 0.011143144114346514\n",
      "Real arb loss 1.0642657685612938e-05\n",
      "Bounds loss: 0.33010393735669824\n",
      "MAPE:  0.0596285778288959\n",
      "Delta:  0.0014326275530810117\n",
      "GRAD\n",
      " tensor([-6.0885, -0.5383,  1.9418, 14.0761])\n",
      "0.00014391515553235923 0.000376661047881921 -0.043046545342719345\n",
      "Epoch: 1520\n",
      "Arb loss 0.011622817972725187\n",
      "Real arb loss 1.1100787180866396e-05\n",
      "Bounds loss: 0.3299796000617435\n",
      "MAPE:  0.05960187252789752\n",
      "Delta:  0.00143242137626389\n",
      "GRAD\n",
      " tensor([-6.0888, -0.5386,  1.9416, 14.0778])\n",
      "0.0001426715544766699 0.00037363772904142056 -0.04406382596655245\n",
      "Epoch: 1521\n",
      "Arb loss 0.012134963801116267\n",
      "Real arb loss 1.1590066656804128e-05\n",
      "Bounds loss: 0.32985630723334647\n",
      "MAPE:  0.05957534268439573\n",
      "Delta:  0.0014322170104794727\n",
      "GRAD\n",
      " tensor([-18.0715,   0.4772,   3.8684,  41.0001])\n",
      "-0.00019539247467537102 -0.0004349139759975973 0.04853936106046386\n",
      "Epoch: 1522\n",
      "Arb loss 0.011545940411718225\n",
      "Real arb loss 1.1027379561047636e-05\n",
      "Bounds loss: 0.32999976635143313\n",
      "MAPE:  0.0596045895276288\n",
      "Delta:  0.0014324968549054224\n",
      "GRAD\n",
      " tensor([-6.0889, -0.5386,  1.9416, 14.0775])\n",
      "0.00014303472073018408 0.0003740336856340454 -0.04388316066893516\n",
      "Epoch: 1523\n",
      "Arb loss 0.012052612769879609\n",
      "Real arb loss 1.1511406910405253e-05\n",
      "Bounds loss: 0.3298763353225664\n",
      "MAPE:  0.05957803906704842\n",
      "Delta:  0.001432291958117834\n",
      "GRAD\n",
      " tensor([-18.0720,   0.4770,   3.8683,  40.9995])\n",
      "-0.00019503245129803837 -0.00043461300368696776 0.048290365148847436\n",
      "Epoch: 1524\n",
      "Arb loss 0.01147058769822446\n",
      "Real arb loss 1.0955425465579003e-05\n",
      "Bounds loss: 0.3300197038675062\n",
      "MAPE:  0.05960726720691435\n",
      "Delta:  0.0014325713015294003\n",
      "GRAD\n",
      " tensor([-6.0889, -0.5386,  1.9416, 14.0772])\n",
      "0.0001433760299898168 0.0003744125708498025 -0.04370329500385717\n",
      "Epoch: 1525\n",
      "Arb loss 0.011971890176267581\n",
      "Real arb loss 1.1434300134476772e-05\n",
      "Bounds loss: 0.3298961403417501\n",
      "MAPE:  0.059580696949559225\n",
      "Delta:  0.0014323659051435097\n",
      "GRAD\n",
      " tensor([-18.0725,   0.4769,   3.8683,  40.9990])\n",
      "-0.0001946938156105471 -0.00043432569643808705 0.0480467254177257\n",
      "Delta imp changed to 0.005980225777330163\n",
      "Epoch: 1526\n",
      "Arb loss 0.011396680056237285\n",
      "Real arb loss 1.0884848865610497e-05\n",
      "Bounds loss: 0.33003942271265624\n",
      "MAPE:  0.05960990718927105\n",
      "Delta:  0.0013977022223677393\n",
      "GRAD\n",
      " tensor([-6.0889, -0.5385,  1.9416, 14.0769])\n",
      "0.00014368761489891302 0.00037476861928598115 -0.043523184346282884\n",
      "arb imp changed to 1040.3796816626175\n",
      "Epoch: 1527\n",
      "Arb loss 0.011898646213192135\n",
      "Real arb loss 1.135865462160288e-05\n",
      "Bounds loss: 0.3299157342938963\n",
      "MAPE:  0.059583318365634005\n",
      "Delta:  0.0013975013898690684\n",
      "GRAD\n",
      " tensor([-18.0821,   0.4730,   3.8667,  41.0074])\n",
      "-0.0001946698688279902 -0.0004343938159885319 0.047853896207188606\n",
      "Epoch: 1528\n",
      "Arb loss 0.01132924963229998\n",
      "Real arb loss 1.0815048573550715e-05\n",
      "Bounds loss: 0.3300590476486709\n",
      "MAPE:  0.059612533481928055\n",
      "Delta:  0.001397773441281321\n",
      "GRAD\n",
      " tensor([-6.0920, -0.5398,  1.9411, 14.0796])\n",
      "0.00012224336262234292 0.0003187835126390315 -0.036438596499069\n",
      "Epoch: 1529\n",
      "Arb loss 0.011742071588288584\n",
      "Real arb loss 1.1209144933383909e-05\n",
      "Bounds loss: 0.32995383026608316\n",
      "MAPE:  0.05958992326511414\n",
      "Delta:  0.0013976025727556747\n",
      "GRAD\n",
      " tensor([-18.0828,   0.4728,   3.8667,  41.0066])\n",
      "-0.00016505245346154496 -0.0003687072518416823 0.040332431514010114\n",
      "Epoch: 1530\n",
      "Arb loss 0.011268485290121331\n",
      "Real arb loss 1.0757048214727633e-05\n",
      "Bounds loss: 0.33007548663607517\n",
      "MAPE:  0.059614720099012745\n",
      "Delta:  0.0013978332504892724\n",
      "GRAD\n",
      " tensor([-6.0920, -0.5398,  1.9411, 14.0793])\n",
      "0.00012245259406717945 0.0003190268360544479 -0.03624144262611906\n",
      "Epoch: 1531\n",
      "Arb loss 0.01167687145324653\n",
      "Real arb loss 1.1146888728149892e-05\n",
      "Bounds loss: 0.32997018369791453\n",
      "MAPE:  0.059592097044559596\n",
      "Delta:  0.0013976620821816766\n",
      "GRAD\n",
      " tensor([-18.0832,   0.4727,   3.8667,  41.0061])\n",
      "-0.00016484358549506695 -0.0003685231864312133 0.04010006139001121\n",
      "Epoch: 1532\n",
      "Arb loss 0.011208628191128075\n",
      "Real arb loss 1.0699912267520281e-05\n",
      "Bounds loss: 0.3300917853614382\n",
      "MAPE:  0.059616882338120555\n",
      "Delta:  0.0013978924778106137\n",
      "GRAD\n",
      " tensor([-6.0920, -0.5398,  1.9412, 14.0791])\n",
      "0.00012265119323073836 0.00031926160675477266 -0.03637672633492617\n",
      "Epoch: 1533\n",
      "Arb loss 0.01161636139142668\n",
      "Real arb loss 1.108913290826723e-05\n",
      "Bounds loss: 0.32998639972766713\n",
      "MAPE:  0.05959424685411816\n",
      "Delta:  0.0013977210246302022\n",
      "GRAD\n",
      " tensor([-6.0923, -0.5400,  1.9410, 14.0805])\n",
      "0.00012173657168612628 0.0003170708812824108 -0.03750701040017357\n",
      "Epoch: 1534\n",
      "Arb loss 0.012052056378947094\n",
      "Real arb loss 1.1505174493887151e-05\n",
      "Bounds loss: 0.3298817706490943\n",
      "MAPE:  0.05957173830901671\n",
      "Delta:  0.00139755087086449\n",
      "GRAD\n",
      " tensor([-18.0820,   0.4729,   3.8667,  41.0076])\n",
      "-0.00016548262997040375 -0.00036975527997884505 0.04151449950985919\n",
      "Epoch: 1535\n",
      "Arb loss 0.0115517212903105\n",
      "Real arb loss 1.1027440888441525e-05\n",
      "Bounds loss: 0.33000374617556055\n",
      "MAPE:  0.0595966336870467\n",
      "Delta:  0.001397782141258118\n",
      "GRAD\n",
      " tensor([-6.0923, -0.5400,  1.9410, 14.0802])\n",
      "0.00012195941566972568 0.0003173376874507916 -0.037307311162047885\n",
      "Epoch: 1536\n",
      "Arb loss 0.011982684950945368\n",
      "Real arb loss 1.1438943415474994e-05\n",
      "Bounds loss: 0.3298990235498991\n",
      "MAPE:  0.05957411099174765\n",
      "Delta:  0.0013976116685649367\n",
      "GRAD\n",
      " tensor([-18.0825,   0.4728,   3.8666,  41.0072])\n",
      "-0.00016526069424860346 -0.00036955555344153623 0.04127835813727565\n",
      "Delta imp changed to 0.0058343666120294286\n",
      "Epoch: 1537\n",
      "Arb loss 0.011488059390094101\n",
      "Real arb loss 1.0966680679044372e-05\n",
      "Bounds loss: 0.33002093956612694\n",
      "MAPE:  0.05959899357057053\n",
      "Delta:  0.0013637489159410475\n",
      "GRAD\n",
      " tensor([-6.0923, -0.5400,  1.9411, 14.0800])\n",
      "0.00012216335897963226 0.000317589831305809 -0.037107580098557635\n",
      "arb imp changed to 1040.8998715034488\n",
      "Epoch: 1538\n",
      "Arb loss 0.011920310650826051\n",
      "Real arb loss 1.1373703429041604e-05\n",
      "Bounds loss: 0.32991612827160277\n",
      "MAPE:  0.05957645754057052\n",
      "Delta:  0.0013635823157926712\n",
      "GRAD\n",
      " tensor([-18.0919,   0.4689,   3.8650,  41.0158])\n",
      "-0.0001653001893584527 -0.0003696542455444707 0.04108413905710928\n",
      "Epoch: 1539\n",
      "Arb loss 0.011430574950443572\n",
      "Real arb loss 1.0906362536661841e-05\n",
      "Bounds loss: 0.33003808316909194\n",
      "MAPE:  0.05960134646635316\n",
      "Delta:  0.0013638077162076779\n",
      "GRAD\n",
      " tensor([-6.0954, -0.5412,  1.9405, 14.0828])\n",
      "0.0001038831083721714 0.00027010153469098075 -0.031098337801475973\n",
      "Epoch: 1540\n",
      "Arb loss 0.011786046831517556\n",
      "Real arb loss 1.1245563322145229e-05\n",
      "Bounds loss: 0.3299489393763215\n",
      "MAPE:  0.059582184542660864\n",
      "Delta:  0.0013636660396228963\n",
      "GRAD\n",
      " tensor([-18.0925,   0.4688,   3.8650,  41.0150])\n",
      "-0.00014021685461362843 -0.0003138283023480515 0.03464033438140457\n",
      "Epoch: 1541\n",
      "Arb loss 0.011377774228238895\n",
      "Real arb loss 1.0855990867144649e-05\n",
      "Bounds loss: 0.3300524866918275\n",
      "MAPE:  0.059603314044974896\n",
      "Delta:  0.0013638572485857156\n",
      "GRAD\n",
      " tensor([-6.0954, -0.5412,  1.9405, 14.0825])\n",
      "0.00010402449478930098 0.0002702778115144522 -0.030896941369887854\n",
      "Epoch: 1542\n",
      "Arb loss 0.011729312651488612\n",
      "Real arb loss 1.1191418651842141e-05\n",
      "Bounds loss: 0.3299632808280395\n",
      "MAPE:  0.059584142693952666\n",
      "Delta:  0.0013637153740244667\n",
      "GRAD\n",
      " tensor([-18.0928,   0.4687,   3.8650,  41.0147])\n",
      "-0.00014007527000670095 -0.0003136966763048754 0.03441847796825237\n",
      "Epoch: 1543\n",
      "Arb loss 0.011325607562410607\n",
      "Real arb loss 1.0806222897390884e-05\n",
      "Bounds loss: 0.3300667892125379\n",
      "MAPE:  0.059605263706880726\n",
      "Delta:  0.0013639063968236954\n",
      "GRAD\n",
      " tensor([-6.0954, -0.5412,  1.9406, 14.0823])\n",
      "0.00010415984493217234 0.0002704491107251572 -0.03069620116521654\n",
      "Epoch: 1544\n",
      "Arb loss 0.011673260690464662\n",
      "Real arb loss 1.1137923903579603e-05\n",
      "Bounds loss: 0.32997752294291544\n",
      "MAPE:  0.059586083166716985\n",
      "Delta:  0.0013637643325449002\n",
      "GRAD\n",
      " tensor([-18.0931,   0.4686,   3.8650,  41.0143])\n",
      "-0.00013993975511517043 -0.0003135690423594628 0.034198528230277025\n",
      "Epoch: 1545\n",
      "Arb loss 0.011274052355202423\n",
      "Real arb loss 1.0757037111827048e-05\n",
      "Bounds loss: 0.3300809936787848\n",
      "MAPE:  0.05960719592397025\n",
      "Delta:  0.0013639551773916314\n",
      "GRAD\n",
      " tensor([-6.0954, -0.5412,  1.9406, 14.0821])\n",
      "0.00010428943315232697 0.00027061562710362086 -0.030715177580804776\n",
      "Epoch: 1546\n",
      "Arb loss 0.011620336875347755\n",
      "Real arb loss 1.1087429106929659e-05\n",
      "Bounds loss: 0.32999166860368545\n",
      "MAPE:  0.05958800642342174\n",
      "Delta:  0.001363812931279336\n",
      "GRAD\n",
      " tensor([-6.0957, -0.5414,  1.9405, 14.0833])\n",
      "0.0001036233493793004 0.00026903252987109383 -0.03193754228578927\n",
      "Epoch: 1547\n",
      "Arb loss 0.01199146187567929\n",
      "Real arb loss 1.1441645531346447e-05\n",
      "Bounds loss: 0.3299028901102446\n",
      "MAPE:  0.05956890859400461\n",
      "Delta:  0.0013636716084154702\n",
      "GRAD\n",
      " tensor([-18.0922,   0.4688,   3.8650,  41.0156])\n",
      "-0.00014042222050481001 -0.00031446592098083315 0.035541379979244\n",
      "Delta imp changed to 0.005692064987345784\n",
      "Epoch: 1548\n",
      "Arb loss 0.011565268772649155\n",
      "Real arb loss 1.1034898739929529e-05\n",
      "Bounds loss: 0.3300066333264174\n",
      "MAPE:  0.059590100993029645\n",
      "Delta:  0.0013305981445958666\n",
      "GRAD\n",
      " tensor([-6.0957, -0.5414,  1.9405, 14.0831])\n",
      "0.00010376247556798113 0.0002692147877646489 -0.03173351202174257\n",
      "arb imp changed to 1041.4203214392005\n",
      "Epoch: 1549\n",
      "Arb loss 0.01193824150596484\n",
      "Real arb loss 1.1385165044993692e-05\n",
      "Bounds loss: 0.3299177906606655\n",
      "MAPE:  0.05957099343244993\n",
      "Delta:  0.0013304600784383972\n",
      "GRAD\n",
      " tensor([-18.1015,   0.4649,   3.8634,  41.0243])\n",
      "-0.00014048964592405788 -0.00031457511129140414 0.03535071435482007\n",
      "Epoch: 1550\n",
      "Arb loss 0.01151621614058862\n",
      "Real arb loss 1.0982615292278042e-05\n",
      "Bounds loss: 0.33002157458637965\n",
      "MAPE:  0.05959219266188958\n",
      "Delta:  0.0013306469943037329\n",
      "GRAD\n",
      " tensor([-6.0987, -0.5426,  1.9400, 14.0859])\n",
      "8.820807287390764e-05 0.0002289304233905609 -0.02663476844354906\n",
      "Epoch: 1551\n",
      "Arb loss 0.011822947890839059\n",
      "Real arb loss 1.127518585674097e-05\n",
      "Bounds loss: 0.32994602260758155\n",
      "MAPE:  0.05957594719429608\n",
      "Delta:  0.00133052962049669\n",
      "GRAD\n",
      " tensor([-18.1021,   0.4648,   3.8634,  41.0236])\n",
      "-0.0001192123791586841 -0.0002671159067875184 0.029831300043272058\n",
      "Epoch: 1552\n",
      "Arb loss 0.01147025398491147\n",
      "Real arb loss 1.093879105176244e-05\n",
      "Bounds loss: 0.33003415643860134\n",
      "MAPE:  0.059593947544110945\n",
      "Delta:  0.0013306882360982907\n",
      "GRAD\n",
      " tensor([-6.0987, -0.5426,  1.9400, 14.0857])\n",
      "8.830721326191782e-05 0.00022906012514234408 -0.026438211800153155\n",
      "Epoch: 1553\n",
      "Arb loss 0.01177350698916611\n",
      "Real arb loss 1.1228025689560474e-05\n",
      "Bounds loss: 0.3299585587734262\n",
      "MAPE:  0.05957769507751074\n",
      "Delta:  0.0013305707267284403\n",
      "GRAD\n",
      " tensor([-18.1023,   0.4647,   3.8634,  41.0233])\n",
      "-0.00011911290087351922 -0.0002670199380458982 0.029622425276041087\n",
      "Epoch: 1554\n",
      "Arb loss 0.011424747158142588\n",
      "Real arb loss 1.0895400057435408e-05\n",
      "Bounds loss: 0.33004666428734764\n",
      "MAPE:  0.059595689107650174\n",
      "Delta:  0.0013307292148675184\n",
      "GRAD\n",
      " tensor([-6.0987, -0.5426,  1.9400, 14.0855])\n",
      "8.840278892074949e-05 0.00022918683526151895 -0.026242173460949036\n",
      "Epoch: 1555\n",
      "Arb loss 0.011724557354814051\n",
      "Real arb loss 1.1181333217706733e-05\n",
      "Bounds loss: 0.329971021936871\n",
      "MAPE:  0.059579429785633894\n",
      "Delta:  0.0013306115746936258\n",
      "GRAD\n",
      " tensor([-18.1026,   0.4647,   3.8634,  41.0230])\n",
      "-0.0001190170216094355 -0.00026692636477143594 0.029414769462203227\n",
      "Epoch: 1556\n",
      "Arb loss 0.011379682203175817\n",
      "Real arb loss 1.0852429504981945e-05\n",
      "Bounds loss: 0.3300590999022365\n",
      "MAPE:  0.05959741763728876\n",
      "Delta:  0.0013307699401201652\n",
      "GRAD\n",
      " tensor([-6.0988, -0.5426,  1.9400, 14.0854])\n",
      "8.849493725648916e-05 0.00022931065211972967 -0.026046616951525436\n",
      "Epoch: 1557\n",
      "Arb loss 0.011676084426552028\n",
      "Real arb loss 1.1135094603792962e-05\n",
      "Bounds loss: 0.32998341383479984\n",
      "MAPE:  0.05958115159870614\n",
      "Delta:  0.0013306521737178113\n",
      "GRAD\n",
      " tensor([-18.1029,   0.4646,   3.8634,  41.0227])\n",
      "-0.00011892459323870064 -0.00026683510504255104 0.029208272732885066\n",
      "Epoch: 1558\n",
      "Arb loss 0.011335046168169103\n",
      "Real arb loss 1.0809867070535689e-05\n",
      "Bounds loss: 0.3300714649936927\n",
      "MAPE:  0.05959913340842772\n",
      "Delta:  0.001330810420986313\n",
      "GRAD\n",
      " tensor([-6.0988, -0.5426,  1.9400, 14.0852])\n",
      "8.85837910623577e-05 0.0002294316709463562 -0.025938570029528263\n",
      "Delta imp changed to 0.005553234133995888\n",
      "Epoch: 1559\n",
      "Arb loss 0.011629061056990094\n",
      "Real arb loss 1.1090244125099573e-05\n",
      "Bounds loss: 0.3299957361459475\n",
      "MAPE:  0.05958286078755655\n",
      "Delta:  0.0012982366173210117\n",
      "GRAD\n",
      " tensor([-6.0990, -0.5427,  1.9399, 14.0862])\n",
      "8.809578139667984e-05 0.00022828523476248197 -0.027216767375054962\n",
      "arb imp changed to 1041.94103159992\n",
      "Epoch: 1560\n",
      "Arb loss 0.011951539289821787\n",
      "Real arb loss 1.1392188449272148e-05\n",
      "Bounds loss: 0.32992040299185077\n",
      "MAPE:  0.05956665457862935\n",
      "Delta:  0.0012981222481517711\n",
      "GRAD\n",
      " tensor([-18.1111,   0.4610,   3.8618,  41.0328])\n",
      "-0.0001194613734543104 -0.00026769420202166216 0.03047461840501131\n",
      "Epoch: 1561\n",
      "Arb loss 0.011587320690611969\n",
      "Real arb loss 1.1044926094215611e-05\n",
      "Bounds loss: 0.33000872077086035\n",
      "MAPE:  0.05958470734645545\n",
      "Delta:  0.001298277323618447\n",
      "GRAD\n",
      " tensor([-6.1020, -0.5440,  1.9394, 14.0891])\n",
      "8.80839439081349e-05 0.00022834087905809763 -0.027001072719682773\n",
      "Epoch: 1562\n",
      "Arb loss 0.011900190779205467\n",
      "Real arb loss 1.134323543655956e-05\n",
      "Bounds loss: 0.3299333662894627\n",
      "MAPE:  0.059568498245469136\n",
      "Delta:  0.0012981629662314961\n",
      "GRAD\n",
      " tensor([-18.1114,   0.4609,   3.8618,  41.0325])\n",
      "-0.00011935828366538281 -0.0002675933644071815 0.03026176492445798\n",
      "Epoch: 1563\n",
      "Arb loss 0.01154007000328895\n",
      "Real arb loss 1.0999896991282575e-05\n",
      "Bounds loss: 0.3300216542689783\n",
      "MAPE:  0.05958654428584323\n",
      "Delta:  0.0012983179127350635\n",
      "GRAD\n",
      " tensor([-6.1020, -0.5440,  1.9394, 14.0889])\n",
      "8.81832522400261e-05 0.0002284749183162349 -0.026801091813956956\n",
      "Epoch: 1564\n",
      "Arb loss 0.011849356478986588\n",
      "Real arb loss 1.1294771655884797e-05\n",
      "Bounds loss: 0.3299462525984766\n",
      "MAPE:  0.05957032791115486\n",
      "Delta:  0.001298203422839077\n",
      "GRAD\n",
      " tensor([-18.1116,   0.4609,   3.8618,  41.0322])\n",
      "-0.00011925883330166087 -0.00026749500051748143 0.030050108033166767\n",
      "Epoch: 1565\n",
      "Arb loss 0.011493282036669536\n",
      "Real arb loss 1.0955307897966023e-05\n",
      "Bounds loss: 0.33003451157148617\n",
      "MAPE:  0.059588367371734674\n",
      "Delta:  0.001298358245064673\n",
      "GRAD\n",
      " tensor([-6.1020, -0.5440,  1.9394, 14.0887])\n",
      "8.827901942198846e-05 0.00022860595099183367 -0.026601573220958352\n",
      "Epoch: 1566\n",
      "Arb loss 0.011799021420317126\n",
      "Real arb loss 1.1246782865795758e-05\n",
      "Bounds loss: 0.32995906371810824\n",
      "MAPE:  0.059572143868072976\n",
      "Delta:  0.0012982436272719405\n",
      "GRAD\n",
      " tensor([-18.1119,   0.4608,   3.8618,  41.0319])\n",
      "-0.00011916288395519281 -0.000267399028135884 0.029839591948363053\n",
      "Epoch: 1567\n",
      "Arb loss 0.011446943435744868\n",
      "Real arb loss 1.0911146115234596e-05\n",
      "Bounds loss: 0.33004729445107106\n",
      "MAPE:  0.059590176891690126\n",
      "Delta:  0.0012983983297266426\n",
      "GRAD\n",
      " tensor([-6.1020, -0.5440,  1.9394, 14.0885])\n",
      "8.837138114692333e-05 0.00022873407452528305 -0.026402484239747448\n",
      "Epoch: 1568\n",
      "Arb loss 0.011749171179400403\n",
      "Real arb loss 1.1199255343104671e-05\n",
      "Bounds loss: 0.3299718013886252\n",
      "MAPE:  0.05957394639908282\n",
      "Delta:  0.0012982835884729658\n",
      "GRAD\n",
      " tensor([-18.1122,   0.4607,   3.8617,  41.0316])\n",
      "-0.00011907030824120923 -0.00026730536801355953 0.029630162934673687\n",
      "Epoch: 1569\n",
      "Arb loss 0.011401041323007398\n",
      "Real arb loss 1.0867399397763022e-05\n",
      "Bounds loss: 0.3300600046224295\n",
      "MAPE:  0.059591973123818684\n",
      "Delta:  0.0012984381755000297\n",
      "GRAD\n",
      " tensor([-6.1020, -0.5439,  1.9394, 14.0883])\n",
      "8.846046645849537e-05 0.0002288593822669105 -0.02620379107396542\n",
      "Delta imp changed to 0.005417789399020379\n",
      "Epoch: 1570\n",
      "Arb loss 0.01169979182786113\n",
      "Real arb loss 1.1152175855123528e-05\n",
      "Bounds loss: 0.3299844672936606\n",
      "MAPE:  0.059575735777795985\n",
      "Delta:  0.001266656892734983\n",
      "GRAD\n",
      " tensor([-18.1124,   0.4607,   3.8617,  41.0313])\n",
      "-0.00011898623858308532 -0.00026721769519899574 0.029422247746301755\n",
      "Epoch: 1571\n",
      "Arb loss 0.011355557654121645\n",
      "Real arb loss 1.0824050574679637e-05\n",
      "Bounds loss: 0.33007264498246225\n",
      "MAPE:  0.05959375659020378\n",
      "Delta:  0.001266807607474225\n",
      "GRAD\n",
      " tensor([-6.1020, -0.5439,  1.9394, 14.0881])\n",
      "8.854132012314775e-05 0.0002289782762522341 -0.026004884488868063\n",
      "Epoch: 1572\n",
      "Arb loss 0.01165085761922376\n",
      "Real arb loss 1.1105519893122144e-05\n",
      "Bounds loss: 0.32999706551717617\n",
      "MAPE:  0.059577512773724896\n",
      "Delta:  0.0012666954426563172\n",
      "GRAD\n",
      " tensor([-18.1127,   0.4606,   3.8617,  41.0310])\n",
      "-0.00011890003105397007 -0.0002671283717365913 0.029214746369259026\n",
      "Epoch: 1573\n",
      "Arb loss 0.011310480768893788\n",
      "Real arb loss 1.0781088557958805e-05\n",
      "Bounds loss: 0.3300852170959656\n",
      "MAPE:  0.059595527544911146\n",
      "Delta:  0.001266846052783785\n",
      "GRAD\n",
      " tensor([-6.1020, -0.5439,  1.9394, 14.0880])\n",
      "8.862433441336748e-05 0.00022909830864115133 -0.02599865688724856\n",
      "Epoch: 1574\n",
      "Arb loss 0.01160453807763408\n",
      "Real arb loss 1.1061369684002394e-05\n",
      "Bounds loss: 0.33000959513102146\n",
      "MAPE:  0.05957927712889568\n",
      "Delta:  0.0012667337793955528\n",
      "GRAD\n",
      " tensor([-6.1022, -0.5441,  1.9394, 14.0890])\n",
      "8.81386381565985e-05 0.00022795493055505212 -0.02717669671333134\n",
      "arb imp changed to 1042.46200211572\n",
      "Epoch: 1575\n",
      "Arb loss 0.011925871045012982\n",
      "Real arb loss 1.1362079841720528e-05\n",
      "Bounds loss: 0.32993436781668084\n",
      "MAPE:  0.05956309288254437\n",
      "Delta:  0.00126662213120533\n",
      "GRAD\n",
      " tensor([-18.1209,   0.4570,   3.8602,  41.0412])\n",
      "-0.00011944056406387737 -0.0002679864250771935 0.030483462793067906\n",
      "Epoch: 1576\n",
      "Arb loss 0.011562329198737403\n",
      "Real arb loss 1.1015638989661197e-05\n",
      "Bounds loss: 0.33002278574842214\n",
      "MAPE:  0.059581178376950435\n",
      "Delta:  0.0012667734172671368\n",
      "GRAD\n",
      " tensor([-6.1053, -0.5453,  1.9388, 14.0919])\n",
      "8.812116769973954e-05 0.00022800964825975267 -0.026958024457742535\n",
      "Epoch: 1577\n",
      "Arb loss 0.011874026752065437\n",
      "Real arb loss 1.131267814392245e-05\n",
      "Bounds loss: 0.32994753736912596\n",
      "MAPE:  0.0595649912175345\n",
      "Delta:  0.0012666617877143962\n",
      "GRAD\n",
      " tensor([-18.1212,   0.4569,   3.8602,  41.0408])\n",
      "-0.00011934316083794805 -0.000267887219540075 0.03026937464331414\n",
      "Epoch: 1578\n",
      "Arb loss 0.011514607387782434\n",
      "Real arb loss 1.0970182898513751e-05\n",
      "Bounds loss: 0.33003592609750587\n",
      "MAPE:  0.05958306997145075\n",
      "Delta:  0.0012668129551358547\n",
      "GRAD\n",
      " tensor([-6.1053, -0.5453,  1.9388, 14.0917])\n",
      "8.821514902446204e-05 0.0002281430260442363 -0.026755007295548472\n",
      "Epoch: 1579\n",
      "Arb loss 0.011822680792447929\n",
      "Real arb loss 1.1263750288822475e-05\n",
      "Bounds loss: 0.3299606307026227\n",
      "MAPE:  0.05956687550818815\n",
      "Delta:  0.0012667012030422313\n",
      "GRAD\n",
      " tensor([-18.1215,   0.4569,   3.8601,  41.0405])\n",
      "-0.00011924915646788214 -0.00026779036234003684 0.03005632803138303\n",
      "Epoch: 1580\n",
      "Arb loss 0.011467334420339783\n",
      "Real arb loss 1.0925153366274671e-05\n",
      "Bounds loss: 0.33004899097947654\n",
      "MAPE:  0.059584947662705064\n",
      "Delta:  0.0012668522560921908\n",
      "GRAD\n",
      " tensor([-6.1053, -0.5453,  1.9389, 14.0915])\n",
      "8.83058207677978e-05 0.00022827353447951726 -0.026552348026820605\n",
      "Epoch: 1581\n",
      "Arb loss 0.011771819074808584\n",
      "Real arb loss 1.1215282877508147e-05\n",
      "Bounds loss: 0.3299736495297543\n",
      "MAPE:  0.0595687460340963\n",
      "Delta:  0.0012667403856639252\n",
      "GRAD\n",
      " tensor([-18.1217,   0.4568,   3.8601,  41.0402])\n",
      "-0.00011915842138976451 -0.000267695775276966 0.029844270651703697\n",
      "Delta imp changed to 0.005285648194166224\n",
      "Epoch: 1582\n",
      "Arb loss 0.011420497720277109\n",
      "Real arb loss 1.0880538441404662e-05\n",
      "Bounds loss: 0.3300619820816861\n",
      "MAPE:  0.0595868117257545\n",
      "Delta:  0.0012359915399498456\n",
      "GRAD\n",
      " tensor([-6.1053, -0.5453,  1.9389, 14.0913])\n",
      "8.838829584567609e-05 0.0002283976225900819 -0.026349489650454805\n",
      "Epoch: 1583\n",
      "Arb loss 0.011721422006760594\n",
      "Real arb loss 1.1167257273642831e-05\n",
      "Bounds loss: 0.32998659670967123\n",
      "MAPE:  0.0595706033136904\n",
      "Delta:  0.0012358822927639498\n",
      "GRAD\n",
      " tensor([-18.1220,   0.4567,   3.8601,  41.0399])\n",
      "-0.00011907587920489959 -0.00026760700646155655 0.02963357152437862\n",
      "Epoch: 1584\n",
      "Arb loss 0.011374074409355828\n",
      "Real arb loss 1.0836316357610907e-05\n",
      "Bounds loss: 0.3300749034349892\n",
      "MAPE:  0.05958866291960876\n",
      "Delta:  0.0012360294565345543\n",
      "GRAD\n",
      " tensor([-6.1053, -0.5453,  1.9389, 14.0911])\n",
      "8.847282848944982e-05 0.00022852274817330986 -0.026147381956767912\n",
      "Epoch: 1585\n",
      "Arb loss 0.011671476677341955\n",
      "Real arb loss 1.1119661226613151e-05\n",
      "Bounds loss: 0.3299994738109532\n",
      "MAPE:  0.0595724476020271\n",
      "Delta:  0.0012359201015124384\n",
      "GRAD\n",
      " tensor([-18.1222,   0.4567,   3.8601,  41.0396])\n",
      "-0.00011899134618720275 -0.00026751668414126684 0.02942325981438776\n",
      "Epoch: 1586\n",
      "Arb loss 0.011328063786646955\n",
      "Real arb loss 1.0792486472349175e-05\n",
      "Bounds loss: 0.33008775417595543\n",
      "MAPE:  0.059590500999984364\n",
      "Delta:  0.0012360671653090971\n",
      "GRAD\n",
      " tensor([-6.1053, -0.5453,  1.9389, 14.0909])\n",
      "8.855441382160656e-05 0.00022864526872667934 -0.02594553888777451\n",
      "Epoch: 1587\n",
      "Arb loss 0.011621976506146593\n",
      "Real arb loss 1.1072488493685296e-05\n",
      "Bounds loss: 0.33001228117269843\n",
      "MAPE:  0.059574278902752215\n",
      "Delta:  0.0012359577061058292\n",
      "GRAD\n",
      " tensor([-18.1225,   0.4566,   3.8601,  41.0393])\n",
      "-0.0001189097213254442 -0.00026742841541427254 0.029213785143553883\n",
      "Epoch: 1588\n",
      "Arb loss 0.011282454581552595\n",
      "Real arb loss 1.0749038074024768e-05\n",
      "Bounds loss: 0.33010053583411975\n",
      "MAPE:  0.05959232621674174\n",
      "Delta:  0.0012361046734922323\n",
      "GRAD\n",
      " tensor([-6.1053, -0.5452,  1.9389, 14.0907])\n",
      "8.8633163746632e-05 0.00022876526614179493 -0.026063286120677986\n",
      "Epoch: 1589\n",
      "Arb loss 0.011576512423455155\n",
      "Real arb loss 1.1029183850127422e-05\n",
      "Bounds loss: 0.3300250202971861\n",
      "MAPE:  0.05957609746179633\n",
      "Delta:  0.0012359951136242987\n",
      "GRAD\n",
      " tensor([-6.1055, -0.5454,  1.9388, 14.0918])\n",
      "8.814527010991835e-05 0.00022762163860934326 -0.027118601097884554\n",
      "arb imp changed to 1042.983233116778\n",
      "Epoch: 1590\n",
      "Arb loss 0.011896396471594526\n",
      "Real arb loss 1.1328372315969352e-05\n",
      "Bounds loss: 0.32994989946128395\n",
      "MAPE:  0.05955993487524774\n",
      "Delta:  0.0012358861665011536\n",
      "GRAD\n",
      " tensor([-18.1307,   0.4530,   3.8585,  41.0495])\n",
      "-0.00011945687991099518 -0.0002682879000321936 0.030484694776062082\n",
      "Epoch: 1591\n",
      "Arb loss 0.011533738456222945\n",
      "Real arb loss 1.0982950558903175e-05\n",
      "Bounds loss: 0.33003842102692627\n",
      "MAPE:  0.05957805287492178\n",
      "Delta:  0.001236033801606529\n",
      "GRAD\n",
      " tensor([-6.1086, -0.5467,  1.9383, 14.0946])\n",
      "8.812375869149403e-05 0.00022767641083809576 -0.02689634871237412\n",
      "Epoch: 1592\n",
      "Arb loss 0.011843953907698835\n",
      "Real arb loss 1.127842467635665e-05\n",
      "Bounds loss: 0.32996327906378814\n",
      "MAPE:  0.05956188731208144\n",
      "Delta:  0.0012359248776620617\n",
      "GRAD\n",
      " tensor([-18.1310,   0.4530,   3.8585,  41.0492])\n",
      "-0.00011936357233621742 -0.0002681894714982036 0.0302684248975037\n",
      "Delta imp changed to 0.0051567299455280245\n",
      "Epoch: 1593\n",
      "Arb loss 0.01148545607835416\n",
      "Real arb loss 1.0936982679343878e-05\n",
      "Bounds loss: 0.3300517717412141\n",
      "MAPE:  0.05957999851559471\n",
      "Delta:  0.0012059242947030234\n",
      "GRAD\n",
      " tensor([-6.1086, -0.5466,  1.9383, 14.0944])\n",
      "8.820905096973419e-05 0.00022780649972620193 -0.02668920373565231\n",
      "Epoch: 1594\n",
      "Arb loss 0.01179199375562624\n",
      "Real arb loss 1.1228935458584704e-05\n",
      "Bounds loss: 0.3299765838023653\n",
      "MAPE:  0.05956382582023524\n",
      "Delta:  0.0012058179212654464\n",
      "GRAD\n",
      " tensor([-18.1312,   0.4529,   3.8585,  41.0489])\n",
      "-0.00011927832578728648 -0.00026809682488382336 0.03005347088036403\n",
      "Epoch: 1595\n",
      "Arb loss 0.011437603414670093\n",
      "Real arb loss 1.0891422917318226e-05\n",
      "Bounds loss: 0.33006504947676873\n",
      "MAPE:  0.05958193060375269\n",
      "Delta:  0.0012059617492082993\n",
      "GRAD\n",
      " tensor([-6.1086, -0.5466,  1.9383, 14.0943])\n",
      "8.829619869077376e-05 0.00022793745106164387 -0.026482772084506445\n",
      "Epoch: 1596\n",
      "Arb loss 0.011740502859093773\n",
      "Real arb loss 1.1179892161633676e-05\n",
      "Bounds loss: 0.3299898152907064\n",
      "MAPE:  0.05956575066436552\n",
      "Delta:  0.0012058552673700777\n",
      "GRAD\n",
      " tensor([-18.1315,   0.4528,   3.8585,  41.0486])\n",
      "-0.00011919127373483107 -0.0002680027748136471 0.029838898578924078\n",
      "Epoch: 1597\n",
      "Arb loss 0.011390179185015706\n",
      "Real arb loss 1.0846270080940086e-05\n",
      "Bounds loss: 0.3300782534768646\n",
      "MAPE:  0.059583848916181126\n",
      "Delta:  0.0012059989947953353\n",
      "GRAD\n",
      " tensor([-6.1086, -0.5466,  1.9383, 14.0941])\n",
      "8.838032414315578e-05 0.00022806571523303898 -0.026276578730415112\n",
      "Epoch: 1598\n",
      "Arb loss 0.011689474125124307\n",
      "Real arb loss 1.1131288084250901e-05\n",
      "Bounds loss: 0.33000297394390254\n",
      "MAPE:  0.05956766186292234\n",
      "Delta:  0.0012058924082132588\n",
      "GRAD\n",
      " tensor([-18.1318,   0.4528,   3.8585,  41.0483])\n",
      "-0.00011910730990094542 -0.00026791084934640885 0.02962515066244875\n",
      "Epoch: 1599\n",
      "Arb loss 0.011343171693002703\n",
      "Real arb loss 1.0801513060600508e-05\n",
      "Bounds loss: 0.3300913853209386\n",
      "MAPE:  0.0595857537103415\n",
      "Delta:  0.001206036038814031\n",
      "GRAD\n",
      " tensor([-6.1086, -0.5466,  1.9383, 14.0939])\n",
      "8.846154380637294e-05 0.000228191378035425 -0.026070593536309472\n",
      "Epoch: 1600\n",
      "Arb loss 0.011638894911623548\n",
      "Real arb loss 1.1083111221075554e-05\n",
      "Bounds loss: 0.33001606131284467\n",
      "MAPE:  0.05956955966928752\n",
      "Delta:  0.0012059293510041512\n",
      "GRAD\n",
      " tensor([-18.1320,   0.4527,   3.8585,  41.0480])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import smilecorrector_gsvi_jo_mw_ar as smilenet\n",
    "import torch\n",
    "importlib.reload(smilenet)\n",
    "# This is for axel\n",
    "R = 0.000 # Rate for > 122 day\n",
    "F = 1 # for ID 102434, Exp date 05/31/2022\n",
    "T = 1\n",
    "S = 1\n",
    "print(T)\n",
    "log_strikes = xs\n",
    "S = torch.tensor(S).reshape(1,1)\n",
    "T = torch.tensor(T).reshape(1,1)\n",
    "R = torch.tensor(R).reshape(1,1)\n",
    "# his, lows = svi_with_noise(log_strikes, *params)\n",
    "# mids = torch.tensor(his + lows) / 2\n",
    "# mids = mids * T\n",
    "his = res[0]\n",
    "lows = res[1]\n",
    "# mids = torch.tensor(((processed['vol_high'].to_numpy() + processed['vol_low'].to_numpy()) / 2))\n",
    "mids = (his + lows) / 2\n",
    "print(mids.shape)\n",
    "mids = mids\n",
    "print(mids.shape)\n",
    "print(min(lows), min(his))\n",
    "print('Mid shape', mids.shape)\n",
    "# print(mids)\n",
    "low = 0\n",
    "print(low)\n",
    "print(his.shape, lows.shape)\n",
    "# datum, log_strikes = pipeline.get_datum('2022-0') \n",
    "model = smilenet.SmileNet(5, log_strikes, mids, low)#, low)\n",
    "datum = torch.tensor(np.vstack([ his.reshape(-1,1) , lows.reshape(-1,1) , log_strikes.reshape(-1,1), np.log(S), T, R])).double()\n",
    "print(datum)\n",
    "print(log_strikes.shape, datum.shape)\n",
    "print(datum.T.shape)\n",
    "model.train(datum.T.double(), log_strikes, epochs=1601)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.0256, -0.0233, -0.0211, -0.0188, -0.0166, -0.0144, -0.0121, -0.0099,\n",
      "        -0.0077, -0.0055, -0.0033, -0.0010,  0.0012,  0.0033,  0.0055,  0.0077,\n",
      "         0.0099,  0.0121,  0.0143,  0.0164,  0.0186,  0.0207,  0.0229,  0.0250,\n",
      "         0.0272,  0.0293,  0.0315,  0.0336,  0.0357,  0.0378,  0.0400,  0.0421,\n",
      "         0.0442,  0.0463,  0.0484,  0.0505,  0.0526,  0.0546,  0.0567])\n",
      "(39,)\n",
      "(39,)\n",
      "Mid shape (39,)\n",
      "3.939319132699472e-08\n",
      "(39,) (39,)\n",
      "torch.Size([39]) torch.Size([120, 1])\n",
      "torch.Size([1, 120])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Project\\smilecorrector_gsvi_jo_mw_ar.py:115: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  mids = torch.sqrt(torch.max(torch.tensor(mids**2 - low),torch.tensor(0)))\n",
      "d:\\Project\\smilecorrector_gsvi_jo_mw_ar.py:292: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  bounds = torch.hstack([torch.tensor(self.strike_low).reshape(1,1), knots, torch.tensor(self.strike_high).reshape(1,1)])\n",
      "d:\\Project\\smilecorrector_gsvi_jo_mw_ar.py:680: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ctx.save_for_backward(coeffs, torch.tensor(x))\n",
      "d:\\Project\\smilecorrector_gsvi_jo_mw_ar.py:684: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(poly(x))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 0 nan\n",
      "Epoch: 0\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 0.0\n",
      "MAPE:  0.0\n",
      "Delta:  0.10695414714600782\n",
      "Breaking and plotting at epoch 0 with bounds loss tensor(0., grad_fn=<MulBackward0>) and arb loss tensor(0., grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import smilecorrector_gsvi_jo_mw_ar as smilenet\n",
    "import torch\n",
    "importlib.reload(smilenet)\n",
    "R = 0.00518\n",
    "F = 2272.376330 # for ID 102434, Exp date 30/12/2022\n",
    "T = 4/365.0\n",
    "S = F * np.exp(-R * T)\n",
    "log_strikes = torch.tensor((processed2['strike_price'].apply(np.log).to_numpy()- np.log(F))) #   \n",
    "print(log_strikes)\n",
    "S = torch.tensor(S).reshape(1,1)\n",
    "T = torch.tensor(T).reshape(1,1)\n",
    "R = torch.tensor(R).reshape(1,1)\n",
    "# his, lows = svi_with_noise(log_strikes, *params)\n",
    "# mids = torch.tensor(his + lows) / 2\n",
    "# mids = mids * T\n",
    "his = processed2['vol_high'].to_numpy() ** 2 * T.item()\n",
    "lows = processed2['vol_low'].to_numpy() ** 2 * T.item()\n",
    "# mids = torch.tensor(((processed2['vol_high'].to_numpy() + processed2['vol_low'].to_numpy()) / 2))\n",
    "mids = (his + lows) / 2\n",
    "print(mids.shape)\n",
    "mids = mids\n",
    "print(mids.shape)\n",
    "print('Mid shape', mids.shape)\n",
    "# print(mids)\n",
    "low = min(mids**2)/2\n",
    "print(low)\n",
    "print(his.shape, lows.shape)\n",
    "# datum, log_strikes = pipeline.get_datum('2022-0') \n",
    "model = smilenet.SmileNet(5, log_strikes, mids, low)#, low)\n",
    "datum = torch.tensor(np.vstack([ his.reshape(-1,1) , lows.reshape(-1,1) , log_strikes.reshape(-1,1), np.log(S), T, R])).double()\n",
    "print(log_strikes.shape, datum.shape)\n",
    "print(datum.T.shape)\n",
    "w_5 = model.train(datum.T.double(), log_strikes, epochs=1601)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.0256, -0.0233, -0.0211, -0.0188, -0.0166, -0.0144, -0.0121, -0.0099,\n",
      "        -0.0077, -0.0055, -0.0033, -0.0010,  0.0012,  0.0033,  0.0055,  0.0077,\n",
      "         0.0099,  0.0121,  0.0143,  0.0164,  0.0186,  0.0207,  0.0229,  0.0250,\n",
      "         0.0272,  0.0293,  0.0315,  0.0336,  0.0357,  0.0378,  0.0400,  0.0421,\n",
      "         0.0442,  0.0463,  0.0484,  0.0505,  0.0526,  0.0546,  0.0567])\n",
      "(39,)\n",
      "(39,)\n",
      "Mid shape (39,)\n",
      "3.939319132699472e-08\n",
      "(39,) (39,)\n",
      "torch.Size([39]) torch.Size([120, 1])\n",
      "torch.Size([1, 120])\n",
      "0.0 0 nan\n",
      "Epoch: 0\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 0.0\n",
      "MAPE:  0.0\n",
      "Delta:  0.1227962577793899\n",
      "Breaking and plotting at epoch 0 with bounds loss tensor(0., grad_fn=<MulBackward0>) and arb loss tensor(0., grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import smilecorrector_gsvi_jo_mw_ar as smilenet\n",
    "import torch\n",
    "importlib.reload(smilenet)\n",
    "R = 0.00518\n",
    "F = 2272.376330 # for ID 102434, Exp date 30/12/2022\n",
    "T = 4/365.0\n",
    "S = F * np.exp(-R * T)\n",
    "log_strikes = torch.tensor((processed2['strike_price'].apply(np.log).to_numpy()- np.log(F))) #   \n",
    "print(log_strikes)\n",
    "S = torch.tensor(S).reshape(1,1)\n",
    "T = torch.tensor(T).reshape(1,1)\n",
    "R = torch.tensor(R).reshape(1,1)\n",
    "# his, lows = svi_with_noise(log_strikes, *params)\n",
    "# mids = torch.tensor(his + lows) / 2\n",
    "# mids = mids * T\n",
    "his = processed2['vol_high'].to_numpy() ** 2 * T.item()\n",
    "lows = processed2['vol_low'].to_numpy() ** 2 * T.item()\n",
    "# mids = torch.tensor(((processed2['vol_high'].to_numpy() + processed2['vol_low'].to_numpy()) / 2))\n",
    "mids = (his + lows) / 2\n",
    "print(mids.shape)\n",
    "mids = mids\n",
    "print(mids.shape)\n",
    "print('Mid shape', mids.shape)\n",
    "# print(mids)\n",
    "low = min(mids**2)/2\n",
    "print(low)\n",
    "print(his.shape, lows.shape)\n",
    "# datum, log_strikes = pipeline.get_datum('2022-0') \n",
    "model = smilenet.SmileNet(4, log_strikes, mids, low)#, low)\n",
    "datum = torch.tensor(np.vstack([ his.reshape(-1,1) , lows.reshape(-1,1) , log_strikes.reshape(-1,1), np.log(S), T, R])).double()\n",
    "print(log_strikes.shape, datum.shape)\n",
    "print(datum.T.shape)\n",
    "w_4 = model.train(datum.T.double(), log_strikes, epochs=1601)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.0256, -0.0233, -0.0211, -0.0188, -0.0166, -0.0144, -0.0121, -0.0099,\n",
      "        -0.0077, -0.0055, -0.0033, -0.0010,  0.0012,  0.0033,  0.0055,  0.0077,\n",
      "         0.0099,  0.0121,  0.0143,  0.0164,  0.0186,  0.0207,  0.0229,  0.0250,\n",
      "         0.0272,  0.0293,  0.0315,  0.0336,  0.0357,  0.0378,  0.0400,  0.0421,\n",
      "         0.0442,  0.0463,  0.0484,  0.0505,  0.0526,  0.0546,  0.0567])\n",
      "(39,)\n",
      "(39,)\n",
      "Mid shape (39,)\n",
      "3.939319132699472e-08\n",
      "(39,) (39,)\n",
      "torch.Size([39]) torch.Size([120, 1])\n",
      "torch.Size([1, 120])\n",
      "0.0 0.0 nan\n",
      "Epoch: 0\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.9827900331114208\n",
      "MAPE:  0.010580652074278196\n",
      "Delta:  0.17593520432298787\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "-0.001323427021484358 0.06797159074817105 nan\n",
      "Epoch: 1\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.8480166404412188\n",
      "MAPE:  0.010534691960926264\n",
      "Delta:  0.1761680417264193\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "-0.0007289361536144678 0.02372758021092114 nan\n",
      "Epoch: 2\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.804167677374033\n",
      "MAPE:  0.010507656817288241\n",
      "Delta:  0.17629645698114516\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "-0.0003688337849059309 0.007251048365930157 nan\n",
      "Epoch: 3\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.7910855702851458\n",
      "MAPE:  0.010492442286811381\n",
      "Delta:  0.176361481070639\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "-0.00017497752375517095 0.002239540167864207 nan\n",
      "Epoch: 4\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.7870743622064102\n",
      "MAPE:  0.010491260440318298\n",
      "Delta:  0.17639234036588256\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "-7.055042904102748e-05 0.0007548516621003198 nan\n",
      "Epoch: 5\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.7857253861538016\n",
      "MAPE:  0.010498952060476833\n",
      "Delta:  0.1764047849211749\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "-1.4191172938327057e-05 0.0003182819021919636 nan\n",
      "Epoch: 6\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.7851570220811042\n",
      "MAPE:  0.010504684977128675\n",
      "Delta:  0.17640728831198488\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "1.6256300777506283e-05 0.00019017511824059863 nan\n",
      "Epoch: 7\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.784817529633352\n",
      "MAPE:  0.010509742752049314\n",
      "Delta:  0.17640442058204675\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "3.271350728561995e-05 0.00015258141760454702 nan\n",
      "Epoch: 8\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.784545199644515\n",
      "MAPE:  0.010511981508390113\n",
      "Delta:  0.1763986497747488\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.161055177920314e-05 0.00014153206903455562 nan\n",
      "Epoch: 9\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.7842926292701238\n",
      "MAPE:  0.010512695170821698\n",
      "Delta:  0.17639130972959857\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.642027993384534e-05 0.00013827219746676 nan\n",
      "Epoch: 10\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.7840459112073508\n",
      "MAPE:  0.010512583834177728\n",
      "Delta:  0.17638312159562303\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.901971481530154e-05 0.00013730241539922083 nan\n",
      "Epoch: 11\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.7838009573945588\n",
      "MAPE:  0.010512026251466218\n",
      "Delta:  0.17637447534530418\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.042372544639129e-05 0.00013700833611818286 nan\n",
      "Epoch: 12\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.7835565617934201\n",
      "MAPE:  0.010511227317047775\n",
      "Delta:  0.17636558188718363\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.118112842561473e-05 0.0001369148765756334 nan\n",
      "Epoch: 13\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.7833123663668964\n",
      "MAPE:  0.010510297869943296\n",
      "Delta:  0.1763565552976872\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.15887730943021e-05 0.00013688167341308066 nan\n",
      "Epoch: 14\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.78306826358597\n",
      "MAPE:  0.010509297868192055\n",
      "Delta:  0.17634745727937226\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.1807259871750055e-05 0.0001368671214088124 nan\n",
      "Epoch: 15\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.7828242201654576\n",
      "MAPE:  0.010508259743945212\n",
      "Delta:  0.17633832120082527\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.1923395590014465e-05 0.0001368583474188334 nan\n",
      "Epoch: 16\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.7825802257889476\n",
      "MAPE:  0.01050720104244934\n",
      "Delta:  0.17632916511641586\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.198418442020625e-05 0.00013685161670795587 nan\n",
      "Epoch: 17\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.7823362768031368\n",
      "MAPE:  0.010506131253523182\n",
      "Delta:  0.1763199987885778\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.2015016969275685e-05 0.00013684552704784636 nan\n",
      "Epoch: 18\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.782092372055961\n",
      "MAPE:  0.01050505551144057\n",
      "Delta:  0.17631082750084878\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.2029679565746e-05 0.00013683983733958627 nan\n",
      "Epoch: 19\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.7818485108256448\n",
      "MAPE:  0.010503976592134449\n",
      "Delta:  0.17630165410498994\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.203552380894649e-05 0.00013683403382447334 nan\n",
      "Epoch: 20\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.7816046933062442\n",
      "MAPE:  0.010502895999622777\n",
      "Delta:  0.1762924801560702\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.20367094465346e-05 0.00013682861576069794 nan\n",
      "Epoch: 21\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.7813609188022264\n",
      "MAPE:  0.010501814543921698\n",
      "Delta:  0.17628330647550272\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.2035261569383096e-05 0.00013682293888883645 nan\n",
      "Epoch: 22\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.781117187766094\n",
      "MAPE:  0.01050073266686914\n",
      "Delta:  0.17627413352753996\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.203246403451267e-05 0.00013681744301785592 nan\n",
      "Epoch: 23\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.7808734998667486\n",
      "MAPE:  0.010499650604789875\n",
      "Delta:  0.17626496155002697\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.202889986433146e-05 0.00013681187144987117 nan\n",
      "Epoch: 24\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.7806298552304165\n",
      "MAPE:  0.010498568486959492\n",
      "Delta:  0.1762557906779929\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.202493784295381e-05 0.00013680634300439198 nan\n",
      "Epoch: 25\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.780386253771678\n",
      "MAPE:  0.010497486382738393\n",
      "Delta:  0.1762466209814384\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.202076670385303e-05 0.0001368008166725554 nan\n",
      "Epoch: 26\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.7801426954781694\n",
      "MAPE:  0.010496404329737946\n",
      "Delta:  0.176237452497086\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.201645151764467e-05 0.00013679525697973816 nan\n",
      "Epoch: 27\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.7798991804006807\n",
      "MAPE:  0.010495322348331948\n",
      "Delta:  0.17622828525018258\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.201208488103681e-05 0.00013678970160035941 nan\n",
      "Epoch: 28\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.779655708522915\n",
      "MAPE:  0.010494240449795687\n",
      "Delta:  0.17621911924965172\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.20076884924503e-05 0.00013678417114304509 nan\n",
      "Epoch: 29\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.779412279791905\n",
      "MAPE:  0.01049315863973525\n",
      "Delta:  0.17620995450059138\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.200327556853512e-05 0.00013677866367833857 nan\n",
      "Epoch: 30\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.779168894158142\n",
      "MAPE:  0.010492076921153252\n",
      "Delta:  0.17620079100576957\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.199884128770371e-05 0.00013677308703030633 nan\n",
      "Epoch: 31\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.7789255517361398\n",
      "MAPE:  0.010490995296442757\n",
      "Delta:  0.1761916287688033\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.199441654324399e-05 0.0001367675928697354 nan\n",
      "Epoch: 32\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.7786822523705343\n",
      "MAPE:  0.010489913765762448\n",
      "Delta:  0.17618246778786564\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.198995337429846e-05 0.0001367619399521569 nan\n",
      "Epoch: 33\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.7784389963351417\n",
      "MAPE:  0.010488832330899233\n",
      "Delta:  0.17617330806957998\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.198555135876859e-05 0.00013675654130651527 nan\n",
      "Epoch: 34\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.7781957831690782\n",
      "MAPE:  0.010487750990172698\n",
      "Delta:  0.1761641496030253\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.198108881732111e-05 0.00013675090296505488 nan\n",
      "Epoch: 35\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.7779526132900814\n",
      "MAPE:  0.010486669745515053\n",
      "Delta:  0.17615499239871835\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.1976659984132034e-05 0.0001367454041811822 nan\n",
      "Epoch: 36\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.777709486441362\n",
      "MAPE:  0.01048558859599567\n",
      "Delta:  0.17614583645057394\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.197222664310441e-05 0.00013673987786999575 nan\n",
      "Epoch: 37\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.7774664026632978\n",
      "MAPE:  0.010484507541722697\n",
      "Delta:  0.1761366817592397\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.196778740879093e-05 0.00013673432922367557 nan\n",
      "Epoch: 38\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.777223361987012\n",
      "MAPE:  0.010483426583114698\n",
      "Delta:  0.17612752832560716\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.19633331863556e-05 0.00013672871286662946 nan\n",
      "Epoch: 39\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.7769803645242508\n",
      "MAPE:  0.010482345720409304\n",
      "Delta:  0.1761183761521695\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.195890600195874e-05 0.00013672323054136903 nan\n",
      "Epoch: 40\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.7767374100282045\n",
      "MAPE:  0.01048126495275465\n",
      "Delta:  0.17610922523401779\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.195447258332653e-05 0.00013671769421408353 nan\n",
      "Epoch: 41\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.7764944985862816\n",
      "MAPE:  0.010480184280527407\n",
      "Delta:  0.1761000755721037\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.195002952873562e-05 0.0001367121203916799 nan\n",
      "Epoch: 42\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.7762516302565157\n",
      "MAPE:  0.010479103703954567\n",
      "Delta:  0.1760909271679777\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.194559980570279e-05 0.00013670660983433613 nan\n",
      "Epoch: 43\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.7760088049179306\n",
      "MAPE:  0.010478023222605395\n",
      "Delta:  0.17608178001914562\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.19411508238532e-05 0.00013670101725649086 nan\n",
      "Epoch: 44\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.775766022707642\n",
      "MAPE:  0.010476942837010277\n",
      "Delta:  0.17607263412885232\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.1936728432178114e-05 0.00013669553244421984 nan\n",
      "Epoch: 45\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.7755232834256713\n",
      "MAPE:  0.010475862546404363\n",
      "Delta:  0.17606348949226924\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.1932278522737185e-05 0.0001366899189528814 nan\n",
      "Epoch: 46\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.775280587291961\n",
      "MAPE:  0.010474782351759372\n",
      "Delta:  0.17605434611409523\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.192786101082536e-05 0.00013668445206183044 nan\n",
      "Epoch: 47\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.775037934037631\n",
      "MAPE:  0.010473702251896717\n",
      "Delta:  0.1760452039884799\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.1923413091126136e-05 0.0001366788554345577 nan\n",
      "Epoch: 48\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.7747953238844538\n",
      "MAPE:  0.01047262224785876\n",
      "Delta:  0.17603606312063047\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.1918974256492945e-05 0.00013667329025268682 nan\n",
      "Epoch: 49\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.7745527567680135\n",
      "MAPE:  0.01047154233932987\n",
      "Delta:  0.17602692350880111\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.191454821185104e-05 0.0001366677832479457 nan\n",
      "Epoch: 50\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.7743102325764895\n",
      "MAPE:  0.010470462525842945\n",
      "Delta:  0.17601778515059402\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.1910098960772366e-05 0.00013666217778307566 nan\n",
      "Epoch: 51\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.7740677514760428\n",
      "MAPE:  0.010469382808210791\n",
      "Delta:  0.17600864804994798\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.190566234114513e-05 0.00013665661093564818 nan\n",
      "Epoch: 52\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.7738253133895558\n",
      "MAPE:  0.010468303186084474\n",
      "Delta:  0.17599951220449317\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.1901248919072884e-05 0.00013665115780536752 nan\n",
      "Epoch: 53\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.7735829181067366\n",
      "MAPE:  0.010467223658584341\n",
      "Delta:  0.1759903776100006\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.1896798159090096e-05 0.00013664553794356937 nan\n",
      "Epoch: 54\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.7733405659148045\n",
      "MAPE:  0.010466144226964735\n",
      "Delta:  0.17598124427289585\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.189237413139036e-05 0.000136640018019496 nan\n",
      "Epoch: 55\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.7730982566279232\n",
      "MAPE:  0.010465064890479528\n",
      "Delta:  0.17597211218832792\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.18879188226018e-05 0.000136634387639889 nan\n",
      "Epoch: 56\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.7728559904334036\n",
      "MAPE:  0.010463985649906199\n",
      "Delta:  0.17596298136165567\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.188350406548636e-05 0.00013662890238208547 nan\n",
      "Epoch: 57\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.772613767065349\n",
      "MAPE:  0.01046290650421213\n",
      "Delta:  0.1759538517855968\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.1879050609993094e-05 0.00013662328491181874 nan\n",
      "Epoch: 58\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.7723715867496126\n",
      "MAPE:  0.010461827454275445\n",
      "Delta:  0.175944723466815\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.1874645298322086e-05 0.00013661783975726927 nan\n",
      "Epoch: 59\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.7721294491721835\n",
      "MAPE:  0.010460748498805777\n",
      "Delta:  0.17593559639669304\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.187019828467587e-05 0.0001366122135398884 nan\n",
      "Epoch: 60\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.771887354645453\n",
      "MAPE:  0.010459669639309119\n",
      "Delta:  0.1759264705824226\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.1865764468805864e-05 0.00013660666316739345 nan\n",
      "Epoch: 61\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.7716453030264263\n",
      "MAPE:  0.010458590874979344\n",
      "Delta:  0.17591734602153553\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.186133820167527e-05 0.0001366011368476583 nan\n",
      "Epoch: 62\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.7714032942639422\n",
      "MAPE:  0.010457512205715391\n",
      "Delta:  0.175908222712558\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.185688880648964e-05 0.00013659548763755858 nan\n",
      "Epoch: 63\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.7711613285671595\n",
      "MAPE:  0.010456433632616368\n",
      "Delta:  0.1758991006594126\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.185247287331496e-05 0.00013659002378663132 nan\n",
      "Epoch: 64\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.7709194055991604\n",
      "MAPE:  0.010455355153917906\n",
      "Delta:  0.17588997985606725\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.1848045411917454e-05 0.00013658446930020496 nan\n",
      "Epoch: 65\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.770677525511973\n",
      "MAPE:  0.010454276770567742\n",
      "Delta:  0.17588086030440417\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.184360289045564e-05 0.00013657886828188914 nan\n",
      "Epoch: 66\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.7704356883794465\n",
      "MAPE:  0.010453198482708242\n",
      "Delta:  0.1758717420069265\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.183919422546701e-05 0.00013657340625217174 nan\n",
      "Epoch: 67\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.7701938939469342\n",
      "MAPE:  0.010452120289415837\n",
      "Delta:  0.17586262495753385\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.183473859804444e-05 0.0001365677499811646 nan\n",
      "Epoch: 68\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.7699521425498075\n",
      "MAPE:  0.010451042192102812\n",
      "Delta:  0.17585350916434\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.183029890054591e-05 0.0001365621464505251 nan\n",
      "Epoch: 69\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.769710434086106\n",
      "MAPE:  0.010449964190428781\n",
      "Delta:  0.1758443946243973\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.1825900244550915e-05 0.00013655671874956976 nan\n",
      "Epoch: 70\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.7694687682360906\n",
      "MAPE:  0.010448886282932862\n",
      "Delta:  0.17583528133034293\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.182143583926102e-05 0.00013655101010123794 nan\n",
      "Epoch: 71\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.7692271454884452\n",
      "MAPE:  0.01044780847182591\n",
      "Delta:  0.17582616929359318\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.181702903367391e-05 0.0001365455650379488 nan\n",
      "Epoch: 72\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.768985565368184\n",
      "MAPE:  0.010446730755006055\n",
      "Delta:  0.17581705850387402\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.1812591768340965e-05 0.0001365399395357736 nan\n",
      "Epoch: 73\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.768744028186049\n",
      "MAPE:  0.01044565313387695\n",
      "Delta:  0.17580794896639584\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.1808168028188994e-05 0.000136534435918656 nan\n",
      "Epoch: 74\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.7685025337178761\n",
      "MAPE:  0.010444575607493262\n",
      "Delta:  0.1757988406786351\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.180372254964816e-05 0.000136528793128865 nan\n",
      "Epoch: 75\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.7682610822013023\n",
      "MAPE:  0.010443498176932794\n",
      "Delta:  0.17578973364426803\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.179931048382436e-05 0.0001365232979644304 nan\n",
      "Epoch: 76\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.768019673366698\n",
      "MAPE:  0.010442420841035237\n",
      "Delta:  0.1757806278572751\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.17948856894046e-05 0.00013651774940492967 nan\n",
      "Epoch: 77\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.7677783072999862\n",
      "MAPE:  0.01044134360022336\n",
      "Delta:  0.17577152331974885\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.1790438051591003e-05 0.0001365120988450208 nan\n",
      "Epoch: 78\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.7675369841729642\n",
      "MAPE:  0.010440266455181904\n",
      "Delta:  0.1757624200355591\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.178602440358837e-05 0.00013650660300490447 nan\n",
      "Epoch: 79\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.767295703703569\n",
      "MAPE:  0.0104391894047302\n",
      "Delta:  0.17575331799858593\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.17815972072011e-05 0.0001365010320959481 nan\n",
      "Epoch: 80\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.7670544660159948\n",
      "MAPE:  0.010438112449593348\n",
      "Delta:  0.17574421721106548\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.17771661865396e-05 0.00013649546739247231 nan\n",
      "Epoch: 81\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.766813271090748\n",
      "MAPE:  0.010437035589516325\n",
      "Delta:  0.17573511767352462\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.17727245258337e-05 0.0001364898386126967 nan\n",
      "Epoch: 82\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.766572119032518\n",
      "MAPE:  0.010435958825015737\n",
      "Delta:  0.1757260193876878\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.176830440845048e-05 0.00013648429304158327 nan\n",
      "Epoch: 83\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.7663310096857447\n",
      "MAPE:  0.01043488215550907\n",
      "Delta:  0.17571692234962366\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.176388189187531e-05 0.00013647875661770836 nan\n",
      "Epoch: 84\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.7660899430257677\n",
      "MAPE:  0.010433805580872688\n",
      "Delta:  0.17570782655960873\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.1759459788636164e-05 0.00013647318416021292 nan\n",
      "Epoch: 85\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.7658489191077296\n",
      "MAPE:  0.010432729101398268\n",
      "Delta:  0.17569873201742536\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.175504418442056e-05 0.00013646768392139297 nan\n",
      "Epoch: 86\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.7656079377955838\n",
      "MAPE:  0.010431652716416301\n",
      "Delta:  0.17568963872178667\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.175059345019495e-05 0.00013646199953953886 nan\n",
      "Epoch: 87\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.7653669994059893\n",
      "MAPE:  0.01043057642749985\n",
      "Delta:  0.17568054667871977\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.174617773628931e-05 0.00013645647933324678 nan\n",
      "Epoch: 88\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.7651261036405193\n",
      "MAPE:  0.01042950023325873\n",
      "Delta:  0.1756714558819265\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.1741746968869684e-05 0.0001364508849129864 nan\n",
      "Epoch: 89\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.7648852506216945\n",
      "MAPE:  0.010428424134231607\n",
      "Delta:  0.1756623663339066\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.1737322306455447e-05 0.00013644531501366686 nan\n",
      "Epoch: 90\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.7646444402977104\n",
      "MAPE:  0.010427348130280458\n",
      "Delta:  0.17565327803344247\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.17328888408608e-05 0.00013643971221066753 nan\n",
      "Epoch: 91\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.764403672718122\n",
      "MAPE:  0.010426272221688114\n",
      "Delta:  0.17564419098193543\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.172848208345737e-05 0.0001364342172471833 nan\n",
      "Epoch: 92\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.7641629476841267\n",
      "MAPE:  0.010425196407486684\n",
      "Delta:  0.17563510517454917\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.17240395059293e-05 0.00013642858087836718 nan\n",
      "Epoch: 93\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.763922265436736\n",
      "MAPE:  0.010424120688777528\n",
      "Delta:  0.1756260206174305\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.171961890004795e-05 0.00013642300964444853 nan\n",
      "Epoch: 94\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.7636816258525063\n",
      "MAPE:  0.010423045065210133\n",
      "Delta:  0.1756169373065752\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.171520798619156e-05 0.00013641749366255507 nan\n",
      "Epoch: 95\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.763441028825489\n",
      "MAPE:  0.010421969536115861\n",
      "Delta:  0.1756078552401365\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.171076639298722e-05 0.00013641185028523406 nan\n",
      "Epoch: 96\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.763200474571878\n",
      "MAPE:  0.010420894102626782\n",
      "Delta:  0.1755987744233574\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.170635537654622e-05 0.0001364063270433702 nan\n",
      "Epoch: 97\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.7629599628713004\n",
      "MAPE:  0.010419818763694343\n",
      "Delta:  0.17558969485072337\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.1701927029856876e-05 0.00013640074398002522 nan\n",
      "Epoch: 98\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.7627194938207578\n",
      "MAPE:  0.010418743519856452\n",
      "Delta:  0.17558061652513302\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.1697502238101656e-05 0.0001363951517543427 nan\n",
      "Epoch: 99\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.7624790674278978\n",
      "MAPE:  0.01041766837112203\n",
      "Delta:  0.17557153944581724\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.169307533781087e-05 0.0001363895526655945 nan\n",
      "Epoch: 100\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.7622386836963089\n",
      "MAPE:  0.010416593317594501\n",
      "Delta:  0.17556246361300148\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.1688671169114464e-05 0.0001363840427632823 nan\n",
      "Epoch: 101\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.7619983424603125\n",
      "MAPE:  0.010415518358446238\n",
      "Delta:  0.17555338902255013\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.1684217773018126e-05 0.0001363783689403153 nan\n",
      "Epoch: 102\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.7617580440002922\n",
      "MAPE:  0.010414443494984773\n",
      "Delta:  0.1755443156829611\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.1679827673734025e-05 0.00013637290591694828 nan\n",
      "Epoch: 103\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.7615177879363093\n",
      "MAPE:  0.01041336872571926\n",
      "Delta:  0.1755352435829775\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.167540234374268e-05 0.00013636731855393158 nan\n",
      "Epoch: 104\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.7612775744789833\n",
      "MAPE:  0.010412294051347063\n",
      "Delta:  0.17552617272863985\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.167096759983725e-05 0.0001363616815017732 nan\n",
      "Epoch: 105\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.761037403707336\n",
      "MAPE:  0.010411219472464144\n",
      "Delta:  0.17551710312145585\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.1666544314321605e-05 0.00013635609758344547 nan\n",
      "Epoch: 106\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.760797275519268\n",
      "MAPE:  0.010410144988481165\n",
      "Delta:  0.17550803475926952\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.166211597062986e-05 0.00013635047967575087 nan\n",
      "Epoch: 107\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.7605571899661392\n",
      "MAPE:  0.010409070599724348\n",
      "Delta:  0.17549896764282402\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.165769797577102e-05 0.00013634493519787405 nan\n",
      "Epoch: 108\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.760317146910161\n",
      "MAPE:  0.010407996305529693\n",
      "Delta:  0.17548990177015844\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.165328359835186e-05 0.00013633936290136095 nan\n",
      "Epoch: 109\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.760077146391847\n",
      "MAPE:  0.010406922106305632\n",
      "Delta:  0.17548083714049367\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.164887276098984e-05 0.00013633382151434503 nan\n",
      "Epoch: 110\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.7598371883483193\n",
      "MAPE:  0.010405848001601587\n",
      "Delta:  0.17547177375306422\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.164443399541252e-05 0.0001363281655908377 nan\n",
      "Epoch: 111\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.7595972729726932\n",
      "MAPE:  0.010404773992337394\n",
      "Delta:  0.17546271161262655\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.164002057356232e-05 0.00013632260975826593 nan\n",
      "Epoch: 112\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.759357400080318\n",
      "MAPE:  0.010403700077817745\n",
      "Delta:  0.175453650714589\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.163560926213506e-05 0.00013631706166861157 nan\n",
      "Epoch: 113\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.7591175696491144\n",
      "MAPE:  0.010402626257811798\n",
      "Delta:  0.17544459105843707\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.163117254336491e-05 0.0001363114127250764 nan\n",
      "Epoch: 114\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.7588777818480459\n",
      "MAPE:  0.010401552533180635\n",
      "Delta:  0.17543553264848433\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.162676064318639e-05 0.00013630585846968746 nan\n",
      "Epoch: 115\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.758638036502048\n",
      "MAPE:  0.010400478903241389\n",
      "Delta:  0.175426475480232\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.162235287425876e-05 0.00013630031579292545 nan\n",
      "Epoch: 116\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.7583983335823072\n",
      "MAPE:  0.01039940536775202\n",
      "Delta:  0.17541741955281126\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.161793377772561e-05 0.0001362947306543516 nan\n",
      "Epoch: 117\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.7581586731550485\n",
      "MAPE:  0.0103983319271447\n",
      "Delta:  0.17540836486806533\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.1613505279046734e-05 0.00013628909598384364 nan\n",
      "Epoch: 118\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.7579190552988881\n",
      "MAPE:  0.010397258581767646\n",
      "Delta:  0.1753993114274992\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.160908981927115e-05 0.00013628352758132678 nan\n",
      "Epoch: 119\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.7576794798888296\n",
      "MAPE:  0.010396185330990607\n",
      "Delta:  0.1753902592286815\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.1604662989701566e-05 0.00013627791053627547 nan\n",
      "Epoch: 120\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.7574399470019177\n",
      "MAPE:  0.010395112175348267\n",
      "Delta:  0.17538120827346235\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.160024886641246e-05 0.00013627234060109572 nan\n",
      "Epoch: 121\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.757200456546874\n",
      "MAPE:  0.010394039114256954\n",
      "Delta:  0.17537215855946894\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.1595838293838625e-05 0.000136266765618398 nan\n",
      "Epoch: 122\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.756961008524117\n",
      "MAPE:  0.010392966147896457\n",
      "Delta:  0.17536311008593466\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.1591422001617815e-05 0.00013626119079268584 nan\n",
      "Epoch: 123\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.7567216029249193\n",
      "MAPE:  0.010391893276304355\n",
      "Delta:  0.1753540628537187\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.1586990723495596e-05 0.00013625553387119904 nan\n",
      "Epoch: 124\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.7564822398850497\n",
      "MAPE:  0.010390820499983671\n",
      "Delta:  0.17534501686530496\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.158258854287556e-05 0.00013625001154771166 nan\n",
      "Epoch: 125\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.7562429191595819\n",
      "MAPE:  0.010389747817895617\n",
      "Delta:  0.17533597211544694\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.157816589762554e-05 0.00013624439594972504 nan\n",
      "Epoch: 126\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.75600364090392\n",
      "MAPE:  0.010388675230734395\n",
      "Delta:  0.17532692860758936\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.157375890896265e-05 0.00013623884916669216 nan\n",
      "Epoch: 127\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.7557644049887509\n",
      "MAPE:  0.01038760273802711\n",
      "Delta:  0.1753178863388431\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.156931643091056e-05 0.00013623314541599818 nan\n",
      "Epoch: 128\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.7555252116812499\n",
      "MAPE:  0.010386530340910534\n",
      "Delta:  0.17530884531528648\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.156491576485678e-05 0.00013622761917009285 nan\n",
      "Epoch: 129\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.7552860606612695\n",
      "MAPE:  0.010385458038072047\n",
      "Delta:  0.17529980552944496\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.1560510969883566e-05 0.00013622207269325948 nan\n",
      "Epoch: 130\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.7550469519559166\n",
      "MAPE:  0.010384385829525236\n",
      "Delta:  0.17529076698189894\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.155607286022601e-05 0.0001362163692497642 nan\n",
      "Epoch: 131\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.7548078858322584\n",
      "MAPE:  0.010383313716678694\n",
      "Delta:  0.1752817296783447\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.1551670004035266e-05 0.00013621084803416839 nan\n",
      "Epoch: 132\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.7545688619619921\n",
      "MAPE:  0.010382241697837025\n",
      "Delta:  0.1752726936124586\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.154725934286564e-05 0.00013620526835500524 nan\n",
      "Epoch: 133\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.7543298804393013\n",
      "MAPE:  0.010381169773640371\n",
      "Delta:  0.17526365878546524\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.154283444752661e-05 0.00013619961755539922 nan\n",
      "Epoch: 134\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.7540909413805192\n",
      "MAPE:  0.01038009794464788\n",
      "Delta:  0.1752546251997158\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.153843456950913e-05 0.0001361940853538135 nan\n",
      "Epoch: 135\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.7538520445691306\n",
      "MAPE:  0.010379026209783343\n",
      "Delta:  0.17524559285068192\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.1534006936471144e-05 0.00013618843093110566 nan\n",
      "Epoch: 136\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.7536131902110954\n",
      "MAPE:  0.01037795457016334\n",
      "Delta:  0.17523656174308436\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.152960256293859e-05 0.00013618288212835505 nan\n",
      "Epoch: 137\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.753374378112714\n",
      "MAPE:  0.010376883024698736\n",
      "Delta:  0.17522753187270323\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.152517814388524e-05 0.0001361772337737932 nan\n",
      "Epoch: 138\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.7531356084401328\n",
      "MAPE:  0.01037581157441096\n",
      "Delta:  0.17521850324290777\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.152078072923061e-05 0.00013617171029067787 nan\n",
      "Epoch: 139\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.75289688096596\n",
      "MAPE:  0.010374740218092812\n",
      "Delta:  0.17520947584882252\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.151635290112644e-05 0.00013616604696464751 nan\n",
      "Epoch: 140\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.7526581959269423\n",
      "MAPE:  0.010373668957020377\n",
      "Delta:  0.17520044969563306\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.1511932247838566e-05 0.00013616042266884065 nan\n",
      "Epoch: 141\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.7524195532461908\n",
      "MAPE:  0.010372597790735684\n",
      "Delta:  0.17519142478193853\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.150754606320085e-05 0.00013615492365326443 nan\n",
      "Epoch: 142\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.75218095269571\n",
      "MAPE:  0.010371526718329423\n",
      "Delta:  0.1751824011015567\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.150310429402616e-05 0.00013614920389182217 nan\n",
      "Epoch: 143\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.751942394653926\n",
      "MAPE:  0.010370455741485885\n",
      "Delta:  0.1751733786640823\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.1498703688257486e-05 0.00013614367318981468 nan\n",
      "Epoch: 144\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.7517038787811008\n",
      "MAPE:  0.010369384858699293\n",
      "Delta:  0.1751643574621604\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.149429127360161e-05 0.0001361380472063578 nan\n",
      "Epoch: 145\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.7514654052357597\n",
      "MAPE:  0.01036831407070742\n",
      "Delta:  0.1751553374977165\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.148990268932785e-05 0.0001361325386982637 nan\n",
      "Epoch: 146\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.7512269738037027\n",
      "MAPE:  0.010367243376656347\n",
      "Delta:  0.17514631876643322\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.148546001643162e-05 0.00013612681288566186 nan\n",
      "Epoch: 147\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.7509885848571196\n",
      "MAPE:  0.010366172778095732\n",
      "Delta:  0.17513730127764135\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.148106702179689e-05 0.0001361212880977014 nan\n",
      "Epoch: 148\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.7507502380355042\n",
      "MAPE:  0.010365102273525705\n",
      "Delta:  0.17512828502249625\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.147663861548857e-05 0.00013611561615056722 nan\n",
      "Epoch: 149\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.7505119335881283\n",
      "MAPE:  0.010364031864059167\n",
      "Delta:  0.1751192700070568\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.147224430990249e-05 0.00013611007909064554 nan\n",
      "Epoch: 150\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.7502736712703986\n",
      "MAPE:  0.010362961548656794\n",
      "Delta:  0.17511025622520762\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.146781656129029e-05 0.00013610438523425916 nan\n",
      "Epoch: 151\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.7500354513483787\n",
      "MAPE:  0.010361891328566294\n",
      "Delta:  0.17510124368266222\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.146344436612882e-05 0.00013609895920574377 nan\n",
      "Epoch: 152\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.749797273344877\n",
      "MAPE:  0.010360821201529992\n",
      "Delta:  0.17509223236954952\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.145898228908763e-05 0.0001360931486653616 nan\n",
      "Epoch: 153\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.7495591379244215\n",
      "MAPE:  0.010359751170620511\n",
      "Delta:  0.17508322230146506\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.1454618457458245e-05 0.00013608770695616723 nan\n",
      "Epoch: 154\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.749321044433157\n",
      "MAPE:  0.01035868123308888\n",
      "Delta:  0.17507421346106322\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.145016588592455e-05 0.00013608193779901523 nan\n",
      "Epoch: 155\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.749082993435598\n",
      "MAPE:  0.010357611391262744\n",
      "Delta:  0.1750652058637383\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.144578797067201e-05 0.00013607644742297254 nan\n",
      "Epoch: 156\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.7488449844356033\n",
      "MAPE:  0.010356541643135144\n",
      "Delta:  0.1750561994962764\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.144136611068273e-05 0.00013607079471733563 nan\n",
      "Epoch: 157\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.7486070177087338\n",
      "MAPE:  0.01035547198976713\n",
      "Delta:  0.17504719436622818\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.14369548969551e-05 0.0001360651805802915 nan\n",
      "Epoch: 158\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.7483690931791054\n",
      "MAPE:  0.010354402430953593\n",
      "Delta:  0.17503819047158675\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.143255904616062e-05 0.00013605961710028147 nan\n",
      "Epoch: 159\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.7481312107497375\n",
      "MAPE:  0.010353332966300938\n",
      "Delta:  0.17502918780951998\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.1428144650644825e-05 0.0001360539851172904 nan\n",
      "Epoch: 160\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.7478933705320072\n",
      "MAPE:  0.010352263596398176\n",
      "Delta:  0.17502018638313122\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.142372757527269e-05 0.00013604833795766158 nan\n",
      "Epoch: 161\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.747655572544019\n",
      "MAPE:  0.010351194321154762\n",
      "Delta:  0.17501118619274647\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.1419333914282106e-05 0.0001360427906390571 nan\n",
      "Epoch: 162\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.7474178166028542\n",
      "MAPE:  0.010350125139898185\n",
      "Delta:  0.1750021872341249\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.141490897231371e-05 0.00013603711282250686 nan\n",
      "Epoch: 163\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.7471801029281888\n",
      "MAPE:  0.010349056053630018\n",
      "Delta:  0.1749931895125983\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.1410501893500715e-05 0.00013603148715091162 nan\n",
      "Epoch: 164\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.7469424314204671\n",
      "MAPE:  0.010347987061958414\n",
      "Delta:  0.1749841930248975\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.140610161502579e-05 0.00013602591290962085 nan\n",
      "Epoch: 165\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.7467048019814326\n",
      "MAPE:  0.010346918164409438\n",
      "Delta:  0.17497519776968984\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.1401715560173145e-05 0.00013602038012061612 nan\n",
      "Epoch: 166\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.7464672145303084\n",
      "MAPE:  0.010345849360655173\n",
      "Delta:  0.17496620374434402\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.139729048275754e-05 0.00013601469866308946 nan\n",
      "Epoch: 167\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.7462296693183992\n",
      "MAPE:  0.010344780651858265\n",
      "Delta:  0.1749572109555455\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.139289247335643e-05 0.00013600910319222503 nan\n",
      "Epoch: 168\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.7459921661871076\n",
      "MAPE:  0.01034371203746738\n",
      "Delta:  0.17494821939841543\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.138847866914542e-05 0.00013600347067155294 nan\n",
      "Epoch: 169\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.7457547051927407\n",
      "MAPE:  0.010342643517523727\n",
      "Delta:  0.17493922907557466\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.138407218951979e-05 0.0001359978589617894 nan\n",
      "Epoch: 170\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.7455172862905621\n",
      "MAPE:  0.01034157509192471\n",
      "Delta:  0.17493023998559906\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.1379662669326365e-05 0.00013599221079052537 nan\n",
      "Epoch: 171\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.7452799095358262\n",
      "MAPE:  0.010340506761056238\n",
      "Delta:  0.17492125212887794\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.137526869791742e-05 0.00013598665789726905 nan\n",
      "Epoch: 172\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.7450425747538334\n",
      "MAPE:  0.010339438523962843\n",
      "Delta:  0.17491226550254885\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.137086657469592e-05 0.0001359810429447661 nan\n",
      "Epoch: 173\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.7448052820445352\n",
      "MAPE:  0.010338370381390398\n",
      "Delta:  0.17490328010789544\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.136643144720843e-05 0.0001359753060438118 nan\n",
      "Epoch: 174\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.7445680316123224\n",
      "MAPE:  0.010337302334045438\n",
      "Delta:  0.17489429595054787\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.136205884526124e-05 0.0001359698104541618 nan\n",
      "Epoch: 175\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.7443308230277397\n",
      "MAPE:  0.010336234380150761\n",
      "Delta:  0.17488531301942756\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.135763212738009e-05 0.00013596411537919462 nan\n",
      "Epoch: 176\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.744093656630458\n",
      "MAPE:  0.010335166521153816\n",
      "Delta:  0.17487633132385705\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.135326299277043e-05 0.00013595863604098923 nan\n",
      "Epoch: 177\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.7438565320357746\n",
      "MAPE:  0.010334098755459584\n",
      "Delta:  0.17486735085362337\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.1348818823959697e-05 0.00013595285106882127 nan\n",
      "Epoch: 178\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.7436194497683895\n",
      "MAPE:  0.010333031085343107\n",
      "Delta:  0.17485837162170614\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.134444328180887e-05 0.0001359473357415153 nan\n",
      "Epoch: 179\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.7433824093496462\n",
      "MAPE:  0.010331963508768277\n",
      "Delta:  0.17484939361596208\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.1340019714962715e-05 0.00013594163483243715 nan\n",
      "Epoch: 180\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.7431454110947813\n",
      "MAPE:  0.010330896027177155\n",
      "Delta:  0.17484041684464668\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.1335630789406395e-05 0.00013593607892947723 nan\n",
      "Epoch: 181\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.742908454742593\n",
      "MAPE:  0.01032982863938418\n",
      "Delta:  0.17483144130156048\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.133121471689872e-05 0.00013593041933390726 nan\n",
      "Epoch: 182\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.7426715404654793\n",
      "MAPE:  0.010328761346127284\n",
      "Delta:  0.17482246699130777\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.132682396136179e-05 0.00013592482546498363 nan\n",
      "Epoch: 183\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.7424346681404987\n",
      "MAPE:  0.010327694146988893\n",
      "Delta:  0.17481349390932\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.13224194547135e-05 0.00013591919178956857 nan\n",
      "Epoch: 184\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.742197837828659\n",
      "MAPE:  0.010326627042247764\n",
      "Delta:  0.17480452205785924\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.1318009292922184e-05 0.00013591355353070877 nan\n",
      "Epoch: 185\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.741961049529566\n",
      "MAPE:  0.010325560031892804\n",
      "Delta:  0.17479555143777184\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.1313631749483335e-05 0.00013590800419283067 nan\n",
      "Epoch: 186\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.741724303079943\n",
      "MAPE:  0.010324493115237919\n",
      "Delta:  0.17478658204321393\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.130921065643612e-05 0.00013590232948190728 nan\n",
      "Epoch: 187\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.7414875986898393\n",
      "MAPE:  0.010323426293236408\n",
      "Delta:  0.17477761388165594\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.130480371673407e-05 0.0001358966631266334 nan\n",
      "Epoch: 188\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.741250936336301\n",
      "MAPE:  0.010322359565818307\n",
      "Delta:  0.17476864695048167\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.130041516154815e-05 0.00013589108573419661 nan\n",
      "Epoch: 189\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.7410143158560265\n",
      "MAPE:  0.010321292932260667\n",
      "Delta:  0.1747596812463359\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.1295996523204046e-05 0.00013588541438203094 nan\n",
      "Epoch: 190\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.7407777374042714\n",
      "MAPE:  0.010320226393227258\n",
      "Delta:  0.1747507167743343\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.129162359629458e-05 0.0001358798869701694 nan\n",
      "Epoch: 191\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.7405412007220726\n",
      "MAPE:  0.010319159947772629\n",
      "Delta:  0.1747417535263463\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.128719757163669e-05 0.00013587413886373412 nan\n",
      "Epoch: 192\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.7403047061852677\n",
      "MAPE:  0.010318093597471602\n",
      "Delta:  0.1747327915115092\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.1282806807328996e-05 0.00013586856433323025 nan\n",
      "Epoch: 193\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.7400682534833358\n",
      "MAPE:  0.010317027340941375\n",
      "Delta:  0.17472383072351919\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.1278418439659745e-05 0.00013586298356660365 nan\n",
      "Epoch: 194\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.7398318426188082\n",
      "MAPE:  0.01031596117817557\n",
      "Delta:  0.17471487116181597\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.127400487991984e-05 0.00013585730205256663 nan\n",
      "Epoch: 195\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.7395954737586448\n",
      "MAPE:  0.010314895110135284\n",
      "Delta:  0.17470591283065942\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.126960483736731e-05 0.0001358516610103777 nan\n",
      "Epoch: 196\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.7393591468240484\n",
      "MAPE:  0.010313829136356823\n",
      "Delta:  0.17469695572754584\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.126520458664796e-05 0.00013584602669225454 nan\n",
      "Epoch: 197\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.7391228617949617\n",
      "MAPE:  0.010312763256794009\n",
      "Delta:  0.17468799985236982\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.126080953932188e-05 0.0001358404240847655 nan\n",
      "Epoch: 198\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.7388866186078797\n",
      "MAPE:  0.010311697471144075\n",
      "Delta:  0.1746790452040806\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.125641294534411e-05 0.00013583479167500467 nan\n",
      "Epoch: 199\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.7386504173062947\n",
      "MAPE:  0.010310631779711584\n",
      "Delta:  0.1746700917828067\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.1252017529312965e-05 0.00013582917883625534 nan\n",
      "Epoch: 200\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.7384142578478288\n",
      "MAPE:  0.010309566182229701\n",
      "Delta:  0.17466113958820081\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.124761747954398e-05 0.00013582353607377584 nan\n",
      "Epoch: 201\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.738178140276167\n",
      "MAPE:  0.010308500679053348\n",
      "Delta:  0.17465218862093065\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.1243213865070913e-05 0.00013581788097327685 nan\n",
      "Epoch: 202\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.7379420646044004\n",
      "MAPE:  0.010307435270190278\n",
      "Delta:  0.17464323888147715\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.1238812732945505e-05 0.00013581222540814952 nan\n",
      "Epoch: 203\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.737706030824976\n",
      "MAPE:  0.010306369955633828\n",
      "Delta:  0.17463429036926503\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.123442895593744e-05 0.00013580666392998264 nan\n",
      "Epoch: 204\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.7374700387660387\n",
      "MAPE:  0.01030530473457814\n",
      "Delta:  0.17462534308112182\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.1230024303516863e-05 0.00013580099204746343 nan\n",
      "Epoch: 205\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.7372340886111215\n",
      "MAPE:  0.010304239607986048\n",
      "Delta:  0.17461639702055176\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.1225637255680745e-05 0.00013579540124952771 nan\n",
      "Epoch: 206\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.7369981802109942\n",
      "MAPE:  0.010303174575159352\n",
      "Delta:  0.1746074521843391\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.12212208960694e-05 0.00013578968003513658 nan\n",
      "Epoch: 207\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.7367623137838817\n",
      "MAPE:  0.010302109637099101\n",
      "Delta:  0.17459850857746065\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.121683439313074e-05 0.00013578409150860615 nan\n",
      "Epoch: 208\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.736526489090938\n",
      "MAPE:  0.010301044792800518\n",
      "Delta:  0.17458956619456156\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.1212425196567324e-05 0.0001357783855626682 nan\n",
      "Epoch: 209\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.7362907063277626\n",
      "MAPE:  0.010299980043024182\n",
      "Delta:  0.1745806250394627\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.120805453773247e-05 0.00013577287303456753 nan\n",
      "Epoch: 210\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.7360549651501413\n",
      "MAPE:  0.010298915386457698\n",
      "Delta:  0.17457168510529444\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.120364981836545e-05 0.00013576719740870935 nan\n",
      "Epoch: 211\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.7358192658329754\n",
      "MAPE:  0.010297850824185958\n",
      "Delta:  0.17456274639786212\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.1199246373978546e-05 0.0001357615185099137 nan\n",
      "Epoch: 212\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.7355836083735872\n",
      "MAPE:  0.010296786356327775\n",
      "Delta:  0.17455380891680158\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.119486074256496e-05 0.00013575591834780187 nan\n",
      "Epoch: 213\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.7353479926269628\n",
      "MAPE:  0.010295721982254057\n",
      "Delta:  0.17454487265886198\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.1190457394767463e-05 0.00013575025620027326 nan\n",
      "Epoch: 214\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.735112418692367\n",
      "MAPE:  0.01029465770230038\n",
      "Delta:  0.17453593762699468\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.118606592946495e-05 0.00013574461899434898 nan\n",
      "Epoch: 215\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.7348768865181794\n",
      "MAPE:  0.010293593516470929\n",
      "Delta:  0.17452700381898423\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.118167131679119e-05 0.00013573899096963604 nan\n",
      "Epoch: 216\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.7346413960801468\n",
      "MAPE:  0.01029252942452314\n",
      "Delta:  0.17451807123523888\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.11772739660854e-05 0.00013573332693594953 nan\n",
      "Epoch: 217\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.7344059474324158\n",
      "MAPE:  0.010291465426780232\n",
      "Delta:  0.17450913987609523\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.117289051581597e-05 0.00013572772083458862 nan\n",
      "Epoch: 218\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.734170540466169\n",
      "MAPE:  0.010290401522818241\n",
      "Delta:  0.17450020973898633\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.11684935688983e-05 0.00013572208920620277 nan\n",
      "Epoch: 219\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.733935175217377\n",
      "MAPE:  0.010289337712674663\n",
      "Delta:  0.17449128082612653\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.1164103160417085e-05 0.0001357164338807726 nan\n",
      "Epoch: 220\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.733699851718816\n",
      "MAPE:  0.010288273996727422\n",
      "Delta:  0.17448235313623375\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.115970392488567e-05 0.00013571078385321567 nan\n",
      "Epoch: 221\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.7334645699529732\n",
      "MAPE:  0.01028721037472722\n",
      "Delta:  0.1744734266707072\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.115530180777039e-05 0.00013570509674354359 nan\n",
      "Epoch: 222\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.7332293299758061\n",
      "MAPE:  0.010286146847168809\n",
      "Delta:  0.1744645014299084\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.115091952756501e-05 0.00013569950579428447 nan\n",
      "Epoch: 223\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.7329941316123003\n",
      "MAPE:  0.010285083413030272\n",
      "Delta:  0.17445557741023535\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.114653883342424e-05 0.0001356938966893262 nan\n",
      "Epoch: 224\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.732758974885642\n",
      "MAPE:  0.01028402007266408\n",
      "Delta:  0.17444665461127062\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.1142134239956505e-05 0.00013568820109599589 nan\n",
      "Epoch: 225\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.7325238599374069\n",
      "MAPE:  0.010282956826662627\n",
      "Delta:  0.1744377330370428\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.113773503195862e-05 0.00013568253343754222 nan\n",
      "Epoch: 226\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.7322887867108496\n",
      "MAPE:  0.010281893674691548\n",
      "Delta:  0.17442881268647115\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.113335096607052e-05 0.00013567691711502405 nan\n",
      "Epoch: 227\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.7320537551087156\n",
      "MAPE:  0.010280830616493838\n",
      "Delta:  0.17441989355677345\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.112895739789458e-05 0.00013567126685576358 nan\n",
      "Epoch: 228\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.7318187651814978\n",
      "MAPE:  0.010279767652224506\n",
      "Delta:  0.17441097564946645\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.112455110733993e-05 0.00013566555615340814 nan\n",
      "Epoch: 229\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.7315838170255624\n",
      "MAPE:  0.010278704782349756\n",
      "Delta:  0.1744020589666282\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.11201832218422e-05 0.00013565999957398933 nan\n",
      "Epoch: 230\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.7313489103656825\n",
      "MAPE:  0.010277642005646223\n",
      "Delta:  0.17439314350141955\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.111578468008915e-05 0.00013565431645967685 nan\n",
      "Epoch: 231\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.7311140454126936\n",
      "MAPE:  0.010276579323225472\n",
      "Delta:  0.17438422925904662\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.11113965603327e-05 0.00013564869209459207 nan\n",
      "Epoch: 232\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.7308792220565667\n",
      "MAPE:  0.010275516734432756\n",
      "Delta:  0.1743753162375511\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.1107020202278974e-05 0.00013564309005087427 nan\n",
      "Epoch: 233\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.7306444402503822\n",
      "MAPE:  0.010274454239199256\n",
      "Delta:  0.17436640443474138\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.110260681606693e-05 0.00013563733512522713 nan\n",
      "Epoch: 234\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.7304097002504575\n",
      "MAPE:  0.010273391838620359\n",
      "Delta:  0.1743574938569336\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.109822903004435e-05 0.00013563174432651426 nan\n",
      "Epoch: 235\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.7301750017644129\n",
      "MAPE:  0.010272329531444089\n",
      "Delta:  0.1743485844977794\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.109384177848231e-05 0.0001356260985315716 nan\n",
      "Epoch: 236\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.7299403448791466\n",
      "MAPE:  0.010271267318138929\n",
      "Delta:  0.17433967635878878\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.108943925291598e-05 0.00013562039422787553 nan\n",
      "Epoch: 237\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.7297057296875835\n",
      "MAPE:  0.010270205199074492\n",
      "Delta:  0.17433076944248405\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.108506311368721e-05 0.00013561480242751944 nan\n",
      "Epoch: 238\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.7294711559867944\n",
      "MAPE:  0.010269143173364035\n",
      "Delta:  0.17432186374412442\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.108066788872545e-05 0.00013560911207477488 nan\n",
      "Epoch: 239\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.7292366239389718\n",
      "MAPE:  0.010268081241809373\n",
      "Delta:  0.17431295926689677\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.107628125677888e-05 0.00013560348316854487 nan\n",
      "Epoch: 240\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.7290021334295433\n",
      "MAPE:  0.010267019403847251\n",
      "Delta:  0.17430405600916254\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.107189908493126e-05 0.0001355978306966099 nan\n",
      "Epoch: 241\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.7287676844909805\n",
      "MAPE:  0.010265957659761482\n",
      "Delta:  0.17429515397000395\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.106749773231556e-05 0.0001355921399658344 nan\n",
      "Epoch: 242\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.7285332771811366\n",
      "MAPE:  0.010264896009756682\n",
      "Delta:  0.17428625315262383\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.106312365721344e-05 0.00013558653294099 nan\n",
      "Epoch: 243\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.7282989113470106\n",
      "MAPE:  0.010263834453192991\n",
      "Delta:  0.17427735355212737\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.10587148627728e-05 0.000135580793686918 nan\n",
      "Epoch: 244\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.728064587208882\n",
      "MAPE:  0.01026277299098989\n",
      "Delta:  0.1742684551744253\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.105434310737067e-05 0.00013557520779172716 nan\n",
      "Epoch: 245\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.7278303044933936\n",
      "MAPE:  0.01026171162211006\n",
      "Delta:  0.17425955801292203\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.1049960251403625e-05 0.0001355695522199385 nan\n",
      "Epoch: 246\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.7275960633127014\n",
      "MAPE:  0.010260650346962413\n",
      "Delta:  0.17425066206941203\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.1045567436514006e-05 0.00013556388628954696 nan\n",
      "Epoch: 247\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.7273618636764203\n",
      "MAPE:  0.010259589165744395\n",
      "Delta:  0.17424176734549052\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.1041193688261544e-05 0.00013555827615507887 nan\n",
      "Epoch: 248\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.7271277054798841\n",
      "MAPE:  0.010258528077841698\n",
      "Delta:  0.17423287383769484\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.103678402418321e-05 0.0001355525341218966 nan\n",
      "Epoch: 249\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.7268935889426542\n",
      "MAPE:  0.010257467084339477\n",
      "Delta:  0.1742239815521429\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.1032428092123716e-05 0.0001355469792280184 nan\n",
      "Epoch: 250\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.7266595137332246\n",
      "MAPE:  0.010256406183830984\n",
      "Delta:  0.1742150904793324\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.102801339773588e-05 0.0001355412061606609 nan\n",
      "Epoch: 251\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.7264254802201044\n",
      "MAPE:  0.010255345377900345\n",
      "Delta:  0.17420620062936132\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.102363736386728e-05 0.00013553558557710677 nan\n",
      "Epoch: 252\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.7261914881316878\n",
      "MAPE:  0.010254284665419791\n",
      "Delta:  0.17419731199535388\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.101925892148085e-05 0.00013552995724985806 nan\n",
      "Epoch: 253\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.7259575374730962\n",
      "MAPE:  0.010253224046379933\n",
      "Delta:  0.17418842457758976\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.101486019365442e-05 0.00013552423974505512 nan\n",
      "Epoch: 254\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.725723628389998\n",
      "MAPE:  0.01025216352153605\n",
      "Delta:  0.17417953837946257\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.101048688582743e-05 0.00013551861917582286 nan\n",
      "Epoch: 255\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.7254897607067994\n",
      "MAPE:  0.01025110309008248\n",
      "Delta:  0.17417065339640428\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.100609120367583e-05 0.00013551292863267506 nan\n",
      "Epoch: 256\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.7252559345360003\n",
      "MAPE:  0.010250042752475952\n",
      "Delta:  0.17416176963217214\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.100172192695762e-05 0.00013550731190126175 nan\n",
      "Epoch: 257\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.7250221497419695\n",
      "MAPE:  0.010248982508300862\n",
      "Delta:  0.17415288708202706\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.0997331953794856e-05 0.00013550164648790108 nan\n",
      "Epoch: 258\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.7247884064004513\n",
      "MAPE:  0.01024792235773487\n",
      "Delta:  0.17414400574943384\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.0992950940909054e-05 0.00013549595902162537 nan\n",
      "Epoch: 259\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.7245547045412168\n",
      "MAPE:  0.010246862301142062\n",
      "Delta:  0.174135125632692\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.098855735430341e-05 0.00013549029497594844 nan\n",
      "Epoch: 260\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.7243210441155963\n",
      "MAPE:  0.0102458023380946\n",
      "Delta:  0.1741262467338513\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.098415738913342e-05 0.00013548452198242078 nan\n",
      "Epoch: 261\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.7240874253031901\n",
      "MAPE:  0.010244742469663008\n",
      "Delta:  0.17411736905388223\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.0979814403384616e-05 0.00013547904209298967 nan\n",
      "Epoch: 262\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.7238538475903256\n",
      "MAPE:  0.010243682693391811\n",
      "Delta:  0.17410849258272346\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.097539741449886e-05 0.0001354732369254208 nan\n",
      "Epoch: 263\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.723620311529606\n",
      "MAPE:  0.010242623011754624\n",
      "Delta:  0.17409961733312082\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.097104469575786e-05 0.00013546767888261702 nan\n",
      "Epoch: 264\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.7233868166867283\n",
      "MAPE:  0.010241563423048432\n",
      "Delta:  0.17409074329374422\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.096664199699674e-05 0.00013546195276137318 nan\n",
      "Epoch: 265\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.7231533633431768\n",
      "MAPE:  0.01024050392829594\n",
      "Delta:  0.1740818704731558\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.0962273650423384e-05 0.0001354563315877355 nan\n",
      "Epoch: 266\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.7229199513098152\n",
      "MAPE:  0.010239444526881322\n",
      "Delta:  0.17407299886523517\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.0957881112867476e-05 0.00013545060694597488 nan\n",
      "Epoch: 267\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.7226865807566911\n",
      "MAPE:  0.010238385219530471\n",
      "Delta:  0.17406412847405403\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.0953510294937665e-05 0.0001354450051084255 nan\n",
      "Epoch: 268\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.7224532514639603\n",
      "MAPE:  0.010237326005153726\n",
      "Delta:  0.17405525929569185\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.0949135066868934e-05 0.00013543935269977325 nan\n",
      "Epoch: 269\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.7222199635105264\n",
      "MAPE:  0.010236266884387684\n",
      "Delta:  0.1740463913307769\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.0944738052116634e-05 0.0001354336066106132 nan\n",
      "Epoch: 270\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.7219867170494911\n",
      "MAPE:  0.010235207857711991\n",
      "Delta:  0.17403752458296162\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.0940365846186e-05 0.00013542798524479593 nan\n",
      "Epoch: 271\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.721753511857783\n",
      "MAPE:  0.010234148924254335\n",
      "Delta:  0.17402865904778841\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.0935972934262885e-05 0.00013542224865892294 nan\n",
      "Epoch: 272\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.7215203481255708\n",
      "MAPE:  0.010233090084833772\n",
      "Delta:  0.17401979472872137\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.0931589137714894e-05 0.00013541658680116253 nan\n",
      "Epoch: 273\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.7212872257159189\n",
      "MAPE:  0.010232031338996724\n",
      "Delta:  0.17401093162403442\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.0927234388375986e-05 0.0001354109975070239 nan\n",
      "Epoch: 274\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.7210541444956886\n",
      "MAPE:  0.010230972685993088\n",
      "Delta:  0.17400206972853346\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.092283757635041e-05 0.0001354052618112167 nan\n",
      "Epoch: 275\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.720821104708662\n",
      "MAPE:  0.010229914127079073\n",
      "Delta:  0.17399320904939874\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.091847637583857e-05 0.0001353996676850544 nan\n",
      "Epoch: 276\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.7205881061029389\n",
      "MAPE:  0.010228855660999885\n",
      "Delta:  0.17398434958029418\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.091408376911577e-05 0.00013539394174399977 nan\n",
      "Epoch: 277\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.7203551488971358\n",
      "MAPE:  0.010227797288862802\n",
      "Delta:  0.17397549132654513\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.0909696922118997e-05 0.00013538823998515692 nan\n",
      "Epoch: 278\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.7201222330413772\n",
      "MAPE:  0.010226739010538074\n",
      "Delta:  0.17396663428700984\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.090532179563567e-05 0.00013538257255441 nan\n",
      "Epoch: 279\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.71988935846836\n",
      "MAPE:  0.010225680825665153\n",
      "Delta:  0.17395777845950977\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.0900952988208736e-05 0.0001353769364574875 nan\n",
      "Epoch: 280\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.7196565251159648\n",
      "MAPE:  0.010224622733952476\n",
      "Delta:  0.17394892384280647\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.089655521517411e-05 0.0001353711869686025 nan\n",
      "Epoch: 281\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.7194237331709816\n",
      "MAPE:  0.010223564736310259\n",
      "Delta:  0.1739400704417995\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.089220079013135e-05 0.00013536559836191397 nan\n",
      "Epoch: 282\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.7191909823485032\n",
      "MAPE:  0.010222506831486901\n",
      "Delta:  0.17393121824880908\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.0887815535305414e-05 0.00013535991019675286 nan\n",
      "Epoch: 283\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.7189582728115214\n",
      "MAPE:  0.01022144902016243\n",
      "Delta:  0.17392236726905902\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.0883426121361985e-05 0.00013535416631582642 nan\n",
      "Epoch: 284\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.7187256046475732\n",
      "MAPE:  0.010220391302933124\n",
      "Delta:  0.17391351750313322\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.087906348788529e-05 0.00013534854903463067 nan\n",
      "Epoch: 285\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.7184929776307953\n",
      "MAPE:  0.010219333678625967\n",
      "Delta:  0.1739046689462348\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.087467840692028e-05 0.0001353428576528204 nan\n",
      "Epoch: 286\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.7182603918803467\n",
      "MAPE:  0.010218276147861641\n",
      "Delta:  0.1738958216021287\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.087031632222683e-05 0.00013533722481073873 nan\n",
      "Epoch: 287\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.7180278472874073\n",
      "MAPE:  0.010217218710255717\n",
      "Delta:  0.17388697546667664\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.086592862624251e-05 0.00013533150912425906 nan\n",
      "Epoch: 288\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.7177953439861164\n",
      "MAPE:  0.010216161366337006\n",
      "Delta:  0.17387813054419354\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.0861540796587335e-05 0.00013532577535435575 nan\n",
      "Epoch: 289\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.7175628819992914\n",
      "MAPE:  0.01021510411620792\n",
      "Delta:  0.17386928683456324\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.085716896147119e-05 0.00013532011557337853 nan\n",
      "Epoch: 290\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.7173304611915947\n",
      "MAPE:  0.010214046959421427\n",
      "Delta:  0.17386044433486547\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.0852807067736094e-05 0.0001353144858526889 nan\n",
      "Epoch: 291\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.7170980815031993\n",
      "MAPE:  0.010212989895625506\n",
      "Delta:  0.173851603043233\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.0848424383631574e-05 0.00013530877970158173 nan\n",
      "Epoch: 292\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.7168657430571632\n",
      "MAPE:  0.010211932925377237\n",
      "Delta:  0.1738427629631417\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.084402746791117e-05 0.00013530300275199636 nan\n",
      "Epoch: 293\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.7166334459668056\n",
      "MAPE:  0.01021087604933069\n",
      "Delta:  0.1738339240969265\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.0839694896165355e-05 0.0001352975029039749 nan\n",
      "Epoch: 294\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.7164011897481648\n",
      "MAPE:  0.010209819265206702\n",
      "Delta:  0.1738250864332628\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.083529384763974e-05 0.00013529171346837732 nan\n",
      "Epoch: 295\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.7161689748902047\n",
      "MAPE:  0.010208762575273141\n",
      "Delta:  0.17381624998391587\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.083092731605898e-05 0.00013528606686208366 nan\n",
      "Epoch: 296\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.715936801139521\n",
      "MAPE:  0.010207705978429012\n",
      "Delta:  0.1738074147427466\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.0826552999594377e-05 0.0001352803752558973 nan\n",
      "Epoch: 297\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.7157046685651474\n",
      "MAPE:  0.010206649475020013\n",
      "Delta:  0.17379858071096946\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.082216626828284e-05 0.00013527462656204303 nan\n",
      "Epoch: 298\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.7154725772568165\n",
      "MAPE:  0.01020559306554062\n",
      "Delta:  0.1737897478906034\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.081781180227285e-05 0.00013526903263116896 nan\n",
      "Epoch: 299\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.7152405269407855\n",
      "MAPE:  0.010204536748573837\n",
      "Delta:  0.17378091627590192\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.081343511226244e-05 0.0001352633499072109 nan\n",
      "Epoch: 300\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.7150085177612149\n",
      "MAPE:  0.010203480524937943\n",
      "Delta:  0.17377208587058898\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.080904866505698e-05 0.0001352575944665313 nan\n",
      "Epoch: 301\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.714776549834613\n",
      "MAPE:  0.010202424395194845\n",
      "Delta:  0.17376325667622136\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.080469268459176e-05 0.0001352519775384975 nan\n",
      "Epoch: 302\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.714544622915211\n",
      "MAPE:  0.010201368358219153\n",
      "Delta:  0.17375442868736604\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.0800297366593306e-05 0.00013524619079363642 nan\n",
      "Epoch: 303\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.714312737286016\n",
      "MAPE:  0.010200312415336804\n",
      "Delta:  0.17374560191071997\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.079593580947783e-05 0.00013524056986280453 nan\n",
      "Epoch: 304\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.7140808926545024\n",
      "MAPE:  0.010199256565213005\n",
      "Delta:  0.17373677634027812\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.07915693591654e-05 0.0001352348861584085 nan\n",
      "Epoch: 305\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.7138490891201181\n",
      "MAPE:  0.010198200808451156\n",
      "Delta:  0.1737279519767524\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.078719950757371e-05 0.00013522920395536708 nan\n",
      "Epoch: 306\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.7136173266720967\n",
      "MAPE:  0.010197145144868195\n",
      "Delta:  0.17371912882059531\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.0782826180095775e-05 0.00013522352616968103 nan\n",
      "Epoch: 307\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.7133856052946788\n",
      "MAPE:  0.010196089574413139\n",
      "Delta:  0.17371030687227226\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.0778443024479536e-05 0.00013521777101788146 nan\n",
      "Epoch: 308\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.7131539251122367\n",
      "MAPE:  0.010195034097794469\n",
      "Delta:  0.17370148613335198\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.077407259601596e-05 0.0001352121044421173 nan\n",
      "Epoch: 309\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.712922285964789\n",
      "MAPE:  0.010193978714199355\n",
      "Delta:  0.173692666601485\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.0769717388599034e-05 0.0001352064609951853 nan\n",
      "Epoch: 310\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.712690687804544\n",
      "MAPE:  0.010192923423544161\n",
      "Delta:  0.17368384827388916\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.0765327594182175e-05 0.00013520069625616582 nan\n",
      "Epoch: 311\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.7124591308310813\n",
      "MAPE:  0.010191868226657288\n",
      "Delta:  0.17367503115643373\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.0760979846242726e-05 0.00013519509721249268 nan\n",
      "Epoch: 312\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.7122276147524162\n",
      "MAPE:  0.010190813122316289\n",
      "Delta:  0.1736662152416774\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.0756578239496974e-05 0.0001351892836932711 nan\n",
      "Epoch: 313\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.711996139927658\n",
      "MAPE:  0.010189758112172388\n",
      "Delta:  0.17365740053883594\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.0752223522909645e-05 0.0001351836474360324 nan\n",
      "Epoch: 314\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.7117647060450663\n",
      "MAPE:  0.010188703194735261\n",
      "Delta:  0.17364858703962738\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.0747874308587626e-05 0.00013517804769058728 nan\n",
      "Epoch: 315\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.7115333130339974\n",
      "MAPE:  0.010187648369814605\n",
      "Delta:  0.17363977474295844\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.074348540312634e-05 0.00013517225740788952 nan\n",
      "Epoch: 316\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.7113019612124458\n",
      "MAPE:  0.010186593638892365\n",
      "Delta:  0.17363096365558336\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.07391013390146e-05 0.00013516650808598207 nan\n",
      "Epoch: 317\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.711070650502068\n",
      "MAPE:  0.010185539001550123\n",
      "Delta:  0.17362215377652285\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.073475521089055e-05 0.0001351609059124792 nan\n",
      "Epoch: 318\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.710839380642866\n",
      "MAPE:  0.010184484456635293\n",
      "Delta:  0.1736133450990518\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.073038860992085e-05 0.0001351552225038466 nan\n",
      "Epoch: 319\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.7106081517657068\n",
      "MAPE:  0.010183430004887103\n",
      "Delta:  0.17360453762658706\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.072600564792751e-05 0.00013514947022297275 nan\n",
      "Epoch: 320\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.7103769639802366\n",
      "MAPE:  0.010182375646615883\n",
      "Delta:  0.17359573136183093\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.0721641848716637e-05 0.0001351437951134793 nan\n",
      "Epoch: 321\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.7101458171462498\n",
      "MAPE:  0.010181321381465377\n",
      "Delta:  0.17358692630131833\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.0717266865563104e-05 0.00013513805483233998 nan\n",
      "Epoch: 322\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.709914711367041\n",
      "MAPE:  0.010180267209764136\n",
      "Delta:  0.17357812244685272\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.071290899127945e-05 0.00013513240871054766 nan\n",
      "Epoch: 323\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.7096836464734044\n",
      "MAPE:  0.010179213130812322\n",
      "Delta:  0.1735693197953262\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.070853397104447e-05 0.00013512667761772512 nan\n",
      "Epoch: 324\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.709452622602479\n",
      "MAPE:  0.010178159145201482\n",
      "Delta:  0.17356051834957703\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.0704189603623107e-05 0.00013512108064039907 nan\n",
      "Epoch: 325\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.7092216395168096\n",
      "MAPE:  0.010177105251979707\n",
      "Delta:  0.17355171810414693\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.069979504823685e-05 0.0001351152539602607 nan\n",
      "Epoch: 326\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.708990697600912\n",
      "MAPE:  0.010176051452864278\n",
      "Delta:  0.17354291906760877\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.069544460045705e-05 0.00013510961366647312 nan\n",
      "Epoch: 327\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.7087597965279995\n",
      "MAPE:  0.01017499774639094\n",
      "Delta:  0.17353412123216938\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.06910776169045e-05 0.00013510393677773624 nan\n",
      "Epoch: 328\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.708528936352481\n",
      "MAPE:  0.010173944132824611\n",
      "Delta:  0.17352532460056083\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.068668904995022e-05 0.00013509813251255665 nan\n",
      "Epoch: 329\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.708298117283836\n",
      "MAPE:  0.010172890613152102\n",
      "Delta:  0.17351652917639052\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.068235026151058e-05 0.00013509253541355015 nan\n",
      "Epoch: 330\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.70806733895993\n",
      "MAPE:  0.01017183718585311\n",
      "Delta:  0.17350773495088265\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.067797350999381e-05 0.00013508679067575358 nan\n",
      "Epoch: 331\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.7078366016248516\n",
      "MAPE:  0.010170783851910633\n",
      "Delta:  0.173498941930487\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.0673611804663565e-05 0.00013508111450244442 nan\n",
      "Epoch: 332\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.7076059051533161\n",
      "MAPE:  0.01016973061074017\n",
      "Delta:  0.1734901501124551\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.066923659868827e-05 0.00013507537041979045 nan\n",
      "Epoch: 333\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.7073752496531467\n",
      "MAPE:  0.01016867746301305\n",
      "Delta:  0.17348135949899152\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.066488553373549e-05 0.0001350696958962727 nan\n",
      "Epoch: 334\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.707144634997395\n",
      "MAPE:  0.010167624408209687\n",
      "Delta:  0.17347257008577027\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.066051496604995e-05 0.00013506399278773173 nan\n",
      "Epoch: 335\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.7069140612267262\n",
      "MAPE:  0.010166571446306779\n",
      "Delta:  0.17346378187603725\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.0656154746309134e-05 0.00013505830760263127 nan\n",
      "Epoch: 336\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.7066835283023938\n",
      "MAPE:  0.01016551857734439\n",
      "Delta:  0.17345499486785965\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.065177759466799e-05 0.0001350525387339152 nan\n",
      "Epoch: 337\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.7064530363590813\n",
      "MAPE:  0.01016446580190887\n",
      "Delta:  0.17344620906403693\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.064742169902381e-05 0.00013504687593102194 nan\n",
      "Epoch: 338\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.706222585207598\n",
      "MAPE:  0.010163413119160268\n",
      "Delta:  0.17343742446074437\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.064305405400038e-05 0.00013504114929985267 nan\n",
      "Epoch: 339\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.7059921749487303\n",
      "MAPE:  0.010162360529590554\n",
      "Delta:  0.17342864105988243\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.063869770616236e-05 0.00013503547170257146 nan\n",
      "Epoch: 340\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.7057618054906651\n",
      "MAPE:  0.010161308032805577\n",
      "Delta:  0.17341985885935418\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.0634331872800864e-05 0.00013502975006818296 nan\n",
      "Epoch: 341\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.705531476900394\n",
      "MAPE:  0.010160255629111254\n",
      "Delta:  0.17341107786066737\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.06299549400957e-05 0.00013502399025955292 nan\n",
      "Epoch: 342\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.7053011892348697\n",
      "MAPE:  0.010159203318831883\n",
      "Delta:  0.17340229806560917\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.0625621376920726e-05 0.00013501839397211945 nan\n",
      "Epoch: 343\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.7050709422070605\n",
      "MAPE:  0.01015815110063288\n",
      "Delta:  0.1733935194665214\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.062124027743753e-05 0.00013501261542547827 nan\n",
      "Epoch: 344\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.7048407361196671\n",
      "MAPE:  0.010157098976007592\n",
      "Delta:  0.17338474207150995\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.061686652241271e-05 0.00013500684760892057 nan\n",
      "Epoch: 345\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.7046105709462083\n",
      "MAPE:  0.01015604694472808\n",
      "Delta:  0.17337596587916349\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.061253898552831e-05 0.0001350012877193718 nan\n",
      "Epoch: 346\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.7043804463240706\n",
      "MAPE:  0.010154995005287885\n",
      "Delta:  0.1733671908813313\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.060815092983173e-05 0.0001349954795001329 nan\n",
      "Epoch: 347\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.7041503626684684\n",
      "MAPE:  0.010153943159477022\n",
      "Delta:  0.17335841708836888\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.060376971832703e-05 0.00013498966838443316 nan\n",
      "Epoch: 348\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.7039203199761346\n",
      "MAPE:  0.0101528914074837\n",
      "Delta:  0.17334964449895182\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.0599456235977947e-05 0.00013498417065838098 nan\n",
      "Epoch: 349\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.7036903177048748\n",
      "MAPE:  0.010151839746659072\n",
      "Delta:  0.17334087310120147\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.059508104332533e-05 0.00013497838317844124 nan\n",
      "Epoch: 350\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.703460356340354\n",
      "MAPE:  0.010150788179464874\n",
      "Delta:  0.1733321029056788\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.059071217838884e-05 0.00013497263341377685 nan\n",
      "Epoch: 351\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.7032304358101429\n",
      "MAPE:  0.010149736705399853\n",
      "Delta:  0.1733233339111494\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.0586340568870014e-05 0.00013496688454150974 nan\n",
      "Epoch: 352\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.7030005561045654\n",
      "MAPE:  0.01014868532455931\n",
      "Delta:  0.17331456611795165\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.058199364094129e-05 0.000134961243221432 nan\n",
      "Epoch: 353\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.7027707170323065\n",
      "MAPE:  0.010147634035944358\n",
      "Delta:  0.17330579952167038\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.057764329619019e-05 0.00013495554701303814 nan\n",
      "Epoch: 354\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.7025409186787517\n",
      "MAPE:  0.010146582840210317\n",
      "Delta:  0.173297034122761\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.0573250580443485e-05 0.00013494969753158337 nan\n",
      "Epoch: 355\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.702311161296741\n",
      "MAPE:  0.010145531738340345\n",
      "Delta:  0.1732882699284295\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.056891910371064e-05 0.00013494409779413186 nan\n",
      "Epoch: 356\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.7020814444529149\n",
      "MAPE:  0.010144480728494016\n",
      "Delta:  0.17327950692792585\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.056455811314198e-05 0.000134938385870087 nan\n",
      "Epoch: 357\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.701851768330181\n",
      "MAPE:  0.010143429811432885\n",
      "Delta:  0.17327074512622798\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.056018370608317e-05 0.00013493258161711985 nan\n",
      "Epoch: 358\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.7016221330775505\n",
      "MAPE:  0.01014237898796267\n",
      "Delta:  0.17326198452552352\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.0555841392019296e-05 0.00013492695456385206 nan\n",
      "Epoch: 359\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.7013925383853161\n",
      "MAPE:  0.010141328256558033\n",
      "Delta:  0.17325322512011457\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.055148186772218e-05 0.0001349212192395255 nan\n",
      "Epoch: 360\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.701162984429632\n",
      "MAPE:  0.010140277618264058\n",
      "Delta:  0.1732444669128464\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.054711604812745e-05 0.00013491547854271868 nan\n",
      "Epoch: 361\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.7009334712115085\n",
      "MAPE:  0.010139227072820202\n",
      "Delta:  0.17323570990467266\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.054276070115549e-05 0.00013490976370111873 nan\n",
      "Epoch: 362\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.7007039986788361\n",
      "MAPE:  0.010138176620307734\n",
      "Delta:  0.17322695409364205\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.053841098701106e-05 0.000134904089959198 nan\n",
      "Epoch: 363\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.7004745667536043\n",
      "MAPE:  0.010137126260194081\n",
      "Delta:  0.17321819947864203\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.0534033788962596e-05 0.00013489827842050328 nan\n",
      "Epoch: 364\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.7002451756620514\n",
      "MAPE:  0.01013607599363175\n",
      "Delta:  0.17320944606429672\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.052968478080899e-05 0.00013489258750620792 nan\n",
      "Epoch: 365\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.7000158251909114\n",
      "MAPE:  0.010135025819628727\n",
      "Delta:  0.17320069384558603\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.052532570559709e-05 0.00013488686554774532 nan\n",
      "Epoch: 366\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6997865153848697\n",
      "MAPE:  0.010133975738457826\n",
      "Delta:  0.17319194282411707\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.052098479851885e-05 0.0001348812033847846 nan\n",
      "Epoch: 367\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6995572461341775\n",
      "MAPE:  0.010132925749560456\n",
      "Delta:  0.17318319299660642\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.051660191079943e-05 0.00013487538286849343 nan\n",
      "Epoch: 368\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.699328017699898\n",
      "MAPE:  0.01013187585419216\n",
      "Delta:  0.17317444437018817\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.051227492358645e-05 0.00013486976187293553 nan\n",
      "Epoch: 369\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6990988297348069\n",
      "MAPE:  0.010130826050891615\n",
      "Delta:  0.1731656969350444\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.050788451954613e-05 0.00013486391471018155 nan\n",
      "Epoch: 370\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6988696826151495\n",
      "MAPE:  0.010129776341249706\n",
      "Delta:  0.17315695070202086\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.0503566045967396e-05 0.0001348583467203346 nan\n",
      "Epoch: 371\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6986405758584586\n",
      "MAPE:  0.01012872672317013\n",
      "Delta:  0.17314820565852476\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.0499195389019924e-05 0.0001348525417906865 nan\n",
      "Epoch: 372\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6984115098592154\n",
      "MAPE:  0.010127677198448207\n",
      "Delta:  0.17313946181345596\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.049483090435736e-05 0.00013484680490327694 nan\n",
      "Epoch: 373\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6981824844937\n",
      "MAPE:  0.010126627766578902\n",
      "Delta:  0.17313071916560882\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.049048517824506e-05 0.00013484109419170665 nan\n",
      "Epoch: 374\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6979534997093535\n",
      "MAPE:  0.010125578427379822\n",
      "Delta:  0.17312197771159887\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.048613668956481e-05 0.00013483541432290913 nan\n",
      "Epoch: 375\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6977245554457192\n",
      "MAPE:  0.010124529180426504\n",
      "Delta:  0.17311323745176818\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.048177346467231e-05 0.00013482961996669207 nan\n",
      "Epoch: 376\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6974956518891002\n",
      "MAPE:  0.010123480026839833\n",
      "Delta:  0.1731044983885314\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.047743119745984e-05 0.00013482397418529413 nan\n",
      "Epoch: 377\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6972667887791504\n",
      "MAPE:  0.010122430965233641\n",
      "Delta:  0.17309576051812403\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.047305536720614e-05 0.00013481814332005904 nan\n",
      "Epoch: 378\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6970379664219681\n",
      "MAPE:  0.010121381997129952\n",
      "Delta:  0.17308702384621955\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.0468718154172976e-05 0.00013481248697155834 nan\n",
      "Epoch: 379\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6968091845132296\n",
      "MAPE:  0.010120333121199983\n",
      "Delta:  0.17307828836599692\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.046435920696979e-05 0.00013480673228216666 nan\n",
      "Epoch: 380\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.696580443211759\n",
      "MAPE:  0.010119284338188919\n",
      "Delta:  0.17306955408108188\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.046001387321031e-05 0.0001348010431052593 nan\n",
      "Epoch: 381\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.696351742398302\n",
      "MAPE:  0.010118235647478348\n",
      "Delta:  0.1730608209889819\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.045562833017048e-05 0.0001347951666765823 nan\n",
      "Epoch: 382\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6961230823824434\n",
      "MAPE:  0.010117187050593503\n",
      "Delta:  0.1730520890965196\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.045131386216539e-05 0.00013478960593182876 nan\n",
      "Epoch: 383\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6958944626205572\n",
      "MAPE:  0.010116138545055178\n",
      "Delta:  0.17304335839125806\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.044693982592108e-05 0.00013478377528153285 nan\n",
      "Epoch: 384\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6956658835624063\n",
      "MAPE:  0.010115090132892085\n",
      "Delta:  0.17303462888337004\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.044259974096299e-05 0.00013477809108708438 nan\n",
      "Epoch: 385\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6954373449514983\n",
      "MAPE:  0.010114041813080062\n",
      "Delta:  0.17302590056684394\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.043824857287049e-05 0.00013477237609060833 nan\n",
      "Epoch: 386\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6952088468320063\n",
      "MAPE:  0.010112993585699098\n",
      "Delta:  0.1730171734434616\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.04338862037379e-05 0.0001347666040799611 nan\n",
      "Epoch: 387\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6949803892925126\n",
      "MAPE:  0.010111945451311211\n",
      "Delta:  0.17300844751502487\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.0429538407281704e-05 0.00013476087710895257 nan\n",
      "Epoch: 388\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.694751972248569\n",
      "MAPE:  0.010110897409468049\n",
      "Delta:  0.1729997227788761\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.042519824782765e-05 0.0001347551932668889 nan\n",
      "Epoch: 389\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6945235956190094\n",
      "MAPE:  0.010109849459810404\n",
      "Delta:  0.17299099923355818\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.042084412743009e-05 0.00013474942386670907 nan\n",
      "Epoch: 390\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6942952595407712\n",
      "MAPE:  0.010108801603131755\n",
      "Delta:  0.17298227688135037\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.041648167614099e-05 0.0001347436709854266 nan\n",
      "Epoch: 391\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6940669639777675\n",
      "MAPE:  0.01010775383909214\n",
      "Delta:  0.17297355572355766\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.041213613954376e-05 0.00013473794053364685 nan\n",
      "Epoch: 392\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.693838708883915\n",
      "MAPE:  0.010106706167648041\n",
      "Delta:  0.172964835757118\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.040777891007764e-05 0.00013473219604331899 nan\n",
      "Epoch: 393\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.693610494274924\n",
      "MAPE:  0.010105658588793937\n",
      "Delta:  0.17295611698391794\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.0403434161627736e-05 0.0001347264589064423 nan\n",
      "Epoch: 394\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6933823201302634\n",
      "MAPE:  0.01010461110259807\n",
      "Delta:  0.1729473994016627\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.039909575710322e-05 0.0001347207803638062 nan\n",
      "Epoch: 395\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6931541863426411\n",
      "MAPE:  0.010103563708433195\n",
      "Delta:  0.1729386830091193\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.039474215973172e-05 0.00013471502018191917 nan\n",
      "Epoch: 396\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.692926093042257\n",
      "MAPE:  0.010102516406986317\n",
      "Delta:  0.17292996780877962\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.0390382259846156e-05 0.00013470923236558185 nan\n",
      "Epoch: 397\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6926980402678116\n",
      "MAPE:  0.01010146919860496\n",
      "Delta:  0.17292125380159754\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.0386036878902196e-05 0.00013470352683842002 nan\n",
      "Epoch: 398\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6924700278719151\n",
      "MAPE:  0.010100422082358392\n",
      "Delta:  0.17291254098492637\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.038169360227496e-05 0.00013469779768993106 nan\n",
      "Epoch: 399\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6922420558865046\n",
      "MAPE:  0.010099375058646465\n",
      "Delta:  0.17290382935826645\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.0377346513807986e-05 0.00013469206195226846 nan\n",
      "Epoch: 400\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.692014124314675\n",
      "MAPE:  0.01009832812740658\n",
      "Delta:  0.17289511892214132\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.037300301746761e-05 0.0001346863479981808 nan\n",
      "Epoch: 401\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6917862331115097\n",
      "MAPE:  0.010097281288463416\n",
      "Delta:  0.17288640967579416\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.036862687868293e-05 0.0001346804838443516 nan\n",
      "Epoch: 402\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6915583825230731\n",
      "MAPE:  0.010096234542982196\n",
      "Delta:  0.17287770162473282\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.0364307921824114e-05 0.00013467487427643032 nan\n",
      "Epoch: 403\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6913305721105756\n",
      "MAPE:  0.010095187888970653\n",
      "Delta:  0.17286899475893536\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.035994714497338e-05 0.00013466906727110928 nan\n",
      "Epoch: 404\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6911028021999823\n",
      "MAPE:  0.01009414132796131\n",
      "Delta:  0.1728602890854963\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.035561384747478e-05 0.00013466338612655449 nan\n",
      "Epoch: 405\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6908750725703499\n",
      "MAPE:  0.01009309485901881\n",
      "Delta:  0.17285158459952954\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.035125608543467e-05 0.0001346575993294019 nan\n",
      "Epoch: 406\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6906473833923117\n",
      "MAPE:  0.010092048482782763\n",
      "Delta:  0.1728428813051286\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.0346905410281195e-05 0.00013465183486371934 nan\n",
      "Epoch: 407\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6904197346200303\n",
      "MAPE:  0.010091002199256651\n",
      "Delta:  0.1728341792009327\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.034257555447397e-05 0.0001346461744020644 nan\n",
      "Epoch: 408\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.69019212606963\n",
      "MAPE:  0.010089956007462484\n",
      "Delta:  0.17282547828320788\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.0338213161249534e-05 0.00013464034911514489 nan\n",
      "Epoch: 409\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6899645580117042\n",
      "MAPE:  0.010088909908857484\n",
      "Delta:  0.17281677855744237\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.033387197816985e-05 0.00013463462544394122 nan\n",
      "Epoch: 410\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.689737030266423\n",
      "MAPE:  0.010087863902433384\n",
      "Delta:  0.17280808001983478\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.0329524460268615e-05 0.0001346288767568593 nan\n",
      "Epoch: 411\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6895095428680236\n",
      "MAPE:  0.010086817988446201\n",
      "Delta:  0.17279938267134448\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.0325178376775526e-05 0.0001346231310188628 nan\n",
      "Epoch: 412\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6892820958034767\n",
      "MAPE:  0.010085772166942987\n",
      "Delta:  0.17279068651158813\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.0320839467321576e-05 0.00013461739940590078 nan\n",
      "Epoch: 413\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6890546890408764\n",
      "MAPE:  0.010084726437711473\n",
      "Delta:  0.17278199153919074\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.0316479559886496e-05 0.00013461161293115698 nan\n",
      "Epoch: 414\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6888273226648558\n",
      "MAPE:  0.010083680801184486\n",
      "Delta:  0.17277329775764516\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.0312155875031905e-05 0.0001346059247756548 nan\n",
      "Epoch: 415\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.688599996501302\n",
      "MAPE:  0.010082635256606026\n",
      "Delta:  0.17276460516055733\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.03077989174594e-05 0.00013460013288524308 nan\n",
      "Epoch: 416\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.688372710717383\n",
      "MAPE:  0.010081589804793524\n",
      "Delta:  0.17275591375354085\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.030345725953733e-05 0.00013459440471497164 nan\n",
      "Epoch: 417\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.688145465197447\n",
      "MAPE:  0.010080544445147709\n",
      "Delta:  0.17274722353381702\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.029911472720361e-05 0.00013458864506032953 nan\n",
      "Epoch: 418\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6879182599866214\n",
      "MAPE:  0.01007949917801455\n",
      "Delta:  0.1727385345014017\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.029476116269471e-05 0.00013458286418099874 nan\n",
      "Epoch: 419\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6876910951126889\n",
      "MAPE:  0.010078454003430189\n",
      "Delta:  0.17272984665806534\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.029041896709163e-05 0.00013457712611408823 nan\n",
      "Epoch: 420\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6874639704953402\n",
      "MAPE:  0.010077408921137525\n",
      "Delta:  0.17272116000170878\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.028608579604743e-05 0.00013457141392625438 nan\n",
      "Epoch: 421\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6872368860828812\n",
      "MAPE:  0.010076363930892703\n",
      "Delta:  0.17271247453063815\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.0281750296310435e-05 0.00013456568462111296 nan\n",
      "Epoch: 422\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6870098418961874\n",
      "MAPE:  0.010075319032798272\n",
      "Delta:  0.17270379024512073\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.027741375884798e-05 0.00013455996259337244 nan\n",
      "Epoch: 423\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6867828379149672\n",
      "MAPE:  0.010074274226862426\n",
      "Delta:  0.17269510714520087\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.027302798321642e-05 0.00013455403519413434 nan\n",
      "Epoch: 424\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6865558744776294\n",
      "MAPE:  0.010073229514547841\n",
      "Delta:  0.1726864252392468\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.026872142455119e-05 0.00013454842831894798 nan\n",
      "Epoch: 425\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6863289510354464\n",
      "MAPE:  0.010072184893460076\n",
      "Delta:  0.17267774451344264\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.0264373444464105e-05 0.00013454264046708353 nan\n",
      "Epoch: 426\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.686102067885678\n",
      "MAPE:  0.01007114036488086\n",
      "Delta:  0.17266906497480686\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.0260020125203475e-05 0.0001345368503971045 nan\n",
      "Epoch: 427\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6858752250240165\n",
      "MAPE:  0.010070095928904158\n",
      "Delta:  0.17266038662412622\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.025569576133648e-05 0.0001345311713810693 nan\n",
      "Epoch: 428\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6856484222551917\n",
      "MAPE:  0.01006905158470814\n",
      "Delta:  0.172651709456266\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.0251348980179245e-05 0.00013452537574598633 nan\n",
      "Epoch: 429\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6854216597678122\n",
      "MAPE:  0.010068007333085077\n",
      "Delta:  0.1726430334749621\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.024699826938761e-05 0.00013451959311250317 nan\n",
      "Epoch: 430\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6851949375319173\n",
      "MAPE:  0.010066963173890105\n",
      "Delta:  0.17263435868075785\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.024267564568419e-05 0.00013451389758623034 nan\n",
      "Epoch: 431\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6849682553926772\n",
      "MAPE:  0.010065919106542998\n",
      "Delta:  0.17262568506866938\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.023832317296861e-05 0.00013450810429560534 nan\n",
      "Epoch: 432\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.684741613506846\n",
      "MAPE:  0.010064875131778877\n",
      "Delta:  0.17261701264371493\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.023397752479397e-05 0.00013450231944722724 nan\n",
      "Epoch: 433\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6845150118521603\n",
      "MAPE:  0.010063831249356128\n",
      "Delta:  0.17260834140458137\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.022963777823186e-05 0.00013449657503095125 nan\n",
      "Epoch: 434\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.684288450352478\n",
      "MAPE:  0.010062787459098851\n",
      "Delta:  0.1725996713501151\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.022531131504415e-05 0.00013449085569050556 nan\n",
      "Epoch: 435\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6840619289575605\n",
      "MAPE:  0.010061743760881516\n",
      "Delta:  0.1725910024778887\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.022097550444471e-05 0.00013448510878755204 nan\n",
      "Epoch: 436\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6838354477058397\n",
      "MAPE:  0.010060700154752716\n",
      "Delta:  0.17258233478938095\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.021661552340184e-05 0.00013447926816345657 nan\n",
      "Epoch: 437\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6836090067471243\n",
      "MAPE:  0.010059656641484189\n",
      "Delta:  0.17257366828862872\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.021229580437492e-05 0.000134473591973161 nan\n",
      "Epoch: 438\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.683382605796509\n",
      "MAPE:  0.010058613219746958\n",
      "Delta:  0.17256500296854857\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.020794537302642e-05 0.00013446778174852625 nan\n",
      "Epoch: 439\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6831562450716733\n",
      "MAPE:  0.010057569890568366\n",
      "Delta:  0.1725563388343062\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.0203619845534675e-05 0.00013446207106249108 nan\n",
      "Epoch: 440\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.682929924397039\n",
      "MAPE:  0.010056526653248424\n",
      "Delta:  0.17254767588146946\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.01992742922841e-05 0.0001344562825299489 nan\n",
      "Epoch: 441\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6827036438956462\n",
      "MAPE:  0.010055483508311128\n",
      "Delta:  0.17253901411335937\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.019493047453416e-05 0.0001344504942786262 nan\n",
      "Epoch: 442\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.682477403559\n",
      "MAPE:  0.01005444045578072\n",
      "Delta:  0.17253035352954182\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.019059217603594e-05 0.00013444471789914036 nan\n",
      "Epoch: 443\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6822512033591068\n",
      "MAPE:  0.010053397495500022\n",
      "Delta:  0.17252169412892981\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.018626730823872e-05 0.00013443902659115992 nan\n",
      "Epoch: 444\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6820250431448454\n",
      "MAPE:  0.010052354626799515\n",
      "Delta:  0.1725130359090718\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.01819322857866e-05 0.00013443326183770754 nan\n",
      "Epoch: 445\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6817989230318027\n",
      "MAPE:  0.010051311850318973\n",
      "Delta:  0.1725043788715854\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.0177569858589344e-05 0.0001344274094556841 nan\n",
      "Epoch: 446\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6815728431593542\n",
      "MAPE:  0.01005026916658217\n",
      "Delta:  0.17249572302106364\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.0173258074215354e-05 0.00013442171939126446 nan\n",
      "Epoch: 447\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.681346803246495\n",
      "MAPE:  0.010049226574508836\n",
      "Delta:  0.1724870683486358\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.016891280151814e-05 0.0001344159218142904 nan\n",
      "Epoch: 448\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6811208034660472\n",
      "MAPE:  0.010048184074780074\n",
      "Delta:  0.17247841485994445\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.016457353324011e-05 0.00013441015969228864 nan\n",
      "Epoch: 449\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6808948437503912\n",
      "MAPE:  0.010047141667142795\n",
      "Delta:  0.1724697625538193\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.0160233458607095e-05 0.00013440436636935615 nan\n",
      "Epoch: 450\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6806689241439834\n",
      "MAPE:  0.010046099351817718\n",
      "Delta:  0.17246111143026505\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.015591240786765e-05 0.00013439865811382123 nan\n",
      "Epoch: 451\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.680443044495845\n",
      "MAPE:  0.010045057128165414\n",
      "Delta:  0.17245246148586638\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.0151550882837626e-05 0.00013439279662230685 nan\n",
      "Epoch: 452\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6802172050555306\n",
      "MAPE:  0.010044014997287944\n",
      "Delta:  0.1724438127274693\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.014724484675437e-05 0.0001343871325835133 nan\n",
      "Epoch: 453\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.679991405483226\n",
      "MAPE:  0.010042972957717888\n",
      "Delta:  0.17243516514537016\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.014290203697591e-05 0.00013438134026788617 nan\n",
      "Epoch: 454\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6797656459865185\n",
      "MAPE:  0.010041931010459066\n",
      "Delta:  0.17242651874577652\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.0138555816703345e-05 0.0001343755083189624 nan\n",
      "Epoch: 455\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6795399266239823\n",
      "MAPE:  0.010040889155783841\n",
      "Delta:  0.17241787352914212\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.013424595501359e-05 0.00013436985158510328 nan\n",
      "Epoch: 456\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6793142470933107\n",
      "MAPE:  0.010039847392188134\n",
      "Delta:  0.17240922948906356\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.012987966546145e-05 0.0001343639594931778 nan\n",
      "Epoch: 457\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6790886077818379\n",
      "MAPE:  0.010038805721672631\n",
      "Delta:  0.17240058663513608\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.012557498562664e-05 0.00013435829521568632 nan\n",
      "Epoch: 458\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6788630082989802\n",
      "MAPE:  0.010037764142346872\n",
      "Delta:  0.17239194495660315\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.0121221711330044e-05 0.0001343524429193721 nan\n",
      "Epoch: 459\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6786374489524882\n",
      "MAPE:  0.01003672265571802\n",
      "Delta:  0.17238330446170871\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.011689779543804e-05 0.0001343467161412093 nan\n",
      "Epoch: 460\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.67841192952363\n",
      "MAPE:  0.010035681260794956\n",
      "Delta:  0.17237466514525737\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.011256611642256e-05 0.00013434094105513328 nan\n",
      "Epoch: 461\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6781864500855397\n",
      "MAPE:  0.010034639957819244\n",
      "Delta:  0.1723660270084535\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.01082261704644e-05 0.000134335140783981 nan\n",
      "Epoch: 462\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6779610106725056\n",
      "MAPE:  0.010033598747240724\n",
      "Delta:  0.17235739005258804\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.010390009119181e-05 0.00013432940433222296 nan\n",
      "Epoch: 463\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6777356111694492\n",
      "MAPE:  0.01003255762822428\n",
      "Delta:  0.17234875427513685\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.0099560675587185e-05 0.00013432359755150003 nan\n",
      "Epoch: 464\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6775102516864167\n",
      "MAPE:  0.010031516601564755\n",
      "Delta:  0.17234011967826468\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.009523976418073e-05 0.000134317856744115 nan\n",
      "Epoch: 465\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6772849321047438\n",
      "MAPE:  0.010030475666583577\n",
      "Delta:  0.17233148625864841\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.0090897893650954e-05 0.0001343120651917662 nan\n",
      "Epoch: 466\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.677059652501598\n",
      "MAPE:  0.010029434823721758\n",
      "Delta:  0.17232285401976638\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.008657268434913e-05 0.00013430629725541543 nan\n",
      "Epoch: 467\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6768344128293942\n",
      "MAPE:  0.0100283940728373\n",
      "Delta:  0.17231422295861334\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.00822374751575e-05 0.00013430051290308498 nan\n",
      "Epoch: 468\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6766092131076975\n",
      "MAPE:  0.010027353413928738\n",
      "Delta:  0.17230559307677878\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.007790523137157e-05 0.00013429471493364709 nan\n",
      "Epoch: 469\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.676384053351368\n",
      "MAPE:  0.010026312847139507\n",
      "Delta:  0.17229696437361786\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.0073549871409995e-05 0.00013428884866384383 nan\n",
      "Epoch: 470\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6761589336669251\n",
      "MAPE:  0.010025272373057097\n",
      "Delta:  0.1722883368529796\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.006924999917395e-05 0.0001342832132104066 nan\n",
      "Epoch: 471\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.675933853659461\n",
      "MAPE:  0.010024231989699803\n",
      "Delta:  0.17227971050516977\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.006491487058451e-05 0.0001342773878603154 nan\n",
      "Epoch: 472\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.675708813639365\n",
      "MAPE:  0.010023191698758463\n",
      "Delta:  0.1722710853361294\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.0060588310252285e-05 0.00013427164173485107 nan\n",
      "Epoch: 473\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.675483813465888\n",
      "MAPE:  0.010022151499483779\n",
      "Delta:  0.1722624613442486\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.005625358678323e-05 0.00013426583193498765 nan\n",
      "Epoch: 474\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6752588532377795\n",
      "MAPE:  0.01002111139236566\n",
      "Delta:  0.1722538385308001\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.005193108775785e-05 0.00013426008166317338 nan\n",
      "Epoch: 475\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6750339328473367\n",
      "MAPE:  0.010020071376860588\n",
      "Delta:  0.17224521689354433\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.004758748783367e-05 0.0001342542634034105 nan\n",
      "Epoch: 476\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6748090524005066\n",
      "MAPE:  0.010019031453543697\n",
      "Delta:  0.1722365964359825\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.0043274827160644e-05 0.0001342485228494894 nan\n",
      "Epoch: 477\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.674584211759167\n",
      "MAPE:  0.01001799162189974\n",
      "Delta:  0.17222797715265176\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.003893940769277e-05 0.00013424273592688163 nan\n",
      "Epoch: 478\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6743594109930404\n",
      "MAPE:  0.010016951882156904\n",
      "Delta:  0.1722193590473387\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.003461321384517e-05 0.00013423695025616134 nan\n",
      "Epoch: 479\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.674134650092076\n",
      "MAPE:  0.010015912234309076\n",
      "Delta:  0.17221074211832083\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.0030281759316786e-05 0.00013423116295763204 nan\n",
      "Epoch: 480\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6739099290510464\n",
      "MAPE:  0.010014872678397083\n",
      "Delta:  0.17220212636637067\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.002595307046498e-05 0.00013422537308449556 nan\n",
      "Epoch: 481\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6736852478663096\n",
      "MAPE:  0.010013833214375874\n",
      "Delta:  0.1721935117908784\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.0021632629571045e-05 0.00013421962371629181 nan\n",
      "Epoch: 482\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6734606064621216\n",
      "MAPE:  0.010012793841962865\n",
      "Delta:  0.17218489839029041\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.00172965750556e-05 0.00013421379320111004 nan\n",
      "Epoch: 483\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6732360049663555\n",
      "MAPE:  0.010011754561785543\n",
      "Delta:  0.17217628616716188\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.0012955553735416e-05 0.0001342079489422554 nan\n",
      "Epoch: 484\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6730114433940326\n",
      "MAPE:  0.010010715373849831\n",
      "Delta:  0.1721676751222144\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.000865749693606e-05 0.00013420230994343196 nan\n",
      "Epoch: 485\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6727869213937674\n",
      "MAPE:  0.010009676276614869\n",
      "Delta:  0.17215906524791716\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "5.000432387769482e-05 0.00013419647067103302 nan\n",
      "Epoch: 486\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6725624392927316\n",
      "MAPE:  0.01000863727167496\n",
      "Delta:  0.17215045655026004\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.999998438159903e-05 0.00013419064566022598 nan\n",
      "Epoch: 487\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.672337997059096\n",
      "MAPE:  0.010007598358796436\n",
      "Delta:  0.17214184903012122\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.9995659480495114e-05 0.00013418486407312802 nan\n",
      "Epoch: 488\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6721135946122763\n",
      "MAPE:  0.010006559537733288\n",
      "Delta:  0.17213324268485478\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.9991342277344586e-05 0.00013417910752955287 nan\n",
      "Epoch: 489\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.671889231902463\n",
      "MAPE:  0.010005520808194071\n",
      "Delta:  0.17212463751300242\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.9987008981511316e-05 0.00013417329254505894 nan\n",
      "Epoch: 490\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.671664909019448\n",
      "MAPE:  0.010004482170674282\n",
      "Delta:  0.17211603351720112\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.998268750688872e-05 0.00013416751467798527 nan\n",
      "Epoch: 491\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6714406258932304\n",
      "MAPE:  0.010003443624873144\n",
      "Delta:  0.1721074306952829\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.997836664955013e-05 0.00013416175020664056 nan\n",
      "Epoch: 492\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.671216382493494\n",
      "MAPE:  0.010002405170584863\n",
      "Delta:  0.1720988290470085\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.997402141604379e-05 0.00013415588617726737 nan\n",
      "Epoch: 493\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6709921789787068\n",
      "MAPE:  0.010001366808695301\n",
      "Delta:  0.17209022857644002\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.996972782034259e-05 0.00013415019936602324 nan\n",
      "Epoch: 494\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6707680150447577\n",
      "MAPE:  0.010000328537787944\n",
      "Delta:  0.1720816292745575\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.996537098833631e-05 0.00013414429231550784 nan\n",
      "Epoch: 495\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6705438910517563\n",
      "MAPE:  0.009999290359501737\n",
      "Delta:  0.17207303115211053\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.996106718502258e-05 0.0001341385945768936 nan\n",
      "Epoch: 496\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6703198066420315\n",
      "MAPE:  0.00999825227223489\n",
      "Delta:  0.1720644341998404\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.9956736066114615e-05 0.00013413276349982794 nan\n",
      "Epoch: 497\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.670095762030438\n",
      "MAPE:  0.009997214277032433\n",
      "Delta:  0.17205583842231476\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.995242468897043e-05 0.00013412701847681507 nan\n",
      "Epoch: 498\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.669871757065306\n",
      "MAPE:  0.009996176373160276\n",
      "Delta:  0.17204724381600367\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.994808409641838e-05 0.00013412115725797147 nan\n",
      "Epoch: 499\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.669647791932776\n",
      "MAPE:  0.00999513856159962\n",
      "Delta:  0.172038650385801\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.994378222555884e-05 0.00013411544722685687 nan\n",
      "Epoch: 500\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6694238663724494\n",
      "MAPE:  0.009994100841048733\n",
      "Delta:  0.17203005812491173\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.993944379871884e-05 0.00013410959996895677 nan\n",
      "Epoch: 501\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6691999806055517\n",
      "MAPE:  0.009993063212612707\n",
      "Delta:  0.1720214670394923\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.993512450512938e-05 0.00013410382312872837 nan\n",
      "Epoch: 502\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.668976134506586\n",
      "MAPE:  0.009992025675747165\n",
      "Delta:  0.17201287712611812\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.993078653026117e-05 0.0001340979544778298 nan\n",
      "Epoch: 503\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6687523282208767\n",
      "MAPE:  0.009990988231151377\n",
      "Delta:  0.17200428838786988\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.992647498525127e-05 0.0001340922027562863 nan\n",
      "Epoch: 504\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6685285615453307\n",
      "MAPE:  0.009989950877891098\n",
      "Delta:  0.17199570082006832\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.992216247523551e-05 0.0001340864540578801 nan\n",
      "Epoch: 505\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6683048344670188\n",
      "MAPE:  0.009988913615930314\n",
      "Delta:  0.17198711442274695\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.991783037755493e-05 0.0001340806067914313 nan\n",
      "Epoch: 506\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6680811471425003\n",
      "MAPE:  0.009987876446102698\n",
      "Delta:  0.17197852919914208\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.991351359928675e-05 0.00013407484475702613 nan\n",
      "Epoch: 507\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.667857499421655\n",
      "MAPE:  0.009986839367527266\n",
      "Delta:  0.17196994514648611\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.990919422265261e-05 0.00013406903465673636 nan\n",
      "Epoch: 508\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6676338913767628\n",
      "MAPE:  0.009985802380718639\n",
      "Delta:  0.17196136226509334\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.990486601919031e-05 0.00013406322729303533 nan\n",
      "Epoch: 509\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6674103229953414\n",
      "MAPE:  0.009984765485683706\n",
      "Delta:  0.17195278055634902\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.9900560642912595e-05 0.000134057474213245 nan\n",
      "Epoch: 510\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6671867941789635\n",
      "MAPE:  0.009983728681917228\n",
      "Delta:  0.17194420001619515\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.9896227000800764e-05 0.00013405162662072367 nan\n",
      "Epoch: 511\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6669633050773234\n",
      "MAPE:  0.009982691970123176\n",
      "Delta:  0.1719356206493597\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.9891901258591886e-05 0.0001340458082050855 nan\n",
      "Epoch: 512\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.666739855633846\n",
      "MAPE:  0.00998165535014256\n",
      "Delta:  0.17192704245435142\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.988759434365608e-05 0.00013404006490813636 nan\n",
      "Epoch: 513\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6665164457154118\n",
      "MAPE:  0.009980618821236895\n",
      "Delta:  0.17191846542780076\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.988325970523011e-05 0.00013403420225654994 nan\n",
      "Epoch: 514\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.666293075513063\n",
      "MAPE:  0.009979582384466085\n",
      "Delta:  0.1719098895743417\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.987896704689021e-05 0.0001340284886519605 nan\n",
      "Epoch: 515\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6660697447705006\n",
      "MAPE:  0.0099785460386357\n",
      "Delta:  0.17190131488662458\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.987462712424673e-05 0.0001340226280419632 nan\n",
      "Epoch: 516\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6658464537248052\n",
      "MAPE:  0.009977509784804214\n",
      "Delta:  0.17189274137264243\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.9870297385790074e-05 0.00013401677034952098 nan\n",
      "Epoch: 517\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6656232023631787\n",
      "MAPE:  0.009976473622914196\n",
      "Delta:  0.17188416903051174\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.986600233736205e-05 0.00013401107052657402 nan\n",
      "Epoch: 518\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6653999904147363\n",
      "MAPE:  0.009975437551894987\n",
      "Delta:  0.17187559785413709\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.986167265796926e-05 0.00013400520712514297 nan\n",
      "Epoch: 519\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6651768181440745\n",
      "MAPE:  0.009974401572899583\n",
      "Delta:  0.171867027849339\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.985735768825439e-05 0.0001339994382434373 nan\n",
      "Epoch: 520\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.664953685385867\n",
      "MAPE:  0.009973365685077569\n",
      "Delta:  0.1718584590134567\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.98530253769669e-05 0.00013399355529375434 nan\n",
      "Epoch: 521\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6647305923221627\n",
      "MAPE:  0.009972329889535515\n",
      "Delta:  0.17184989134933826\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.984872722268996e-05 0.00013398783268769865 nan\n",
      "Epoch: 522\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6645075386780885\n",
      "MAPE:  0.009971294184776318\n",
      "Delta:  0.17184132485098114\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.9844406252885776e-05 0.0001339820207266751 nan\n",
      "Epoch: 523\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6642845245945417\n",
      "MAPE:  0.009970258571660822\n",
      "Delta:  0.17183275952217422\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.984008581832011e-05 0.00013397620454891346 nan\n",
      "Epoch: 524\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.664061550070647\n",
      "MAPE:  0.009969223050124725\n",
      "Delta:  0.17182419536269322\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.983576750827723e-05 0.0001339703887125454 nan\n",
      "Epoch: 525\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6638386150979425\n",
      "MAPE:  0.009968187620144718\n",
      "Delta:  0.17181563237204084\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.983144588432964e-05 0.00013396455780856353 nan\n",
      "Epoch: 526\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.663615719693606\n",
      "MAPE:  0.009967152281886257\n",
      "Delta:  0.17180707055065422\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.982713035439623e-05 0.00013395875535349155 nan\n",
      "Epoch: 527\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6633928638024096\n",
      "MAPE:  0.009966117035048327\n",
      "Delta:  0.1717985098973541\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.982281491738849e-05 0.00013395295878315672 nan\n",
      "Epoch: 528\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6631700474066844\n",
      "MAPE:  0.009965081879632765\n",
      "Delta:  0.1717899504119924\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.9818512030563866e-05 0.00013394718589121446 nan\n",
      "Epoch: 529\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6629472704591757\n",
      "MAPE:  0.009964046815424274\n",
      "Delta:  0.17178139209228105\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.9814189005847886e-05 0.00013394136240574284 nan\n",
      "Epoch: 530\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6627245330361615\n",
      "MAPE:  0.00996301184272889\n",
      "Delta:  0.1717728349415477\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.980986790481534e-05 0.0001339355213229032 nan\n",
      "Epoch: 531\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6625018351590128\n",
      "MAPE:  0.009961976961821323\n",
      "Delta:  0.1717642789593296\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.9805554573234545e-05 0.0001339297216110813 nan\n",
      "Epoch: 532\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.662279176751052\n",
      "MAPE:  0.009960942172329585\n",
      "Delta:  0.17175572414416018\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.980124694609067e-05 0.00013392393468925068 nan\n",
      "Epoch: 533\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6620565577831496\n",
      "MAPE:  0.009959907473924286\n",
      "Delta:  0.17174717049492766\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.9796927957035386e-05 0.00013391811257523756 nan\n",
      "Epoch: 534\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6618339783059382\n",
      "MAPE:  0.009958872867159501\n",
      "Delta:  0.1717386180134517\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.9792619151056705e-05 0.0001339123253982777 nan\n",
      "Epoch: 535\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6616114382534772\n",
      "MAPE:  0.009957838351637481\n",
      "Delta:  0.17173006669785143\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.9788291736962975e-05 0.00013390644457478285 nan\n",
      "Epoch: 536\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.661388937773516\n",
      "MAPE:  0.009956803928029454\n",
      "Delta:  0.17172151655119067\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.978398935995276e-05 0.00013390070153385114 nan\n",
      "Epoch: 537\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6611664766292276\n",
      "MAPE:  0.00995576959528666\n",
      "Delta:  0.1717129675690378\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.9779668610749894e-05 0.0001338948341863544 nan\n",
      "Epoch: 538\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6609440550192833\n",
      "MAPE:  0.009954735354419023\n",
      "Delta:  0.17170441975441605\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.977536203509825e-05 0.00013388905766309467 nan\n",
      "Epoch: 539\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6607216727849257\n",
      "MAPE:  0.009953701204592564\n",
      "Delta:  0.17169587310475976\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.977104746617389e-05 0.00013388324673579977 nan\n",
      "Epoch: 540\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6604993299754487\n",
      "MAPE:  0.009952667146139958\n",
      "Delta:  0.1716873276213097\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.9766729129596676e-05 0.00013387740249348745 nan\n",
      "Epoch: 541\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6602770266383093\n",
      "MAPE:  0.009951633179310498\n",
      "Delta:  0.17167878330458097\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.9762416119425446e-05 0.00013387157215971612 nan\n",
      "Epoch: 542\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6600547627425326\n",
      "MAPE:  0.009950599304017484\n",
      "Delta:  0.1716702401535273\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.9758114314402135e-05 0.0001338658160707773 nan\n",
      "Epoch: 543\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6598325381569958\n",
      "MAPE:  0.0099495655195252\n",
      "Delta:  0.17166169816609336\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.975380089833337e-05 0.00013385998447856817 nan\n",
      "Epoch: 544\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6596103529992012\n",
      "MAPE:  0.009948531826589672\n",
      "Delta:  0.17165315734414094\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.974948150748837e-05 0.00013385415762501296 nan\n",
      "Epoch: 545\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6593882072534147\n",
      "MAPE:  0.009947498224976698\n",
      "Delta:  0.17164461768856396\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.974516027711484e-05 0.00013384828396201254 nan\n",
      "Epoch: 546\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.659166100989447\n",
      "MAPE:  0.009946464715247898\n",
      "Delta:  0.17163607919954632\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.974086784770293e-05 0.00013384254354498193 nan\n",
      "Epoch: 547\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.658944033978327\n",
      "MAPE:  0.0099454312961595\n",
      "Delta:  0.17162754187201296\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.973654168138886e-05 0.00013383665171440295 nan\n",
      "Epoch: 548\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6587220064634378\n",
      "MAPE:  0.009944397969040106\n",
      "Delta:  0.17161900571162297\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.973225046878138e-05 0.00013383093414243152 nan\n",
      "Epoch: 549\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.65850001814783\n",
      "MAPE:  0.009943364732413943\n",
      "Delta:  0.17161047071224572\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.972792077617694e-05 0.00013382502283776354 nan\n",
      "Epoch: 550\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.658278069345025\n",
      "MAPE:  0.009942331587791108\n",
      "Delta:  0.17160193688035377\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.972361445454432e-05 0.00013381922086397324 nan\n",
      "Epoch: 551\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6580561598658095\n",
      "MAPE:  0.009941298534302886\n",
      "Delta:  0.1715934042118047\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.9719304252571206e-05 0.0001338134025008486 nan\n",
      "Epoch: 552\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6578342897295202\n",
      "MAPE:  0.009940265572152508\n",
      "Delta:  0.17158487270713293\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.971500472017443e-05 0.00013380762313397465 nan\n",
      "Epoch: 553\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6576124588636614\n",
      "MAPE:  0.009939232700926693\n",
      "Delta:  0.17157634236437638\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.971068151526925e-05 0.00013380173926946792 nan\n",
      "Epoch: 554\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6573906674336307\n",
      "MAPE:  0.009938199921445444\n",
      "Delta:  0.17156781318746556\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.97063911873985e-05 0.00013379599796603525 nan\n",
      "Epoch: 555\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.657168915195262\n",
      "MAPE:  0.009937167232651261\n",
      "Delta:  0.1715592851706281\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.970206850163361e-05 0.00013379012041891958 nan\n",
      "Epoch: 556\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6569472023665435\n",
      "MAPE:  0.009936134635494136\n",
      "Delta:  0.17155075831928446\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.9697753772615094e-05 0.00013378428044552582 nan\n",
      "Epoch: 557\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6567255288773386\n",
      "MAPE:  0.009935102129646463\n",
      "Delta:  0.171542232631938\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.969344456540181e-05 0.00013377844275319628 nan\n",
      "Epoch: 558\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6565038947160158\n",
      "MAPE:  0.009934069715303103\n",
      "Delta:  0.17153370810751006\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.968913428915478e-05 0.000133772612499361 nan\n",
      "Epoch: 559\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6562822998624043\n",
      "MAPE:  0.009933037392114659\n",
      "Delta:  0.1715251847460528\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.968484334688661e-05 0.00013376685066501803 nan\n",
      "Epoch: 560\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6560607441953394\n",
      "MAPE:  0.0099320051597232\n",
      "Delta:  0.17151666254411865\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.968052141640644e-05 0.00013376098256523417 nan\n",
      "Epoch: 561\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.655839227883008\n",
      "MAPE:  0.009930973018868817\n",
      "Delta:  0.17150814150689186\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.96762304862397e-05 0.00013375520553027265 nan\n",
      "Epoch: 562\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6556177507667575\n",
      "MAPE:  0.009929940968889876\n",
      "Delta:  0.17149962162892407\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.967190305837921e-05 0.0001337493093669373 nan\n",
      "Epoch: 563\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6553963130360168\n",
      "MAPE:  0.009928909010565663\n",
      "Delta:  0.17149110291634398\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.9667603688297035e-05 0.00013374350875872132 nan\n",
      "Epoch: 564\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.655174914524725\n",
      "MAPE:  0.009927877143274883\n",
      "Delta:  0.17148258536420827\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.9663312109538005e-05 0.00013373775484093464 nan\n",
      "Epoch: 565\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6549535551477874\n",
      "MAPE:  0.009926845366598705\n",
      "Delta:  0.17147406897105\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.9658987811396216e-05 0.00013373182673481754 nan\n",
      "Epoch: 566\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6547322351856963\n",
      "MAPE:  0.009925813681855526\n",
      "Delta:  0.17146555374234898\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.9654682313771126e-05 0.00013372602458538996 nan\n",
      "Epoch: 567\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6545109544221317\n",
      "MAPE:  0.009924782088075077\n",
      "Delta:  0.17145703967475015\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.965038272930489e-05 0.000133720214817723 nan\n",
      "Epoch: 568\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.654289712861888\n",
      "MAPE:  0.009923750585356543\n",
      "Delta:  0.17144852676710867\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.9646064219754926e-05 0.0001337143209534375 nan\n",
      "Epoch: 569\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6540685106362725\n",
      "MAPE:  0.009922719174247648\n",
      "Delta:  0.17144001502253842\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.964176645472218e-05 0.0001337085387569381 nan\n",
      "Epoch: 570\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6538473475527113\n",
      "MAPE:  0.00992168785388239\n",
      "Delta:  0.17143150443735167\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.963745421160404e-05 0.00013370267677359493 nan\n",
      "Epoch: 571\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6536262237353687\n",
      "MAPE:  0.009920656624940261\n",
      "Delta:  0.17142299501389974\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.9633173750063264e-05 0.0001336969392984333 nan\n",
      "Epoch: 572\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6534051389705118\n",
      "MAPE:  0.009919625486396744\n",
      "Delta:  0.17141448674660345\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.962886086090634e-05 0.00013369108120109274 nan\n",
      "Epoch: 573\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6531840934498192\n",
      "MAPE:  0.00991859443919605\n",
      "Delta:  0.17140597964089116\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.9624531977210395e-05 0.0001336851395505878 nan\n",
      "Epoch: 574\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6529630873035837\n",
      "MAPE:  0.009917563483914607\n",
      "Delta:  0.1713974736993734\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.962024939547671e-05 0.00013367939481978564 nan\n",
      "Epoch: 575\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6527421201984134\n",
      "MAPE:  0.009916532619094488\n",
      "Delta:  0.17138896891398267\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.9615950219461524e-05 0.00013367358766303017 nan\n",
      "Epoch: 576\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6525211922297247\n",
      "MAPE:  0.00991550184516396\n",
      "Delta:  0.17138046528743286\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.961162689065546e-05 0.00013366767473477204 nan\n",
      "Epoch: 577\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6523003035645094\n",
      "MAPE:  0.009914471162890409\n",
      "Delta:  0.17137196282373268\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.9607325560918625e-05 0.00013366184378482693 nan\n",
      "Epoch: 578\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6520794540594488\n",
      "MAPE:  0.009913440571674922\n",
      "Delta:  0.17136346151898085\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.960303015344447e-05 0.0001336560492440908 nan\n",
      "Epoch: 579\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6518586436465819\n",
      "MAPE:  0.009912410071261058\n",
      "Delta:  0.17135496137203193\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.959872305809743e-05 0.00013365017911848298 nan\n",
      "Epoch: 580\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.65163787244298\n",
      "MAPE:  0.009911379662171075\n",
      "Delta:  0.1713464623847582\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.959441798968456e-05 0.00013364434369611544 nan\n",
      "Epoch: 581\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6514171403834936\n",
      "MAPE:  0.009910349344120488\n",
      "Delta:  0.17133796455668163\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.9590132476740045e-05 0.00013363856682324649 nan\n",
      "Epoch: 582\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6511964473636256\n",
      "MAPE:  0.009909319116647145\n",
      "Delta:  0.17132946788432096\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.9585824189124494e-05 0.00013363272151811767 nan\n",
      "Epoch: 583\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6509757934886033\n",
      "MAPE:  0.009908288980280762\n",
      "Delta:  0.17132097237144805\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.958150460232513e-05 0.00013362680623285605 nan\n",
      "Epoch: 584\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6507551788661516\n",
      "MAPE:  0.009907258935567301\n",
      "Delta:  0.17131247801986793\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.957722152298949e-05 0.0001336210299558438 nan\n",
      "Epoch: 585\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6505346032589465\n",
      "MAPE:  0.009906228981394594\n",
      "Delta:  0.1713039848231955\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.957291262264185e-05 0.0001336151731650137 nan\n",
      "Epoch: 586\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6503140667921175\n",
      "MAPE:  0.009905199118384533\n",
      "Delta:  0.17129549278572395\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.9568613158301744e-05 0.0001336093411712369 nan\n",
      "Epoch: 587\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6500935694169276\n",
      "MAPE:  0.009904169346334559\n",
      "Delta:  0.17128700190570628\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.9564313271521776e-05 0.0001336035057664109 nan\n",
      "Epoch: 588\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6498731111312108\n",
      "MAPE:  0.009903139665156312\n",
      "Delta:  0.17127851218308449\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.956001910350061e-05 0.0001335976896406077 nan\n",
      "Epoch: 589\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6496526918953636\n",
      "MAPE:  0.0099021100749504\n",
      "Delta:  0.17127002361674867\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.9555703851011934e-05 0.00013359179216765327 nan\n",
      "Epoch: 590\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.649432311835799\n",
      "MAPE:  0.009901080576029795\n",
      "Delta:  0.17126153621017975\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.9551414558424156e-05 0.00013358597230106461 nan\n",
      "Epoch: 591\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6492119708166777\n",
      "MAPE:  0.009900051167978886\n",
      "Delta:  0.17125304995880108\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.9547109366998576e-05 0.0001335801233046663 nan\n",
      "Epoch: 592\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6489916688782604\n",
      "MAPE:  0.009899021850935294\n",
      "Delta:  0.17124456486520534\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.954280756319651e-05 0.00013357428527716042 nan\n",
      "Epoch: 593\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6487714059946619\n",
      "MAPE:  0.009897992624827906\n",
      "Delta:  0.171236080928682\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.953851255351527e-05 0.00013356844362055753 nan\n",
      "Epoch: 594\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.648551182164077\n",
      "MAPE:  0.009896963489700742\n",
      "Delta:  0.1712275981479373\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.9534215092350564e-05 0.00013356261817853987 nan\n",
      "Epoch: 595\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.648330997351986\n",
      "MAPE:  0.00989593444528546\n",
      "Delta:  0.17121911652326088\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.9529896474442836e-05 0.00013355667983006025 nan\n",
      "Epoch: 596\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6481108517367187\n",
      "MAPE:  0.009894905492593227\n",
      "Delta:  0.17121063605814504\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.95256284273049e-05 0.00013355096007650058 nan\n",
      "Epoch: 597\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6478907449501567\n",
      "MAPE:  0.009893876629852081\n",
      "Delta:  0.17120215674380082\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.952130638624652e-05 0.00013354502702755955 nan\n",
      "Epoch: 598\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6476706773360839\n",
      "MAPE:  0.009892847858741175\n",
      "Delta:  0.17119367858934273\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.951701217659199e-05 0.00013353920002967534 nan\n",
      "Epoch: 599\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.64745064871192\n",
      "MAPE:  0.009891819178387454\n",
      "Delta:  0.17118520158987546\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.951273907094489e-05 0.00013353344963484837 nan\n",
      "Epoch: 600\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6472306589436945\n",
      "MAPE:  0.009890790588184444\n",
      "Delta:  0.17117672574165632\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.9508408863307984e-05 0.00013352746937844717 nan\n",
      "Epoch: 601\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.647010708402323\n",
      "MAPE:  0.009889762089875909\n",
      "Delta:  0.17116825105433042\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.950413074644722e-05 0.00013352168478286686 nan\n",
      "Epoch: 602\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6467907967576818\n",
      "MAPE:  0.009888733682083926\n",
      "Delta:  0.1711597775188506\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.9499810655717624e-05 0.00013351575451925335 nan\n",
      "Epoch: 603\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6465709242419173\n",
      "MAPE:  0.00988770536568097\n",
      "Delta:  0.17115130514227153\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.9495545557332044e-05 0.00013351004324668736 nan\n",
      "Epoch: 604\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.646351090486613\n",
      "MAPE:  0.009886677139156702\n",
      "Delta:  0.17114283391505067\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.949122776864989e-05 0.0001335041066711229 nan\n",
      "Epoch: 605\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6461312958550107\n",
      "MAPE:  0.00988564900413896\n",
      "Delta:  0.1711343638460764\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.948693896578149e-05 0.00013349828152176002 nan\n",
      "Epoch: 606\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.645911540155855\n",
      "MAPE:  0.0098846209598272\n",
      "Delta:  0.1711258949302578\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.9482639273512596e-05 0.00013349242371796244 nan\n",
      "Epoch: 607\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6456918234351343\n",
      "MAPE:  0.009883593006427497\n",
      "Delta:  0.1711174271693286\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.9478344969822174e-05 0.00013348657220824123 nan\n",
      "Epoch: 608\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6454721456747128\n",
      "MAPE:  0.009882565143837507\n",
      "Delta:  0.17110896056223676\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.9474038819274924e-05 0.000133480678479736 nan\n",
      "Epoch: 609\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6452525069362887\n",
      "MAPE:  0.009881537372444323\n",
      "Delta:  0.17110049511087957\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.946975498620887e-05 0.00013347488227211102 nan\n",
      "Epoch: 610\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6450329070516174\n",
      "MAPE:  0.00988050969146817\n",
      "Delta:  0.17109203081130842\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.946548033946119e-05 0.0001334690951322326 nan\n",
      "Epoch: 611\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6448133459980505\n",
      "MAPE:  0.00987948210084115\n",
      "Delta:  0.1710835676618221\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.946115319348632e-05 0.0001334631271272535 nan\n",
      "Epoch: 612\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.644593824065353\n",
      "MAPE:  0.009878454601774937\n",
      "Delta:  0.1710751056712731\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.945687681501276e-05 0.00013345735116598867 nan\n",
      "Epoch: 613\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6443743409298492\n",
      "MAPE:  0.009877427193008836\n",
      "Delta:  0.1710666448308458\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.945256521071695e-05 0.00013345139786014037 nan\n",
      "Epoch: 614\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.644154896875447\n",
      "MAPE:  0.009876399875843794\n",
      "Delta:  0.17105818514643692\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.944827186037504e-05 0.00013344557992978068 nan\n",
      "Epoch: 615\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6439354916717388\n",
      "MAPE:  0.009875372649065283\n",
      "Delta:  0.17104972661479387\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.944398550921214e-05 0.0001334397312179325 nan\n",
      "Epoch: 616\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6437161253615906\n",
      "MAPE:  0.009874345513121942\n",
      "Delta:  0.17104126923458976\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.943970832682609e-05 0.00013343394394582653 nan\n",
      "Epoch: 617\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6434967978362562\n",
      "MAPE:  0.00987331846741154\n",
      "Delta:  0.17103281300412695\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.943540378965494e-05 0.00013342805681404446 nan\n",
      "Epoch: 618\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6432775092521408\n",
      "MAPE:  0.009872291512636074\n",
      "Delta:  0.1710243579279548\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.943109337307572e-05 0.00013342211745703825 nan\n",
      "Epoch: 619\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6430582596872867\n",
      "MAPE:  0.009871264649312202\n",
      "Delta:  0.171015904006949\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.942682629893724e-05 0.00013341638488206797 nan\n",
      "Epoch: 620\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6428390487941287\n",
      "MAPE:  0.009870237875728561\n",
      "Delta:  0.1710074512335673\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.9422510240537676e-05 0.00013341041203029924 nan\n",
      "Epoch: 621\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6426198769597296\n",
      "MAPE:  0.009869211193851353\n",
      "Delta:  0.1709989996160575\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.941824048576571e-05 0.00013340465531641588 nan\n",
      "Epoch: 622\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.642400743821228\n",
      "MAPE:  0.009868184601818384\n",
      "Delta:  0.17099054914637166\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.941392683721624e-05 0.00013339870713480195 nan\n",
      "Epoch: 623\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.642181649685405\n",
      "MAPE:  0.009867158101250032\n",
      "Delta:  0.17098209983188628\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.9409641334485777e-05 0.00013339286250779736 nan\n",
      "Epoch: 624\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6419625943743956\n",
      "MAPE:  0.00986613169136601\n",
      "Delta:  0.17097365166765896\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.940535832986814e-05 0.00013338704491749898 nan\n",
      "Epoch: 625\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.641743577836067\n",
      "MAPE:  0.009865105371759025\n",
      "Delta:  0.17096520465313336\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.940106594719662e-05 0.00013338117966599228 nan\n",
      "Epoch: 626\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6415246001409463\n",
      "MAPE:  0.009864079142910468\n",
      "Delta:  0.1709567587897836\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.939677879156612e-05 0.00013337532706558797 nan\n",
      "Epoch: 627\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6413056612605161\n",
      "MAPE:  0.009863053004744778\n",
      "Delta:  0.17094831407658675\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.9392472804776766e-05 0.00013336941634423116 nan\n",
      "Epoch: 628\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6410867612824314\n",
      "MAPE:  0.0098620269575142\n",
      "Delta:  0.17093987051663273\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.938817815869356e-05 0.00013336352249770922 nan\n",
      "Epoch: 629\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6408679001712223\n",
      "MAPE:  0.00986100100136271\n",
      "Delta:  0.17093142810785322\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.9383895646570863e-05 0.0001333576976607631 nan\n",
      "Epoch: 630\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.64064907780589\n",
      "MAPE:  0.009859975135484244\n",
      "Delta:  0.17092298684804483\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.9379606682831145e-05 0.00013335184452756277 nan\n",
      "Epoch: 631\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.640430294225142\n",
      "MAPE:  0.009858949360214836\n",
      "Delta:  0.1709145467381812\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.9375326218514815e-05 0.0001333460207770809 nan\n",
      "Epoch: 632\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.640211549373045\n",
      "MAPE:  0.0098579236752901\n",
      "Delta:  0.17090610777668053\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.9371030805933636e-05 0.00013334012127974582 nan\n",
      "Epoch: 633\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.639992843366127\n",
      "MAPE:  0.00985689808129018\n",
      "Delta:  0.17089766996596856\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.936673893551902e-05 0.00013333425244288488 nan\n",
      "Epoch: 634\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6397741761463451\n",
      "MAPE:  0.009855872577928257\n",
      "Delta:  0.17088923330531067\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.936245081466062e-05 0.0001333283844934252 nan\n",
      "Epoch: 635\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6395555477045054\n",
      "MAPE:  0.009854847165263329\n",
      "Delta:  0.17088079779393686\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.935816623485856e-05 0.00013332255605746912 nan\n",
      "Epoch: 636\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6393369579680872\n",
      "MAPE:  0.009853821842962315\n",
      "Delta:  0.170872363431113\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.935388119664541e-05 0.00013331667883376142 nan\n",
      "Epoch: 637\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6391184070093616\n",
      "MAPE:  0.009852796611297813\n",
      "Delta:  0.17086393021678845\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.934958528779454e-05 0.0001333107893137786 nan\n",
      "Epoch: 638\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6388998948407445\n",
      "MAPE:  0.009851771470420184\n",
      "Delta:  0.1708554981526916\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.934528754230172e-05 0.00013330489178464688 nan\n",
      "Epoch: 639\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6386814214676169\n",
      "MAPE:  0.009850746420330708\n",
      "Delta:  0.17084706723900708\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.934100788589468e-05 0.00013329904766812284 nan\n",
      "Epoch: 640\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6384629867947038\n",
      "MAPE:  0.009849721460709384\n",
      "Delta:  0.17083863747251515\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.9336714376124746e-05 0.00013329315433008304 nan\n",
      "Epoch: 641\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6382445908949408\n",
      "MAPE:  0.009848696591826534\n",
      "Delta:  0.17083020885545377\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.933245363991645e-05 0.00013328739038998005 nan\n",
      "Epoch: 642\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6380262335486\n",
      "MAPE:  0.009847671812761258\n",
      "Delta:  0.17082178138209514\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.932813526836721e-05 0.00013328140197521599 nan\n",
      "Epoch: 643\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6378079151157203\n",
      "MAPE:  0.009846647125081948\n",
      "Delta:  0.17081335506215634\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.9323874190099204e-05 0.00013327562560061512 nan\n",
      "Epoch: 644\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6375896352412196\n",
      "MAPE:  0.009845622527355194\n",
      "Delta:  0.17080492988572127\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.931956466358578e-05 0.00013326966723070655 nan\n",
      "Epoch: 645\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6373713942154706\n",
      "MAPE:  0.009844598020801596\n",
      "Delta:  0.1707965058609369\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.931528907570204e-05 0.0001332638435150857 nan\n",
      "Epoch: 646\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6371531918102158\n",
      "MAPE:  0.00984357360434667\n",
      "Delta:  0.17078808298187725\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.931100065341809e-05 0.00013325794864160745 nan\n",
      "Epoch: 647\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6369350281342632\n",
      "MAPE:  0.009842549278734182\n",
      "Delta:  0.17077966125060573\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.930671923419894e-05 0.00013325210636183638 nan\n",
      "Epoch: 648\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6367169030937867\n",
      "MAPE:  0.00984152504336025\n",
      "Delta:  0.17077124066579755\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.930243946632551e-05 0.00013324625380350952 nan\n",
      "Epoch: 649\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6364988166979124\n",
      "MAPE:  0.00984050089831792\n",
      "Delta:  0.17076282122704203\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.9298138243059064e-05 0.00013324031201800146 nan\n",
      "Epoch: 650\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6362807690849586\n",
      "MAPE:  0.009839476844348626\n",
      "Delta:  0.17075440293787442\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.9293862583343895e-05 0.00013323448328628196 nan\n",
      "Epoch: 651\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6360627600621784\n",
      "MAPE:  0.009838452880525867\n",
      "Delta:  0.17074598579380051\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.9289578616384944e-05 0.00013322859531839093 nan\n",
      "Epoch: 652\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6358447897188026\n",
      "MAPE:  0.009837429007316847\n",
      "Delta:  0.1707375697961103\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.928528467462723e-05 0.0001332227073096437 nan\n",
      "Epoch: 653\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6356268580471778\n",
      "MAPE:  0.009836405224644181\n",
      "Delta:  0.17072915494637822\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.928101725287792e-05 0.00013321687463507814 nan\n",
      "Epoch: 654\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6354089649490797\n",
      "MAPE:  0.009835381532215174\n",
      "Delta:  0.17072074123994774\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.9276726394098525e-05 0.00013321097825980122 nan\n",
      "Epoch: 655\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.635191110521004\n",
      "MAPE:  0.009834357930343594\n",
      "Delta:  0.17071232868069186\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.9272435207359244e-05 0.00013320507569358764 nan\n",
      "Epoch: 656\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6349732947653537\n",
      "MAPE:  0.00983333441911052\n",
      "Delta:  0.17070391726853784\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.926815774031201e-05 0.00013319922658994177 nan\n",
      "Epoch: 657\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6347555175869957\n",
      "MAPE:  0.00983231099819618\n",
      "Delta:  0.170695507001015\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.92638790029476e-05 0.00013319335480377337 nan\n",
      "Epoch: 658\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6345377790153244\n",
      "MAPE:  0.00983128766762832\n",
      "Delta:  0.17068709787821174\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.9259576920035464e-05 0.00013318740957912745 nan\n",
      "Epoch: 659\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6343200791626782\n",
      "MAPE:  0.009830264427991734\n",
      "Delta:  0.17067868990398455\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.925530036947734e-05 0.00013318154162988982 nan\n",
      "Epoch: 660\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6341024178950185\n",
      "MAPE:  0.009829241278781042\n",
      "Delta:  0.17067028307384666\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.9251032635311276e-05 0.000133175733107338 nan\n",
      "Epoch: 661\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.633884795107543\n",
      "MAPE:  0.00982821821937243\n",
      "Delta:  0.17066187738616512\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.924674586714861e-05 0.0001331698357466271 nan\n",
      "Epoch: 662\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6336672109377497\n",
      "MAPE:  0.009827195250573705\n",
      "Delta:  0.17065347284406027\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.924246819182354e-05 0.00013316397545093395 nan\n",
      "Epoch: 663\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6334496653173773\n",
      "MAPE:  0.009826172371956099\n",
      "Delta:  0.1706450694458519\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.923817423141408e-05 0.00013315802986268999 nan\n",
      "Epoch: 664\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6332321583780638\n",
      "MAPE:  0.009825149584346654\n",
      "Delta:  0.1706366671941908\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.9233901939560454e-05 0.00013315218971454712 nan\n",
      "Epoch: 665\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6330146899398637\n",
      "MAPE:  0.00982412688677937\n",
      "Delta:  0.17062826608525086\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.922962242659423e-05 0.00013314632258831782 nan\n",
      "Epoch: 666\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6327972600391654\n",
      "MAPE:  0.00982310427938219\n",
      "Delta:  0.1706198661201362\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.922531511108996e-05 0.00013314032339128978 nan\n",
      "Epoch: 667\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6325798688839315\n",
      "MAPE:  0.009822081763345997\n",
      "Delta:  0.17061146730346222\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.92210621965139e-05 0.00013313456431884862 nan\n",
      "Epoch: 668\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6323625160743718\n",
      "MAPE:  0.009821059336718282\n",
      "Delta:  0.17060306962581862\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.921678227909343e-05 0.00013312866039916216 nan\n",
      "Epoch: 669\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.632145201839321\n",
      "MAPE:  0.009820037000633225\n",
      "Delta:  0.17059467309168472\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.921250007750011e-05 0.00013312280285249223 nan\n",
      "Epoch: 670\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6319279260953898\n",
      "MAPE:  0.009819014754591519\n",
      "Delta:  0.17058627770132195\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.9208203380946e-05 0.00013311681228256322 nan\n",
      "Epoch: 671\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6317106890519932\n",
      "MAPE:  0.009817992599806613\n",
      "Delta:  0.17057788345707484\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.9203947512843627e-05 0.00013311104686586361 nan\n",
      "Epoch: 672\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.631493490333991\n",
      "MAPE:  0.00981697053436532\n",
      "Delta:  0.17056949035185037\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.9199646405928554e-05 0.00013310506152752755 nan\n",
      "Epoch: 673\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6312763302925786\n",
      "MAPE:  0.00981594856012915\n",
      "Delta:  0.1705610983932374\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.919536865666263e-05 0.00013309919666726344 nan\n",
      "Epoch: 674\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6310592087234743\n",
      "MAPE:  0.009814926675921942\n",
      "Delta:  0.17055270757712349\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.919110653056613e-05 0.0001330933702038406 nan\n",
      "Epoch: 675\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6308421255563834\n",
      "MAPE:  0.009813904881610616\n",
      "Delta:  0.17054431790071597\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.918682161625387e-05 0.00013308745111573206 nan\n",
      "Epoch: 676\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.630625080934721\n",
      "MAPE:  0.00981288317787433\n",
      "Delta:  0.17053592936777373\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.918253260832728e-05 0.00013308152395030692 nan\n",
      "Epoch: 677\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6304080748639587\n",
      "MAPE:  0.009811861564733383\n",
      "Delta:  0.1705275419788667\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.9178272597316663e-05 0.00013307571581600008 nan\n",
      "Epoch: 678\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6301911071423238\n",
      "MAPE:  0.009810840041219132\n",
      "Delta:  0.1705191557289219\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.9173983686534584e-05 0.00013306976745597332 nan\n",
      "Epoch: 679\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6299741779907877\n",
      "MAPE:  0.009809818608538207\n",
      "Delta:  0.17051077062273984\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.916968947887845e-05 0.00013306382086752944 nan\n",
      "Epoch: 680\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.629757287398749\n",
      "MAPE:  0.009808797266441282\n",
      "Delta:  0.17050238666109552\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.9165443007148646e-05 0.00013305804712337999 nan\n",
      "Epoch: 681\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6295404350768026\n",
      "MAPE:  0.009807776013827025\n",
      "Delta:  0.17049400383572155\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.916114562258933e-05 0.00013305207609959346 nan\n",
      "Epoch: 682\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6293236213388274\n",
      "MAPE:  0.009806754852046727\n",
      "Delta:  0.17048562215517118\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.915685791184732e-05 0.00013304614360520883 nan\n",
      "Epoch: 683\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6291068461143234\n",
      "MAPE:  0.009805733780806541\n",
      "Delta:  0.1704772416176669\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.915262020055433e-05 0.00013304040905803838 nan\n",
      "Epoch: 684\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.628890109073117\n",
      "MAPE:  0.009804712798634608\n",
      "Delta:  0.17046886221455682\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.914833459501722e-05 0.0001330344831717012 nan\n",
      "Epoch: 685\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.628673410519313\n",
      "MAPE:  0.009803691906964906\n",
      "Delta:  0.1704604839538787\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.914402756406311e-05 0.00013302846640206312 nan\n",
      "Epoch: 686\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.628456750593242\n",
      "MAPE:  0.009802671106423943\n",
      "Delta:  0.17045210683915668\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.913975597009568e-05 0.0001330225771737359 nan\n",
      "Epoch: 687\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6282401290794621\n",
      "MAPE:  0.009801650396099941\n",
      "Delta:  0.17044373086422202\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.913550143703649e-05 0.00013301677461641237 nan\n",
      "Epoch: 688\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.628023545829191\n",
      "MAPE:  0.009800629775297002\n",
      "Delta:  0.1704353560260392\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.913123119443252e-05 0.00013301090847051 nan\n",
      "Epoch: 689\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6278070009383487\n",
      "MAPE:  0.009799609244498778\n",
      "Delta:  0.17042698232715858\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.912693884551178e-05 0.00013300494080881187 nan\n",
      "Epoch: 690\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.627590494564541\n",
      "MAPE:  0.00979858880438394\n",
      "Delta:  0.17041860977122014\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.912267680867721e-05 0.00013299909769404206 nan\n",
      "Epoch: 691\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6273740264973484\n",
      "MAPE:  0.009797568454077407\n",
      "Delta:  0.17041023835293018\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.91184011353063e-05 0.00013299319350401628 nan\n",
      "Epoch: 692\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.627157596828539\n",
      "MAPE:  0.009796548194085259\n",
      "Delta:  0.1704018680744852\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.9114113969350726e-05 0.00013298724017540842 nan\n",
      "Epoch: 693\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6269412056304065\n",
      "MAPE:  0.00979552802464138\n",
      "Delta:  0.170393498937716\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.910985304151794e-05 0.0001329814030467391 nan\n",
      "Epoch: 694\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.626724852706207\n",
      "MAPE:  0.00979450794490735\n",
      "Delta:  0.17038513093802393\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.910556766102303e-05 0.00013297547020330036 nan\n",
      "Epoch: 695\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.626508538204027\n",
      "MAPE:  0.009793487955559276\n",
      "Delta:  0.17037676407944824\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.9101304609222574e-05 0.00013296958421227245 nan\n",
      "Epoch: 696\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6262922620399842\n",
      "MAPE:  0.00979246805637572\n",
      "Delta:  0.17036839835805684\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.909702820754536e-05 0.0001329636978765203 nan\n",
      "Epoch: 697\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6260760242069954\n",
      "MAPE:  0.009791448247125837\n",
      "Delta:  0.17036003377599696\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.9092751514434596e-05 0.00013295776694932648 nan\n",
      "Epoch: 698\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.625859824769927\n",
      "MAPE:  0.009790428528276508\n",
      "Delta:  0.17035167033319082\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.908847975615416e-05 0.00013295188906281563 nan\n",
      "Epoch: 699\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6256436636348726\n",
      "MAPE:  0.00978940889937411\n",
      "Delta:  0.17034330802867026\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.9084212850991626e-05 0.00013294600656299504 nan\n",
      "Epoch: 700\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6254275408016978\n",
      "MAPE:  0.009788389360529658\n",
      "Delta:  0.1703349468614812\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.907993532965449e-05 0.00013294007959285814 nan\n",
      "Epoch: 701\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.625211456335051\n",
      "MAPE:  0.009787369911920788\n",
      "Delta:  0.17032658683330487\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.907567002987445e-05 0.00013293421023019558 nan\n",
      "Epoch: 702\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6249954101336461\n",
      "MAPE:  0.009786350553203592\n",
      "Delta:  0.17031822794193213\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.907137872556255e-05 0.00013292821682175937 nan\n",
      "Epoch: 703\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6247794023914335\n",
      "MAPE:  0.009785331285242652\n",
      "Delta:  0.17030987019166494\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.9067115354684e-05 0.00013292234687323212 nan\n",
      "Epoch: 704\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6245634329001164\n",
      "MAPE:  0.009784312107185753\n",
      "Delta:  0.1703015135776182\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.906286080907929e-05 0.00013291652413305322 nan\n",
      "Epoch: 705\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6243475015753817\n",
      "MAPE:  0.00978329301852314\n",
      "Delta:  0.17029315809816195\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.905857322201612e-05 0.0001329105466150171 nan\n",
      "Epoch: 706\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6241316086610547\n",
      "MAPE:  0.009782274020482288\n",
      "Delta:  0.17028480375879618\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.905431419033324e-05 0.00013290469173277142 nan\n",
      "Epoch: 707\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6239157539502722\n",
      "MAPE:  0.009781255112146042\n",
      "Delta:  0.17027645055453078\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.9050035546671644e-05 0.00013289876659072775 nan\n",
      "Epoch: 708\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.623699937549525\n",
      "MAPE:  0.009780236294029009\n",
      "Delta:  0.1702680984885783\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.904576616659995e-05 0.00013289284423534387 nan\n",
      "Epoch: 709\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6234841594466394\n",
      "MAPE:  0.009779217566118648\n",
      "Delta:  0.1702597475592342\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.904152132467754e-05 0.00013288706107839054 nan\n",
      "Epoch: 710\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6232684194079832\n",
      "MAPE:  0.00977819892729423\n",
      "Delta:  0.17025139776219356\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.9037220097525314e-05 0.00013288101813080377 nan\n",
      "Epoch: 711\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6230527178477125\n",
      "MAPE:  0.00977718037957607\n",
      "Delta:  0.17024304910692956\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.903295762015425e-05 0.00013287512312842864 nan\n",
      "Epoch: 712\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6228370545179847\n",
      "MAPE:  0.0097761619217089\n",
      "Delta:  0.17023470158671758\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.902868871636823e-05 0.00013286923522637384 nan\n",
      "Epoch: 713\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.622621429399654\n",
      "MAPE:  0.00977514355372212\n",
      "Delta:  0.17022635520252474\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.9024432953514996e-05 0.0001328633799256851 nan\n",
      "Epoch: 714\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6224058424322039\n",
      "MAPE:  0.00977412527540284\n",
      "Delta:  0.17021800995198721\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.902013737329014e-05 0.00013285737019352872 nan\n",
      "Epoch: 715\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6221902938585917\n",
      "MAPE:  0.009773107087817822\n",
      "Delta:  0.17020966584175595\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.9015877571112476e-05 0.0001328514608943676 nan\n",
      "Epoch: 716\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.621974783508204\n",
      "MAPE:  0.0097720889902902\n",
      "Delta:  0.17020132286561362\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.9011611447769e-05 0.0001328455989879629 nan\n",
      "Epoch: 717\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6217593112965454\n",
      "MAPE:  0.009771070982224067\n",
      "Delta:  0.17019298102450944\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.900734038237875e-05 0.00013283966082844323 nan\n",
      "Epoch: 718\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6215438773396873\n",
      "MAPE:  0.009770053064433737\n",
      "Delta:  0.1701846403191577\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.9003088140930906e-05 0.00013283382166295876 nan\n",
      "Epoch: 719\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6213284814694662\n",
      "MAPE:  0.00976903523608007\n",
      "Delta:  0.17017630074622792\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.899881106090742e-05 0.00013282785854618062 nan\n",
      "Epoch: 720\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6211131238792724\n",
      "MAPE:  0.009768017498108768\n",
      "Delta:  0.1701679623098206\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.8994540901126094e-05 0.00013282194452968188 nan\n",
      "Epoch: 721\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6208978044818563\n",
      "MAPE:  0.009766999850063253\n",
      "Delta:  0.17015962500863113\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.899029551463929e-05 0.00013281610616333595 nan\n",
      "Epoch: 722\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6206825231469761\n",
      "MAPE:  0.009765982291432147\n",
      "Delta:  0.17015128883831732\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.8986007414542065e-05 0.00013281012981480877 nan\n",
      "Epoch: 723\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6204672800906885\n",
      "MAPE:  0.00976496482318877\n",
      "Delta:  0.17014295380602068\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.898174341816386e-05 0.00013280419804539978 nan\n",
      "Epoch: 724\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6202520752330973\n",
      "MAPE:  0.009763947445064114\n",
      "Delta:  0.17013461990751294\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.897747852472545e-05 0.0001327983063248439 nan\n",
      "Epoch: 725\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.620036908501687\n",
      "MAPE:  0.00976293015662407\n",
      "Delta:  0.1701262871428201\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.897321490282547e-05 0.00013279241890851168 nan\n",
      "Epoch: 726\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6198217798818861\n",
      "MAPE:  0.009761912957887095\n",
      "Delta:  0.17011795551159925\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.896894653516615e-05 0.00013278645431136216 nan\n",
      "Epoch: 727\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6196066894911192\n",
      "MAPE:  0.009760895849524954\n",
      "Delta:  0.1701096250145311\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.8964676706453325e-05 0.00013278055264609456 nan\n",
      "Epoch: 728\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6193916372198194\n",
      "MAPE:  0.009759878830862469\n",
      "Delta:  0.17010129565173762\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.896042686808322e-05 0.0001327746793866602 nan\n",
      "Epoch: 729\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.619176623014386\n",
      "MAPE:  0.009758861901797884\n",
      "Delta:  0.1700929674196917\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.895615333599945e-05 0.00013276873629131103 nan\n",
      "Epoch: 730\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.618961646980316\n",
      "MAPE:  0.009757845062853777\n",
      "Delta:  0.1700846403222973\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.89518836340741e-05 0.00013276280287222164 nan\n",
      "Epoch: 731\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6187467090943202\n",
      "MAPE:  0.009756828313804136\n",
      "Delta:  0.17007631435877632\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.894761602969311e-05 0.00013275685356917144 nan\n",
      "Epoch: 732\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6185318093744954\n",
      "MAPE:  0.009755811654966964\n",
      "Delta:  0.17006798952864532\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.8943372569443255e-05 0.0001327510412960642 nan\n",
      "Epoch: 733\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6183169475914303\n",
      "MAPE:  0.009754795085133074\n",
      "Delta:  0.1700596658276717\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.893909101955085e-05 0.00013274504155491584 nan\n",
      "Epoch: 734\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6181021240409732\n",
      "MAPE:  0.00975377860581973\n",
      "Delta:  0.170051343262207\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.8934816882284515e-05 0.00013273908648403498 nan\n",
      "Epoch: 735\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.61788733864319\n",
      "MAPE:  0.00975276221649924\n",
      "Delta:  0.17004302183086387\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.893057173382953e-05 0.0001327332327029085 nan\n",
      "Epoch: 736\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6176725912265828\n",
      "MAPE:  0.009751745916615\n",
      "Delta:  0.17003470152858635\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.892630924302477e-05 0.00013272731149605033 nan\n",
      "Epoch: 737\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6174578818926684\n",
      "MAPE:  0.009750729706539313\n",
      "Delta:  0.1700263823581973\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.892203443362941e-05 0.00013272134990838236 nan\n",
      "Epoch: 738\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6172432106991637\n",
      "MAPE:  0.009749713586602813\n",
      "Delta:  0.17001806432166494\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.8917790244962234e-05 0.0001327155066450647 nan\n",
      "Epoch: 739\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6170285774470874\n",
      "MAPE:  0.009748697555861777\n",
      "Delta:  0.1700097474136566\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.8913516343840335e-05 0.0001327095259595623 nan\n",
      "Epoch: 740\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6168139823511112\n",
      "MAPE:  0.00974768161539721\n",
      "Delta:  0.17000143163909787\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.8909252473583464e-05 0.0001327036050795538 nan\n",
      "Epoch: 741\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6165994253069103\n",
      "MAPE:  0.009746665764658151\n",
      "Delta:  0.16999311699615696\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.8905014395250745e-05 0.00013269777542412875 nan\n",
      "Epoch: 742\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.61638490615942\n",
      "MAPE:  0.009745650003066394\n",
      "Delta:  0.1699848034803232\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.890071733798518e-05 0.0001326917175679121 nan\n",
      "Epoch: 743\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6161704252699707\n",
      "MAPE:  0.009744634332255067\n",
      "Delta:  0.16997649110149643\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.8896479528548475e-05 0.00013268586681636219 nan\n",
      "Epoch: 744\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6159559822961709\n",
      "MAPE:  0.009743618750680227\n",
      "Delta:  0.16996817984947896\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.889220981252329e-05 0.00013267992343135582 nan\n",
      "Epoch: 745\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6157415773801713\n",
      "MAPE:  0.009742603258939683\n",
      "Delta:  0.1699598697295683\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.888794683177711e-05 0.00013267399815808378 nan\n",
      "Epoch: 746\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6155272104851102\n",
      "MAPE:  0.00974158785697097\n",
      "Delta:  0.16995156074049345\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.888368850353153e-05 0.00013266806677481036 nan\n",
      "Epoch: 747\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.615312881613273\n",
      "MAPE:  0.009740572544835853\n",
      "Delta:  0.1699432528813375\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.8879425197267956e-05 0.00013266213139462302 nan\n",
      "Epoch: 748\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.615098590763529\n",
      "MAPE:  0.009739557322492895\n",
      "Delta:  0.1699349461528205\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.887516996032737e-05 0.00013265622610514338 nan\n",
      "Epoch: 749\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6148843378796904\n",
      "MAPE:  0.009738542189707483\n",
      "Delta:  0.16992664055344509\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.887091152017131e-05 0.00013265031116282966 nan\n",
      "Epoch: 750\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6146701229697786\n",
      "MAPE:  0.00973752714661677\n",
      "Delta:  0.1699183360836297\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.88666546811789e-05 0.00013264438525595335 nan\n",
      "Epoch: 751\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6144559460439263\n",
      "MAPE:  0.009736512193116928\n",
      "Delta:  0.16991003274297628\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.886237082091238e-05 0.00013263836352572778 nan\n",
      "Epoch: 752\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6142418072492586\n",
      "MAPE:  0.009735497330064367\n",
      "Delta:  0.1699017305359502\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.8858137850493755e-05 0.00013263253260409336 nan\n",
      "Epoch: 753\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6140277062701278\n",
      "MAPE:  0.009734482556063363\n",
      "Delta:  0.16989342945377864\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.8853883515054264e-05 0.00013262662531299263 nan\n",
      "Epoch: 754\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6138136432222834\n",
      "MAPE:  0.009733467871573516\n",
      "Delta:  0.16988512949996615\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.884960497020252e-05 0.00013262060911733986 nan\n",
      "Epoch: 755\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6135996182739174\n",
      "MAPE:  0.009732453277318908\n",
      "Delta:  0.16987683067849976\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.884535910054666e-05 0.0001326147389039134 nan\n",
      "Epoch: 756\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6133856311818446\n",
      "MAPE:  0.009731438772312452\n",
      "Delta:  0.1698685329837024\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.884109951308613e-05 0.00013260878919951757 nan\n",
      "Epoch: 757\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6131716820667816\n",
      "MAPE:  0.009730424357170737\n",
      "Delta:  0.1698602364177788\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.88368406788009e-05 0.00013260287368754842 nan\n",
      "Epoch: 758\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6129577708659881\n",
      "MAPE:  0.009729410031502227\n",
      "Delta:  0.16985194098047518\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.883257792975826e-05 0.00013259691571809729 nan\n",
      "Epoch: 759\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6127438976403878\n",
      "MAPE:  0.009728395795737357\n",
      "Delta:  0.16984364667233076\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.882833286268262e-05 0.0001325910104826855 nan\n",
      "Epoch: 760\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.61253006229735\n",
      "MAPE:  0.009727381649432135\n",
      "Delta:  0.16983535349021642\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.8824059578400636e-05 0.00013258502931012828 nan\n",
      "Epoch: 761\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6123162649517768\n",
      "MAPE:  0.009726367593088339\n",
      "Delta:  0.1698270614387991\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.881982081939018e-05 0.00013257917430054 nan\n",
      "Epoch: 762\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.612102505392658\n",
      "MAPE:  0.00972535362573843\n",
      "Delta:  0.16981877051208938\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.8815563101101134e-05 0.00013257322536641691 nan\n",
      "Epoch: 763\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6118887837638969\n",
      "MAPE:  0.009724339748206657\n",
      "Delta:  0.1698104807131817\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.881128877698426e-05 0.00013256720719645454 nan\n",
      "Epoch: 764\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6116751001695222\n",
      "MAPE:  0.009723325960886774\n",
      "Delta:  0.16980219204477023\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.880705519927364e-05 0.0001325613805274184 nan\n",
      "Epoch: 765\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6114614542932821\n",
      "MAPE:  0.009722312262326664\n",
      "Delta:  0.16979390449981013\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.8802769295086534e-05 0.00013255532302958173 nan\n",
      "Epoch: 766\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6112478464996585\n",
      "MAPE:  0.009721298654288866\n",
      "Delta:  0.16978561808706114\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.879855136952216e-05 0.00013254952051167113 nan\n",
      "Epoch: 767\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6110342763701795\n",
      "MAPE:  0.009720285134913674\n",
      "Delta:  0.1697773327948551\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.879426697068645e-05 0.00013254347864033456 nan\n",
      "Epoch: 768\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6108207442829805\n",
      "MAPE:  0.009719271705813161\n",
      "Delta:  0.16976904863435316\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.87900382917239e-05 0.00013253765837539788 nan\n",
      "Epoch: 769\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.610607249873471\n",
      "MAPE:  0.009718258365412473\n",
      "Delta:  0.16976076559596953\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.8785751649793596e-05 0.00013253156671411137 nan\n",
      "Epoch: 770\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.610393793571284\n",
      "MAPE:  0.009717245115763159\n",
      "Delta:  0.16975248368941928\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.878152539211644e-05 0.00013252575937050537 nan\n",
      "Epoch: 771\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6101803749109054\n",
      "MAPE:  0.009716231954668694\n",
      "Delta:  0.1697442029043258\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.8777275746592075e-05 0.00013251984769191427 nan\n",
      "Epoch: 772\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6099669940528658\n",
      "MAPE:  0.009715218882968214\n",
      "Delta:  0.16973592324453435\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.877297773331346e-05 0.0001325137075931515 nan\n",
      "Epoch: 773\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6097536513573811\n",
      "MAPE:  0.009714205902320847\n",
      "Delta:  0.1697276447181294\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.8768761659157e-05 0.0001325079292475717 nan\n",
      "Epoch: 774\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.609540346234441\n",
      "MAPE:  0.00971319300993663\n",
      "Delta:  0.16971936731107717\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.8764501894948964e-05 0.00013250196022429606 nan\n",
      "Epoch: 775\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.609327078983505\n",
      "MAPE:  0.009712180207353035\n",
      "Delta:  0.16971109103066834\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.876025222788627e-05 0.0001324960356403615 nan\n",
      "Epoch: 776\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.609113849525491\n",
      "MAPE:  0.009711167494127988\n",
      "Delta:  0.1697028158750638\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.875597190678871e-05 0.0001324899983775607 nan\n",
      "Epoch: 777\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6089006580341783\n",
      "MAPE:  0.009710154871059857\n",
      "Delta:  0.16969454184934052\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.8751741744790245e-05 0.00013248412215904892 nan\n",
      "Epoch: 778\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6086875042428574\n",
      "MAPE:  0.009709142337123583\n",
      "Delta:  0.16968626894486077\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.874747743088825e-05 0.00013247814382788548 nan\n",
      "Epoch: 779\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6084743883082961\n",
      "MAPE:  0.00970812989288605\n",
      "Delta:  0.16967799716729504\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.8743255631311655e-05 0.00013247231227098144 nan\n",
      "Epoch: 780\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6082613099868484\n",
      "MAPE:  0.009707117537382048\n",
      "Delta:  0.16966972650930412\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.873899160173778e-05 0.00013246633362018478 nan\n",
      "Epoch: 781\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.608048269507611\n",
      "MAPE:  0.009706105271555982\n",
      "Delta:  0.1696614569779287\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.87347213894429e-05 0.00013246030441804724 nan\n",
      "Epoch: 782\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6078352669443132\n",
      "MAPE:  0.009705093095808632\n",
      "Delta:  0.16965318857409237\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.873047759157423e-05 0.00013245440096465444 nan\n",
      "Epoch: 783\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6076223020871803\n",
      "MAPE:  0.009704081009251147\n",
      "Delta:  0.1696449212931882\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.8726226313577925e-05 0.00013244844705417869 nan\n",
      "Epoch: 784\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.607409375009819\n",
      "MAPE:  0.00970306901218849\n",
      "Delta:  0.16963665513636034\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.872199918548592e-05 0.00013244259709344064 nan\n",
      "Epoch: 785\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6071964855376004\n",
      "MAPE:  0.009702057103942516\n",
      "Delta:  0.16962839009938696\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.871773422010506e-05 0.0001324366034101132 nan\n",
      "Epoch: 786\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.606983633894043\n",
      "MAPE:  0.009701045285389221\n",
      "Delta:  0.16962012618856193\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.8713485039653115e-05 0.0001324306482712867 nan\n",
      "Epoch: 787\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.606770820009645\n",
      "MAPE:  0.009700033556432851\n",
      "Delta:  0.1696118634010824\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.870920948663038e-05 0.00013242459429885223 nan\n",
      "Epoch: 788\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6065580440356741\n",
      "MAPE:  0.009699021917579011\n",
      "Delta:  0.16960360174129657\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.870497779141392e-05 0.00013241872460656445 nan\n",
      "Epoch: 789\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6063453056684764\n",
      "MAPE:  0.009698010367614905\n",
      "Delta:  0.16959534120164044\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.8700723783379196e-05 0.00013241276996567297 nan\n",
      "Epoch: 790\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6061326050370317\n",
      "MAPE:  0.009696998907103365\n",
      "Delta:  0.1695870817857736\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.869648060512599e-05 0.00013240683239523765 nan\n",
      "Epoch: 791\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.605919942106392\n",
      "MAPE:  0.00969598753594163\n",
      "Delta:  0.16957882349173456\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.8692234407843316e-05 0.00013240089672394983 nan\n",
      "Epoch: 792\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.60570731686599\n",
      "MAPE:  0.00969497625401542\n",
      "Delta:  0.1695705663199105\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.868797990431606e-05 0.0001323949274384395 nan\n",
      "Epoch: 793\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6054947293622863\n",
      "MAPE:  0.009693965061677568\n",
      "Delta:  0.16956231027158514\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.868373997213293e-05 0.00013238901375733914 nan\n",
      "Epoch: 794\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6052821794984735\n",
      "MAPE:  0.00969295395836112\n",
      "Delta:  0.1695540553441628\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.8679481242652756e-05 0.00013238300851192708 nan\n",
      "Epoch: 795\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6050696674140408\n",
      "MAPE:  0.009691942944933979\n",
      "Delta:  0.16954580154070606\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.867524042362348e-05 0.00013237711365643445 nan\n",
      "Epoch: 796\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.604857192924251\n",
      "MAPE:  0.009690932020285271\n",
      "Delta:  0.16953754885805325\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.8670983807341806e-05 0.00013237109441421868 nan\n",
      "Epoch: 797\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6046447562212451\n",
      "MAPE:  0.009689921185669815\n",
      "Delta:  0.16952929729875804\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.866674616799127e-05 0.00013236520414483532 nan\n",
      "Epoch: 798\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.604432357090508\n",
      "MAPE:  0.009688910439811429\n",
      "Delta:  0.16952104685947836\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.8662504220309266e-05 0.00013235925984700359 nan\n",
      "Epoch: 799\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6042199956112488\n",
      "MAPE:  0.009687899783240403\n",
      "Delta:  0.16951279754082013\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.8658244499288905e-05 0.00013235325206240045 nan\n",
      "Epoch: 800\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.604007671877806\n",
      "MAPE:  0.009686889216464387\n",
      "Delta:  0.1695045493456716\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.865400200959602e-05 0.00013234732641942415 nan\n",
      "Epoch: 801\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6037953857508769\n",
      "MAPE:  0.009685878738768253\n",
      "Delta:  0.1694963022709871\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.8649766310138176e-05 0.0001323414084558605 nan\n",
      "Epoch: 802\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6035831372106515\n",
      "MAPE:  0.009684868350096269\n",
      "Delta:  0.16948805631549121\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.864549093408499e-05 0.0001323353307893793 nan\n",
      "Epoch: 803\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6033709265057405\n",
      "MAPE:  0.00968385805166101\n",
      "Delta:  0.16947981148578428\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.864126992631945e-05 0.00013232947600827494 nan\n",
      "Epoch: 804\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.603158753271189\n",
      "MAPE:  0.00968284784178257\n",
      "Delta:  0.16947156777252673\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.863701433954759e-05 0.00013232350375314006 nan\n",
      "Epoch: 805\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6029466176878835\n",
      "MAPE:  0.009681837721229504\n",
      "Delta:  0.16946332518145482\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.863278077871236e-05 0.00013231757600151717 nan\n",
      "Epoch: 806\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6027345196769713\n",
      "MAPE:  0.009680827689857452\n",
      "Delta:  0.16945508370871123\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.8628519829341244e-05 0.00013231155168957898 nan\n",
      "Epoch: 807\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6025224593857263\n",
      "MAPE:  0.009679817748210622\n",
      "Delta:  0.16944684335881294\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.862428055008028e-05 0.00013230561926025342 nan\n",
      "Epoch: 808\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.602310436659359\n",
      "MAPE:  0.009678807895643645\n",
      "Delta:  0.16943860412796313\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.8620046380065673e-05 0.00013229969495620608 nan\n",
      "Epoch: 809\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6020984514773637\n",
      "MAPE:  0.009677798132094453\n",
      "Delta:  0.16943036601517186\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.8615788043493424e-05 0.00013229369684153447 nan\n",
      "Epoch: 810\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6018865039505137\n",
      "MAPE:  0.009676788458103878\n",
      "Delta:  0.16942212902440953\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.861156609015094e-05 0.0001322878342853162 nan\n",
      "Epoch: 811\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6016745938541352\n",
      "MAPE:  0.00967577887253144\n",
      "Delta:  0.16941389314938732\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.860729566802391e-05 0.00013228173883161887 nan\n",
      "Epoch: 812\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6014627215538177\n",
      "MAPE:  0.009674769377305423\n",
      "Delta:  0.16940565839819274\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.860305784804009e-05 0.00013227581022456913 nan\n",
      "Epoch: 813\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.60125088677478\n",
      "MAPE:  0.009673759971021928\n",
      "Delta:  0.16939742476517783\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.8598815985845256e-05 0.00013226986784642403 nan\n",
      "Epoch: 814\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6010390895315973\n",
      "MAPE:  0.009672750653864066\n",
      "Delta:  0.16938919225090318\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.8594575263516404e-05 0.00013226391516540925 nan\n",
      "Epoch: 815\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.600827329833283\n",
      "MAPE:  0.00967174142578375\n",
      "Delta:  0.1693809608550515\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.8590326013786544e-05 0.00013225791860382863 nan\n",
      "Epoch: 816\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.600615607742595\n",
      "MAPE:  0.00967073228730784\n",
      "Delta:  0.16937273057894303\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.858610533031715e-05 0.00013225204392863787 nan\n",
      "Epoch: 817\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.600403923056927\n",
      "MAPE:  0.009669723237246228\n",
      "Delta:  0.16936450141761505\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.858185029521511e-05 0.00013224603995309892 nan\n",
      "Epoch: 818\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.6001922759757772\n",
      "MAPE:  0.009668714276682156\n",
      "Delta:  0.16935627337676185\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.857759244791815e-05 0.0001322400054405426 nan\n",
      "Epoch: 819\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5999806665404963\n",
      "MAPE:  0.009667705405836124\n",
      "Delta:  0.16934804645673526\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.8573370882820655e-05 0.00013223411815710406 nan\n",
      "Epoch: 820\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5997690945079879\n",
      "MAPE:  0.00966669662360672\n",
      "Delta:  0.16933982065126643\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.856911181105872e-05 0.00013222809161839155 nan\n",
      "Epoch: 821\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.599557560093591\n",
      "MAPE:  0.009665687931012301\n",
      "Delta:  0.16933159596658318\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.856488542481774e-05 0.00013222218426822696 nan\n",
      "Epoch: 822\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5993460630991327\n",
      "MAPE:  0.009664679327164428\n",
      "Delta:  0.16932337239702624\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.856062771607661e-05 0.00013221615210334825 nan\n",
      "Epoch: 823\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.599134603716788\n",
      "MAPE:  0.009663670812897436\n",
      "Delta:  0.16931514994777563\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.855641463108462e-05 0.0001322103008931652 nan\n",
      "Epoch: 824\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5989231816496619\n",
      "MAPE:  0.009662662386961918\n",
      "Delta:  0.16930692861115146\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.8552154057524e-05 0.0001322042444569238 nan\n",
      "Epoch: 825\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5987117972184872\n",
      "MAPE:  0.009661654050845663\n",
      "Delta:  0.16929870839507052\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.854791283137594e-05 0.0001321982750426276 nan\n",
      "Epoch: 826\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5985004502766047\n",
      "MAPE:  0.009660645803808621\n",
      "Delta:  0.16929048929613288\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.854370510509742e-05 0.0001321924427636345 nan\n",
      "Epoch: 827\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5982891405973239\n",
      "MAPE:  0.009659637644919816\n",
      "Delta:  0.1692822713085434\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.853942157112545e-05 0.00013218629668776405 nan\n",
      "Epoch: 828\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.598077868674792\n",
      "MAPE:  0.009658629576417067\n",
      "Delta:  0.16927405444501184\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.8535201773169945e-05 0.00013218039889051347 nan\n",
      "Epoch: 829\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5978666341046526\n",
      "MAPE:  0.009657621596572694\n",
      "Delta:  0.1692658386946244\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.8530961874071465e-05 0.00013217443953106311 nan\n",
      "Epoch: 830\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5976554369778444\n",
      "MAPE:  0.0096566137056723\n",
      "Delta:  0.1692576240606601\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.8526702215778705e-05 0.0001321683875541435 nan\n",
      "Epoch: 831\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5974442774348718\n",
      "MAPE:  0.009655605904496425\n",
      "Delta:  0.16924941054633957\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.852248782261093e-05 0.00013216250315783995 nan\n",
      "Epoch: 832\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.597233155200511\n",
      "MAPE:  0.009654598191746097\n",
      "Delta:  0.16924119814387734\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.851825194462922e-05 0.00013215654755061035 nan\n",
      "Epoch: 833\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5970220703810862\n",
      "MAPE:  0.009653590567982961\n",
      "Delta:  0.16923298685678637\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.8514010634326254e-05 0.0001321505722540195 nan\n",
      "Epoch: 834\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5968110230005832\n",
      "MAPE:  0.009652583033291482\n",
      "Delta:  0.16922477668586233\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.850975976755656e-05 0.0001321445467677984 nan\n",
      "Epoch: 835\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5966000131316749\n",
      "MAPE:  0.009651575588056393\n",
      "Delta:  0.16921656763259857\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.8505523898789704e-05 0.00013213856838745208 nan\n",
      "Epoch: 836\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5963890406916523\n",
      "MAPE:  0.009650568231949925\n",
      "Delta:  0.1692083596943332\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.850130476552472e-05 0.00013213266867728723 nan\n",
      "Epoch: 837\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5961781055474586\n",
      "MAPE:  0.009649560964215978\n",
      "Delta:  0.1692001528681108\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.849704002296562e-05 0.00013212659331773846 nan\n",
      "Epoch: 838\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5959672079720442\n",
      "MAPE:  0.009648553786438715\n",
      "Delta:  0.16919194716152527\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.849282655516873e-05 0.000132120713606243 nan\n",
      "Epoch: 839\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5957563476456347\n",
      "MAPE:  0.009647546696836725\n",
      "Delta:  0.16918374256577703\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.848859453643328e-05 0.0001321147646098364 nan\n",
      "Epoch: 840\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.595545524671391\n",
      "MAPE:  0.009646539696148832\n",
      "Delta:  0.1691755390838816\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.848433521464912e-05 0.00013210868638946494 nan\n",
      "Epoch: 841\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5953347392480521\n",
      "MAPE:  0.009645532785180178\n",
      "Delta:  0.16916733672033454\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.8480103230330585e-05 0.00013210272705588277 nan\n",
      "Epoch: 842\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5951239911784305\n",
      "MAPE:  0.00964452596316564\n",
      "Delta:  0.16915913547038713\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.8475872982289836e-05 0.00013209677605685588 nan\n",
      "Epoch: 843\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.594913280441785\n",
      "MAPE:  0.009643519229876626\n",
      "Delta:  0.16915093533362227\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.847164171495333e-05 0.00013209081219744956 nan\n",
      "Epoch: 844\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.594702607051187\n",
      "MAPE:  0.009642512585478664\n",
      "Delta:  0.16914273631008903\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.846739492936347e-05 0.00013208479053872235 nan\n",
      "Epoch: 845\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.594491971091363\n",
      "MAPE:  0.009641506030453667\n",
      "Delta:  0.16913453840228887\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.846316087192548e-05 0.000132078828650406 nan\n",
      "Epoch: 846\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5942813724595286\n",
      "MAPE:  0.009640499564207075\n",
      "Delta:  0.16912634160794526\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.845894147786911e-05 0.00013207290895567159 nan\n",
      "Epoch: 847\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5940708110809743\n",
      "MAPE:  0.009639493186461085\n",
      "Delta:  0.16911814592445493\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.845469567826832e-05 0.00013206687352051993 nan\n",
      "Epoch: 848\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5938602871327845\n",
      "MAPE:  0.009638486898207451\n",
      "Delta:  0.16910995135616047\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.8450467745819736e-05 0.00013206092034079298 nan\n",
      "Epoch: 849\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.593649800476371\n",
      "MAPE:  0.009637480698642672\n",
      "Delta:  0.1691017578999168\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.844622701172252e-05 0.00013205492883894276 nan\n",
      "Epoch: 850\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.593439351165375\n",
      "MAPE:  0.00963647458809975\n",
      "Delta:  0.1690935655577655\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.8441988052538854e-05 0.00013204893233520476 nan\n",
      "Epoch: 851\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5932289392003127\n",
      "MAPE:  0.009635468566557106\n",
      "Delta:  0.169085374329283\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.8437770330256313e-05 0.00013204298453406427 nan\n",
      "Epoch: 852\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5930185644961345\n",
      "MAPE:  0.009634462633735897\n",
      "Delta:  0.16907718421075502\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.843352831751524e-05 0.00013203698458397195 nan\n",
      "Epoch: 853\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5928082271284922\n",
      "MAPE:  0.009633456790046381\n",
      "Delta:  0.1690689952061657\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.8429273437067266e-05 0.00013203092022240348 nan\n",
      "Epoch: 854\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5925979271925268\n",
      "MAPE:  0.00963245103577508\n",
      "Delta:  0.16906080731756712\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.842507902591553e-05 0.00013202508499376986 nan\n",
      "Epoch: 855\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5923876643158283\n",
      "MAPE:  0.009631445369292991\n",
      "Delta:  0.1690526205346126\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.842082803735437e-05 0.00013201904299131595 nan\n",
      "Epoch: 856\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.592177438820314\n",
      "MAPE:  0.009630439792181563\n",
      "Delta:  0.16904443486674442\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.841659763177297e-05 0.0001320130605254599 nan\n",
      "Epoch: 857\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.591967250603716\n",
      "MAPE:  0.009629434303934334\n",
      "Delta:  0.1690362503103596\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.841236266639459e-05 0.00013200705149307712 nan\n",
      "Epoch: 858\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.59175709970089\n",
      "MAPE:  0.009628428904784266\n",
      "Delta:  0.1690280668661058\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.840813895001794e-05 0.00013200111429756411 nan\n",
      "Epoch: 859\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5915469859900384\n",
      "MAPE:  0.009627423594050962\n",
      "Delta:  0.1690198845319585\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.8403900982152415e-05 0.0001319951048563972 nan\n",
      "Epoch: 860\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5913369095787389\n",
      "MAPE:  0.009626418372450244\n",
      "Delta:  0.1690117033102036\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.839966381009475e-05 0.0001319890824140746 nan\n",
      "Epoch: 861\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.591126870480232\n",
      "MAPE:  0.009625413239922317\n",
      "Delta:  0.16900352320058343\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.839544002477325e-05 0.000131983133238478 nan\n",
      "Epoch: 862\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5909168685704862\n",
      "MAPE:  0.009624408196014185\n",
      "Delta:  0.16899534420071238\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.839120466537672e-05 0.00013197711944679114 nan\n",
      "Epoch: 863\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5907069039448931\n",
      "MAPE:  0.009623403241149221\n",
      "Delta:  0.1689871663124237\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.838698674247688e-05 0.00013197119378793865 nan\n",
      "Epoch: 864\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5904969764558128\n",
      "MAPE:  0.009622398374617008\n",
      "Delta:  0.16897898953264767\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.838274273477605e-05 0.00013196513767144147 nan\n",
      "Epoch: 865\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5902870863033487\n",
      "MAPE:  0.009621393597369486\n",
      "Delta:  0.16897081386566953\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.837851196248799e-05 0.00013195914716235269 nan\n",
      "Epoch: 866\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5900772333756967\n",
      "MAPE:  0.009620388909026053\n",
      "Delta:  0.1689626393091296\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.837430118165287e-05 0.000131953264836282 nan\n",
      "Epoch: 867\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.589867417493411\n",
      "MAPE:  0.009619384308635107\n",
      "Delta:  0.16895446585952723\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.837004497404429e-05 0.00013194713023723104 nan\n",
      "Epoch: 868\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5896576390502153\n",
      "MAPE:  0.009618379798159297\n",
      "Delta:  0.16894629352441504\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.8365824172669214e-05 0.00013194119113435487 nan\n",
      "Epoch: 869\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.589447897727823\n",
      "MAPE:  0.00961737537605802\n",
      "Delta:  0.16893812229768781\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.836160400178979e-05 0.0001319352365060089 nan\n",
      "Epoch: 870\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5892381935435225\n",
      "MAPE:  0.009616392132929008\n",
      "Delta:  0.16892995217911644\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.835739384245752e-05 0.0001319293180029879 nan\n",
      "Epoch: 871\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.589028526432504\n",
      "MAPE:  0.009615483631486411\n",
      "Delta:  0.16892178316688714\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.835313988893475e-05 0.00013192321522959016 nan\n",
      "Epoch: 872\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5888188966802055\n",
      "MAPE:  0.00961457521112056\n",
      "Delta:  0.1689136152682754\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.8348914813534094e-05 0.0001319172529973267 nan\n",
      "Epoch: 873\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.588609304055845\n",
      "MAPE:  0.009613666870701882\n",
      "Delta:  0.16890544847827993\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.8344682571643816e-05 0.00013191123908207203 nan\n",
      "Epoch: 874\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5883997486341297\n",
      "MAPE:  0.009612758610747289\n",
      "Delta:  0.16889728279798866\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.8340448938977154e-05 0.00013190520420180984 nan\n",
      "Epoch: 875\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.588190230440932\n",
      "MAPE:  0.009611850431411417\n",
      "Delta:  0.16888911822751362\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.833624197808639e-05 0.00013189930783663595 nan\n",
      "Epoch: 876\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5879807492488238\n",
      "MAPE:  0.009610942331509668\n",
      "Delta:  0.1688809547622275\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.833200627429868e-05 0.00013189328444895843 nan\n",
      "Epoch: 877\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5877713052521638\n",
      "MAPE:  0.009610034312149325\n",
      "Delta:  0.16887279240686232\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.832776929386551e-05 0.0001318872242765945 nan\n",
      "Epoch: 878\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.587561898501928\n",
      "MAPE:  0.00960912637348555\n",
      "Delta:  0.16886463116151085\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.8323559012630746e-05 0.00013188132948860343 nan\n",
      "Epoch: 879\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5873525287281083\n",
      "MAPE:  0.009608218514228143\n",
      "Delta:  0.16885647102154178\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.8319331796942144e-05 0.00013187530739600106 nan\n",
      "Epoch: 880\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5871431961254363\n",
      "MAPE:  0.009607310735409874\n",
      "Delta:  0.16884831198969244\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.831509723335348e-05 0.00013186928842845447 nan\n",
      "Epoch: 881\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5869339006815293\n",
      "MAPE:  0.009606403037198438\n",
      "Delta:  0.16884015406708097\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.831086561585263e-05 0.000131863254398068 nan\n",
      "Epoch: 882\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5867246424128707\n",
      "MAPE:  0.009605495419177339\n",
      "Delta:  0.16883199725308728\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.830664709709609e-05 0.00013185729470943652 nan\n",
      "Epoch: 883\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5865154211940735\n",
      "MAPE:  0.009604587881178073\n",
      "Delta:  0.1688238415453773\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.830241944520086e-05 0.00013185129027082354 nan\n",
      "Epoch: 884\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5863062370887544\n",
      "MAPE:  0.009603680423387828\n",
      "Delta:  0.16881568694537064\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.829819326290785e-05 0.0001318452869036868 nan\n",
      "Epoch: 885\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5860970900878084\n",
      "MAPE:  0.009602773045861225\n",
      "Delta:  0.16880753345269672\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.829397427852378e-05 0.00013183930406757138 nan\n",
      "Epoch: 886\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5858879801512675\n",
      "MAPE:  0.009601865748407276\n",
      "Delta:  0.16879938106601813\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.828975499071575e-05 0.00013183334159649895 nan\n",
      "Epoch: 887\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5856789072394466\n",
      "MAPE:  0.009600958530850466\n",
      "Delta:  0.16879122978526387\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.828552383362439e-05 0.0001318273040158413 nan\n",
      "Epoch: 888\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5854698714640705\n",
      "MAPE:  0.009600051393713538\n",
      "Delta:  0.16878307961231517\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.828129058243036e-05 0.00013182127000199717 nan\n",
      "Epoch: 889\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.585260872812064\n",
      "MAPE:  0.009599144337021064\n",
      "Delta:  0.168774930547403\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.8277074047642365e-05 0.0001318152881731871 nan\n",
      "Epoch: 890\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5850519111932846\n",
      "MAPE:  0.009598237360254874\n",
      "Delta:  0.1687667825875836\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.827285455111241e-05 0.00013180932088385777 nan\n",
      "Epoch: 891\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5848429865773046\n",
      "MAPE:  0.009597330463445868\n",
      "Delta:  0.16875863573323469\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.82686342891947e-05 0.0001318033186495926 nan\n",
      "Epoch: 892\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5846340990121353\n",
      "MAPE:  0.00959642364676219\n",
      "Delta:  0.16875048998436332\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.8264409851617174e-05 0.00013179730868684292 nan\n",
      "Epoch: 893\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5844252485026322\n",
      "MAPE:  0.00959551691030254\n",
      "Delta:  0.16874234534155205\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.8260163541424816e-05 0.00013179121070561184 nan\n",
      "Epoch: 894\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5842164351808594\n",
      "MAPE:  0.009594610254575519\n",
      "Delta:  0.1687342018083695\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.825596233293261e-05 0.00013178530694757384 nan\n",
      "Epoch: 895\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5840076587316778\n",
      "MAPE:  0.009593703678227403\n",
      "Delta:  0.16872605937708274\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.825173316114206e-05 0.0001317792576103205 nan\n",
      "Epoch: 896\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.583798919378361\n",
      "MAPE:  0.009592797182387612\n",
      "Delta:  0.16871791805228836\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.8247530752276724e-05 0.0001317733516713604 nan\n",
      "Epoch: 897\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5835902168863811\n",
      "MAPE:  0.009591890765937928\n",
      "Delta:  0.16870977782934868\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.824329735664268e-05 0.00013176727504737862 nan\n",
      "Epoch: 898\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5833815515187104\n",
      "MAPE:  0.009590984430070329\n",
      "Delta:  0.16870163871336988\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.823905425199726e-05 0.0001317611844403599 nan\n",
      "Epoch: 899\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5831729232900613\n",
      "MAPE:  0.009590078174915325\n",
      "Delta:  0.16869350070586758\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.8234849381323386e-05 0.00013175525893116546 nan\n",
      "Epoch: 900\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5829643319316204\n",
      "MAPE:  0.009589171999214718\n",
      "Delta:  0.16868536380026944\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.823064611059191e-05 0.0001317493233283784 nan\n",
      "Epoch: 901\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5827557774520353\n",
      "MAPE:  0.009588265903038878\n",
      "Delta:  0.16867722799618393\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.822639940194051e-05 0.00013174319924114108 nan\n",
      "Epoch: 902\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5825472601422963\n",
      "MAPE:  0.009587359887854611\n",
      "Delta:  0.16866909330081659\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.822218061673045e-05 0.0001317372111453441 nan\n",
      "Epoch: 903\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5823387797797395\n",
      "MAPE:  0.009586453952470566\n",
      "Delta:  0.16866095970933495\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.821796761000918e-05 0.00013173122899867717 nan\n",
      "Epoch: 904\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.582130336347587\n",
      "MAPE:  0.009585548097136291\n",
      "Delta:  0.16865282722064262\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.8213756091763926e-05 0.0001317252466337404 nan\n",
      "Epoch: 905\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.581921929838825\n",
      "MAPE:  0.009584642321548606\n",
      "Delta:  0.1686446958343668\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.820953773909675e-05 0.00013171925135235796 nan\n",
      "Epoch: 906\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5817135602665287\n",
      "MAPE:  0.009583736625925382\n",
      "Delta:  0.1686365655515385\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.820529063098711e-05 0.0001317131234661595 nan\n",
      "Epoch: 907\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.581505227833077\n",
      "MAPE:  0.009582831011130388\n",
      "Delta:  0.16862843637688507\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.8201087189170266e-05 0.00013170717426458367 nan\n",
      "Epoch: 908\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5812969322484345\n",
      "MAPE:  0.009581925475967664\n",
      "Delta:  0.16862030830292069\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.819687968316e-05 0.0001317012198686074 nan\n",
      "Epoch: 909\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5810886735134828\n",
      "MAPE:  0.00958102002036149\n",
      "Delta:  0.16861218133020928\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.819264710043125e-05 0.0001316951434476854 nan\n",
      "Epoch: 910\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5808804518138209\n",
      "MAPE:  0.009580114645333312\n",
      "Delta:  0.1686040554628576\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.818843375486992e-05 0.00013168915886807575 nan\n",
      "Epoch: 911\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5806722669968505\n",
      "MAPE:  0.009579209349949533\n",
      "Delta:  0.16859593069750012\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.818422234820208e-05 0.000131683177727826 nan\n",
      "Epoch: 912\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5804641190497861\n",
      "MAPE:  0.009578304134475241\n",
      "Delta:  0.16858780703368836\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.818000158246516e-05 0.00013167713385142665 nan\n",
      "Epoch: 913\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5802560080644348\n",
      "MAPE:  0.009577398999177816\n",
      "Delta:  0.16857968447287872\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.8175782028092584e-05 0.0001316711285845873 nan\n",
      "Epoch: 914\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5800479339724003\n",
      "MAPE:  0.009576493943736868\n",
      "Delta:  0.16857156301474518\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.8171547017861194e-05 0.00013166503342298963 nan\n",
      "Epoch: 915\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5798398969083638\n",
      "MAPE:  0.009575588968963072\n",
      "Delta:  0.16856344266177153\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.8167355069184126e-05 0.0001316591318516469 nan\n",
      "Epoch: 916\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5796318965590723\n",
      "MAPE:  0.009574684073284778\n",
      "Delta:  0.16855532340657717\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.8163125306088794e-05 0.00013165304378426335 nan\n",
      "Epoch: 917\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5794239332118316\n",
      "MAPE:  0.009573779258041018\n",
      "Delta:  0.16854720525541492\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.81589172135477e-05 0.0001316470855613483 nan\n",
      "Epoch: 918\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5792160066541583\n",
      "MAPE:  0.0095728745223794\n",
      "Delta:  0.16853908820451047\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.8154697416036285e-05 0.0001316410516796207 nan\n",
      "Epoch: 919\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.579008116998213\n",
      "MAPE:  0.009571969866787626\n",
      "Delta:  0.1685309722557152\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.815048240958131e-05 0.0001316350277524858 nan\n",
      "Epoch: 920\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5788002642209107\n",
      "MAPE:  0.009571065291262174\n",
      "Delta:  0.16852285740810014\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.814625637927783e-05 0.000131628970159281 nan\n",
      "Epoch: 921\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.578592448368044\n",
      "MAPE:  0.009570160795888941\n",
      "Delta:  0.16851474366340158\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.814205564118712e-05 0.00013162302024061212 nan\n",
      "Epoch: 922\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5783846692622607\n",
      "MAPE:  0.00956925637986318\n",
      "Delta:  0.1685066310172358\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.8137822515670337e-05 0.00013161692808383307 nan\n",
      "Epoch: 923\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.578176927120758\n",
      "MAPE:  0.009568352044424508\n",
      "Delta:  0.16849851947493916\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.813362067535021e-05 0.00013161096121616644 nan\n",
      "Epoch: 924\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5779692217384103\n",
      "MAPE:  0.009567447788456035\n",
      "Delta:  0.1684904090311184\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.812941487275513e-05 0.0001316049832290611 nan\n",
      "Epoch: 925\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5777615531254474\n",
      "MAPE:  0.009566543612160913\n",
      "Delta:  0.16848229968632006\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.8125188796932505e-05 0.0001315988995977957 nan\n",
      "Epoch: 926\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5775539214412284\n",
      "MAPE:  0.009565639516166645\n",
      "Delta:  0.1684741914438387\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.812096230000229e-05 0.00013159284583519337 nan\n",
      "Epoch: 927\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5773463266312475\n",
      "MAPE:  0.009564735500273322\n",
      "Delta:  0.16846608430362373\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.811676399896214e-05 0.0001315868905397144 nan\n",
      "Epoch: 928\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.577138768532822\n",
      "MAPE:  0.009563831563766273\n",
      "Delta:  0.16845797826080344\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.811254621051031e-05 0.0001315808504503968 nan\n",
      "Epoch: 929\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.57693124727238\n",
      "MAPE:  0.00956292770738021\n",
      "Delta:  0.16844987331853986\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.81083277182881e-05 0.0001315747997444605 nan\n",
      "Epoch: 930\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5767237628593094\n",
      "MAPE:  0.009562023931016843\n",
      "Delta:  0.16844176947683015\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.8104123239745e-05 0.00013156881843634505 nan\n",
      "Epoch: 931\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5765163151768293\n",
      "MAPE:  0.009561120234185462\n",
      "Delta:  0.16843366673319252\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.8099907663967656e-05 0.0001315627904597827 nan\n",
      "Epoch: 932\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5763089042911993\n",
      "MAPE:  0.00956021661726048\n",
      "Delta:  0.16842556508937515\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.809569272901104e-05 0.00013155675552234403 nan\n",
      "Epoch: 933\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.57610153020605\n",
      "MAPE:  0.009559313080334331\n",
      "Delta:  0.16841746454514891\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.809147290241178e-05 0.00013155069933601382 nan\n",
      "Epoch: 934\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5758941929475268\n",
      "MAPE:  0.009558409623371171\n",
      "Delta:  0.16840936510121643\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.808725667815317e-05 0.0001315446398287845 nan\n",
      "Epoch: 935\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5756868925135072\n",
      "MAPE:  0.00955750624663955\n",
      "Delta:  0.1684012667568498\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.808307717274474e-05 0.00013153876135441056 nan\n",
      "Epoch: 936\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5754796286113837\n",
      "MAPE:  0.00955660294848042\n",
      "Delta:  0.16839316950574434\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.807884394764095e-05 0.00013153265855025964 nan\n",
      "Epoch: 937\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5752724015873405\n",
      "MAPE:  0.009555699730805143\n",
      "Delta:  0.16838507335682582\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.807462695932685e-05 0.00013152660699500274 nan\n",
      "Epoch: 938\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5750652113532668\n",
      "MAPE:  0.0095547965930899\n",
      "Delta:  0.16837697830723866\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.807044179466757e-05 0.00013152068589306065 nan\n",
      "Epoch: 939\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5748580576963436\n",
      "MAPE:  0.009553893534521497\n",
      "Delta:  0.16836888435150338\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.8066200049268204e-05 0.00013151452151716203 nan\n",
      "Epoch: 940\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.574650940992428\n",
      "MAPE:  0.00955299055668674\n",
      "Delta:  0.16836079149902605\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.806199556928181e-05 0.0001315085151344375 nan\n",
      "Epoch: 941\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5744438609853233\n",
      "MAPE:  0.009552087658508844\n",
      "Delta:  0.168352699743411\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.80577895684009e-05 0.000131502526344085 nan\n",
      "Epoch: 942\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5742368176400168\n",
      "MAPE:  0.00955118483970612\n",
      "Delta:  0.16834460908479346\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.805357244108688e-05 0.00013149645043564195 nan\n",
      "Epoch: 943\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.574029811086352\n",
      "MAPE:  0.00955028210102212\n",
      "Delta:  0.16833651952492573\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.804938600033726e-05 0.00013149053703853664 nan\n",
      "Epoch: 944\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5738228410611776\n",
      "MAPE:  0.009549379441472956\n",
      "Delta:  0.16832843105852113\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.8045153460685164e-05 0.0001314843914137498 nan\n",
      "Epoch: 945\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5736159079227277\n",
      "MAPE:  0.009548476862295444\n",
      "Delta:  0.16832034369321913\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.8040959719664045e-05 0.00013147843335781229 nan\n",
      "Epoch: 946\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5734090113684471\n",
      "MAPE:  0.009547574362592638\n",
      "Delta:  0.16831225742236777\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.803673344166981e-05 0.00013147233812571546 nan\n",
      "Epoch: 947\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5732021516068944\n",
      "MAPE:  0.009546671942933306\n",
      "Delta:  0.168304172251323\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.803253666429974e-05 0.00013146634468341745 nan\n",
      "Epoch: 948\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5729953284705747\n",
      "MAPE:  0.009545769602748983\n",
      "Delta:  0.16829608817499858\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.802832478334462e-05 0.00013146031447430762 nan\n",
      "Epoch: 949\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5727885420100272\n",
      "MAPE:  0.009544867342284978\n",
      "Delta:  0.16828800519581594\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.802410564286319e-05 0.00013145421921545442 nan\n",
      "Epoch: 950\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5725817923202463\n",
      "MAPE:  0.009543965162137319\n",
      "Delta:  0.16827992331487598\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.801991071368139e-05 0.0001314482570451414 nan\n",
      "Epoch: 951\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5723750791845847\n",
      "MAPE:  0.009543063061026624\n",
      "Delta:  0.1682718425279835\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.801570132006994e-05 0.00013144221051508698 nan\n",
      "Epoch: 952\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.572168402728418\n",
      "MAPE:  0.009542161039836568\n",
      "Delta:  0.1682637628374521\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.8011507924661245e-05 0.0001314362331589214 nan\n",
      "Epoch: 953\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.571961762835672\n",
      "MAPE:  0.009541259097877659\n",
      "Delta:  0.1682556842404692\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.800725603504308e-05 0.00013143000632009905 nan\n",
      "Epoch: 954\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5717551598912474\n",
      "MAPE:  0.009540357236978186\n",
      "Delta:  0.1682476067467565\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.800308402719278e-05 0.00013142412879463272 nan\n",
      "Epoch: 955\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5715485933386804\n",
      "MAPE:  0.009539455454677772\n",
      "Delta:  0.16823953034275246\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.7998860368103635e-05 0.000131418019480245 nan\n",
      "Epoch: 956\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5713420635350266\n",
      "MAPE:  0.009538553752626218\n",
      "Delta:  0.16823145503702716\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.799467803007218e-05 0.0001314120874051916 nan\n",
      "Epoch: 957\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.57113557019443\n",
      "MAPE:  0.009537652129518334\n",
      "Delta:  0.16822338082250812\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.7990448834300814e-05 0.00013140595241623032 nan\n",
      "Epoch: 958\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5709291136284538\n",
      "MAPE:  0.009536750586742823\n",
      "Delta:  0.16821530770695803\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.798626245661186e-05 0.00013139999044309292 nan\n",
      "Epoch: 959\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5707226935579361\n",
      "MAPE:  0.009535849123101172\n",
      "Delta:  0.16820723568305318\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.798203678646473e-05 0.0001313938731583031 nan\n",
      "Epoch: 960\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5705163102195718\n",
      "MAPE:  0.00953494773970281\n",
      "Delta:  0.16819916475728292\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.797785187260484e-05 0.00013138792983213854 nan\n",
      "Epoch: 961\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5703099633328046\n",
      "MAPE:  0.009534046435193047\n",
      "Delta:  0.1681910949226711\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.797363776254393e-05 0.00013138184084682258 nan\n",
      "Epoch: 962\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5701036531191217\n",
      "MAPE:  0.009533145210822535\n",
      "Delta:  0.16818302618400838\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.7969418348503545e-05 0.00013137574874588775 nan\n",
      "Epoch: 963\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5698973795760844\n",
      "MAPE:  0.009532244066378794\n",
      "Delta:  0.16817495854206624\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.796522583805363e-05 0.00013136975834127096 nan\n",
      "Epoch: 964\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.569691142536709\n",
      "MAPE:  0.009531343001333141\n",
      "Delta:  0.16816689199219947\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.7961017490938396e-05 0.000131363719106381 nan\n",
      "Epoch: 965\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5694849420703771\n",
      "MAPE:  0.009530442015679418\n",
      "Delta:  0.16815882653695124\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.795683309333221e-05 0.00013135773422146002 nan\n",
      "Epoch: 966\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5692787780844921\n",
      "MAPE:  0.00952954110937208\n",
      "Delta:  0.16815076217217384\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.795260212686614e-05 0.00013135160030330884 nan\n",
      "Epoch: 967\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5690726508056687\n",
      "MAPE:  0.009528640283296674\n",
      "Delta:  0.16814269890557806\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.794840984634341e-05 0.00013134559572336446 nan\n",
      "Epoch: 968\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5688665600236154\n",
      "MAPE:  0.009527739536583126\n",
      "Delta:  0.16813463673053827\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.794419384102078e-05 0.00013133950511634573 nan\n",
      "Epoch: 969\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5686605058660283\n",
      "MAPE:  0.009526838869874824\n",
      "Delta:  0.16812657565092348\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.794001419694549e-05 0.0001313335456938347 nan\n",
      "Epoch: 970\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.568454488119803\n",
      "MAPE:  0.009525938282167133\n",
      "Delta:  0.16811851566049987\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.793580277406839e-05 0.0001313274682811505 nan\n",
      "Epoch: 971\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5682485069627639\n",
      "MAPE:  0.009525037774158343\n",
      "Delta:  0.16811045676449052\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.793159918325962e-05 0.00013132144012883984 nan\n",
      "Epoch: 972\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5680425623103496\n",
      "MAPE:  0.00952413734566752\n",
      "Delta:  0.16810239896145837\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.792738895376125e-05 0.00013131534258659094 nan\n",
      "Epoch: 973\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5678366542640896\n",
      "MAPE:  0.009523236997129567\n",
      "Delta:  0.16809434225239928\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.792319441349058e-05 0.0001313093500088236 nan\n",
      "Epoch: 974\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.567630782652098\n",
      "MAPE:  0.00952233672769242\n",
      "Delta:  0.16808628663455571\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.7918988193784706e-05 0.00013130327499399908 nan\n",
      "Epoch: 975\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5674249475963546\n",
      "MAPE:  0.009521436538113045\n",
      "Delta:  0.16807823210977094\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.7914780475499796e-05 0.00013129720801230427 nan\n",
      "Epoch: 976\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5672191490769665\n",
      "MAPE:  0.009520536428236456\n",
      "Delta:  0.1680701786781767\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.791059400643949e-05 0.00013129121588473236 nan\n",
      "Epoch: 977\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5670133869693261\n",
      "MAPE:  0.009519636397495118\n",
      "Delta:  0.16806212633608145\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.7906391825502936e-05 0.00013128516915661415 nan\n",
      "Epoch: 978\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5668076613517474\n",
      "MAPE:  0.009518736446207769\n",
      "Delta:  0.16805407508600617\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.790219102246418e-05 0.00013127911785970614 nan\n",
      "Epoch: 979\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5666019722241094\n",
      "MAPE:  0.009517836574585718\n",
      "Delta:  0.1680460249275993\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.789797071436119e-05 0.00013127298448623037 nan\n",
      "Epoch: 980\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5663963197077135\n",
      "MAPE:  0.009516936783076439\n",
      "Delta:  0.16803797586401864\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.789377843417153e-05 0.0001312669783396503 nan\n",
      "Epoch: 981\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.566190703595943\n",
      "MAPE:  0.00951603707069382\n",
      "Delta:  0.16802992789043408\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.788960147461552e-05 0.0001312610151843474 nan\n",
      "Epoch: 982\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5659851238142168\n",
      "MAPE:  0.009515137437298994\n",
      "Delta:  0.1680218810041516\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.788537729261133e-05 0.00013125487102272348 nan\n",
      "Epoch: 983\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.565779580638767\n",
      "MAPE:  0.009514237883994433\n",
      "Delta:  0.1680138352129863\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.7881186545639665e-05 0.00013124886569326755 nan\n",
      "Epoch: 984\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5655740738448825\n",
      "MAPE:  0.009513338409800617\n",
      "Delta:  0.16800579051120024\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.7876968597759806e-05 0.00013124272198594689 nan\n",
      "Epoch: 985\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5653686036419605\n",
      "MAPE:  0.009512439015839981\n",
      "Delta:  0.16799774690324368\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.787280690798923e-05 0.00013123683231752725 nan\n",
      "Epoch: 986\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5651631696250092\n",
      "MAPE:  0.009511539700263237\n",
      "Delta:  0.1679897043795452\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.786858546745876e-05 0.00013123069129961085 nan\n",
      "Epoch: 987\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5649577721802626\n",
      "MAPE:  0.009510640464695196\n",
      "Delta:  0.16798166295002345\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.7864381179874016e-05 0.00013122460180448048 nan\n",
      "Epoch: 988\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5647524112197675\n",
      "MAPE:  0.009509741308969696\n",
      "Delta:  0.16797362261167678\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.786019187286161e-05 0.00013121859621134657 nan\n",
      "Epoch: 989\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.564547086604949\n",
      "MAPE:  0.009508842232158829\n",
      "Delta:  0.167965583361869\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.78559790799693e-05 0.00013121247940850456 nan\n",
      "Epoch: 990\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.564341798502564\n",
      "MAPE:  0.009507943235445583\n",
      "Delta:  0.1679575452044255\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.785180637101316e-05 0.0001312065299199361 nan\n",
      "Epoch: 991\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5641365466435737\n",
      "MAPE:  0.009507044317354753\n",
      "Delta:  0.16794950813249382\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.784759528364546e-05 0.0001312004238831488 nan\n",
      "Epoch: 992\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5639313312656429\n",
      "MAPE:  0.00950614547896038\n",
      "Delta:  0.16794147215240063\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.7843404833214365e-05 0.00013119438153308405 nan\n",
      "Epoch: 993\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5637261522618773\n",
      "MAPE:  0.00950524672010322\n",
      "Delta:  0.16793343726056015\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.783919354178767e-05 0.00013118827440894432 nan\n",
      "Epoch: 994\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.563521009726314\n",
      "MAPE:  0.009504348040954763\n",
      "Delta:  0.1679254034603529\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.7834997704332416e-05 0.00013118223081232117 nan\n",
      "Epoch: 995\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5633159035523363\n",
      "MAPE:  0.00950344944111256\n",
      "Delta:  0.16791737074906388\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.783081689330171e-05 0.00013117623842251458 nan\n",
      "Epoch: 996\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.563110833652642\n",
      "MAPE:  0.009502550920159952\n",
      "Delta:  0.16790933912405037\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.7826615635182534e-05 0.000131170147781412 nan\n",
      "Epoch: 997\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5629058001735932\n",
      "MAPE:  0.00950165247896306\n",
      "Delta:  0.16790130858862654\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.782242509515644e-05 0.00013116412563562996 nan\n",
      "Epoch: 998\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5627008030008627\n",
      "MAPE:  0.00950075411681111\n",
      "Delta:  0.16789327914087318\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.781822157196025e-05 0.00013115802123175868 nan\n",
      "Epoch: 999\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5624958422557638\n",
      "MAPE:  0.009499855834444142\n",
      "Delta:  0.16788525078285077\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.781401759490489e-05 0.00013115194211732462 nan\n",
      "Epoch: 1000\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5622909178915017\n",
      "MAPE:  0.009498957631523286\n",
      "Delta:  0.16787722351451592\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.7809828216505146e-05 0.00013114589257445797 nan\n",
      "Epoch: 1001\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5620860298546138\n",
      "MAPE:  0.009498059507966674\n",
      "Delta:  0.16786919733329822\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.780565485917876e-05 0.00013113992049995638 nan\n",
      "Epoch: 1002\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5618811780168445\n",
      "MAPE:  0.009497161463133511\n",
      "Delta:  0.16786117223638902\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.780143194804687e-05 0.0001311337558992376 nan\n",
      "Epoch: 1003\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5616763626717027\n",
      "MAPE:  0.009496263498420584\n",
      "Delta:  0.16785314823198763\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.779723533498981e-05 0.0001311276881176271 nan\n",
      "Epoch: 1004\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5614715836606778\n",
      "MAPE:  0.009495365613038627\n",
      "Delta:  0.16784512531555987\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.779304768798287e-05 0.00013112164693629413 nan\n",
      "Epoch: 1005\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.561266840934984\n",
      "MAPE:  0.009494467806982643\n",
      "Delta:  0.16783710348548148\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.77888631889023e-05 0.00013111561732093158 nan\n",
      "Epoch: 1006\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.561062134469332\n",
      "MAPE:  0.009493570079896615\n",
      "Delta:  0.16782908274110497\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.7784659873872926e-05 0.00013110953262041036 nan\n",
      "Epoch: 1007\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5608574643424902\n",
      "MAPE:  0.009492672432351528\n",
      "Delta:  0.16782106308546926\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.778048186682149e-05 0.0001311035142828043 nan\n",
      "Epoch: 1008\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5606528304436205\n",
      "MAPE:  0.009491774863917292\n",
      "Delta:  0.16781304451420764\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.7776267255494886e-05 0.00013109735911265297 nan\n",
      "Epoch: 1009\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5604482329790574\n",
      "MAPE:  0.00949087737529573\n",
      "Delta:  0.16780502703334396\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.777208523842891e-05 0.00013109134262712097 nan\n",
      "Epoch: 1010\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5602436717250963\n",
      "MAPE:  0.009489979965768374\n",
      "Delta:  0.16779701063728908\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.776789892835254e-05 0.00013108532305572407 nan\n",
      "Epoch: 1011\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5600391466793424\n",
      "MAPE:  0.009489082635103462\n",
      "Delta:  0.16778899532664449\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.776368685643906e-05 0.00013107916226295924 nan\n",
      "Epoch: 1012\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5598346580548983\n",
      "MAPE:  0.00948818538440215\n",
      "Delta:  0.16778098110561374\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.775950960289599e-05 0.00013107315172855571 nan\n",
      "Epoch: 1013\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5596302056100917\n",
      "MAPE:  0.009487288212847155\n",
      "Delta:  0.16777296796823543\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.775532150258499e-05 0.00013106712660226894 nan\n",
      "Epoch: 1014\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5594257893604802\n",
      "MAPE:  0.009486391119993802\n",
      "Delta:  0.16776495591621066\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.775113011568077e-05 0.0001310610368115972 nan\n",
      "Epoch: 1015\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.559221409399696\n",
      "MAPE:  0.009485494106682701\n",
      "Delta:  0.16775694494997184\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.774692277664805e-05 0.00013105491029530292 nan\n",
      "Epoch: 1016\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5590170657777565\n",
      "MAPE:  0.009484597173057146\n",
      "Delta:  0.16774893507207608\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.774274654484323e-05 0.0001310489051969954 nan\n",
      "Epoch: 1017\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.558812758298103\n",
      "MAPE:  0.009483700318343514\n",
      "Delta:  0.16774092627718576\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.77385637828176e-05 0.00013104286200349424 nan\n",
      "Epoch: 1018\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5586084870129282\n",
      "MAPE:  0.00948280354264824\n",
      "Delta:  0.1677329185662777\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.773434982241476e-05 0.00013103669863645528 nan\n",
      "Epoch: 1019\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5584042521023231\n",
      "MAPE:  0.009481906846843182\n",
      "Delta:  0.16772491194446612\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.773017544579261e-05 0.00013103071490716545 nan\n",
      "Epoch: 1020\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5582000532790559\n",
      "MAPE:  0.009481010229632054\n",
      "Delta:  0.16771690640499237\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.77259861143553e-05 0.00013102461768055296 nan\n",
      "Epoch: 1021\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.557995890712805\n",
      "MAPE:  0.009480113691951854\n",
      "Delta:  0.16770890195024615\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.772177844813985e-05 0.0001310185023759569 nan\n",
      "Epoch: 1022\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.557791764424496\n",
      "MAPE:  0.009479217233693112\n",
      "Delta:  0.1677008985831835\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.771759585242563e-05 0.00013101243823676612 nan\n",
      "Epoch: 1023\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5575876743271735\n",
      "MAPE:  0.009478320854631545\n",
      "Delta:  0.1676928962994808\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.771342128462308e-05 0.00013100644406849327 nan\n",
      "Epoch: 1024\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.557383620304635\n",
      "MAPE:  0.009477424554269843\n",
      "Delta:  0.16768489509767326\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.7709224955894136e-05 0.00013100032095092473 nan\n",
      "Epoch: 1025\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5571796025505313\n",
      "MAPE:  0.009476528333580052\n",
      "Delta:  0.16767689498129135\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.770502438578017e-05 0.00013099421564954916 nan\n",
      "Epoch: 1026\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5569756210298697\n",
      "MAPE:  0.009475632192145375\n",
      "Delta:  0.16766889595092732\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.770084953542586e-05 0.00013098819832524367 nan\n",
      "Epoch: 1027\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5567716755984349\n",
      "MAPE:  0.009474736129580285\n",
      "Delta:  0.16766089800214978\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.769665867720985e-05 0.00013098211295581308 nan\n",
      "Epoch: 1028\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5565677663549753\n",
      "MAPE:  0.009473840146403333\n",
      "Delta:  0.1676529011375243\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.769245878788464e-05 0.00013097597866706945 nan\n",
      "Epoch: 1029\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5563638933684152\n",
      "MAPE:  0.009472944242679292\n",
      "Delta:  0.16764490535844612\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.7688291620606726e-05 0.00013096999001582788 nan\n",
      "Epoch: 1030\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.55616005640484\n",
      "MAPE:  0.009472048417572243\n",
      "Delta:  0.16763691065931066\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.768410093480835e-05 0.0001309639073554525 nan\n",
      "Epoch: 1031\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5559562556033826\n",
      "MAPE:  0.009471152671677596\n",
      "Delta:  0.1676289170439424\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.7679909576991975e-05 0.00013095781949079566 nan\n",
      "Epoch: 1032\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5557524909649256\n",
      "MAPE:  0.0094702570049149\n",
      "Delta:  0.16762092451233523\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.7675713715333856e-05 0.00013095170002874745 nan\n",
      "Epoch: 1033\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.55554876253141\n",
      "MAPE:  0.00946936141776883\n",
      "Delta:  0.16761293306512548\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.76715284850604e-05 0.00013094564656235264 nan\n",
      "Epoch: 1034\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.555345070192941\n",
      "MAPE:  0.009468465909477437\n",
      "Delta:  0.1676049427004124\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.766734657324356e-05 0.00013093957082976893 nan\n",
      "Epoch: 1035\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5551414139769577\n",
      "MAPE:  0.009467570480472984\n",
      "Delta:  0.16759695341752132\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.76631650505599e-05 0.00013093349963200218 nan\n",
      "Epoch: 1036\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.554937793869203\n",
      "MAPE:  0.009466675130480749\n",
      "Delta:  0.1675889652162686\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.765897103398142e-05 0.00013092741924225493 nan\n",
      "Epoch: 1037\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5547342098767696\n",
      "MAPE:  0.009465779859582033\n",
      "Delta:  0.16758097809862973\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.7654787685647015e-05 0.00013092133305481202 nan\n",
      "Epoch: 1038\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5545306620014667\n",
      "MAPE:  0.009464884667892633\n",
      "Delta:  0.1675729920626983\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.7650605191074114e-05 0.00013091527111863677 nan\n",
      "Epoch: 1039\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5543271501983886\n",
      "MAPE:  0.009463989555092138\n",
      "Delta:  0.16756500710821284\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.764642377497186e-05 0.00013090920444192022 nan\n",
      "Epoch: 1040\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5541236744677136\n",
      "MAPE:  0.009463094521417125\n",
      "Delta:  0.1675570232348743\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.7642235286748935e-05 0.00013090310389907156 nan\n",
      "Epoch: 1041\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5539202348548828\n",
      "MAPE:  0.009462199566929548\n",
      "Delta:  0.1675490404437494\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.7638032524388585e-05 0.00013089694711665434 nan\n",
      "Epoch: 1042\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5537168314400773\n",
      "MAPE:  0.009461304692118049\n",
      "Delta:  0.1675410587371113\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.763388164397142e-05 0.00013089099753638145 nan\n",
      "Epoch: 1043\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.553513463894121\n",
      "MAPE:  0.009460409895449332\n",
      "Delta:  0.16753307810614892\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.762967986138289e-05 0.00013088486455148374 nan\n",
      "Epoch: 1044\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5533101324948204\n",
      "MAPE:  0.009459515178088766\n",
      "Delta:  0.16752509855927253\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.762549665815463e-05 0.00013087875528861037 nan\n",
      "Epoch: 1045\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5531068371981025\n",
      "MAPE:  0.009458620540175112\n",
      "Delta:  0.16751712009325093\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.762130954216737e-05 0.00013087268592471002 nan\n",
      "Epoch: 1046\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5529035779347904\n",
      "MAPE:  0.009457725981121726\n",
      "Delta:  0.16750914270862138\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.7617128346111315e-05 0.0001308666138539749 nan\n",
      "Epoch: 1047\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5527003547019043\n",
      "MAPE:  0.00945683150102893\n",
      "Delta:  0.16750116640427387\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.7612948261166466e-05 0.00013086052290689487 nan\n",
      "Epoch: 1048\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5524971675215704\n",
      "MAPE:  0.009455937099999007\n",
      "Delta:  0.1674931911799042\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.760874925324732e-05 0.00013085437511994868 nan\n",
      "Epoch: 1049\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.552294016474839\n",
      "MAPE:  0.00945504277852091\n",
      "Delta:  0.16748521703856367\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.760459851926857e-05 0.00013084842577304467 nan\n",
      "Epoch: 1050\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.552090901246446\n",
      "MAPE:  0.00945414853512322\n",
      "Delta:  0.16747724397204866\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.760040237006269e-05 0.00013084228107096418 nan\n",
      "Epoch: 1051\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5518878221324977\n",
      "MAPE:  0.009453254371164569\n",
      "Delta:  0.16746927198784775\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.759620996197533e-05 0.0001308361374566802 nan\n",
      "Epoch: 1052\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5516847791240838\n",
      "MAPE:  0.009452360286637386\n",
      "Delta:  0.16746130108521604\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.75920363749438e-05 0.0001308301108338128 nan\n",
      "Epoch: 1053\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5514817720324519\n",
      "MAPE:  0.0094514662806241\n",
      "Delta:  0.16745333126088338\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.758784665004345e-05 0.00013082397704577975 nan\n",
      "Epoch: 1054\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5512788010167204\n",
      "MAPE:  0.009450572353994243\n",
      "Delta:  0.1674453625174343\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.758367886936732e-05 0.00013081794017810733 nan\n",
      "Epoch: 1055\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5510758659193296\n",
      "MAPE:  0.009449678506012835\n",
      "Delta:  0.16743739485107612\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.757949123879168e-05 0.00013081183259688878 nan\n",
      "Epoch: 1056\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5508729668428118\n",
      "MAPE:  0.009448784737214345\n",
      "Delta:  0.16742942826501472\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.75753119566491e-05 0.00013080574465806905 nan\n",
      "Epoch: 1057\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5506701037495139\n",
      "MAPE:  0.009447891047301413\n",
      "Delta:  0.16742146275773429\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.7571132421930784e-05 0.00013079965370732527 nan\n",
      "Epoch: 1058\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.550467276636929\n",
      "MAPE:  0.009446997436463198\n",
      "Delta:  0.1674134983291592\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.7566944152865887e-05 0.00013079353971212626 nan\n",
      "Epoch: 1059\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5502644855336098\n",
      "MAPE:  0.009446103904673278\n",
      "Delta:  0.1674055349806337\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.756276309691998e-05 0.0001307874348707161 nan\n",
      "Epoch: 1060\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5500617304181756\n",
      "MAPE:  0.009445210452045823\n",
      "Delta:  0.16739757271083233\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.755860619176655e-05 0.00013078145240530414 nan\n",
      "Epoch: 1061\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5498590110937538\n",
      "MAPE:  0.009444317077446949\n",
      "Delta:  0.1673896115155943\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.755439460579769e-05 0.00013077521798765535 nan\n",
      "Epoch: 1062\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5496563279437279\n",
      "MAPE:  0.009443423782929459\n",
      "Delta:  0.1673816514039554\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.755022736968595e-05 0.0001307691815445322 nan\n",
      "Epoch: 1063\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5494536806540473\n",
      "MAPE:  0.009442530566931484\n",
      "Delta:  0.16737369236837363\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.754608060608678e-05 0.00013076322590399592 nan\n",
      "Epoch: 1064\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5492510690923762\n",
      "MAPE:  0.009441637428897259\n",
      "Delta:  0.16736573440530492\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.754185500532859e-05 0.00013075693374897668 nan\n",
      "Epoch: 1065\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5490484937729743\n",
      "MAPE:  0.009440744371242146\n",
      "Delta:  0.16735777752782696\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.7537689076615486e-05 0.0001307508958451331 nan\n",
      "Epoch: 1066\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5488459542947057\n",
      "MAPE:  0.00943985139207538\n",
      "Delta:  0.1673498217258343\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.753351845954157e-05 0.00013074481361752266 nan\n",
      "Epoch: 1067\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5486434507190892\n",
      "MAPE:  0.009438958491812005\n",
      "Delta:  0.1673418669999941\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.752932896534556e-05 0.00013073869314084163 nan\n",
      "Epoch: 1068\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.548440983098201\n",
      "MAPE:  0.009438065670539838\n",
      "Delta:  0.16733391335334777\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.7525175688734045e-05 0.00013073269686658673 nan\n",
      "Epoch: 1069\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5482385512325418\n",
      "MAPE:  0.009437172927594833\n",
      "Delta:  0.16732596077971695\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.752097856197679e-05 0.00013072651771850463 nan\n",
      "Epoch: 1070\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5480361553981419\n",
      "MAPE:  0.00943628026404044\n",
      "Delta:  0.1673180092863219\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.751682455683692e-05 0.0001307205145749668 nan\n",
      "Epoch: 1071\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5478337953153276\n",
      "MAPE:  0.00943538767874287\n",
      "Delta:  0.16731005886582942\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.751261692192976e-05 0.00013071427908262212 nan\n",
      "Epoch: 1072\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5476314713366333\n",
      "MAPE:  0.009434495173297574\n",
      "Delta:  0.16730210952709534\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.750846335233039e-05 0.0001307082902249901 nan\n",
      "Epoch: 1073\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5474291830731164\n",
      "MAPE:  0.00943360274592946\n",
      "Delta:  0.16729416126095611\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.750427315103334e-05 0.00013070214220722853 nan\n",
      "Epoch: 1074\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5472269307639748\n",
      "MAPE:  0.009432710397757716\n",
      "Delta:  0.167286214073423\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.75000960176164e-05 0.00013069602340587405 nan\n",
      "Epoch: 1075\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5470247143568177\n",
      "MAPE:  0.009431818128694753\n",
      "Delta:  0.16727826796219208\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.749593267916463e-05 0.0001306899850974652 nan\n",
      "Epoch: 1076\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5468225337199528\n",
      "MAPE:  0.009430925938049265\n",
      "Delta:  0.16727032292483826\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.749173833629161e-05 0.00013068381256831074 nan\n",
      "Epoch: 1077\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5466203890538797\n",
      "MAPE:  0.009430033826756688\n",
      "Delta:  0.16726237896643048\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.7487577573779305e-05 0.00013067775646069535 nan\n",
      "Epoch: 1078\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5464182801713418\n",
      "MAPE:  0.009429141793943328\n",
      "Delta:  0.16725443608123414\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.748341152305269e-05 0.00013067170627734104 nan\n",
      "Epoch: 1079\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5462162070560534\n",
      "MAPE:  0.00942824983963938\n",
      "Delta:  0.16724649427001664\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.7479230627867075e-05 0.00013066558187779798 nan\n",
      "Epoch: 1080\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5460141698156495\n",
      "MAPE:  0.009427357964297113\n",
      "Delta:  0.1672385535351435\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.747502774915535e-05 0.00013065936519418564 nan\n",
      "Epoch: 1081\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5458121685856403\n",
      "MAPE:  0.00942646616855832\n",
      "Delta:  0.16723061388017368\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.747088865064697e-05 0.00013065338773199375 nan\n",
      "Epoch: 1082\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.545610202989017\n",
      "MAPE:  0.009425574450895667\n",
      "Delta:  0.1672226752943232\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.746670772148853e-05 0.00013064727683598232 nan\n",
      "Epoch: 1083\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5454082732249468\n",
      "MAPE:  0.009424682811998744\n",
      "Delta:  0.1672147377844706\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.7462527583586045e-05 0.0001306411383070749 nan\n",
      "Epoch: 1084\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5452063793289834\n",
      "MAPE:  0.009423791252151445\n",
      "Delta:  0.1672068013503661\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.7458352355200795e-05 0.00013063503311461222 nan\n",
      "Epoch: 1085\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5450045212424508\n",
      "MAPE:  0.009422899771155919\n",
      "Delta:  0.16719886599107145\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.745418107876542e-05 0.00013062894456927765 nan\n",
      "Epoch: 1086\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5448026989324861\n",
      "MAPE:  0.009422008368754075\n",
      "Delta:  0.16719093170580854\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.7450004628690756e-05 0.00013062281053566327 nan\n",
      "Epoch: 1087\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5446009124622284\n",
      "MAPE:  0.009421117045317411\n",
      "Delta:  0.16718299849532522\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.744583764682009e-05 0.00013061673687053688 nan\n",
      "Epoch: 1088\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5443991617312756\n",
      "MAPE:  0.009420225800586773\n",
      "Delta:  0.16717506635792131\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.7441661447100714e-05 0.00013061061342101166 nan\n",
      "Epoch: 1089\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5441974468093949\n",
      "MAPE:  0.009419334634580254\n",
      "Delta:  0.16716713529502075\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.7437496555002845e-05 0.0001306045313670401 nan\n",
      "Epoch: 1090\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.543995767625516\n",
      "MAPE:  0.009418443547308383\n",
      "Delta:  0.1671592053046161\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.74333240590985e-05 0.00013059843300056162 nan\n",
      "Epoch: 1091\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5437941241977047\n",
      "MAPE:  0.00941755253857003\n",
      "Delta:  0.16715127638786142\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.7429135103360665e-05 0.00013059225265943386 nan\n",
      "Epoch: 1092\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5435925166453834\n",
      "MAPE:  0.009416661609238973\n",
      "Delta:  0.1671433485473909\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.7424984676469606e-05 0.00013058622348049997 nan\n",
      "Epoch: 1093\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.543390944728042\n",
      "MAPE:  0.009415770758040287\n",
      "Delta:  0.16713542177664728\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.742081492747907e-05 0.0001305801403910234 nan\n",
      "Epoch: 1094\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5431894085218012\n",
      "MAPE:  0.009414879985313434\n",
      "Delta:  0.1671274960787434\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.7416623964902094e-05 0.00013057394033866299 nan\n",
      "Epoch: 1095\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5429879082000415\n",
      "MAPE:  0.009413989292063447\n",
      "Delta:  0.16711957145710762\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.7412468648588835e-05 0.00013056787788667812 nan\n",
      "Epoch: 1096\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.542786443543263\n",
      "MAPE:  0.009413098677149394\n",
      "Delta:  0.16711164790566535\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.740830238247895e-05 0.00013056180182169363 nan\n",
      "Epoch: 1097\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5425850145653681\n",
      "MAPE:  0.009412208140683938\n",
      "Delta:  0.1671037254261298\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.740411679327039e-05 0.00013055562452457536 nan\n",
      "Epoch: 1098\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5423836214154092\n",
      "MAPE:  0.009411317683414716\n",
      "Delta:  0.16709580402161311\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.73999597125907e-05 0.00013054956282498864 nan\n",
      "Epoch: 1099\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.542182263907925\n",
      "MAPE:  0.009410427304518904\n",
      "Delta:  0.16708788368723435\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.739577022483399e-05 0.00013054338201023974 nan\n",
      "Epoch: 1100\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.541980942219518\n",
      "MAPE:  0.009409537004750666\n",
      "Delta:  0.16707996442829176\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.7391629859117046e-05 0.00013053736934032223 nan\n",
      "Epoch: 1101\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.541779656083748\n",
      "MAPE:  0.009408646783066323\n",
      "Delta:  0.1670720462364607\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.738742606591462e-05 0.00013053111342897772 nan\n",
      "Epoch: 1102\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5415784058685773\n",
      "MAPE:  0.009407756640993456\n",
      "Delta:  0.167064129122222\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.73832776817229e-05 0.0001305251126539897 nan\n",
      "Epoch: 1103\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5413771911734864\n",
      "MAPE:  0.009406866576767835\n",
      "Delta:  0.1670562130762011\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.737911828689434e-05 0.0001305190095104436 nan\n",
      "Epoch: 1104\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5411760121492124\n",
      "MAPE:  0.009405976591112095\n",
      "Delta:  0.16704829810012123\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.7374934175392625e-05 0.00013051284654308493 nan\n",
      "Epoch: 1105\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.540974868880843\n",
      "MAPE:  0.009405086684480809\n",
      "Delta:  0.1670403841979946\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.737076740435331e-05 0.00013050673247494426 nan\n",
      "Epoch: 1106\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5407737612858792\n",
      "MAPE:  0.009404196856564575\n",
      "Delta:  0.16703247136680766\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.736660782755919e-05 0.0001305006418075294 nan\n",
      "Epoch: 1107\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.540572689321151\n",
      "MAPE:  0.009403307107103095\n",
      "Delta:  0.16702455960524196\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.73624439190079e-05 0.00013049456424540917 nan\n",
      "Epoch: 1108\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5403716529593696\n",
      "MAPE:  0.009402417435900728\n",
      "Delta:  0.16701664891390455\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.735825451906983e-05 0.00013048834204332227 nan\n",
      "Epoch: 1109\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5401706524162444\n",
      "MAPE:  0.009401527844100324\n",
      "Delta:  0.16700873929693635\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.735410500333881e-05 0.00013048230517698212 nan\n",
      "Epoch: 1110\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5399696873991513\n",
      "MAPE:  0.00940063833045696\n",
      "Delta:  0.16700083074755923\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.734993976174273e-05 0.00013047618094774727 nan\n",
      "Epoch: 1111\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5397687580355641\n",
      "MAPE:  0.009399748895451985\n",
      "Delta:  0.16699292326828316\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.734576387410705e-05 0.0001304700304289863 nan\n",
      "Epoch: 1112\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5395678643588495\n",
      "MAPE:  0.009398859539223857\n",
      "Delta:  0.16698501686076944\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.734160820729638e-05 0.00013046395658522503 nan\n",
      "Epoch: 1113\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5393670062438338\n",
      "MAPE:  0.009397970261348292\n",
      "Delta:  0.16697711152152472\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.7337436193783944e-05 0.00013045782208465084 nan\n",
      "Epoch: 1114\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5391661837768102\n",
      "MAPE:  0.009397081062094068\n",
      "Delta:  0.16696920725316225\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.733326514483327e-05 0.00013045166931402452 nan\n",
      "Epoch: 1115\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5389653969787849\n",
      "MAPE:  0.009396191941645038\n",
      "Delta:  0.16696130405540432\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.732912080440688e-05 0.00013044563726127834 nan\n",
      "Epoch: 1116\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.538764645656853\n",
      "MAPE:  0.00939530289926191\n",
      "Delta:  0.16695340192367503\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.73249382377805e-05 0.0001304394541669085 nan\n",
      "Epoch: 1117\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.538563930036382\n",
      "MAPE:  0.009394413935823515\n",
      "Delta:  0.1669455008642404\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.732077542279889e-05 0.00013043333334050722 nan\n",
      "Epoch: 1118\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.53836325001443\n",
      "MAPE:  0.009393525050969388\n",
      "Delta:  0.16693760087368614\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.731661810208898e-05 0.00013042724021505858 nan\n",
      "Epoch: 1119\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5381626055412823\n",
      "MAPE:  0.009392636244538658\n",
      "Delta:  0.16692970195097873\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.731243386890682e-05 0.00013042104936411558 nan\n",
      "Epoch: 1120\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.537961996760175\n",
      "MAPE:  0.00939174751702475\n",
      "Delta:  0.1669218041004944\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.7308280475610864e-05 0.00013041495569510175 nan\n",
      "Epoch: 1121\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5377614235145067\n",
      "MAPE:  0.009390858867913224\n",
      "Delta:  0.16691390731696853\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.730411940312429e-05 0.00013040884756521098 nan\n",
      "Epoch: 1122\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5375608858194358\n",
      "MAPE:  0.009389970297237241\n",
      "Delta:  0.16690601160156676\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.7299949172852074e-05 0.000130402709162869 nan\n",
      "Epoch: 1123\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5373603837144223\n",
      "MAPE:  0.009389081805143407\n",
      "Delta:  0.16689811695570136\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.729578924023148e-05 0.00013039659590130537 nan\n",
      "Epoch: 1124\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5371599171537123\n",
      "MAPE:  0.00938819339152538\n",
      "Delta:  0.16689022337753723\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.729163321381957e-05 0.00013039048643359585 nan\n",
      "Epoch: 1125\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5369594861243883\n",
      "MAPE:  0.009387305056272383\n",
      "Delta:  0.1668823308663063\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.7287470648860186e-05 0.0001303843827920037 nan\n",
      "Epoch: 1126\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5367590906104136\n",
      "MAPE:  0.009386416799569221\n",
      "Delta:  0.16687443942298363\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.728329826841904e-05 0.00013037821334782596 nan\n",
      "Epoch: 1127\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.536558730705834\n",
      "MAPE:  0.009385528621510625\n",
      "Delta:  0.16686654904909104\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.727915285196449e-05 0.00013037214979505496 nan\n",
      "Epoch: 1128\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5363584062408253\n",
      "MAPE:  0.009384640521521753\n",
      "Delta:  0.16685865974001265\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.7274963027477135e-05 0.00013036591020465504 nan\n",
      "Epoch: 1129\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.536158117478795\n",
      "MAPE:  0.009383752500941754\n",
      "Delta:  0.16685077150304262\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.727081605948591e-05 0.00013035985299880704 nan\n",
      "Epoch: 1130\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5359578641324176\n",
      "MAPE:  0.009382864558158116\n",
      "Delta:  0.16684288433091354\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.726665651977324e-05 0.00013035372598801942 nan\n",
      "Epoch: 1131\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5357576463018674\n",
      "MAPE:  0.009381976693916393\n",
      "Delta:  0.1668349982256071\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.7262500287414966e-05 0.00013034761133901007 nan\n",
      "Epoch: 1132\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5355574639610763\n",
      "MAPE:  0.009381088908084527\n",
      "Delta:  0.1668271131864555\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.7258327931953836e-05 0.00013034145252421858 nan\n",
      "Epoch: 1133\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5353573171707893\n",
      "MAPE:  0.009380201200869086\n",
      "Delta:  0.1668192292160326\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.725418184836627e-05 0.0001303353797248441 nan\n",
      "Epoch: 1134\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5351572057918423\n",
      "MAPE:  0.009379313571751438\n",
      "Delta:  0.1668113463098394\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.725001351857383e-05 0.00013032921117972496 nan\n",
      "Epoch: 1135\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5349571299641747\n",
      "MAPE:  0.009378426021380507\n",
      "Delta:  0.1668034644714712\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.724584317195024e-05 0.00013032305085258766 nan\n",
      "Epoch: 1136\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5347570896680698\n",
      "MAPE:  0.009377538549610044\n",
      "Delta:  0.16679558370114825\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.724169489689345e-05 0.00013031695257237352 nan\n",
      "Epoch: 1137\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5345570848012056\n",
      "MAPE:  0.009376651156101189\n",
      "Delta:  0.1667877039950729\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.723752178426022e-05 0.00013031078594727408 nan\n",
      "Epoch: 1138\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.534357115461404\n",
      "MAPE:  0.009375763841199444\n",
      "Delta:  0.1667798253572721\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.723336952550117e-05 0.00013030466368058047 nan\n",
      "Epoch: 1139\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5341571815735078\n",
      "MAPE:  0.00937487660471435\n",
      "Delta:  0.16677194778415158\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.7229218448907595e-05 0.00013029858229685054 nan\n",
      "Epoch: 1140\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5339572830677284\n",
      "MAPE:  0.00937398944617711\n",
      "Delta:  0.16676407127539852\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.7225055624933177e-05 0.00013029243231521548 nan\n",
      "Epoch: 1141\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5337574200422497\n",
      "MAPE:  0.009373102366308771\n",
      "Delta:  0.1667561958328563\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.722089091868664e-05 0.00013028624931454846 nan\n",
      "Epoch: 1142\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5335575925406342\n",
      "MAPE:  0.009372215365163142\n",
      "Delta:  0.1667483214567229\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.7216729804677726e-05 0.00013028012439808556 nan\n",
      "Epoch: 1143\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5333578004667063\n",
      "MAPE:  0.009371357763232006\n",
      "Delta:  0.16674044814628328\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.7212589042611164e-05 0.00013027407441701389 nan\n",
      "Epoch: 1144\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5331580436985004\n",
      "MAPE:  0.009370500861125433\n",
      "Delta:  0.16673257589802815\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.720842733940689e-05 0.0001302679086320202 nan\n",
      "Epoch: 1145\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5329583224065455\n",
      "MAPE:  0.009369644034992065\n",
      "Delta:  0.16672470471533377\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.720425752369195e-05 0.00013026171331564917 nan\n",
      "Epoch: 1146\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5327586366290273\n",
      "MAPE:  0.009368787285059296\n",
      "Delta:  0.16671683459943684\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.720009866743258e-05 0.00013025558834034445 nan\n",
      "Epoch: 1147\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5325589862510296\n",
      "MAPE:  0.009367930610842817\n",
      "Delta:  0.1667089655483942\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.719594988689124e-05 0.00013024949147311116 nan\n",
      "Epoch: 1148\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5323593712224177\n",
      "MAPE:  0.009367074012169721\n",
      "Delta:  0.16670109756041052\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.719178306833438e-05 0.00013024329894217868 nan\n",
      "Epoch: 1149\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.532159791682745\n",
      "MAPE:  0.00936621748965765\n",
      "Delta:  0.16669323063837718\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.7187636615708684e-05 0.00013023721179683534 nan\n",
      "Epoch: 1150\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5319602474634488\n",
      "MAPE:  0.00936536104256874\n",
      "Delta:  0.1666853647787835\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.718348217813695e-05 0.00013023107621701335 nan\n",
      "Epoch: 1151\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5317607386317\n",
      "MAPE:  0.009364504671182737\n",
      "Delta:  0.16667749998284512\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.7179338760638956e-05 0.00013022499711246027 nan\n",
      "Epoch: 1152\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5315612650939345\n",
      "MAPE:  0.009363648375250075\n",
      "Delta:  0.16666963624860964\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.717515238727987e-05 0.00013021872984753102 nan\n",
      "Epoch: 1153\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5313618271313105\n",
      "MAPE:  0.009362792155809999\n",
      "Delta:  0.1666617735831213\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.717100733953039e-05 0.00013021263671231242 nan\n",
      "Epoch: 1154\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.531162424470039\n",
      "MAPE:  0.009361936011888738\n",
      "Delta:  0.1666539119793764\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.716686938277537e-05 0.00013020654560624845 nan\n",
      "Epoch: 1155\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5309630570999868\n",
      "MAPE:  0.009361079943405471\n",
      "Delta:  0.1666460514360779\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.716269198656864e-05 0.00013020033175370482 nan\n",
      "Epoch: 1156\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5307637252020496\n",
      "MAPE:  0.009360223951089215\n",
      "Delta:  0.16663819195968327\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.7158545868675183e-05 0.00013019423220739235 nan\n",
      "Epoch: 1157\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.530564428594156\n",
      "MAPE:  0.009359368034178936\n",
      "Delta:  0.16663033354486426\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.715439224700635e-05 0.0001301881004155403 nan\n",
      "Epoch: 1158\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5303651673186338\n",
      "MAPE:  0.009358512192946835\n",
      "Delta:  0.16662247619275605\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.7150234968484916e-05 0.00013018194102465408 nan\n",
      "Epoch: 1159\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5301659414106759\n",
      "MAPE:  0.009357656427600634\n",
      "Delta:  0.1666146199038525\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.714608870448611e-05 0.0001301758104229611 nan\n",
      "Epoch: 1160\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.529966750819171\n",
      "MAPE:  0.009356800737835094\n",
      "Delta:  0.16660676467620306\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.714194042465536e-05 0.00013016970621693158 nan\n",
      "Epoch: 1161\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5297675954966952\n",
      "MAPE:  0.00935594512352727\n",
      "Delta:  0.16659891051002837\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.713776275488968e-05 0.00013016346349037367 nan\n",
      "Epoch: 1162\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.52956847564813\n",
      "MAPE:  0.009355089585569548\n",
      "Delta:  0.16659105741010952\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.713362024233447e-05 0.0001301573677896517 nan\n",
      "Epoch: 1163\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5293693910414854\n",
      "MAPE:  0.009354234122925945\n",
      "Delta:  0.16658320537047377\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.712947583496163e-05 0.00013015124426229985 nan\n",
      "Epoch: 1164\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5291703417123048\n",
      "MAPE:  0.009353378735837314\n",
      "Delta:  0.16657535439132176\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.712531340034243e-05 0.0001301450649278113 nan\n",
      "Epoch: 1165\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.528971327738897\n",
      "MAPE:  0.009352523424693877\n",
      "Delta:  0.1665675044755413\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.7121152536244715e-05 0.00013013889146384905 nan\n",
      "Epoch: 1166\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.528772349105225\n",
      "MAPE:  0.009351668189335484\n",
      "Delta:  0.16655965562275532\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.711702640747273e-05 0.00013013283688345645 nan\n",
      "Epoch: 1167\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.528573405622487\n",
      "MAPE:  0.009350813029099514\n",
      "Delta:  0.16655180782706291\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.711286278691329e-05 0.00013012665151168612 nan\n",
      "Epoch: 1168\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5283744974836235\n",
      "MAPE:  0.009349957944693022\n",
      "Delta:  0.16654396109459385\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.710870174939874e-05 0.0001301204677149892 nan\n",
      "Epoch: 1169\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5281756246791671\n",
      "MAPE:  0.009349102936215463\n",
      "Delta:  0.16653611542480248\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.710456499401605e-05 0.00013011438409205045 nan\n",
      "Epoch: 1170\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5279767870489778\n",
      "MAPE:  0.00934824800293692\n",
      "Delta:  0.1665282708135296\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.7100383278930735e-05 0.00013010810286462338 nan\n",
      "Epoch: 1171\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5277779848879935\n",
      "MAPE:  0.00934739314617944\n",
      "Delta:  0.1665204272681475\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.709626695686975e-05 0.00013010210194719374 nan\n",
      "Epoch: 1172\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.527579217760851\n",
      "MAPE:  0.009346538364070603\n",
      "Delta:  0.1665125847776511\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.709209629538691e-05 0.0001300958677747932 nan\n",
      "Epoch: 1173\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5273804860169216\n",
      "MAPE:  0.00934568365814157\n",
      "Delta:  0.16650474335097437\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.70879747627162e-05 0.00013008984985318772 nan\n",
      "Epoch: 1174\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5271817893188269\n",
      "MAPE:  0.009344829026904122\n",
      "Delta:  0.1664969029798216\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.708380645168653e-05 0.00013008360177502176 nan\n",
      "Epoch: 1175\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.526983128011107\n",
      "MAPE:  0.00934397447202069\n",
      "Delta:  0.1664890636718669\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.7079625260515456e-05 0.00013007731593295269 nan\n",
      "Epoch: 1176\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5267845021443405\n",
      "MAPE:  0.009343119993550676\n",
      "Delta:  0.16648122542913923\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.707550651206205e-05 0.00013007132369069474 nan\n",
      "Epoch: 1177\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5265859112631563\n",
      "MAPE:  0.009342265589591727\n",
      "Delta:  0.1664733882411274\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.70713520749344e-05 0.00013006512888313893 nan\n",
      "Epoch: 1178\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5263873556698566\n",
      "MAPE:  0.009341411261546676\n",
      "Delta:  0.1664655521136584\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.70672124093241e-05 0.0001300590137149893 nan\n",
      "Epoch: 1179\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.526188835235831\n",
      "MAPE:  0.009340557008846093\n",
      "Delta:  0.16645771704415824\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.70630649207493e-05 0.00013005288136280768 nan\n",
      "Epoch: 1180\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.525990349980305\n",
      "MAPE:  0.009339702831574587\n",
      "Delta:  0.16644988303381442\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.705890117884248e-05 0.000130046658519678 nan\n",
      "Epoch: 1181\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5257919000343567\n",
      "MAPE:  0.00933884873029208\n",
      "Delta:  0.1664420500852175\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.7054748281705194e-05 0.00013004048584086547 nan\n",
      "Epoch: 1182\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5255934853143842\n",
      "MAPE:  0.009337994704718954\n",
      "Delta:  0.16643421819644724\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.705062218002265e-05 0.0001300344135084508 nan\n",
      "Epoch: 1183\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.525395105660269\n",
      "MAPE:  0.009337140754205818\n",
      "Delta:  0.16642638736292906\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.7046466243760854e-05 0.0001300282400084063 nan\n",
      "Epoch: 1184\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5251967612193624\n",
      "MAPE:  0.009336286879209026\n",
      "Delta:  0.16641855758951393\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.704231068553e-05 0.00013002204909795534 nan\n",
      "Epoch: 1185\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5249984520111912\n",
      "MAPE:  0.009335433080057222\n",
      "Delta:  0.16641072887602396\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.70381659881669e-05 0.0001300158927763917 nan\n",
      "Epoch: 1186\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5248001779759703\n",
      "MAPE:  0.009334579356494652\n",
      "Delta:  0.1664029012205369\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.703403102246373e-05 0.00013000978607924374 nan\n",
      "Epoch: 1187\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.524601939031018\n",
      "MAPE:  0.009333725708147148\n",
      "Delta:  0.16639507462131864\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.702987518645507e-05 0.00013000359982218157 nan\n",
      "Epoch: 1188\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.524403735290648\n",
      "MAPE:  0.009332872135395874\n",
      "Delta:  0.16638724908172756\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.702572324921661e-05 0.00012999741325780967 nan\n",
      "Epoch: 1189\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5242055667482997\n",
      "MAPE:  0.009332018638428662\n",
      "Delta:  0.16637942460100005\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.7021587431750334e-05 0.00012999131729063418 nan\n",
      "Epoch: 1190\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5240074332588565\n",
      "MAPE:  0.00933116521651189\n",
      "Delta:  0.1663716011763393\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.701742540202947e-05 0.00012998506504746654 nan\n",
      "Epoch: 1191\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5238093350535113\n",
      "MAPE:  0.00933031187072577\n",
      "Delta:  0.166363778811992\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.701331985590418e-05 0.00012997909705358968 nan\n",
      "Epoch: 1192\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5236112716920593\n",
      "MAPE:  0.009329458599134399\n",
      "Delta:  0.16635595749844626\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.700912410471325e-05 0.0001299727083589053 nan\n",
      "Epoch: 1193\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5234132438085914\n",
      "MAPE:  0.009328605404631369\n",
      "Delta:  0.16634813725059466\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.7005008631861855e-05 0.00012996667944220608 nan\n",
      "Epoch: 1194\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5232152508478753\n",
      "MAPE:  0.009327752284691428\n",
      "Delta:  0.1663403180549673\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.7000852264278414e-05 0.00012996047499180818 nan\n",
      "Epoch: 1195\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5230172930703603\n",
      "MAPE:  0.00932689924051944\n",
      "Delta:  0.16633249991825283\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.699671330610222e-05 0.00012995433121154587 nan\n",
      "Epoch: 1196\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5228193703766157\n",
      "MAPE:  0.00932604627168613\n",
      "Delta:  0.16632468283744067\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.6992566670289726e-05 0.00012994816285305522 nan\n",
      "Epoch: 1197\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5226214827970783\n",
      "MAPE:  0.009325193378340145\n",
      "Delta:  0.1663168668136935\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.698843160322319e-05 0.00012994204054483927 nan\n",
      "Epoch: 1198\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5224236302546261\n",
      "MAPE:  0.00932434056021349\n",
      "Delta:  0.1663090518449728\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.69842731077863e-05 0.00012993581048037495 nan\n",
      "Epoch: 1199\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5222258129063346\n",
      "MAPE:  0.009323487817941782\n",
      "Delta:  0.1663012379350606\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.6980144207009467e-05 0.00012992970648806335 nan\n",
      "Epoch: 1200\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5220280305532552\n",
      "MAPE:  0.00932263515074335\n",
      "Delta:  0.16629342507892061\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.697598983594009e-05 0.00012992350507190498 nan\n",
      "Epoch: 1201\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5218302833367081\n",
      "MAPE:  0.009321782559221012\n",
      "Delta:  0.16628561328067432\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.697183689039708e-05 0.0001299172977383689 nan\n",
      "Epoch: 1202\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5216325712586807\n",
      "MAPE:  0.009320930043356242\n",
      "Delta:  0.16627780253997007\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.69677099124155e-05 0.00012991120939020995 nan\n",
      "Epoch: 1203\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.521434894131101\n",
      "MAPE:  0.009320077602452301\n",
      "Delta:  0.1662699928523755\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.6963558306689634e-05 0.00012990499517284704 nan\n",
      "Epoch: 1204\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.521237252138523\n",
      "MAPE:  0.009319225237284158\n",
      "Delta:  0.16626218422187153\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.6959440178184764e-05 0.00012989893061099433 nan\n",
      "Epoch: 1205\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5210396450462644\n",
      "MAPE:  0.009318372946854381\n",
      "Delta:  0.16625437664277765\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.6955262215431226e-05 0.0001298926066578554 nan\n",
      "Epoch: 1206\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5208420732419397\n",
      "MAPE:  0.009317520732835852\n",
      "Delta:  0.16624657012492794\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.695113586639099e-05 0.00012988651813583552 nan\n",
      "Epoch: 1207\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5206445363604117\n",
      "MAPE:  0.009316668593728891\n",
      "Delta:  0.16623876465962667\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.694699595364504e-05 0.0001298803635726431 nan\n",
      "Epoch: 1208\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5204470344951644\n",
      "MAPE:  0.009315816529891231\n",
      "Delta:  0.16623096024901485\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.6942852895637266e-05 0.00012987417148258018 nan\n",
      "Epoch: 1209\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5202495676962762\n",
      "MAPE:  0.00931496454157925\n",
      "Delta:  0.1662231568935012\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.693870525029897e-05 0.0001298679818617643 nan\n",
      "Epoch: 1210\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5200521359529933\n",
      "MAPE:  0.009314112628822714\n",
      "Delta:  0.166215354593734\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.69345875981908e-05 0.00012986190108843498 nan\n",
      "Epoch: 1211\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5198547390928647\n",
      "MAPE:  0.009313260790875227\n",
      "Delta:  0.16620755334461365\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.693043054626589e-05 0.00012985567502421524 nan\n",
      "Epoch: 1212\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5196573773297812\n",
      "MAPE:  0.009312409028605426\n",
      "Delta:  0.16619975315257515\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.6926298585492354e-05 0.00012984953866790327 nan\n",
      "Epoch: 1213\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5194600505204017\n",
      "MAPE:  0.009311557341425789\n",
      "Delta:  0.16619195401333386\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.692215541712841e-05 0.00012984334003007802 nan\n",
      "Epoch: 1214\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5192627587524\n",
      "MAPE:  0.00931070572986642\n",
      "Delta:  0.16618415592863858\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.691799752920556e-05 0.00012983710825054118 nan\n",
      "Epoch: 1215\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5190655020691306\n",
      "MAPE:  0.009309854193985792\n",
      "Delta:  0.16617635890082133\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.6913880359156224e-05 0.00012983103274344376 nan\n",
      "Epoch: 1216\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5188682802261921\n",
      "MAPE:  0.009309002732803672\n",
      "Delta:  0.16616856292300133\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.690972894016987e-05 0.00012982479651268974 nan\n",
      "Epoch: 1217\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5186710934607823\n",
      "MAPE:  0.009308151347393148\n",
      "Delta:  0.16616076800075624\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.690558961184532e-05 0.00012981863288474838 nan\n",
      "Epoch: 1218\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5184739416556277\n",
      "MAPE:  0.009307300037270184\n",
      "Delta:  0.1661529741319628\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.69014626530706e-05 0.0001298124970974257 nan\n",
      "Epoch: 1219\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5182768247614842\n",
      "MAPE:  0.009306448802192184\n",
      "Delta:  0.16614518131445186\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.6897315737037815e-05 0.0001298062973482672 nan\n",
      "Epoch: 1220\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.518079742868512\n",
      "MAPE:  0.009305597642545028\n",
      "Delta:  0.16613738955142554\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.689317620154565e-05 0.00012980011926377877 nan\n",
      "Epoch: 1221\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5178826959368357\n",
      "MAPE:  0.009304746558259663\n",
      "Delta:  0.16612959884154366\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.688904620397949e-05 0.00012979396711432223 nan\n",
      "Epoch: 1222\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5176856839201158\n",
      "MAPE:  0.009303895549127342\n",
      "Delta:  0.1661218091831077\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.6884912619615804e-05 0.0001297878189916446 nan\n",
      "Epoch: 1223\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.517488706805285\n",
      "MAPE:  0.009303044615120205\n",
      "Delta:  0.16611402057659996\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.688075948600101e-05 0.0001297815796258428 nan\n",
      "Epoch: 1224\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5172917647238515\n",
      "MAPE:  0.009302193756747158\n",
      "Delta:  0.16610623302515404\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.6876625226621726e-05 0.0001297753995866957 nan\n",
      "Epoch: 1225\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5170948575787948\n",
      "MAPE:  0.009301342973719411\n",
      "Delta:  0.16609844652552072\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.687248438906e-05 0.00012976921486773652 nan\n",
      "Epoch: 1226\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.516897985370247\n",
      "MAPE:  0.009300492265995424\n",
      "Delta:  0.1660906610786789\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.68683594903041e-05 0.0001297631019691048 nan\n",
      "Epoch: 1227\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5167011479822945\n",
      "MAPE:  0.009299641633070793\n",
      "Delta:  0.1660828766818675\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.686421672994712e-05 0.00012975686514826723 nan\n",
      "Epoch: 1228\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5165043455959655\n",
      "MAPE:  0.00929879107590557\n",
      "Delta:  0.16607509333793954\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.686009745791253e-05 0.00012975079025956404 nan\n",
      "Epoch: 1229\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5163075779586925\n",
      "MAPE:  0.009297940593156515\n",
      "Delta:  0.1660673110428804\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.685592550945916e-05 0.00012974443763724697 nan\n",
      "Epoch: 1230\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5161108454847052\n",
      "MAPE:  0.009297090186907409\n",
      "Delta:  0.1660595298053246\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.685181771080238e-05 0.00012973839240149054 nan\n",
      "Epoch: 1231\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5159141477009097\n",
      "MAPE:  0.009296239854883101\n",
      "Delta:  0.16605174961450503\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.684768033280662e-05 0.00012973217831957484 nan\n",
      "Epoch: 1232\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.515717484856383\n",
      "MAPE:  0.009295389598438555\n",
      "Delta:  0.16604397047522038\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.6843535310037154e-05 0.00012972596964344607 nan\n",
      "Epoch: 1233\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5155208569359544\n",
      "MAPE:  0.00929453941734224\n",
      "Delta:  0.1660361923886264\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.683940602123737e-05 0.00012971982159382112 nan\n",
      "Epoch: 1234\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.515324263840771\n",
      "MAPE:  0.00929368931125631\n",
      "Delta:  0.1660284153519969\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.683528638471657e-05 0.00012971368944680872 nan\n",
      "Epoch: 1235\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5151277055397998\n",
      "MAPE:  0.009292839280065558\n",
      "Delta:  0.16602063936361589\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.6831134670632935e-05 0.0001297074393631359 nan\n",
      "Epoch: 1236\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5149311822048062\n",
      "MAPE:  0.009291989324505121\n",
      "Delta:  0.16601286442869573\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.6827004669736105e-05 0.00012970127595346437 nan\n",
      "Epoch: 1237\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5147346936974926\n",
      "MAPE:  0.009291139443980575\n",
      "Delta:  0.1660050905435179\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.6822867466378426e-05 0.00012969507744420294 nan\n",
      "Epoch: 1238\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.514538240064086\n",
      "MAPE:  0.00929028963878635\n",
      "Delta:  0.16599731770916462\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.681873078382637e-05 0.00012968886547981562 nan\n",
      "Epoch: 1239\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5143418213180064\n",
      "MAPE:  0.009289439908951475\n",
      "Delta:  0.16598954592543597\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.681461288935651e-05 0.000129682773603923 nan\n",
      "Epoch: 1240\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5141454372704335\n",
      "MAPE:  0.00928859025364285\n",
      "Delta:  0.1659817751890998\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.681046991272808e-05 0.00012967653766293719 nan\n",
      "Epoch: 1241\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.51394908813261\n",
      "MAPE:  0.00928774067391856\n",
      "Delta:  0.16597400550420624\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.680633580456117e-05 0.0001296703359514595 nan\n",
      "Epoch: 1242\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5137527738457386\n",
      "MAPE:  0.009286891169415721\n",
      "Delta:  0.16596623686916978\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.68022057795725e-05 0.0001296641668874221 nan\n",
      "Epoch: 1243\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5135564943534443\n",
      "MAPE:  0.009286041739988272\n",
      "Delta:  0.16595846928319935\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.6798068310538454e-05 0.00012965796750441516 nan\n",
      "Epoch: 1244\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5133602496946832\n",
      "MAPE:  0.009285192385703075\n",
      "Delta:  0.16595070274741713\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.679394267070869e-05 0.00012965179007173866 nan\n",
      "Epoch: 1245\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.513164039829287\n",
      "MAPE:  0.009284343106570272\n",
      "Delta:  0.16594293725974663\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.678980593952886e-05 0.00012964557793160303 nan\n",
      "Epoch: 1246\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.512967864802838\n",
      "MAPE:  0.009283493902835536\n",
      "Delta:  0.1659351728219152\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.6785684223227264e-05 0.00012963945268207322 nan\n",
      "Epoch: 1247\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5127717244769192\n",
      "MAPE:  0.009282644773625566\n",
      "Delta:  0.165927409431318\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.678155350656965e-05 0.00012963325786385926 nan\n",
      "Epoch: 1248\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.512575618949871\n",
      "MAPE:  0.00928179571972965\n",
      "Delta:  0.1659196470893355\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.677742202230384e-05 0.0001296270642626718 nan\n",
      "Epoch: 1249\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5123795482129112\n",
      "MAPE:  0.009280946740864798\n",
      "Delta:  0.16591188579598182\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.6773268825961445e-05 0.00012962078529343835 nan\n",
      "Epoch: 1250\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5121835123882101\n",
      "MAPE:  0.00928009783782783\n",
      "Delta:  0.16590412555474604\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.676916590129476e-05 0.00012961471105876754 nan\n",
      "Epoch: 1251\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.511987511159184\n",
      "MAPE:  0.009279249008977423\n",
      "Delta:  0.16589636635717425\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.6765023714145926e-05 0.00012960846063037046 nan\n",
      "Epoch: 1252\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5117915447853703\n",
      "MAPE:  0.009278400255707638\n",
      "Delta:  0.16588860820966747\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.6760890655139775e-05 0.00012960227269143143 nan\n",
      "Epoch: 1253\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5115956131653305\n",
      "MAPE:  0.009277551577477106\n",
      "Delta:  0.16588085111059805\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.675676579557475e-05 0.00012959608913043486 nan\n",
      "Epoch: 1254\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5113997162855175\n",
      "MAPE:  0.009276702974304177\n",
      "Delta:  0.1658730950584927\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.675264625608744e-05 0.0001295899304323278 nan\n",
      "Epoch: 1255\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5112038541014288\n",
      "MAPE:  0.009275854446011126\n",
      "Delta:  0.16586534005235604\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.674850970942668e-05 0.0001295837210616435 nan\n",
      "Epoch: 1256\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5110080266827315\n",
      "MAPE:  0.009275005992889397\n",
      "Delta:  0.16585758609489615\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.674437572771417e-05 0.00012957749496400606 nan\n",
      "Epoch: 1257\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5108122340477634\n",
      "MAPE:  0.009274157614993476\n",
      "Delta:  0.16584983318557445\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.6740253270782794e-05 0.00012957133890900696 nan\n",
      "Epoch: 1258\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.510616476083758\n",
      "MAPE:  0.009273309311930959\n",
      "Delta:  0.16584208132236644\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.673612257199977e-05 0.00012956512172868084 nan\n",
      "Epoch: 1259\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5104207528761489\n",
      "MAPE:  0.009272461084093266\n",
      "Delta:  0.16583433050652616\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.673198644578047e-05 0.0001295589078043058 nan\n",
      "Epoch: 1260\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5102250644130812\n",
      "MAPE:  0.009271612931420184\n",
      "Delta:  0.16582658073884068\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.672787654924626e-05 0.00012955277366877294 nan\n",
      "Epoch: 1261\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5100294105671224\n",
      "MAPE:  0.009270764853360517\n",
      "Delta:  0.16581883201484734\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.6723729453912455e-05 0.00012954650615260022 nan\n",
      "Epoch: 1262\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5098337915327957\n",
      "MAPE:  0.00926991685083554\n",
      "Delta:  0.1658110843406019\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.671960524815777e-05 0.00012954032152334705 nan\n",
      "Epoch: 1263\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5096382071779937\n",
      "MAPE:  0.009269068923220457\n",
      "Delta:  0.16580333771219574\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.6715487439175085e-05 0.00012953415813721225 nan\n",
      "Epoch: 1264\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5094426574637352\n",
      "MAPE:  0.009268221070441124\n",
      "Delta:  0.1657955921284555\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.6711354037332065e-05 0.00012952793948195485 nan\n",
      "Epoch: 1265\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.509247142466548\n",
      "MAPE:  0.009267373292763127\n",
      "Delta:  0.16578784759185372\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.670723672273169e-05 0.00012952178579495044 nan\n",
      "Epoch: 1266\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5090516620814496\n",
      "MAPE:  0.009266525589789952\n",
      "Delta:  0.16578010409961053\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.670311865540011e-05 0.00012951561263085942 nan\n",
      "Epoch: 1267\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5088562163309436\n",
      "MAPE:  0.009265677961731139\n",
      "Delta:  0.16577236165173803\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.669898265319272e-05 0.0001295093741245923 nan\n",
      "Epoch: 1268\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5086608053067225\n",
      "MAPE:  0.00926483040888646\n",
      "Delta:  0.1657646202510969\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.6694849251460724e-05 0.00012950313513637735 nan\n",
      "Epoch: 1269\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.508465429002578\n",
      "MAPE:  0.009263982931322844\n",
      "Delta:  0.16575687989714305\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.6690717043551544e-05 0.00012949691507246897 nan\n",
      "Epoch: 1270\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5082700873830288\n",
      "MAPE:  0.009263135528748434\n",
      "Delta:  0.16574914058956575\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.668661611895164e-05 0.0001294908071959311 nan\n",
      "Epoch: 1271\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.508074780271944\n",
      "MAPE:  0.009262288200673267\n",
      "Delta:  0.165741402323067\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.6682480164150775e-05 0.0001294845775676734 nan\n",
      "Epoch: 1272\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.50787950784608\n",
      "MAPE:  0.009261440947658722\n",
      "Delta:  0.16573366510334064\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.66783488418665e-05 0.00012947834411414227 nan\n",
      "Epoch: 1273\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5076842701042805\n",
      "MAPE:  0.009260593769841806\n",
      "Delta:  0.1657259289295061\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.667423222748379e-05 0.0001294721594410353 nan\n",
      "Epoch: 1274\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.507489066966075\n",
      "MAPE:  0.009259746666904933\n",
      "Delta:  0.16571819379901315\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.6670096137124695e-05 0.00012946593071816448 nan\n",
      "Epoch: 1275\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5072938984909727\n",
      "MAPE:  0.009258899639014677\n",
      "Delta:  0.1657104597149769\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.666598126079613e-05 0.00012945975604872206 nan\n",
      "Epoch: 1276\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5070987645905802\n",
      "MAPE:  0.009258052685949331\n",
      "Delta:  0.1657027266737691\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.6661858995933336e-05 0.00012945356022220356 nan\n",
      "Epoch: 1277\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5069036652898975\n",
      "MAPE:  0.009257205807685085\n",
      "Delta:  0.1656949946765018\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.665774049450455e-05 0.00012944737156339592 nan\n",
      "Epoch: 1278\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5067086005712265\n",
      "MAPE:  0.00925635900428449\n",
      "Delta:  0.16568726372243894\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.665359790689827e-05 0.00012944108876444815 nan\n",
      "Epoch: 1279\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5065135705695178\n",
      "MAPE:  0.009255512276328072\n",
      "Delta:  0.16567953381545897\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.6649493534167696e-05 0.00012943495106387815 nan\n",
      "Epoch: 1280\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.506318575059234\n",
      "MAPE:  0.009254665622830345\n",
      "Delta:  0.16567180494911748\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.664537910337163e-05 0.000129428786496244 nan\n",
      "Epoch: 1281\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5061236140739873\n",
      "MAPE:  0.009253819043993547\n",
      "Delta:  0.1656640771249689\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.664123085917904e-05 0.0001294224685527423 nan\n",
      "Epoch: 1282\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5059286878379083\n",
      "MAPE:  0.009252972540820498\n",
      "Delta:  0.16565635034850265\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.6637131248972175e-05 0.0001294163555107808 nan\n",
      "Epoch: 1283\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.505733796035469\n",
      "MAPE:  0.009252126111830109\n",
      "Delta:  0.16564862461154922\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.663299890328432e-05 0.0001294101173442419 nan\n",
      "Epoch: 1284\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.505538938848235\n",
      "MAPE:  0.009251279757950977\n",
      "Delta:  0.16564089991941938\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.662888392403808e-05 0.00012940392771665366 nan\n",
      "Epoch: 1285\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5053441161962176\n",
      "MAPE:  0.0092504334788788\n",
      "Delta:  0.16563317626912397\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.662475280392542e-05 0.00012939767933262125 nan\n",
      "Epoch: 1286\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.505149328160985\n",
      "MAPE:  0.009249587274901008\n",
      "Delta:  0.1656254536632243\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.662063678428918e-05 0.0001293914957155584 nan\n",
      "Epoch: 1287\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5049545746381388\n",
      "MAPE:  0.009248741145662777\n",
      "Delta:  0.16561773209910682\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.66165118099271e-05 0.00012938526954409113 nan\n",
      "Epoch: 1288\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5047598556848476\n",
      "MAPE:  0.009247895091319862\n",
      "Delta:  0.16561001157814248\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.661239550141083e-05 0.0001293790814762552 nan\n",
      "Epoch: 1289\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5045651712368768\n",
      "MAPE:  0.009247049111804125\n",
      "Delta:  0.16560229209878383\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.660828899716307e-05 0.0001293729082161299 nan\n",
      "Epoch: 1290\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5043705212650733\n",
      "MAPE:  0.009246203206860808\n",
      "Delta:  0.16559457365929509\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.660413920998252e-05 0.0001293665897857954 nan\n",
      "Epoch: 1291\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.504175905980963\n",
      "MAPE:  0.00924535737737712\n",
      "Delta:  0.16558685626673186\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.6600044290023845e-05 0.00012936048266054545 nan\n",
      "Epoch: 1292\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.503981325059759\n",
      "MAPE:  0.009244511622093738\n",
      "Delta:  0.165579139911896\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.659591710109989e-05 0.0001293542283449245 nan\n",
      "Epoch: 1293\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5037867787160106\n",
      "MAPE:  0.009243665942001631\n",
      "Delta:  0.16557142460001897\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.659180700561372e-05 0.00012934806115316722 nan\n",
      "Epoch: 1294\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.503592266811796\n",
      "MAPE:  0.009242820336290689\n",
      "Delta:  0.16556371032815836\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.6587668737996246e-05 0.00012934178633094984 nan\n",
      "Epoch: 1295\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5033977895020931\n",
      "MAPE:  0.009241974805870216\n",
      "Delta:  0.16555599710086655\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.658355938313985e-05 0.00012933557612360147 nan\n",
      "Epoch: 1296\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.503203346682845\n",
      "MAPE:  0.009241129350247429\n",
      "Delta:  0.16554828491324436\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.65794455124513e-05 0.00012932939959042766 nan\n",
      "Epoch: 1297\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5030089382965561\n",
      "MAPE:  0.009240283969159937\n",
      "Delta:  0.16554057376592757\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.657532285989863e-05 0.000129323173979623 nan\n",
      "Epoch: 1298\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5028145644101358\n",
      "MAPE:  0.009239438662916316\n",
      "Delta:  0.16553286366025802\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.657119572915036e-05 0.0001293169118969928 nan\n",
      "Epoch: 1299\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5026202250715126\n",
      "MAPE:  0.009238593431825672\n",
      "Delta:  0.1655251545968649\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.656710057993063e-05 0.00012931079347278107 nan\n",
      "Epoch: 1300\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5024259200579202\n",
      "MAPE:  0.009237748274836416\n",
      "Delta:  0.16551744657034229\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.656297328098358e-05 0.0001293045387598113 nan\n",
      "Epoch: 1301\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5022316495673065\n",
      "MAPE:  0.009236903192906053\n",
      "Delta:  0.1655097395859001\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.655884074822314e-05 0.00012929824420493397 nan\n",
      "Epoch: 1302\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5020374136526282\n",
      "MAPE:  0.00923605818622235\n",
      "Delta:  0.16550203364429242\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.655474828418882e-05 0.00012929214551904433 nan\n",
      "Epoch: 1303\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5018432120127674\n",
      "MAPE:  0.009235213253560874\n",
      "Delta:  0.1654943287387756\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.6550613613582925e-05 0.0001292858433213917 nan\n",
      "Epoch: 1304\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5016490449465658\n",
      "MAPE:  0.009234368396200981\n",
      "Delta:  0.16548662487622323\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.654649658242249e-05 0.00012927962181585873 nan\n",
      "Epoch: 1305\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5014549123259349\n",
      "MAPE:  0.009233523613598187\n",
      "Delta:  0.165478922053604\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.654240072410332e-05 0.00012927349605862393 nan\n",
      "Epoch: 1306\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5012608140002441\n",
      "MAPE:  0.009232678905079336\n",
      "Delta:  0.1654712202673024\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.653826778477921e-05 0.00012926720653194668 nan\n",
      "Epoch: 1307\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5010667502085424\n",
      "MAPE:  0.00923183427184377\n",
      "Delta:  0.16546351952334293\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.653415660871296e-05 0.00012926098589993718 nan\n",
      "Epoch: 1308\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5008727208405088\n",
      "MAPE:  0.009230989713334378\n",
      "Delta:  0.16545581981801238\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.653004315002818e-05 0.00012925479768577386 nan\n",
      "Epoch: 1309\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5006787258406245\n",
      "MAPE:  0.009230145229295172\n",
      "Delta:  0.16544812115157684\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.6525917129391914e-05 0.00012924852220075334 nan\n",
      "Epoch: 1310\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5004847653330113\n",
      "MAPE:  0.009229300820349005\n",
      "Delta:  0.16544042352600294\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.652183312636726e-05 0.00012924242193401714 nan\n",
      "Epoch: 1311\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5002908390478646\n",
      "MAPE:  0.009228456485370648\n",
      "Delta:  0.16543272693422728\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.651769285723972e-05 0.00012923609714132755 nan\n",
      "Epoch: 1312\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.5000969473152495\n",
      "MAPE:  0.009227612225700111\n",
      "Delta:  0.16542503138544723\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.6513582969476275e-05 0.0001292298972280781 nan\n",
      "Epoch: 1313\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.4999030899409158\n",
      "MAPE:  0.009226768040580886\n",
      "Delta:  0.16541733687452465\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.6509466468447336e-05 0.00012922367255030487 nan\n",
      "Epoch: 1314\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.499709266955164\n",
      "MAPE:  0.009225923930170193\n",
      "Delta:  0.165409643402442\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.650535552475077e-05 0.0001292174536716706 nan\n",
      "Epoch: 1315\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.4995154783424403\n",
      "MAPE:  0.009225079894439311\n",
      "Delta:  0.16540195096816834\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.650124333049899e-05 0.00012921124888587432 nan\n",
      "Epoch: 1316\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.49932172407476\n",
      "MAPE:  0.009224235933208619\n",
      "Delta:  0.165394259571799\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.6497142270007785e-05 0.00012920505649693936 nan\n",
      "Epoch: 1317\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.499128004126694\n",
      "MAPE:  0.009223392046550488\n",
      "Delta:  0.16538656921138106\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.649301135806194e-05 0.00012919875695160954 nan\n",
      "Epoch: 1318\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.4989343186520494\n",
      "MAPE:  0.009222548234929719\n",
      "Delta:  0.16537887989174027\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.6488894171470285e-05 0.00012919251607002025 nan\n",
      "Epoch: 1319\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.498740667555999\n",
      "MAPE:  0.009221704498128305\n",
      "Delta:  0.16537119161049477\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.648479608915235e-05 0.0001291863531649451 nan\n",
      "Epoch: 1320\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.4985470507148175\n",
      "MAPE:  0.00922086083555167\n",
      "Delta:  0.16536350436437375\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.64806879885149e-05 0.0001291801549037075 nan\n",
      "Epoch: 1321\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.4983534681746757\n",
      "MAPE:  0.009220017247405812\n",
      "Delta:  0.1653558181549227\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.647655645473314e-05 0.00012917382880062167 nan\n",
      "Epoch: 1322\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.4981599201202949\n",
      "MAPE:  0.009219173734595614\n",
      "Delta:  0.16534813298590512\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.6472466759373e-05 0.00012916769524784488 nan\n",
      "Epoch: 1323\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.4979664062563003\n",
      "MAPE:  0.009218330295794164\n",
      "Delta:  0.1653404488502912\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.646833911392534e-05 0.0001291614051585066 nan\n",
      "Epoch: 1324\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.4977729268103879\n",
      "MAPE:  0.00921748693200407\n",
      "Delta:  0.16533276575424477\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.646423908871711e-05 0.00012915522481493635 nan\n",
      "Epoch: 1325\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.497579481611304\n",
      "MAPE:  0.009216643642511759\n",
      "Delta:  0.16532508369308757\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.646012200348881e-05 0.000129148971308779 nan\n",
      "Epoch: 1326\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.4973860707618007\n",
      "MAPE:  0.009215800427768862\n",
      "Delta:  0.16531740266952896\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.645601836894553e-05 0.00012914276589848228 nan\n",
      "Epoch: 1327\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.4971926941830047\n",
      "MAPE:  0.00921495728757924\n",
      "Delta:  0.16530972268123384\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.645189485008583e-05 0.0001291364835862563 nan\n",
      "Epoch: 1328\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.496999351983227\n",
      "MAPE:  0.009214114222229631\n",
      "Delta:  0.16530204373137813\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.6447790968739966e-05 0.00012913026990279963 nan\n",
      "Epoch: 1329\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.496806044052861\n",
      "MAPE:  0.009213271231408552\n",
      "Delta:  0.1652943658166042\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.6443682012897725e-05 0.0001291240550381767 nan\n",
      "Epoch: 1330\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.4966127703868473\n",
      "MAPE:  0.009212428314974338\n",
      "Delta:  0.1652866889376397\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.6439583438639964e-05 0.00012911785899050177 nan\n",
      "Epoch: 1331\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.496419530950197\n",
      "MAPE:  0.009211585473026859\n",
      "Delta:  0.16527901309265747\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.6435446678927406e-05 0.00012911153237826767 nan\n",
      "Epoch: 1332\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.4962263259314752\n",
      "MAPE:  0.009210742706148786\n",
      "Delta:  0.16527133828785787\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.643137681303866e-05 0.0001291054346619358 nan\n",
      "Epoch: 1333\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.496033154981313\n",
      "MAPE:  0.009209900013069833\n",
      "Delta:  0.16526366451207342\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.642724004211285e-05 0.0001290991126374763 nan\n",
      "Epoch: 1334\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.4958400184285288\n",
      "MAPE:  0.009209057395023272\n",
      "Delta:  0.1652559917762509\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.642314425729044e-05 0.00012909290945350982 nan\n",
      "Epoch: 1335\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.4956469160884729\n",
      "MAPE:  0.009208214851425723\n",
      "Delta:  0.1652483200735053\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.64190043625301e-05 0.00012908656278309838 nan\n",
      "Epoch: 1336\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.495453848168938\n",
      "MAPE:  0.009207372382959347\n",
      "Delta:  0.1652406494110149\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.641494227075604e-05 0.00012908052188509433 nan\n",
      "Epoch: 1337\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.495260814205761\n",
      "MAPE:  0.00920652998792708\n",
      "Delta:  0.1652329797758117\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.6410824753317925e-05 0.00012907422902064258 nan\n",
      "Epoch: 1338\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.4950678145689826\n",
      "MAPE:  0.00920568766775868\n",
      "Delta:  0.16522531117694383\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.640670434663541e-05 0.00012906795003697624 nan\n",
      "Epoch: 1339\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.49487484923099\n",
      "MAPE:  0.009204845422362903\n",
      "Delta:  0.16521764361477748\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.6402584426674665e-05 0.00012906165093851119 nan\n",
      "Epoch: 1340\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.4946819182150017\n",
      "MAPE:  0.009204003251962547\n",
      "Delta:  0.16520997708912089\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.639849851206801e-05 0.00012905552101594164 nan\n",
      "Epoch: 1341\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.4944890212612936\n",
      "MAPE:  0.009203161155302985\n",
      "Delta:  0.16520231159424473\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.63943979209791e-05 0.00012904928555257378 nan\n",
      "Epoch: 1342\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.4942961585208336\n",
      "MAPE:  0.009202319133209907\n",
      "Delta:  0.16519464713246315\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.6390266410845094e-05 0.00012904296856763864 nan\n",
      "Epoch: 1343\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.4941033301086188\n",
      "MAPE:  0.009201477186048709\n",
      "Delta:  0.16518698370877305\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.638619203645167e-05 0.00012903684993692544 nan\n",
      "Epoch: 1344\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.4939105357214215\n",
      "MAPE:  0.009200635312648715\n",
      "Delta:  0.16517932131362478\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.638205948837015e-05 0.00012903049601065142 nan\n",
      "Epoch: 1345\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.4937177757040017\n",
      "MAPE:  0.009199793514487077\n",
      "Delta:  0.1651716599565174\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.637796373185843e-05 0.00012902429989269937 nan\n",
      "Epoch: 1346\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.4935250498137542\n",
      "MAPE:  0.009198951790548367\n",
      "Delta:  0.16516399963126238\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.637385054251375e-05 0.00012901803609854934 nan\n",
      "Epoch: 1347\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.4933323581449633\n",
      "MAPE:  0.009198110141181246\n",
      "Delta:  0.16515634034062848\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.6369749533425875e-05 0.0001290118055435885 nan\n",
      "Epoch: 1348\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.4931397006411624\n",
      "MAPE:  0.009197268566247894\n",
      "Delta:  0.16514868208249303\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.636564748861094e-05 0.00012900558714667998 nan\n",
      "Epoch: 1349\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.4929470772773892\n",
      "MAPE:  0.00919642706563199\n",
      "Delta:  0.1651410248569164\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.636154011916638e-05 0.00012899932557530747 nan\n",
      "Epoch: 1350\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.4927544881113008\n",
      "MAPE:  0.009195585639602212\n",
      "Delta:  0.16513336866466716\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.6357445374400896e-05 0.0001289931306042158 nan\n",
      "Epoch: 1351\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.492561933036656\n",
      "MAPE:  0.009194744287726578\n",
      "Delta:  0.1651257135035498\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.63533426766638e-05 0.0001289868886991119 nan\n",
      "Epoch: 1352\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.4923694121167228\n",
      "MAPE:  0.009193903010285578\n",
      "Delta:  0.16511805937476703\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.6349212928120664e-05 0.00012898053475918214 nan\n",
      "Epoch: 1353\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.4921769255118897\n",
      "MAPE:  0.009193061807982591\n",
      "Delta:  0.16511040628267482\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.634512688628245e-05 0.00012897437430503533 nan\n",
      "Epoch: 1354\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.4919844729265694\n",
      "MAPE:  0.009192220679583965\n",
      "Delta:  0.16510275421994539\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.634104871070743e-05 0.00012896822366015304 nan\n",
      "Epoch: 1355\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.4917920543393675\n",
      "MAPE:  0.009191379624966522\n",
      "Delta:  0.16509510318516982\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.6336906774469e-05 0.000128961841000641 nan\n",
      "Epoch: 1356\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.4915996700896497\n",
      "MAPE:  0.009190538645707588\n",
      "Delta:  0.1650874531887646\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.633282695398755e-05 0.00012895566968162964 nan\n",
      "Epoch: 1357\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.4914073198552964\n",
      "MAPE:  0.009189697740379034\n",
      "Delta:  0.16507980422036372\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.6328703750320166e-05 0.0001289493472911296 nan\n",
      "Epoch: 1358\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.4912150038548557\n",
      "MAPE:  0.009188856909943212\n",
      "Delta:  0.16507215628701885\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.632462347098354e-05 0.0001289431999630386 nan\n",
      "Epoch: 1359\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.4910227218204257\n",
      "MAPE:  0.009188016153221264\n",
      "Delta:  0.1650645093815333\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.632051287134509e-05 0.00012893690628801302 nan\n",
      "Epoch: 1360\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.4908304739634692\n",
      "MAPE:  0.00918717547124363\n",
      "Delta:  0.1650568635088019\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.6316406925761555e-05 0.0001289306455229955 nan\n",
      "Epoch: 1361\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.4906382602280956\n",
      "MAPE:  0.009186334863754203\n",
      "Delta:  0.16504921866794575\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.631231275520342e-05 0.00012892441376088914 nan\n",
      "Epoch: 1362\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.4904460805642663\n",
      "MAPE:  0.009185494330537926\n",
      "Delta:  0.1650415748569108\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.630822331685991e-05 0.00012891823197347385 nan\n",
      "Epoch: 1363\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.490253934890708\n",
      "MAPE:  0.009184653871210152\n",
      "Delta:  0.16503393207480577\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.63040875973153e-05 0.00012891184214125495 nan\n",
      "Epoch: 1364\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.490061823510703\n",
      "MAPE:  0.009183813487135895\n",
      "Delta:  0.16502629032915844\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.6300001914967304e-05 0.00012890565528334008 nan\n",
      "Epoch: 1365\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.4898697461149308\n",
      "MAPE:  0.009182973177050434\n",
      "Delta:  0.16501864961160018\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.6295913356364515e-05 0.00012889943502292223 nan\n",
      "Epoch: 1366\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.489677702746399\n",
      "MAPE:  0.009182132941159401\n",
      "Delta:  0.1650110099224956\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.6291800821718354e-05 0.00012889316121866834 nan\n",
      "Epoch: 1367\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.489485693478095\n",
      "MAPE:  0.009181292779741402\n",
      "Delta:  0.16500337126569087\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.6287722185067715e-05 0.00012888697931390247 nan\n",
      "Epoch: 1368\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.4892937181663313\n",
      "MAPE:  0.00918045269225867\n",
      "Delta:  0.16499573363548212\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.628360136560428e-05 0.0001288806570352019 nan\n",
      "Epoch: 1369\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.4891017770134156\n",
      "MAPE:  0.009179612679453759\n",
      "Delta:  0.1649880970387195\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.627952048152917e-05 0.0001288744654455165 nan\n",
      "Epoch: 1370\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.488909869817909\n",
      "MAPE:  0.009178772740731358\n",
      "Delta:  0.16498046146870338\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.6275403475903865e-05 0.00012886815119250716 nan\n",
      "Epoch: 1371\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.4887179967556934\n",
      "MAPE:  0.009177932876620108\n",
      "Delta:  0.1649728269312833\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.6271310478185335e-05 0.00012886191410610426 nan\n",
      "Epoch: 1372\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.4885261577050672\n",
      "MAPE:  0.00917709308674952\n",
      "Delta:  0.16496519342238788\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.6267203174465976e-05 0.0001288556287878384 nan\n",
      "Epoch: 1373\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.488334352731049\n",
      "MAPE:  0.009176253371363324\n",
      "Delta:  0.16495756094426708\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.626312092892437e-05 0.00012884944673963172 nan\n",
      "Epoch: 1374\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.4881425816731362\n",
      "MAPE:  0.009175413729850423\n",
      "Delta:  0.16494992949267698\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.625901286658962e-05 0.00012884314786743012 nan\n",
      "Epoch: 1375\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.4879508446984377\n",
      "MAPE:  0.009174574162911906\n",
      "Delta:  0.16494229907176625\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.625492703858036e-05 0.0001288369493307462 nan\n",
      "Epoch: 1376\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.4877591416508527\n",
      "MAPE:  0.009173734669902917\n",
      "Delta:  0.1649346696777571\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.625080315079355e-05 0.00012883057374335483 nan\n",
      "Epoch: 1377\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.4875674727870418\n",
      "MAPE:  0.009172895251943832\n",
      "Delta:  0.1649270413168171\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.6246739325739306e-05 0.00012882446409978598 nan\n",
      "Epoch: 1378\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.4873758377045478\n",
      "MAPE:  0.00917205590726851\n",
      "Delta:  0.16491941397892954\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.624262587604733e-05 0.00012881814139131809 nan\n",
      "Epoch: 1379\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.4871842367135844\n",
      "MAPE:  0.009171216637337073\n",
      "Delta:  0.1649117876721692\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.623853367391462e-05 0.00012881189770774792 nan\n",
      "Epoch: 1380\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.4869926696898121\n",
      "MAPE:  0.00917037744160758\n",
      "Delta:  0.16490416239292172\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.623443528750659e-05 0.0001288056388856207 nan\n",
      "Epoch: 1381\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.4868011366489746\n",
      "MAPE:  0.009169538320062292\n",
      "Delta:  0.16489653814209693\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.6230324658114164e-05 0.00012879932859499732 nan\n",
      "Epoch: 1382\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.4866096376608198\n",
      "MAPE:  0.009168699273131775\n",
      "Delta:  0.16488891492160362\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.622624884198512e-05 0.00012879314985936308 nan\n",
      "Epoch: 1383\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.4864181725229741\n",
      "MAPE:  0.00916786029990021\n",
      "Delta:  0.16488129272559116\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.622214933769353e-05 0.00012878686252615346 nan\n",
      "Epoch: 1384\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.486226741390133\n",
      "MAPE:  0.009167021401213334\n",
      "Delta:  0.16487367155785582\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.6218031752975897e-05 0.00012878052569309517 nan\n",
      "Epoch: 1385\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.4860353443290777\n",
      "MAPE:  0.009166182577089337\n",
      "Delta:  0.16486605142126853\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.6213982223597405e-05 0.00012877445725112402 nan\n",
      "Epoch: 1386\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.4858439809341557\n",
      "MAPE:  0.00916534382604867\n",
      "Delta:  0.16485843230449887\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.6209832059940226e-05 0.0001287679493553462 nan\n",
      "Epoch: 1387\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.4856526518516688\n",
      "MAPE:  0.009164505150773801\n",
      "Delta:  0.16485081422402842\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.620578873315573e-05 0.00012876192133659536 nan\n",
      "Epoch: 1388\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.4854613563617776\n",
      "MAPE:  0.009163666548207812\n",
      "Delta:  0.16484319716213391\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.620167201507819e-05 0.00012875556313862724 nan\n",
      "Epoch: 1389\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.4852700949483184\n",
      "MAPE:  0.00916282802050394\n",
      "Delta:  0.1648355811308047\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.619757424706439e-05 0.00012874927756489907 nan\n",
      "Epoch: 1390\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.4850788674966051\n",
      "MAPE:  0.009161989567075222\n",
      "Delta:  0.16482796612680686\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.619349185552846e-05 0.0001287430788747823 nan\n",
      "Epoch: 1391\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.4848876738708316\n",
      "MAPE:  0.009161151187481429\n",
      "Delta:  0.16482035214749602\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.61893907992561e-05 0.000128736776643823 nan\n",
      "Epoch: 1392\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.4846965142180195\n",
      "MAPE:  0.009160312882324143\n",
      "Delta:  0.16481273919583903\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.6185297250977975e-05 0.00012873050730199953 nan\n",
      "Epoch: 1393\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.4845053884825548\n",
      "MAPE:  0.009159474651376497\n",
      "Delta:  0.16480512727048852\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.618118914834213e-05 0.00012872418373577332 nan\n",
      "Epoch: 1394\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.484314296738171\n",
      "MAPE:  0.009158636494911693\n",
      "Delta:  0.1647975163737334\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.6177112624445904e-05 0.00012871799248470595 nan\n",
      "Epoch: 1395\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.4841232387816785\n",
      "MAPE:  0.009157798412200154\n",
      "Delta:  0.1647899065002596\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.617303337961509e-05 0.00012871178454565424 nan\n",
      "Epoch: 1396\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.4839322146311291\n",
      "MAPE:  0.009156960403286871\n",
      "Delta:  0.16478229765040614\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.61689198452131e-05 0.00012870541903875488 nan\n",
      "Epoch: 1397\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.4837412245136201\n",
      "MAPE:  0.009156122469149288\n",
      "Delta:  0.164774689829714\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.6164835743267574e-05 0.00012869920598312934 nan\n",
      "Epoch: 1398\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.4835502681961408\n",
      "MAPE:  0.009155284608783397\n",
      "Delta:  0.16476708303322338\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.61607478920989e-05 0.00012869294400430498 nan\n",
      "Epoch: 1399\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.4833593457445482\n",
      "MAPE:  0.009154446822515042\n",
      "Delta:  0.16475947726144258\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.615664063611913e-05 0.0001286866216360094 nan\n",
      "Epoch: 1400\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.4831684572416721\n",
      "MAPE:  0.009153609110745059\n",
      "Delta:  0.1647518725174592\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.6152571365754014e-05 0.00012868044504388276 nan\n",
      "Epoch: 1401\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.4829776024645192\n",
      "MAPE:  0.009152771472562443\n",
      "Delta:  0.16474426879490522\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.614846974293485e-05 0.00012867411720851596 nan\n",
      "Epoch: 1402\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.4827867816306821\n",
      "MAPE:  0.009151933908824694\n",
      "Delta:  0.1647366660990014\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.614437039318631e-05 0.00012866782268905474 nan\n",
      "Epoch: 1403\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.4825959946839777\n",
      "MAPE:  0.009151096419423937\n",
      "Delta:  0.1647290644292636\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.6140284572282475e-05 0.00012866157806934453 nan\n",
      "Epoch: 1404\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.4824052415436624\n",
      "MAPE:  0.009150259003883\n",
      "Delta:  0.1647214637833535\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.6136193317725116e-05 0.00012865529450023505 nan\n",
      "Epoch: 1405\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.4822145222607428\n",
      "MAPE:  0.00914942166259744\n",
      "Delta:  0.1647138641620568\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.6132132767384704e-05 0.00012864916132715454 nan\n",
      "Epoch: 1406\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.482023836605547\n",
      "MAPE:  0.009148584394447897\n",
      "Delta:  0.16470626556020665\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.612802766734703e-05 0.00012864282023150597 nan\n",
      "Epoch: 1407\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.4818331848795556\n",
      "MAPE:  0.009147747200937329\n",
      "Delta:  0.1646986679850319\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.612389236868797e-05 0.00012863634839155313 nan\n",
      "Epoch: 1408\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.4816425672697273\n",
      "MAPE:  0.009146910082712926\n",
      "Delta:  0.1646910714413965\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.6119865889759915e-05 0.00012863034447074817 nan\n",
      "Epoch: 1409\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.481451983075917\n",
      "MAPE:  0.009146073036883046\n",
      "Delta:  0.1646834759112684\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.611575433866033e-05 0.00012862398320390156 nan\n",
      "Epoch: 1410\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.4812614328209284\n",
      "MAPE:  0.009145236065635618\n",
      "Delta:  0.1646758814085496\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.611165168033615e-05 0.0001286176497410363 nan\n",
      "Epoch: 1411\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.481070916456787\n",
      "MAPE:  0.00914439916888917\n",
      "Delta:  0.16466828793166596\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.610757343459504e-05 0.00012861141928321995 nan\n",
      "Epoch: 1412\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.4808804338241623\n",
      "MAPE:  0.009143562345847662\n",
      "Delta:  0.1646606954764878\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.610349878797493e-05 0.0001286052040088137 nan\n",
      "Epoch: 1413\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.480689984893858\n",
      "MAPE:  0.009142725596532886\n",
      "Delta:  0.16465310404231348\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.609940046929051e-05 0.00012859887754179677 nan\n",
      "Epoch: 1414\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.480499569823813\n",
      "MAPE:  0.00914188892166622\n",
      "Delta:  0.1646455136329317\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.60953073133652e-05 0.0001285925890056605 nan\n",
      "Epoch: 1415\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.4803091885511077\n",
      "MAPE:  0.009141052320768367\n",
      "Delta:  0.16463792424738302\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.609123311349883e-05 0.0001285863724989067 nan\n",
      "Epoch: 1416\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.4801188409623751\n",
      "MAPE:  0.00914021579358431\n",
      "Delta:  0.16463033588243722\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.608713819942434e-05 0.0001285800482079269 nan\n",
      "Epoch: 1417\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.4799285272104505\n",
      "MAPE:  0.00913937934073045\n",
      "Delta:  0.16462274854139558\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.6083043872213736e-05 0.00012857375971531138 nan\n",
      "Epoch: 1418\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.4797382472355973\n",
      "MAPE:  0.009138542961962929\n",
      "Delta:  0.1646151622240522\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.60789737878331e-05 0.0001285675494108185 nan\n",
      "Epoch: 1419\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.4795480009153807\n",
      "MAPE:  0.009137706656754797\n",
      "Delta:  0.164607576926307\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.607487914021213e-05 0.000128561242798364 nan\n",
      "Epoch: 1420\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.4793577883856033\n",
      "MAPE:  0.009136870425725833\n",
      "Delta:  0.16459999265209457\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.607080056306945e-05 0.0001285549812025666 nan\n",
      "Epoch: 1421\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.4791676095729254\n",
      "MAPE:  0.009136034268677559\n",
      "Delta:  0.1645924093986604\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.606667563822331e-05 0.0001285485366464556 nan\n",
      "Epoch: 1422\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.47897746474126\n",
      "MAPE:  0.009135198186607213\n",
      "Delta:  0.16458482717352413\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.606263401840671e-05 0.0001285424515138356 nan\n",
      "Epoch: 1423\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.4787873533522085\n",
      "MAPE:  0.00913436217726923\n",
      "Delta:  0.16457724596286505\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.6058539171611734e-05 0.0001285361394862683 nan\n",
      "Epoch: 1424\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.4785972757346872\n",
      "MAPE:  0.00913352624213354\n",
      "Delta:  0.16456966577533513\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.605445386229867e-05 0.00012852985653311055 nan\n",
      "Epoch: 1425\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.478407231838967\n",
      "MAPE:  0.009132690380939178\n",
      "Delta:  0.16456208660925553\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.6050367391692326e-05 0.00012852356661474662 nan\n",
      "Epoch: 1426\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.478217221668622\n",
      "MAPE:  0.009131854593816527\n",
      "Delta:  0.16455450846470843\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.604627955295815e-05 0.00012851725945939307 nan\n",
      "Epoch: 1427\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.4780272452424075\n",
      "MAPE:  0.009131018880828946\n",
      "Delta:  0.16454693134180998\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.604219763315598e-05 0.0001285110043949267 nan\n",
      "Epoch: 1428\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.4778373024765983\n",
      "MAPE:  0.009130183241575131\n",
      "Delta:  0.1645393552394772\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.6038128520442534e-05 0.00012850477740811161 nan\n",
      "Epoch: 1429\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.477647393322998\n",
      "MAPE:  0.009129347675931489\n",
      "Delta:  0.164531780155494\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.6034019081986344e-05 0.00012849839323392231 nan\n",
      "Epoch: 1430\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.4774575180071898\n",
      "MAPE:  0.009128512184842027\n",
      "Delta:  0.16452420609638674\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.602994902325186e-05 0.00012849215835564198 nan\n",
      "Epoch: 1431\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.4772676763018222\n",
      "MAPE:  0.009127676767387028\n",
      "Delta:  0.16451663305556702\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.60258725419882e-05 0.00012848589340352934 nan\n",
      "Epoch: 1432\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.4770778682446366\n",
      "MAPE:  0.009126841423777895\n",
      "Delta:  0.16450906103398297\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.602178056900552e-05 0.00012847959595629899 nan\n",
      "Epoch: 1433\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.4768880938769284\n",
      "MAPE:  0.009126006154135587\n",
      "Delta:  0.16450149003407444\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.601769325096594e-05 0.0001284732907764763 nan\n",
      "Epoch: 1434\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.4766983532033995\n",
      "MAPE:  0.009125170958520338\n",
      "Delta:  0.16449392005496674\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.6013616563977955e-05 0.00012846700854030058 nan\n",
      "Epoch: 1435\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.4765086461834471\n",
      "MAPE:  0.009124335836821163\n",
      "Delta:  0.16448635109480222\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.600954128419765e-05 0.00012846077579364845 nan\n",
      "Epoch: 1436\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.4763189727372923\n",
      "MAPE:  0.009123500788612146\n",
      "Delta:  0.16447878315324083\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.600545282729129e-05 0.00012845444100839654 nan\n",
      "Epoch: 1437\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.4761293330088991\n",
      "MAPE:  0.009122665814656256\n",
      "Delta:  0.1644712162323414\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.6001375775595044e-05 0.00012844819358026616 nan\n",
      "Epoch: 1438\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.4759397268625833\n",
      "MAPE:  0.009121830914334874\n",
      "Delta:  0.16446365033011923\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.599727283793875e-05 0.00012844181031668178 nan\n",
      "Epoch: 1439\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.4757501544921467\n",
      "MAPE:  0.009120996088528729\n",
      "Delta:  0.16445608545072307\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.5993233373953224e-05 0.00012843568097120617 nan\n",
      "Epoch: 1440\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.4755606155161114\n",
      "MAPE:  0.009120161335529358\n",
      "Delta:  0.16444852158360515\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.598912064346372e-05 0.0001284292823698907 nan\n",
      "Epoch: 1441\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.4753711103251674\n",
      "MAPE:  0.009119326657101988\n",
      "Delta:  0.1644409587407064\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.598506168052019e-05 0.0001284230796254615 nan\n",
      "Epoch: 1442\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.475181638623589\n",
      "MAPE:  0.0091184920519988\n",
      "Delta:  0.1644333969130759\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.5980965730163526e-05 0.0001284167165207517 nan\n",
      "Epoch: 1443\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.4749922006412852\n",
      "MAPE:  0.009117657521243546\n",
      "Delta:  0.16442583610668757\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.59768885272549e-05 0.00012841044788280964 nan\n",
      "Epoch: 1444\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.4748027962321775\n",
      "MAPE:  0.00911682306411852\n",
      "Delta:  0.16441827631834988\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.5972799105231665e-05 0.00012840411619341463 nan\n",
      "Epoch: 1445\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.4746134254825676\n",
      "MAPE:  0.009115988681163253\n",
      "Delta:  0.16441071754996348\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.596872307416344e-05 0.00012839783574813968 nan\n",
      "Epoch: 1446\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.4744240883101705\n",
      "MAPE:  0.009115154371939053\n",
      "Delta:  0.164403159799218\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.5964658461072894e-05 0.0001283916178685951 nan\n",
      "Epoch: 1447\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.4742347846160477\n",
      "MAPE:  0.009114320136090644\n",
      "Delta:  0.1643956030641279\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.596057006434062e-05 0.00012838527445691028 nan\n",
      "Epoch: 1448\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.474045514578611\n",
      "MAPE:  0.009113485974446913\n",
      "Delta:  0.164388047348495\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.59565018005037e-05 0.00012837902831674963 nan\n",
      "Epoch: 1449\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.4738562780477549\n",
      "MAPE:  0.009112651886194667\n",
      "Delta:  0.16438049264890106\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.595241524485427e-05 0.00012837270380128274 nan\n",
      "Epoch: 1450\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.4736670751323273\n",
      "MAPE:  0.009111817872042636\n",
      "Delta:  0.1643729389682447\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.594833821569555e-05 0.0001283664262951012 nan\n",
      "Epoch: 1451\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.4734779057563439\n",
      "MAPE:  0.009110983931520284\n",
      "Delta:  0.16436538630485148\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.5944256076624335e-05 0.00012836009160666073 nan\n",
      "Epoch: 1452\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.4732887699973807\n",
      "MAPE:  0.009110150065132236\n",
      "Delta:  0.16435783465945297\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.594019122683424e-05 0.00012835387796095166 nan\n",
      "Epoch: 1453\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.4730996676703951\n",
      "MAPE:  0.009109316271972824\n",
      "Delta:  0.16435028402909907\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.5936095971366164e-05 0.000128347489598446 nan\n",
      "Epoch: 1454\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.4729105990261213\n",
      "MAPE:  0.009108482553132865\n",
      "Delta:  0.16434273441867897\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.5932027293860145e-05 0.00012834124873861708 nan\n",
      "Epoch: 1455\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.472721563840562\n",
      "MAPE:  0.009107648907796825\n",
      "Delta:  0.16433518582371612\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.5927941764278835e-05 0.00012833489633401474 nan\n",
      "Epoch: 1456\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.4725325622713377\n",
      "MAPE:  0.009106815336570801\n",
      "Delta:  0.1643276382468718\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.5923893067789656e-05 0.00012832873935131328 nan\n",
      "Epoch: 1457\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.4723435940239675\n",
      "MAPE:  0.009105981838197112\n",
      "Delta:  0.16432009168198486\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.591978963985888e-05 0.00012832230009796053 nan\n",
      "Epoch: 1458\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.472154659507448\n",
      "MAPE:  0.00910514841451255\n",
      "Delta:  0.16431254613794122\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.591571455381249e-05 0.0001283160293250596 nan\n",
      "Epoch: 1459\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.4719657584669876\n",
      "MAPE:  0.009104315064387337\n",
      "Delta:  0.16430500160997516\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.591165593759161e-05 0.00012830978708489038 nan\n",
      "Epoch: 1460\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.4717768908539224\n",
      "MAPE:  0.009103481787665672\n",
      "Delta:  0.1642974580952724\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.590756237865534e-05 0.00012830343721170756 nan\n",
      "Epoch: 1461\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.471588056820017\n",
      "MAPE:  0.00910264858494724\n",
      "Delta:  0.16428991559946626\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.5903496980193026e-05 0.00012829716941586966 nan\n",
      "Epoch: 1462\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.471399256237781\n",
      "MAPE:  0.009101815455774546\n",
      "Delta:  0.16428237411782165\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.589941948984766e-05 0.00012829086258325795 nan\n",
      "Epoch: 1463\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.4712104891579938\n",
      "MAPE:  0.00910098240039227\n",
      "Delta:  0.16427483365221723\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.589535084209562e-05 0.00012828457955760264 nan\n",
      "Epoch: 1464\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.4710217555389515\n",
      "MAPE:  0.009100149418646286\n",
      "Delta:  0.16426729420109223\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.589127172827112e-05 0.00012827828550032727 nan\n",
      "Epoch: 1465\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.4708330553902174\n",
      "MAPE:  0.009099316510495833\n",
      "Delta:  0.164259755766058\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.588717626419214e-05 0.00012827186809327706 nan\n",
      "Epoch: 1466\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.470644388886549\n",
      "MAPE:  0.009098483676875081\n",
      "Delta:  0.16425221834969206\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.588314540554528e-05 0.00012826575852098454 nan\n",
      "Epoch: 1467\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.4704557555684938\n",
      "MAPE:  0.009097650915623038\n",
      "Delta:  0.1642446819412743\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.5879046246311006e-05 0.00012825934899618474 nan\n",
      "Epoch: 1468\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.470267155870557\n",
      "MAPE:  0.00909681822883861\n",
      "Delta:  0.16423714655191582\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.587497994024137e-05 0.00012825308449571082 nan\n",
      "Epoch: 1469\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.4700785895727837\n",
      "MAPE:  0.009095985615471919\n",
      "Delta:  0.16422961217611232\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.587091022911771e-05 0.00012824677937761653 nan\n",
      "Epoch: 1470\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.4698900567282391\n",
      "MAPE:  0.009095153075769144\n",
      "Delta:  0.16422207881431522\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.586681657370306e-05 0.00012824041205772296 nan\n",
      "Epoch: 1471\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.4697015574216847\n",
      "MAPE:  0.009094320610134113\n",
      "Delta:  0.1642145464703489\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.5862763193293965e-05 0.00012823418498297823 nan\n",
      "Epoch: 1472\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.4695130914403007\n",
      "MAPE:  0.009093488217671582\n",
      "Delta:  0.16420701513749122\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.585869189466241e-05 0.00012822787471011843 nan\n",
      "Epoch: 1473\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.4693246588997266\n",
      "MAPE:  0.00909265589895464\n",
      "Delta:  0.16419948481857707\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.585460645356587e-05 0.0001282215131713782 nan\n",
      "Epoch: 1474\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.4691362598686224\n",
      "MAPE:  0.009091823654202906\n",
      "Delta:  0.16419195551582086\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.58505514803198e-05 0.00012821529124396047 nan\n",
      "Epoch: 1475\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.4689478941351863\n",
      "MAPE:  0.009090991482561178\n",
      "Delta:  0.16418442722411183\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.584646913063928e-05 0.0001282089247947038 nan\n",
      "Epoch: 1476\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.4687595619051\n",
      "MAPE:  0.009090159384957736\n",
      "Delta:  0.16417689994783735\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.584240394800432e-05 0.00012820265456991997 nan\n",
      "Epoch: 1477\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.4685712630303387\n",
      "MAPE:  0.009089327360736242\n",
      "Delta:  0.16416937368407103\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.583833112214997e-05 0.00012819635505734173 nan\n",
      "Epoch: 1478\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.4683829975472764\n",
      "MAPE:  0.009088495410110416\n",
      "Delta:  0.16416184843395998\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.583425280668685e-05 0.00012819000256003577 nan\n",
      "Epoch: 1479\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.4681947655270617\n",
      "MAPE:  0.009087663533337688\n",
      "Delta:  0.16415432419829765\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.583019873460881e-05 0.0001281837681863518 nan\n",
      "Epoch: 1480\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.468006566789585\n",
      "MAPE:  0.00908683172978277\n",
      "Delta:  0.1641468009729965\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.582609075887145e-05 0.00012817730402037153 nan\n",
      "Epoch: 1481\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.4678184016655695\n",
      "MAPE:  0.009086000000763211\n",
      "Delta:  0.16413927876679732\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.582206211756201e-05 0.00012817116818686358 nan\n",
      "Epoch: 1482\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.467630269666342\n",
      "MAPE:  0.00908516834428067\n",
      "Delta:  0.16413175756656972\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.581796753100331e-05 0.00012816474159560443 nan\n",
      "Epoch: 1483\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.4674421712120722\n",
      "MAPE:  0.009084336762083959\n",
      "Delta:  0.16412423738303072\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.5813919063664166e-05 0.00012815853219405593 nan\n",
      "Epoch: 1484\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.46725410597733\n",
      "MAPE:  0.009083505252869693\n",
      "Delta:  0.16411671820850288\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.5809843035149456e-05 0.0001281521928324647 nan\n",
      "Epoch: 1485\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.4670660741462065\n",
      "MAPE:  0.009082673817432574\n",
      "Delta:  0.1641092000474023\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.580576099255662e-05 0.00012814583302600546 nan\n",
      "Epoch: 1486\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.4668780757420308\n",
      "MAPE:  0.009081842455779771\n",
      "Delta:  0.16410168290060823\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.580171199364269e-05 0.00012813959880686454 nan\n",
      "Epoch: 1487\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.4666901105739067\n",
      "MAPE:  0.009081011167307721\n",
      "Delta:  0.16409416676259037\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.5797632400534916e-05 0.0001281332343917585 nan\n",
      "Epoch: 1488\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.4665021788261885\n",
      "MAPE:  0.009080179952685313\n",
      "Delta:  0.1640866516382619\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.57935708326751e-05 0.0001281269615776015 nan\n",
      "Epoch: 1489\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.4663142803578686\n",
      "MAPE:  0.009079348811366648\n",
      "Delta:  0.16407913752455738\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.578949928457643e-05 0.00012812062725298112 nan\n",
      "Epoch: 1490\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.466126415252519\n",
      "MAPE:  0.00907851774375283\n",
      "Delta:  0.1640716244230071\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.578543461031259e-05 0.00012811432549231228 nan\n",
      "Epoch: 1491\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.4659385834557426\n",
      "MAPE:  0.009077686749565078\n",
      "Delta:  0.16406411233237567\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.578135409394335e-05 0.0001281079682459163 nan\n",
      "Epoch: 1492\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.4657507850422427\n",
      "MAPE:  0.009076855829133226\n",
      "Delta:  0.16405660125515487\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.5777310851202735e-05 0.00012810175031574556 nan\n",
      "Epoch: 1493\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.4655630198011522\n",
      "MAPE:  0.009076024981729207\n",
      "Delta:  0.164049091185122\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.577320188781098e-05 0.0001280952657742862 nan\n",
      "Epoch: 1494\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.4653752881166218\n",
      "MAPE:  0.009075194208840244\n",
      "Delta:  0.1640415821329517\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.5769182096422334e-05 0.00012808912357920033 nan\n",
      "Epoch: 1495\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.4651875894802524\n",
      "MAPE:  0.009074363508452171\n",
      "Delta:  0.16403407408390766\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.57650915652863e-05 0.00012808273565900752 nan\n",
      "Epoch: 1496\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.464999924245538\n",
      "MAPE:  0.00907353288191242\n",
      "Delta:  0.16402656704948737\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.576101904429919e-05 0.00012807636373923792 nan\n",
      "Epoch: 1497\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.4648122923823623\n",
      "MAPE:  0.009072702329262947\n",
      "Delta:  0.16401906102662886\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.575697363040643e-05 0.00012807014974614006 nan\n",
      "Epoch: 1498\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.464624693652727\n",
      "MAPE:  0.00907187184948419\n",
      "Delta:  0.16401155601077858\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.5752909341612025e-05 0.00012806383701591262 nan\n",
      "Epoch: 1499\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.4644371281946695\n",
      "MAPE:  0.009071041443176161\n",
      "Delta:  0.16400405200492543\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.574882976782213e-05 0.0001280574660582623 nan\n",
      "Epoch: 1500\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.4642495960868314\n",
      "MAPE:  0.009070211110612188\n",
      "Delta:  0.16399654901146904\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.5744760653221306e-05 0.00012805111937552738 nan\n",
      "Epoch: 1501\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.4640620972870073\n",
      "MAPE:  0.009069380851739126\n",
      "Delta:  0.16398904702858655\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.574070575313893e-05 0.00012804484372275216 nan\n",
      "Epoch: 1502\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.46387463168456\n",
      "MAPE:  0.009068550666036668\n",
      "Delta:  0.1639815460538397\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.573663685181195e-05 0.00012803850851594856 nan\n",
      "Epoch: 1503\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.4636871993600646\n",
      "MAPE:  0.009067720553949669\n",
      "Delta:  0.16397404608941743\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.5732599545211805e-05 0.0001280322999583916 nan\n",
      "Epoch: 1504\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.463499800121511\n",
      "MAPE:  0.009066890514575172\n",
      "Delta:  0.1639665471300318\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.572850034156861e-05 0.0001280258297583492 nan\n",
      "Epoch: 1505\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.4633124343452493\n",
      "MAPE:  0.009066060549596881\n",
      "Delta:  0.16395904918572538\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.5724453510698204e-05 0.0001280195908316406 nan\n",
      "Epoch: 1506\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.4631251016861455\n",
      "MAPE:  0.009065230657538698\n",
      "Delta:  0.16395155224780322\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.572038923000843e-05 0.00012801325438294153 nan\n",
      "Epoch: 1507\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.4629378022803095\n",
      "MAPE:  0.009064400838994274\n",
      "Delta:  0.1639440563190196\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.571631272232146e-05 0.0001280068897507869 nan\n",
      "Epoch: 1508\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.4627505361623407\n",
      "MAPE:  0.009063571094155266\n",
      "Delta:  0.16393656140127194\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.5712255501317856e-05 0.00012800057899886585 nan\n",
      "Epoch: 1509\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.4625633032467809\n",
      "MAPE:  0.009062741422649435\n",
      "Delta:  0.16392906749129116\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.570819252402991e-05 0.00012799427490206572 nan\n",
      "Epoch: 1510\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.4623761035172835\n",
      "MAPE:  0.009061911824454271\n",
      "Delta:  0.16392157458991397\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.5704133917245926e-05 0.00012798795076052194 nan\n",
      "Epoch: 1511\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.462188936996553\n",
      "MAPE:  0.009061082299713119\n",
      "Delta:  0.163914082696317\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.570008825388605e-05 0.00012798170133898612 nan\n",
      "Epoch: 1512\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.4620018035687172\n",
      "MAPE:  0.009060252847842433\n",
      "Delta:  0.16390659180827172\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.5696011086615584e-05 0.00012797530392127943 nan\n",
      "Epoch: 1513\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.461814703443572\n",
      "MAPE:  0.009059423469911513\n",
      "Delta:  0.16389910193083526\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.56919395100952e-05 0.00012796893675381948 nan\n",
      "Epoch: 1514\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.4616276365702412\n",
      "MAPE:  0.009058594165542997\n",
      "Delta:  0.16389161306298408\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.568789492220837e-05 0.00012796270507298146 nan\n",
      "Epoch: 1515\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.4614406027440563\n",
      "MAPE:  0.009057764933946338\n",
      "Delta:  0.16388412520018783\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.568382004110916e-05 0.00012795630193052077 nan\n",
      "Epoch: 1516\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.461253602209038\n",
      "MAPE:  0.009056935776314168\n",
      "Delta:  0.1638766383473046\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.567975463432017e-05 0.00012794996189247065 nan\n",
      "Epoch: 1517\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.4610666348663202\n",
      "MAPE:  0.009056106692068711\n",
      "Delta:  0.16386915250267461\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.567571326230535e-05 0.00012794371513780156 nan\n",
      "Epoch: 1518\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.4608797005729917\n",
      "MAPE:  0.009055277680696663\n",
      "Delta:  0.16386166766225235\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.567164412661029e-05 0.00012793735676253082 nan\n",
      "Epoch: 1519\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.4606927994855523\n",
      "MAPE:  0.009054448742849159\n",
      "Delta:  0.1638541838304809\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.566757573032376e-05 0.00012793098642893685 nan\n",
      "Epoch: 1520\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.4605059316148443\n",
      "MAPE:  0.00905361987865637\n",
      "Delta:  0.16384670100713206\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.566353632506903e-05 0.0001279247479076817 nan\n",
      "Epoch: 1521\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.460319096761725\n",
      "MAPE:  0.00905279108720932\n",
      "Delta:  0.1638392191873489\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.5659480552462384e-05 0.00012791843516701817 nan\n",
      "Epoch: 1522\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.4601322950280227\n",
      "MAPE:  0.009051962369026155\n",
      "Delta:  0.16383173837370668\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.565538977896466e-05 0.00012791197379946606 nan\n",
      "Epoch: 1523\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.4599455266241572\n",
      "MAPE:  0.00905113372500086\n",
      "Delta:  0.16382425857183305\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.565135438217016e-05 0.00012790573926291238 nan\n",
      "Epoch: 1524\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.459758791212291\n",
      "MAPE:  0.009050305153698632\n",
      "Delta:  0.1638167797725486\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.564729931999523e-05 0.00012789943253710412 nan\n",
      "Epoch: 1525\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.4595720888912538\n",
      "MAPE:  0.009049476655533822\n",
      "Delta:  0.16380930197896867\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.564323047662189e-05 0.00012789305047111732 nan\n",
      "Epoch: 1526\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.459385419764423\n",
      "MAPE:  0.00904864823104575\n",
      "Delta:  0.16380182519324424\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.563917030708797e-05 0.00012788672395724898 nan\n",
      "Epoch: 1527\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.4591987837440983\n",
      "MAPE:  0.009047819879784926\n",
      "Delta:  0.16379434941384763\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.563509450372649e-05 0.0001278802927746625 nan\n",
      "Epoch: 1528\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.4590121809764165\n",
      "MAPE:  0.009046991602486537\n",
      "Delta:  0.16378687464323294\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.5631067530971237e-05 0.00012787411812087424 nan\n",
      "Epoch: 1529\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.4588256110804467\n",
      "MAPE:  0.009046163397463457\n",
      "Delta:  0.16377940087329543\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.562701535593128e-05 0.00012786778452911207 nan\n",
      "Epoch: 1530\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.4586390742815434\n",
      "MAPE:  0.009045335265710367\n",
      "Delta:  0.1637719281080568\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.5622921488686075e-05 0.00012786131789443989 nan\n",
      "Epoch: 1531\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.4584525707671734\n",
      "MAPE:  0.009044507208087443\n",
      "Delta:  0.16376445635423867\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.5618897954291526e-05 0.0001278551108639947 nan\n",
      "Epoch: 1532\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.4582661001520483\n",
      "MAPE:  0.009043679222953103\n",
      "Delta:  0.1637569856002157\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.561482157394714e-05 0.00012784868971127406 nan\n",
      "Epoch: 1533\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.4580796627418935\n",
      "MAPE:  0.009042851311657094\n",
      "Delta:  0.16374951585453607\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.561078212350633e-05 0.00012784243729857536 nan\n",
      "Epoch: 1534\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.4578932582840332\n",
      "MAPE:  0.009042023473065703\n",
      "Delta:  0.1637420471110456\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.560672996711812e-05 0.0001278361083867363 nan\n",
      "Epoch: 1535\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.4577068868834508\n",
      "MAPE:  0.009041195707637235\n",
      "Delta:  0.16373457937171876\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.560264940300929e-05 0.00012782967703306447 nan\n",
      "Epoch: 1536\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.4575205486828917\n",
      "MAPE:  0.009040368016122792\n",
      "Delta:  0.16372711264110051\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.559860338171351e-05 0.00012782337602068594 nan\n",
      "Epoch: 1537\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.4573342434857395\n",
      "MAPE:  0.009039540397616067\n",
      "Delta:  0.16371964691342833\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.5594564504702895e-05 0.0001278171037424336 nan\n",
      "Epoch: 1538\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.4571479712435522\n",
      "MAPE:  0.009038712851943624\n",
      "Delta:  0.16371218218742645\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.55904856860867e-05 0.00012781069246359245 nan\n",
      "Epoch: 1539\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.4569617321523258\n",
      "MAPE:  0.009037885379842299\n",
      "Delta:  0.1637047184695278\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.558645465535527e-05 0.00012780443222037974 nan\n",
      "Epoch: 1540\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.4567755259853812\n",
      "MAPE:  0.009037057980658098\n",
      "Delta:  0.1636972557518024\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.5582380021613744e-05 0.00012779801748852293 nan\n",
      "Epoch: 1541\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.4565893529612346\n",
      "MAPE:  0.009036230655096603\n",
      "Delta:  0.16368979404128225\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.5578331737905486e-05 0.00012779170000853934 nan\n",
      "Epoch: 1542\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.4564032129316054\n",
      "MAPE:  0.009035403402562437\n",
      "Delta:  0.16368233333354731\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.557427099216582e-05 0.00012778532509438723 nan\n",
      "Epoch: 1543\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.4562171059735725\n",
      "MAPE:  0.009034576223499636\n",
      "Delta:  0.16367487363053135\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.5570248062065666e-05 0.00012777912387529344 nan\n",
      "Epoch: 1544\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.4560310318275989\n",
      "MAPE:  0.009033749116732085\n",
      "Delta:  0.1636674149259385\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.556616146411674e-05 0.000127772651225877 nan\n",
      "Epoch: 1545\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.4558449908823952\n",
      "MAPE:  0.009032922083955475\n",
      "Delta:  0.16365995723008356\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.5562123519249376e-05 0.00012776636542033426 nan\n",
      "Epoch: 1546\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.4556589828592947\n",
      "MAPE:  0.009032095124069718\n",
      "Delta:  0.1636525005348971\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.5558057633066085e-05 0.00012775997002900663 nan\n",
      "Epoch: 1547\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.455473007911272\n",
      "MAPE:  0.009031268237670545\n",
      "Delta:  0.16364504484484593\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.5554013854864905e-05 0.00012775365990658205 nan\n",
      "Epoch: 1548\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.4552870659076163\n",
      "MAPE:  0.00903044142424038\n",
      "Delta:  0.1636375901562058\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.554995256744743e-05 0.0001277472898866261 nan\n",
      "Epoch: 1549\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.4551011569289394\n",
      "MAPE:  0.009029614684162291\n",
      "Delta:  0.16363013647173594\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.5545914701294876e-05 0.00012774100794044063 nan\n",
      "Epoch: 1550\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.4549152808404981\n",
      "MAPE:  0.00902878801684145\n",
      "Delta:  0.16362268378749764\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.554186559835305e-05 0.00012773466793347676 nan\n",
      "Epoch: 1551\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.4547294377202284\n",
      "MAPE:  0.009027961422647559\n",
      "Delta:  0.16361523210522375\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.5537798067707413e-05 0.00012772827095330896 nan\n",
      "Epoch: 1552\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.4545436276444437\n",
      "MAPE:  0.009027134901926291\n",
      "Delta:  0.16360778142782334\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.553375602134313e-05 0.00012772195139676423 nan\n",
      "Epoch: 1553\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.4543578504939292\n",
      "MAPE:  0.009026308454199963\n",
      "Delta:  0.16360033175102062\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.5529721800274814e-05 0.00012771568261371602 nan\n",
      "Epoch: 1554\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.4541721061882886\n",
      "MAPE:  0.009025482079113304\n",
      "Delta:  0.16359288307342956\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.552564664572767e-05 0.00012770923076088625 nan\n",
      "Epoch: 1555\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.4539863949872134\n",
      "MAPE:  0.009024655777804832\n",
      "Delta:  0.163585435401641\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.552159503212749e-05 0.00012770290153563124 nan\n",
      "Epoch: 1556\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.4538007167057803\n",
      "MAPE:  0.00902382954951462\n",
      "Delta:  0.1635779887316975\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.551755934434354e-05 0.00012769660260458782 nan\n",
      "Epoch: 1557\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.4536150712933926\n",
      "MAPE:  0.009023003394044219\n",
      "Delta:  0.16357054306088797\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.551351558967909e-05 0.00012769027447878667 nan\n",
      "Epoch: 1558\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.4534294587859529\n",
      "MAPE:  0.009022177311545393\n",
      "Delta:  0.16356309839042638\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.550943258074813e-05 0.00012768379425232013 nan\n",
      "Epoch: 1559\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.453243879397977\n",
      "MAPE:  0.009021351303001477\n",
      "Delta:  0.16355565472662748\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.550540966585803e-05 0.00012767756193043933 nan\n",
      "Epoch: 1560\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.453058332762565\n",
      "MAPE:  0.009020525366802312\n",
      "Delta:  0.16354821205955594\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.550134608638512e-05 0.00012767114049527795 nan\n",
      "Epoch: 1561\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.4528728191480151\n",
      "MAPE:  0.009019699504208245\n",
      "Delta:  0.1635407703957572\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.549731653658018e-05 0.00012766488631599238 nan\n",
      "Epoch: 1562\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.452687338304727\n",
      "MAPE:  0.009018873714008318\n",
      "Delta:  0.1635333297295599\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.549325815517147e-05 0.0001276584830188776 nan\n",
      "Epoch: 1563\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.4525018904428182\n",
      "MAPE:  0.009018047997262956\n",
      "Delta:  0.16352589006557353\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.548920460822892e-05 0.00012765212278575966 nan\n",
      "Epoch: 1564\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.452316475493153\n",
      "MAPE:  0.009017222353595663\n",
      "Delta:  0.16351845140290158\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.548516315194817e-05 0.00012764581211777148 nan\n",
      "Epoch: 1565\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.4521310933771865\n",
      "MAPE:  0.009016396782777932\n",
      "Delta:  0.16351101373946117\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.5481119558488103e-05 0.00012763946188398823 nan\n",
      "Epoch: 1566\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.451945744145843\n",
      "MAPE:  0.009015571285010677\n",
      "Delta:  0.16350357707549615\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.547704234902916e-05 0.0001276329912254237 nan\n",
      "Epoch: 1567\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.4517604279674206\n",
      "MAPE:  0.009014745861079504\n",
      "Delta:  0.16349614141639726\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.547303262236735e-05 0.00012762680534028625 nan\n",
      "Epoch: 1568\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.4515751444218796\n",
      "MAPE:  0.009013920509029013\n",
      "Delta:  0.163488706751025\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.546895574519816e-05 0.00012762032399460388 nan\n",
      "Epoch: 1569\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.4513898939316459\n",
      "MAPE:  0.009013095230910418\n",
      "Delta:  0.16348127309025293\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.546493796142581e-05 0.0001276140907260359 nan\n",
      "Epoch: 1570\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.451204676130043\n",
      "MAPE:  0.009012270025049774\n",
      "Delta:  0.163473840424314\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.5460871518132606e-05 0.00012760765855690526 nan\n",
      "Epoch: 1571\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.4510194912992351\n",
      "MAPE:  0.00901144489268525\n",
      "Delta:  0.16346640876105792\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.545682588552591e-05 0.00012760130327515995 nan\n",
      "Epoch: 1572\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.4508343393210676\n",
      "MAPE:  0.00901061983335876\n",
      "Delta:  0.16345897809697674\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.545280508838623e-05 0.00012759505186643594 nan\n",
      "Epoch: 1573\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.4506492200382926\n",
      "MAPE:  0.00900979484638376\n",
      "Delta:  0.16345154842790535\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.544872550771295e-05 0.00012758856230499216 nan\n",
      "Epoch: 1574\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.450464133789899\n",
      "MAPE:  0.009008969933256816\n",
      "Delta:  0.16344411976334705\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.544467876010927e-05 0.00012758219640507384 nan\n",
      "Epoch: 1575\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.4502790803899033\n",
      "MAPE:  0.009008145093197632\n",
      "Delta:  0.16343669209782918\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.544065284317611e-05 0.00012757594093626423 nan\n",
      "Epoch: 1576\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.4500940596716023\n",
      "MAPE:  0.009007320325494566\n",
      "Delta:  0.16342926542784172\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.5436607034710086e-05 0.0001275695577301894 nan\n",
      "Epoch: 1577\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.4499090718137428\n",
      "MAPE:  0.009006495630914144\n",
      "Delta:  0.1634218397565305\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.5432566532888075e-05 0.00012756322026652445 nan\n",
      "Epoch: 1578\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.4497241167434485\n",
      "MAPE:  0.009005671009220756\n",
      "Delta:  0.16341441508292284\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.542850330968573e-05 0.0001275567937594202 nan\n",
      "Epoch: 1579\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.449539194583281\n",
      "MAPE:  0.009004846460894795\n",
      "Delta:  0.1634069914106264\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.542448020472545e-05 0.00012755051879298485 nan\n",
      "Epoch: 1580\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.4493543051070013\n",
      "MAPE:  0.00900402198506626\n",
      "Delta:  0.16339956873297976\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.542040225441468e-05 0.00012754402782566565 nan\n",
      "Epoch: 1581\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.4491694486211815\n",
      "MAPE:  0.009003197582967797\n",
      "Delta:  0.1633921470588397\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.541639095012595e-05 0.00012753780013596838 nan\n",
      "Epoch: 1582\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.4489846247376799\n",
      "MAPE:  0.009002373252990734\n",
      "Delta:  0.1633847263772107\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.541234632515767e-05 0.00012753142274957163 nan\n",
      "Epoch: 1583\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.4487998336669448\n",
      "MAPE:  0.009001548996112227\n",
      "Delta:  0.1633773066934322\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.540828373944539e-05 0.0001275250065689848 nan\n",
      "Epoch: 1584\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.4486150754586393\n",
      "MAPE:  0.009000724812452378\n",
      "Delta:  0.16336988801033328\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.540426799115593e-05 0.00012751874900829296 nan\n",
      "Epoch: 1585\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.4484303498764222\n",
      "MAPE:  0.00899990070114092\n",
      "Delta:  0.16336247032015638\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.5400206497792084e-05 0.00012751229640450834 nan\n",
      "Epoch: 1586\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.4482456571963276\n",
      "MAPE:  0.008999076663366311\n",
      "Delta:  0.16335505363026984\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.5396181881374176e-05 0.00012750602491695684 nan\n",
      "Epoch: 1587\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.4480609971494751\n",
      "MAPE:  0.00899825269785652\n",
      "Delta:  0.163347637934544\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.539211164811263e-05 0.00012749954496271698 nan\n",
      "Epoch: 1588\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.4478763700312605\n",
      "MAPE:  0.008997428806017012\n",
      "Delta:  0.1633402232403254\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.53880812057994e-05 0.0001274932276829066 nan\n",
      "Epoch: 1589\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.4476917755995593\n",
      "MAPE:  0.0089966049868168\n",
      "Delta:  0.16333280954100882\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.538405623377706e-05 0.00012748692513220305 nan\n",
      "Epoch: 1590\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.447507213826549\n",
      "MAPE:  0.008995781240166199\n",
      "Delta:  0.16332539683559577\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.537999313802832e-05 0.00012748048687760694 nan\n",
      "Epoch: 1591\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.4473226849021714\n",
      "MAPE:  0.008994957566799975\n",
      "Delta:  0.16331798513020812\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.537596327158777e-05 0.00012747415991853916 nan\n",
      "Epoch: 1592\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.4471381886587826\n",
      "MAPE:  0.008994133966110972\n",
      "Delta:  0.16331057441931326\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.5371908993785404e-05 0.0001274677467176799 nan\n",
      "Epoch: 1593\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.4469537252146851\n",
      "MAPE:  0.00899331043865552\n",
      "Delta:  0.16330316470679299\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.536789376541339e-05 0.00012746149188269662 nan\n",
      "Epoch: 1594\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.446769294334184\n",
      "MAPE:  0.008992486983308788\n",
      "Delta:  0.16329575598616503\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.536384216546896e-05 0.00012745507601696904 nan\n",
      "Epoch: 1595\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.4465848962437957\n",
      "MAPE:  0.008991663601149063\n",
      "Delta:  0.1632883482632642\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.535980629338798e-05 0.00012744871859127205 nan\n",
      "Epoch: 1596\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.446400530852436\n",
      "MAPE:  0.008990840291869456\n",
      "Delta:  0.163280941535417\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.5355744417219235e-05 0.00012744225799932174 nan\n",
      "Epoch: 1597\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.4462161983028128\n",
      "MAPE:  0.008990017055990366\n",
      "Delta:  0.1632735358067645\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.535171911879132e-05 0.0001274359535307079 nan\n",
      "Epoch: 1598\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.4460318983625706\n",
      "MAPE:  0.008989193892538945\n",
      "Delta:  0.1632661310712291\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.5347682578356086e-05 0.00012742960565681472 nan\n",
      "Epoch: 1599\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.4458476310879949\n",
      "MAPE:  0.008988370801840393\n",
      "Delta:  0.16325872733054148\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "4.5343647521400854e-05 0.00012742325405967758 nan\n",
      "Epoch: 1600\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.4456633964779673\n",
      "MAPE:  0.008987547783854796\n",
      "Delta:  0.1632513245843546\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import smilecorrector_gsvi_jo_mw_ar as smilenet\n",
    "import torch\n",
    "importlib.reload(smilenet)\n",
    "R = 0.00518\n",
    "F = 2272.376330 # for ID 102434, Exp date 30/12/2022\n",
    "T = 4/365.0\n",
    "S = F * np.exp(-R * T)\n",
    "log_strikes = torch.tensor((processed2['strike_price'].apply(np.log).to_numpy()- np.log(F))) #   \n",
    "print(log_strikes)\n",
    "S = torch.tensor(S).reshape(1,1)\n",
    "T = torch.tensor(T).reshape(1,1)\n",
    "R = torch.tensor(R).reshape(1,1)\n",
    "# his, lows = svi_with_noise(log_strikes, *params)\n",
    "# mids = torch.tensor(his + lows) / 2\n",
    "# mids = mids * T\n",
    "his = processed2['vol_high'].to_numpy() ** 2 * T.item()\n",
    "lows = processed2['vol_low'].to_numpy() ** 2 * T.item()\n",
    "# mids = torch.tensor(((processed2['vol_high'].to_numpy() + processed2['vol_low'].to_numpy()) / 2))\n",
    "mids = (his + lows) / 2\n",
    "print(mids.shape)\n",
    "mids = mids\n",
    "print(mids.shape)\n",
    "print('Mid shape', mids.shape)\n",
    "# print(mids)\n",
    "low = min(mids**2)/2\n",
    "print(low)\n",
    "print(his.shape, lows.shape)\n",
    "# datum, log_strikes = pipeline.get_datum('2022-0') \n",
    "model = smilenet.SmileNet(3, log_strikes, mids, low)#, low)\n",
    "datum = torch.tensor(np.vstack([ his.reshape(-1,1) , lows.reshape(-1,1) , log_strikes.reshape(-1,1), np.log(S), T, R])).double()\n",
    "print(log_strikes.shape, datum.shape)\n",
    "print(datum.T.shape)\n",
    "w_6 = model.train(datum.T.double(), log_strikes, epochs=1601, inlr=1.0e-11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABnUAAAZJCAYAAACI2ZYTAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8g+/7EAAAACXBIWXMAAA9hAAAPYQGoP6dpAAEAAElEQVR4nOzdd3QU1f//8demJ5QgPQEM1RJApQYRCBKQXqSogEpR/AjoxwKKHxQCgtIUkRZFunQVlC69g1SlBEEggIQSSQ8kpM3vj/yy38RkN50l8Hycs4dh5j33vmczszln37n3mgzDMAQAAAAAAAAAAIB7mp2tEwAAAAAAAAAAAEDWKOoAAAAAAAAAAAAUAhR1AAAAAAAAAAAACgGKOgAAAAAAAAAAAIUARR0AAAAAAAAAAIBCgKIOAAAAAAAAAABAIUBRBwAAAAAAAAAAoBCgqAMAAAAAAAAAAFAIONg6gQdRcnKyrl69qmLFislkMtk6HQAAAAAAAAAAYEOGYSg6Olqenp6ys7M8Hoeijg1cvXpVlSpVsnUaAAAAAAAAAADgHvL333+rYsWKFo9T1LGBYsWKSUr54RQvXtzG2QAAAAAAAAAAAFuKiopSpUqVzPUDSyjq2EDqlGvFixenqAMAAAAAAAAAACQpyyVbLE/MBgAAAAAAAAAAgHsGRR0AAAAAAAAAAIBCgKIOAAAAAAAAAABAIUBRBwAAAAAAAAAAoBCgqAMAAAAAAAAAAFAIUNQBAAAAAAAAAAAoBCjqAAAAAAAAAAAAFAIUdQAAAAAAAAAAAAoBijoAAAAAAAAAAACFAEUdAAAAAAAAAACAQsDB1gkg95KTk5WYmKjk5GRbpwIAwH3Bzs5Ojo6OMplMtk4FAAAAAAAgA4o6hVBkZKSioqJ0+/ZtCjoAAOQzR0dHFStWTKVLl5a9vb2t0wEAAAAAADCjqFOIGIahGzduKDw8XG5ubipdurRcXFxkZ2fHXxQDAJBHhmEoKSlJMTExioiIUGxsrCpVqkRhBwAAAAAA3DMo6hQi4eHhCg8PV/ny5fXQQw/ZOh0AAO5LRYsWlbu7uy5fvqybN2+qXLlytk4JAAAAAABAkmRn6wSQPYZhKCIiQsWKFaOgAwBAAXN1dVXx4sUVHR0twzBsnQ4AAAAAAIAkijqFRmJiou7cuSN3d3dbpwIAwAOhWLFiSkhIUEJCgq1TAQAAAAAAkERRp9BISkqSJDk4MGMeAAB3Q+paOsnJyTbOBAAAAAAAIAVFnULGZDLZOgUAAB4I/M4FAAAAAAD3Goo6AAAAAAAAAAAAhQBFHQAAAAAAAAAAgEKAog4AAAAAAAAAAEAhQFEHAAAAAAAAAACgEKCoAwAAAAAAAAAAUAhQ1AGAuyA0NFQlS5aUyWTSoUOHbJ3OfeXixYsymUwymUyaP3++rdO5pz0I79XgwYNlMpnUp08fW6cCAAAAAACQ7yjqAJnYsWOH+YvPUaNGWY29fv26vL29zfEDBw6UYRh3J1Hkyrp16zRq1Ci1b99ejz/+uEqXLi1HR0c99NBDqlevnoYMGaIzZ87ka58jR45UeHi42rVrpwYNGmQ4npycrMDAQM2fP1+DBg1SgwYN5OzsbL6vduzYkeM+b926pRkzZsjPz08VKlSQs7OzypUrp7p16+rtt9/Wpk2bsmzj5MmT+s9//qNq1arJ1dVVZcqUUdOmTfXNN98oMTEx27ls2LBBzz//vCpWrChnZ2dVrFhRzz//vDZs2JDj6wKsGTZsmJycnPT999/ryJEjtk4HAAAAAAAgXznYOgGgMAsODlaLFi109uxZSdI777yjKVOm2DYpC/r27asFCxbIy8tLFy9etHU6NpOYmKgOHTpkeiwiIkJHjx7V0aNHNW3aNH366af66KOP8tznpUuX9N1330lKKe5k5vvvv1ffvn3z3Feq7du3q1+/frp06VK6/SEhIQoJCdGxY8e0e/duPffccxbb+O677/TWW28pPj7evC8uLk579uzRnj17NG/ePK1bt06lS5e22EZycrLeeOMNzZkzJ93+4OBgBQcH6+eff9brr7+ub7/9VnZ2BfN3BvPnz1e/fv0kSUFBQapcuXKB9GNLJpNJkuTv759lIfp+9/DDD6tPnz767rvvNGLECK1fv97WKQEAAAAAAOQbijpALl2+fFktWrTQ+fPnJUkffPCBJk6caOOskB3u7u5q3ry5fHx8VLVqVXl4eMjNzU1Xr17Vjh07NHfuXEVGRup///ufSpQooTfffDNP/U2YMEEJCQl65pln5OPjk2lM2tFdjo6Oql27thISEnTixIkc97dlyxZ17NhRcXFx5vybN2+usmXL6vbt2zp9+rTWrl2rGzduWGxj/fr1evPNN5WcnKxy5crp448/lo+Pj8LCwvTdd99p5cqVOnjwoJ5//nnt2LFD9vb2mbbz8ccfmws6derU0Ycffqhq1arp/Pnzmjhxoo4dO6bZs2erTJky+vzzz3N8rZJUuXJlRsdl04PyXg0ZMkTfffedNmzYoCNHjqhevXq2TgkAAAAAACBfUNQBciEoKEgtWrQwj3j5+OOPNXbsWNsmhWxxcHBQaGioxSJEp06d9Pbbb6tevXoKDw/XyJEjNWDAAIvxWYmIiNDChQslSS+//LLFOG9vb02dOlUNGjTQU089JRcXF40aNSrHRZ1//vlHL730kuLi4vTUU09p48aNKleuXLqYZ555Rq+//nq6EThpJSQk6O2331ZycrKKFy+uvXv3qlq1aubjbdq00eDBgzVz5kzt2bPH4iijs2fP6osvvpAk1a9fX7t27ZKrq6skqUGDBurUqZN8fX11+PBhTZo0Sf3791f16tVzdL1AZh599FHVrVvXPOrufl0/CAAAAAAAPHhYUwfIoXPnzsnX19dc0Bk9ejQFnUImqwJNlSpV9MILL0hKKZL8+eefue5r2bJlunXrlhwdHdWjRw+LcQ0bNtTbb7+tRo0aycXFJdf9/e9//1NoaKjc3Nz0888/ZyjopOXk5JTp/lWrVunChQvm9tIWdFJNmjRJDz30kHk7M1OmTDGvuzNt2jRzQSeVm5ubpk2bJillWryvvvoqi6sDsq93796SpB9++EHR0dE2zgYAAAAAACB/UNQBcuDMmTPy9fXV33//LUkaN26cxTVSJGnHjh0ZFrpfsWKF/Pz8VKZMGbm6uurRRx/Vhx9+qLCwsCz7j4mJ0fjx4/X000+rZMmS5gXnu3fvrrVr12Z6zqhRo2QymbRgwQJJKeu7pOaU9vVv27ZtU8+ePVWlShW5urrKzc1NXl5eatSokYYOHapt27ZlmW9hVqxYMfN2XFxcrttZsWKFJKl58+YqVapUnvOyJjw8XEuWLJGUMirIy8srV+38/PPP5m1L6/y4ubmZC1+BgYHmdaVSGYahX375RZL02GOPqVGjRpm206hRIz366KOSpF9++SVXU4NdvHjRfB+nHZGR+vylrqcjpRTs/n3vpz6b//bzzz+rR48eevjhh+Xi4qISJUqofv36Gj16tMLDwy3m07dvX5lMJvPaPdeuXdOwYcNUs2ZNFStWLEOf4eHhmjdvnl5++WV5e3uraNGicnJyUvny5dW6dWvNmjXL4qiqypUrp3t+R48eneH60v4MLb1X/xYfH6+ZM2fq2WefVZkyZcz5tGvXTosWLVJycnK2rz8iIkIjR45UzZo1VaRIEZUoUULNmjXT4sWLLbaRatWqVerSpYsqVqwoZ2dnFStWTFWrVlXTpk01YsQIHTx40OK53bp1kyTdvn3bfC8CAAAAAAAUdky/BmRTYGCg/Pz8dP36dUnS5MmT9d5772X7/OTkZL3yyitatGhRuv1nz57VpEmTtGrVKu3evVvly5fP9Pxjx46pQ4cOunr1arr9wcHB+umnn/TTTz+pa9euWrx4cZ5GekjSe++9pylTpmTYf/nyZV2+fFm//fab5s+fr5s3b+apn3tVbGys+UtgOzs7PfLII7lq586dO9q3b58kWSxq5Ke1a9cqNjZWUso0cqlu376tq1evqmjRoipXrlymRby09uzZIyllCitL96Mk+fr66ttvv5Uk7d27N937FBQUZL5XfX19rfbn6+urM2fOKDg4WBcvXlSVKlWsxhe08PBwde/ePUPh8s6dOzpy5IiOHDmimTNn6pdffsny53rgwAF17NjR6rNSp04dXbp0KcP+GzduaNOmTdq0aZO++eYbrV+/3urPI79cvHhRbdu2zTBC7caNG9qwYYM2bNigb7/9Vr/88otKlixpta0zZ86oTZs25pGNqXbv3q3du3dr//79mj59eobzkpKS1LNnT/3www/p9sfHxysmJkZBQUHas2ePNmzYoMOHD2fat5eXl8qXL6/r169rw4YNVqc/BAAAAAAAKCwo6gDZcPz4cbVs2VL//POPTCaTpk2bpsGDB+eojREjRmjfvn3q0qWLXn31VXl5eenGjRuaMWOG1q1bp3Pnzum9997T0qVLM5wbHBwsPz8/hYeHm//y/qWXXlKpUqUUGBioL7/8Un/88YdWrlypvn37atmyZeZzBw0apO7du+uTTz7RL7/8Ik9PT/36668W81y7dq25oPPEE09o4MCBevzxx+Xu7q6IiAidOnVKW7ZssfoX8oVRQkKCrl27pn379mnChAn666+/JEn9+/dPN2onJw4dOqQ7d+5ISllDpqAdOHDAvF27dm0dOnRIH3/8sbZu3WoeWVGmTBm98MILGjFiRKZTs8XExJhHoj322GNW+0t7/PTp0+mOBQYGZhqXnXbyq6jToEEDnThxQr/88os++eQTSdKvv/4qT0/PdHFp+7tz545atmypo0ePyt7eXr169VK7du1UpUoVJSQkaNeuXZo8ebJCQkLUrl07HTt2zOKIqJiYGHXr1k1xcXH6+OOP1apVK7m5uenEiRPy8PAwxyUlJcnHx0cdOnRQnTp1VK5cOcXHxysoKEiLFi3Sxo0bdezYMb300ksZRhVt2rRJ8fHxql27tiRp4MCBGjRoULqY1GnysiMmJkZ+fn7m6fe6dOmi/v37y9PTU0FBQZo+fbp27typPXv2qGPHjtq1a5fF6Qxv376tjh07KjQ0VJ988olatmypokWL6tixYxo9erSuXLmiGTNmqGPHjmrdunW6cwMCAswFnSZNmuj1119XtWrVVKRIEYWGhur48ePauHGjIiMjrV5Pw4YNtXr1au3cuTPb7wEAAAAAAMA9zcBdFxkZaUgyIiMjs31ObGysERgYaMTGxmYZm5ycbNy6k3Dfv5KTk/PyY7Bq+/bthiRDktGlSxejVKlShiTDZDIZs2bNylU7koyxY8dmiElOTjaee+45Q5Lh4OBghISEZIjp3r27uY3Zs2dnOB4XF2c8++yz5pj169dniOnTp48hyfDy8rKa8yuvvGKOi46OthgXGhpqtR1r0r4nuX3Nmzcv1/2nCgoKstpH69atc/Sc/tuECRPMbf399985Pt/f3998/vbt27OMb968uTl+/vz5hoODg8VrK1++vPH7779naOP06dPmmMGDB1vt759//jHHvvTSS+mOBQQEmI/98MMPVtv54YcfzLHffPNNltf5b2l/jpndF/PmzTMfDwoKstrW8OHDDUlGiRIljMOHD2cac/HiRcPDw8OQZPTq1SvD8dRnTZJRtGjRTN/ntM6ePWv1+Ny5c83tbdmyJdOY1OP+/v5W28rqvRo6dKj5+CeffJLheHJystG7d29zzMyZMzPEpL1+d3d34+TJkxli/vrrL8PFxcWQZHTq1CnD8aZNmxqSDB8fHyMhIcHi9WT1OTR69GhzLtevX7cam5mc/O4FAAAAAADIi+zWDRipcx+KTUiS90jLIzHuF4GftpabU8HfwmnXF5k5c6YGDBiQq3bq1aun4cOHZ9hvMpn0/vvva9OmTUpMTNT+/fvTTZ119epVrVq1SpLUpk0bvfbaaxnacHZ21ty5c1WjRg0lJiZq+vTpatu2ba7yTJ1erm7duipatKjFuKymXSrMSpcurRkzZqhbt24WRyFkx5UrV8zbZcuWzY/UrEq7LtObb74pk8mksWPH6tVXX1W5cuV07tw5TZo0SfPnz9f169fVpUsX/fHHHypevLj5vLQLylv7+UtSkSJFzNsxMTHpjuVXO3dTTEyMZsyYIUkaM2aM6tWrl2mcl5eXRowYoUGDBumHH37QrFmz0l1DWh9++KGefPJJq/3WqFHD6vF+/fpp6tSp+v333/Xzzz/Lz88vG1eTc3fu3NHs2bMlSTVr1tSoUaMyxJhMJs2cOVMbN25UaGiopk+froEDB1psc8yYMapZs2aG/dWrV1eXLl20bNky83R/aaV+DjVu3FgODpY/57P6HEr73F24cCHT0WkAAAAAAACFCUUdIAsmk8m8ePuaNWvUv39/OTk55bidXr16WVzLJO2Xx6nTHqXasWOHkpKSJCnTgk6qypUrq1WrVtqwYYP5nNwUJFKnhdq1a5fOnz+vatWq5biNrJw4cSLPbVSsWDHPbVSoUMGcS2JiooKDg7Vx40bNmTNHb775ps6fP6///e9/uW7/n3/+kSS5ubnl6p7JqVu3bpm34+LitHDhQr3yyivmfd7e3po3b56cnJw0a9YsXbx4UQEBARo2bFi681JllbOzs7N5O3Utn/xu527auXOneTqv7t27W41t1qyZpJRp+44cOWL+/7/17t07RzkYhqEbN24oKipK8fHx5v0VKlTQ77//rj/++CNH7eXEkSNHFBERIUnq27evxc+P4sWL64UXXlBAQIACAwN17dq1dNPJpTKZTOrVq5fF/urVq6dly5YpLCxMERERKlGihPmYh4eH/vrrL61Zs0bDhw9X6dKlc3VNaYs+qYUiAAAAAACAwoyizn3I1dFegZ+2zjqwkHN1zP0IipwYOHCgduzYocDAQK1fv149e/bU8uXLrf71eGasrSuS9ovHtCMcJOnkyZPmbR8fH6t9+Pj4aMOGDbp9+7YuXLiQ5QiAzLz66qtauHChQkNDVatWLXXu3FmtW7dW06ZNVb169Ry3l5latWrlSzt55ejomC6Xp556Su3bt9eAAQP07LPPavjw4frrr780d+7cXLWfOnImJ2ua5IWLi4t5+4knnkhX0Enr888/14IFC3Tnzh0tX748XVEnbRtpiwqZSV0vSJJcXV0t5pKXdu6mw4cPm7czK1JYYqlYULRoUVWtWjVbbaxbt04BAQHatWtXhs+AtG7evJntvHIqp581AQEB5vMye79Kly6tUqVKWWzj3597aYs6ffr00a5du3Tu3DlVr15dXbt2VatWrdS0adMcFXTTPntpi54AAAAAAACFlZ2tE0D+M5lMcnNyuO9flka95LcyZcpoy5Yt5oLGypUr1bdvX/PC89nl5uZm8Zid3f89iqmjclKlnVIrqym8ypcvn+l5OeHn56fp06fL1dVVcXFxWr58ufr3768aNWqoYsWKevPNNwt0tMC94IknntDYsWMlSfPmzdOmTZty1U5qYeNujT4pVqyYefu5556zGFeqVCnVr19fkvTHH3+kK7qkbSOrqdDSfkn+7ynW8quduykkJCRX592+fTvT/WmLFJYYhqHXX39dHTp00Lp166wWdKSCvZfy+7PG2meeZP1zr3///ho+fLgcHBwUGRmpefPmqVevXqpUqZKqV6+uIUOGZBjVmJm075ejo2OW8QAAAAAAAPc6RuoA2eDh4aFt27apadOmunTpkhYvXixXV1fNmjXrrhWXJN21vgYPHqwePXpoyZIl2rx5s/bu3avIyEgFBwfr22+/1axZszR8+HBz4SOn0o4IyK2KFStm60vz3OrcubMGDRokSfrxxx+tFkksKVOmjCQpIiJChmEU+M+vUqVKOnDggHk7q1hJSk5OVlhYmPlL+goVKphj0q4JlJm///47Q3up0o6myEs7d1PawsLRo0ezXQSwNHIkO9Mfzp07V3PmzJGUMlLs3XfflY+PjypUqCA3NzdzG6+++qq+//5781SQBe1ufq5Z8tlnn+mNN97Q4sWLtXXrVh04cEC3b9/W+fPnNXnyZE2bNk1Tp07Vm2++abGNtAWngvy8AAAAAAAAuFso6gDZVKlSJW3dulXNmjXT1atXNXv2bLm6umrq1KkF2m/aKYpu3Lhh9UvvtNNAZbWAeFbKli2rd999V++++66Sk5P1+++/a9WqVZo+fboiIiL02WefqUGDBurcuXOO265du3aecpNSRtD07ds3z+1YklqQkaRLly7lqY3k5GRFRkYW+JfKNWvW1A8//CAp48iHf0t7PO1UgsWKFVOlSpX0999/688//7TaRtrjjz/+eLpj3t7emcbltJ27Ke1UYWXKlMmXdZuy8t1330mSqlevrn379lmcfi63I+9y4t+fNY888ojF2Pz8rLHGy8tLw4cP1/Dhw5WQkKBDhw5pxYoV+vbbbxUXF6dBgwbJx8dHderUyfT88PBw8/bDDz9cYHkCAAAAAADcLUy/BuRAtWrVtHXrVvPURNOmTdNHH31UoH2mXfPlt99+sxp78OBBSSnTHv17LY+8/OW9nZ2d6tatqzFjxmjr1q3m/StWrMh1m/e64OBg83ZupwRLW7w6e/ZsnnPKSrNmzczbWU1Ndf78eUkpU8T9+0v5Jk2aSJLOnDljdXH5nTt3mrefeeaZdMeqVKkiT0/PDHGZ2bVrl6SUUUKVK1e2Gpsb2b330xYG9u7dm+95ZObUqVOSpE6dOlks6BiGoaNHjxZ4Lrn5rPn3eQXJ0dFRjRs31pQpU7RkyRJJKe/Njz/+aPGc1OfO2dk539YEAwAAAAAAsCWKOkAOPfbYY9q8ebP5i/AJEybo008/LbD+mjdvbp6Cae7cuRbjLl++rM2bN2c4J1Xq+i5pF6XPjbp165oXH8/tou2GYeT5VZCjdCSZR7xIuR9Z1LRpU/P2oUOH8pxTVpo1a2YeHbRmzRqLo3WCgoL0+++/S0opxqRd20SSunTpYt6eP39+pm3cvn3bXNTz9vbOMKrDZDKZR3H9+eef5mnh/u3AgQPmkTqdO3cukGm/Uu99yfr937JlS/M6MFOnTr0rU50lJiZKSr+u0L/98ssvunbtmtV28uP5rlevnnk02YIFCyyuGxYdHZ3uZ+/h4ZHrPnPLz8/PvG3tcyj1uatTpw5r6gAAAAAAgPsCRR0gF5544gn9+uuvKl68uCTJ399fX375ZYH05enpqeeff16StGHDBi1YsCBDTHx8vPr376+EhARJ0ltvvZUhJvWL15CQEKuLsS9fvtzqYuyHDx82T2lUpUqV7F/IPeLnn3/O8gvyXbt2mQt1Dg4O6tmzZ676qlSpkry8vCSlH9lQUOzt7TV06FBJKVPGjRkzJkNMYmKiBg0aZP7CPrP1SJ5//nnzSK9x48aZR/Wk9cEHH5jvgw8++CDTfN59911zcfHtt9/OcF/Fxsbq7bfflpTyPr/77rvZucwcS1t0yOxaUpUoUcL87Ozbt0/vvfeexcKGlDJF2ezZs/OUW40aNSSlFOEym2Lt/PnzGjx4cJbtpF6jtevLirOzs15//XVJKeteZXb/GIaht956y1xIyeyzJj8sWrTIXPDKzKZNm8zblj6H7ty5o+PHj0tSrtbEAgAAAAAAuBexpg6QS/Xr19f69evVunVr3bp1S0OHDpWbm5sGDhyY73199dVX2rp1q8LDw9W/f3/t2bNHL774oh566CH9+eef+uKLL8wjL1544QW1bds2QxuNGzeWlLK+y5tvvqm3335bpUuXNh9PnZpo2LBhevPNN9W5c2c1a9ZMjzzyiIoUKaLQ0FDt2bNH06ZNk5RSQEj9Argw+fnnn/Xiiy+qffv28vPzU82aNVWiRAnduXNH58+f15o1a7RixQrzl/kjR47Uo48+muv+OnfurKlTp2r79u0yDMPqSJR/j4pJ/ZlK0saNG3Xx4kXz/6tXr26eJi2t//73v1q+fLmOHj2q0aNH68yZM+rTp4/Kli2r8+fP66uvvtL+/fslSe3atVO3bt0ytOHo6Khp06apY8eOioqK0jPPPKNPPvlEDRs2VHh4uL777jv99NNPklKmanvllVcyvZ5HHnlEH3zwgcaPH6/Dhw/rmWee0bBhw1StWjWdP39eEyZM0LFjxySlFIZSCxz5rU6dOnJxcVFcXJxGjBghR0dHeXl5mUcoVahQwTz12aeffqqdO3fqt99+09dff60dO3ZowIABeuqpp1SkSBGFh4fr1KlT2rJlizZs2KDatWvn6Tl49dVX9cEHH+jq1at6+umnNWzYMNWqVUtxcXHatm2bpkyZojt37qhu3bpWp2Br3LixgoKCtHr1an377bd65plnzKN3ihcvbp4yMisjR47UypUrdeHCBY0aNUonTpxQv3795OHhoaCgIE2fPl07duyQJD399NN64403cn3t1rzyyisaOnSounbtqsaNG6tatWpycXHRjRs3tHnzZgUEBEhKmRqxd+/embaxa9cuc6E7tTAOAAAAAABQ6Bm46yIjIw1JRmRkZLbPiY2NNQIDA43Y2NgCzAyptm/fbkgyJBn+/v5WY7du3Wq4uLgYkgyTyWTMmzcv03a2b99utZ2s+jt69Kjh6elpjsvs1bVrV4v3SFJSktGoUSOL56by8vKy2ockw9nZOd11FiZ9+vTJ8vokGa6ursaXX36Z5/5OnDhhbnPnzp1WY7OTV+qrT58+Ftu5evWqUa9ePavnt2vXzoiKirKaz6xZswwnJyeLbTRs2ND4559/rLaRlJRk9O/f32our732mpGUlGS1HWuCgoLMbVm6Lz/88EOL/f/72YyKijK6du2arZ/Ds88+m6Gv1HvMy8sry9zj4+ON5557zup9uGLFiizbPHbsmOHs7JzlvZKd9yooKMh47LHHrF73M888Y4SGhmZ6fnavf968eeb2goKC0h3Lznvv7u5ubNiwwWL7ffv2NSQZNWvWtJqHNfzuBQAAAAAAd0t26wZMvwbkUYsWLbRy5Uo5OTnJMAy99tprWr58eb73U6dOHZ05c0bjxo2Tj4+PSpQoIScnJ3l6eqpr165avXq1fvrpp3Trh6RlZ2enTZs26ZNPPtGTTz6pokWLZjpqZPv27fr666/VrVs31a5dW2XKlJGDg4OKFy+uOnXqaOjQoQoMDCzwNW0KysSJEzV37lz17dtX9evXV6VKleTs7CxXV1dVqFBBzz33nMaPH6/z58/r/fffz3N/tWrV0tNPPy1J5sXdC5qHh4cOHDigb775Rr6+vipTpowcHR1Vvnx5derUSStXrtS6detUrFgxq+0MGDBAR44c0YABA1S1alW5uLioVKlSatKkiQICArR37950o70yY2dnpzlz5mjdunXq3LmzPD09zfdt586dtX79es2ePTvDuj75bfz48fruu+/UtGlTlSxZMsOaU2kVK1ZMP/30k3bv3q3XX39djz76qIoVKyYHBweVLFlSDRo00ODBg7V+/XrzOla55ejoqHXr1mnq1KmqX7++3Nzc5OrqqurVq+vNN9/U0aNH1aNHjyzbeeqpp7R//3717NlTDz/8sJydnXOdU+XKlfXHH39o+vTp8vX1ValSpeTo6Khy5cqpTZs2+v7777Vr1y7zumIF4eTJk5owYYI6duwob29vlSpVSvb29ipRooQaNWokf39/nTlzRm3atMn0/Li4OK1cuVKSNGjQoALLEwAAAAAA4G4zGcZdWAka6URFRcnd3V2RkZHmNVmyEhcXp6CgIFWpUsXil/YA7k0rVqwwT5d3+fJlFS1a1NYpAfe1RYsW6ZVXXlGpUqV08eLFXD9z/O4FAAAAAAB3S3brBozUAYAC1qNHD9WrV0/h4eGaPn26rdMB7mvJycn6/PPPJaWs1UQRFQAAAAAA3E8o6gBAATOZTJowYYIkafLkybp165aNMwLuXz/88INOnz6thx9+WP/9739tnQ4AAAAAAEC+crB1AgDwIPDz89PUqVMVGhqqS5cuydvb29YpAfelpKQk+fv7q0WLFnJ1dbV1OgAAAAAAAPmKog4A3CVvv/22rVMA7nu9evWydQoAAAAAAAAFhunXAAAAAAAAAAAACgGKOgAAAAAAAAAAAIUARR0AAAAAAAAAAIBCgKIOAAAAAAAAAABAIUBRBwAAAAAAAAAAoBCgqAMAAAAAAAAAAFAIUNQBAAAAAAAAAAAoBCjqAAAAAAAAAAAAFAIUdQAAAAAAAAAAAAoBijoAAAAAAAAAAACFAEUdAAAAAAAAAACAQoCiDgAAAAAAAAAAQCHgYOsEAAAAAAAAAADIT0nJhg4GhSkkOk5li7moYZWSsrcz2TotIM8o6gAAAAAAAAAA7hsbT17T6DWBuhYZZ97n4e4i/47ealPLw4aZAXnH9GsAcBecOXNGTk5OcnFxUXBwsM3y2LFjh0wmk0wmk3bs2GGzPAqDB+G9at++vUwmk/z9/W2dCgAAAAAA+WLjyWsauOhouoKOJF2PjNPARUe18eQ1G2UG5A+KOkAm0n6ZO2rUKKux169fl7e3tzl+4MCBMgzj7iSKfLVhwwbzzzE7P/uceP/995WQkKDXXntNFSpUsBq7dOlSPffccypfvrxcXFzk5eWll19+Wfv378+3fABJGjFihCTpiy++0JUrV2ycDQAAAAAAeZOUbGj0mkBl9s1c6r7RawKVlMx3dyi8KOoAeRAcHCxfX1+dPn1akvTOO+8oICBAJtO9Nz9n3759ZTKZVLlyZVunck+6deuWBg4cWCBt79u3T+vXr5eTk5M++ugji3GxsbFq3769evXqpc2bN+vGjRu6c+eOLl++rMWLF6tJkyYaPXp0geSYatSoUeai1v3o4sWL5uubP3++rdOxuUaNGqlVq1a6ffu2Pv/8c1unAwAAAABAnhwMCsswQictQ9K1yDgdDAq7e0kB+YyiDpBLly9flq+vr86ePStJ+uCDDzRlyhTbJoVcGzFihC5duqSyZcvme9tjx46VJPXo0UOVKlWyGNe/f3+tX79ekvTss8/q559/1sGDBzVnzhxVq1ZNycnJGjVqlGbNmpXrXJo3by7DMGQYhpo3b57rdh4ED8p7NWTIEEnSnDlzdO0aQ9ABAAAAAIVXSLTlgk5u4oB7EUUdIBeCgoLk6+ur8+fPS5I+/vhjTZw40cZZIbeOHDmiqVOnytnZWZ999lm+tn3mzBlt3LhRkvTyyy9bjNu2bZuWLVsmSerYsaM2b96szp07q0GDBurfv78OHDighx9+WJI0bNgwhYeH52ueeHC1bNlSZcuWVXx8vL799ltbpwMAAAAAQK6VLeaSr3HAvYiiDpBD586dk6+vry5evChJGj16tHkkBgqfpKQkDRgwQElJSRo+fLiqV6+er+3PmzdPhmGobNmyatmypcW4L774QpLk4OCgmTNnyt7ePt3x0qVLa8KECZKkiIgIzZ49O1/zxIPL3t5eL774oqT/u18BAAAAACiMGlYpKQ93F1maVN4kycPdRQ2rlLybaQH5iqIOkANnzpyRr6+v/v77b0nSuHHjNHLkSIvxO3bsMK/fsWPHDknSihUr5OfnpzJlysjV1VWPPvqoPvzwQ4WFZT2XZ0xMjMaPH6+nn35aJUuWlLOzsypWrKju3btr7dq1mZ6TukbKggULJEmXLl0y55T29W/btm1Tz549VaVKFbm6usrNzU1eXl5q1KiRhg4dqm3btmWZb2Hw1Vdf6dixY3rkkUc0bNiwfG9/xYoVkqTOnTvLwcEh05jo6Ght3bpVUsqoiYoVK2Ya17VrVxUvXlyStGrVqlzlk9k9KUnz58+XyWRKt2ZPZvdJajEzraSkJC1YsEAdOnSQp6ennJ2dVapUKTVp0kSTJ09WbGysxXyaN28uk8lknt7sr7/+0ltvvaUaNWrIzc0tQ5/Xrl3TzJkz1b17d9WoUUNFihSRs7OzKlSooM6dO2v58uVKTk7OtC+TyaQqVaqY/9+vX78M1zdq1Kgs36t/y81zaen6g4OD9f7776t69epydXVVqVKl1Lp1a23YsMFqO0lJSZo/f75at26t8uXLy8nJSe7u7qpRo4b8/Pz0+eefKzAw0OL53bp1k5QyreTevXut9gUAAAAAwL3K3s4k/47ekpShsJP6f/+O3rK3uz/XEsaDIfNvGAFkEBgYKD8/P12/fl2SNHnyZL333nvZPj85OVmvvPKKFi1alG7/2bNnNWnSJK1atUq7d+9W+fLlMz3/2LFj6tChg65evZpuf3BwsH766Sf99NNP6tq1qxYvXiwXl7wNIX3vvfcyXR/o8uXLunz5sn777TfNnz9fN2/ezFM/tnbx4kX5+/tLkgICAuTs7Jyv7V+6dElBQUGSUhakt+TQoUOKj4+XJPn6+lqMc3JyUqNGjbRp0yYdOnRICQkJcnR0zNecc+ry5cvq1KmT/vjjj3T7w8LCtHfvXu3du1cBAQFat26dHnnkEatt/fLLL+rdu7du3bqV6fGkpCRVrFgx06LN1atXtXr1aq1evVpz5szRypUrVbRo0dxfWDbl53O5d+9edenSJd1zFRcXp02bNmnTpk2aNGmShg4dmuG8mJgYtWvXTrt37063PyEhQVFRUTp37py2bdumo0eP6scff8y07wYNGsje3l5JSUnasGGDmjRpkt23AAAAAACAe0qbWh4KeLmuRq8J1LXI/1s7p7y7i/w7eqtNLQ8bZgfkHUUdIBuOHz+uli1b6p9//pHJZNK0adM0ePDgHLUxYsQI7du3T126dNGrr74qLy8v3bhxQzNmzNC6det07tw5vffee1q6dGmGc4ODg+Xn56fw8HCZTCb17dtXL730kkqVKqXAwEB9+eWX+uOPP7Ry5Ur17dvXvDaLJA0aNEjdu3fXJ598ol9++UWenp769ddfLea5du1ac0HniSee0MCBA/X444/L3d1dEREROnXqlLZs2aKDBw/m6PrvRQMHDtTt27fVu3dvtWjRIt/bT/sle4MGDSzGpR1B8dhjj1lt87HHHtOmTZuUmJiov/76S97e3nlPVFKXLl1Uv359zZw5UwEBAZKkEydOZIirUKGCeTs0NFRNmjTR33//LWdnZw0YMEC+vr6qXLmyYmJitGnTJn399dc6d+6c2rZtq6NHj8rd3T3T/i9fvqyXX35Zbm5uGjFihJo2bSp7e3sdOnTIXJxJnRasRYsWatu2rWrXrq0yZcooOjpaFy5c0Hfffaf9+/dr8+bNGjx4sHl0WqoTJ07o6tWrat26tSRp7Nix6ty5c7qYsmXLZvs9y8tz+W/Xrl1Tly5dZGdnp/Hjx6tJkyZycnLSnj179OmnnyoiIkL/+9//1LZtW9WsWTPduaNGjTLfax06dFDv3r318MMPy8XFRSEhITp27JjWrl2b6Yi8VG5ubqpZs6aOHz+unTt3Zvs9AAAAAADgXtSmlodaeZfXwaAwhUTHqWyxlCnXGKGD+4KBuy4yMtKQZERGRmb7nNjYWCMwMNCIjY0twMyQavv27YYkQ5LRpUsXo1SpUoYkw2QyGbNmzcpVO5KMsWPHZohJTk42nnvuOUOS4eDgYISEhGSI6d69u7mN2bNnZzgeFxdnPPvss+aY9evXZ4jp06ePIcnw8vKymvMrr7xijouOjrYYFxoaarUda9K+J7l9zZs3L9f9G4ZhLF682JBklChRwrhx44Z5f9qfmb+/f576GDhwoCHJcHJyMhITEy3GDRs2zNznoUOHrLY5adIkc+zGjRtznFPa69u+fXuG4/7+/ubjWenVq5f5Xrlw4UKmMUePHjWKFCliSDKGDx+e4bivr6+5P09PT+PSpUsW+0tOTjb++usvqzmNHDnS/KyePXs2w/GgoKBs30NZvVf58VymvX4vLy/jypUrGWJ2795tmEwmQ5Lx3//+N8PxSpUqGZKM7t27W72erJ7Zfv36GZIMNzc3Izk52Wrsg4LfvQAAAAAA4G7Jbt2ANXXuR4Yhxd+6/193aTHvn3/+WaGhoZKkmTNnasCAAblqp169eho+fHiG/SaTSe+//74kKTExUfv37093/OrVq+b1U9q0aaPXXnstQxvOzs6aO3euec2W6dOn5ypHSebp5erWrWt1+qqSJQvvgnJhYWHmqfPGjRuXo9EZOXHlyhVJUqlSpWRvb28xLjo62ryd1ZRhRYoUMW/HxMTkMcPcu3jxopYvXy4p5X5Lu1ZNWnXq1DGPaps/f77VNsePH6+HH37Y4nGTyaTq1atbbWPkyJEqXbq0DMPQ6tWrrcbmRUE8l9OmTUs3EipVkyZN5OPjI0kZpliT/u+Zbdq0qdX2s3pmU5+D27dvm9sEAAAAAADAvYXp1+5HCbelzz1tnUXBG35VciqSdVwemUwm87RPa9asUf/+/eXk5JTjdnr16mVx+qN69eqZty9cuJDu2I4dO5SUlCRJmX5xnKpy5cpq1aqVNmzYYD7HWiHBEg+PlHlFd+3apfPnz6tatWo5biMrmU3rlVMVK1bM9blDhw5VSEiIfHx89MYbb+Q5F0v++ecfSdJDDz1kNS4u7v/md83q3kq77k9sbGwessubdevWKSkpSW5ubmrbtq3V2GbNmmnixIm6evWqLl++nGnhxsnJST169MhRDsnJybp+/bqio6OVkJBg3l+xYkXdvHkzwzo/+Sm/n8sSJUqoffv2FtupV6+eDhw4kOHzQUp5Zi9fvqzly5fr9ddfl5ubWy6uKH3R5/r16+bPAgAAAAAAANw7KOoAWRg4cKB27NihwMBArV+/Xj179tTy5cvNf32fXdbWSkn7ZWraURuSdPLkSfN26l/rW+Lj46MNGzbo9u3bunDhgmrUqJGjHCXp1Vdf1cKFCxUaGqpatWqpc+fOat26tZo2bZrlKInsqlWrVr60kxs7duzQvHnzZG9vr2+++UZ2dgU3YDEsLExS1kUdFxcX83Z8fLzV2Dt37pi3XV1d85Bd3hw+fFhSyqiOnDwL169fz7SoU6NGjXTvgyWGYWjx4sWaM2eOfvvtN6uFrZs3b2Y7r5zK7+eyRo0aVu/F1M+If38+SFKfPn00ZswY7du3T1WqVFGPHj3k5+enJk2aqEyZMtm9pHT36a1bt7J9HgAAAAAAAO4eijr3I0e3lFEs9zvH3P01ek6VKVNGW7ZsUbNmzXTu3DnzoucLFy7MUUHA2l/Pp20n9a//U6UWBqSsF3EvX758puflhJ+fn6ZPn64PPvhAsbGxWr58uXmarQoVKqhDhw4aOHCgnnzyyVy1b0t37tzRf/7zH0nSf//7Xz311FMF2l9qkSKrETXFihUzb2c1pVraL9uzmqqtIIWEhOTqvNu3b2e6P6vCl5Qyoqlr167asGFDtvoqyJFM+f1cZjW6JvUzIjk5OcOxESNGKDg4WPPmzVNISIhmzJihGTNmSJJq1qypbt26adCgQSpXrpzVPtK+X46OjlZjAQAAAAAAYBsUde5HJtNdmZbsQeLh4aFt27apadOmunTpkhYvXixXV1fNmjXL4pRqBeFu9TV48GD16NFDS5Ys0ebNm7V3715FRkYqODhY3377rWbNmqXhw4dr7NixuWo/7SiH3KpYsaJKlCiRo3NWrlyps2fPytHRUd7e3lq2bFmGmMDAQPP2yZMnzTE+Pj4W142xJHWURFYFtrRTyV25ckX169e3GPv333+btytVqpSjfPJTavGxdOnS2r59e7bPs/QeZmeqwM8++8xc0PH19dXgwYNVt25dlS9fXq6urubCR7NmzbR7927ztIkF7W5+BmTG0dFRc+bM0ZAhQ7R06VJt27ZNhw8fVnx8vE6dOqVTp05p8uTJWrRokTp37myxnbT3aU6fLQAAAAAAANwdFHWAbKpUqZK2bt2qZs2a6erVq5o9e7ZcXV01derUAu037dRsN27csPpFftrFzbNaFD0rZcuW1bvvvqt3331XycnJ+v3337Vq1SpNnz5dERER+uyzz9SgQQOrXxJbUrt27TzlJknz5s1T3759c3RO6tRlCQkJGjBgQJbxP/30k3766Sdzf7kt6oSHh1uN8/b2Nm//+eefVmNTjzs4OORqer38UqpUKUkp04E9/vjjuVq/KScMw9Ds2bMlSU2bNtW2bdssjpTL7Si1nLDVc2mNt7e3xowZozFjxiguLk579uzRkiVLtHDhQsXExKhnz546f/68xbVy0t6ntiwYAgAAAAAAwLKCW0wCuA9Vq1ZNW7duNU+3NG3aNH300UcF2mfa9Wd+++03q7EHDx6UlDKVU9WqVdMdy8toAjs7O9WtW1djxozR1q1bzftXrFiR6zYfBKnFq8jISKvTlTVo0EBOTk6SpJ07d1qMi4+P14EDB8znFMQUWdm9T+rUqSMppVCWur5OQQoLCzMXR3r06GGxoBMTE6MzZ85YbCe/RtXk13NZUFxcXNSyZUvNnTtXkyZNkpQyvdratWstnnP27FlJKaOpspoODgAAAAAAALZBUQfIoccee0ybN282/8X9hAkT9OmnnxZYf82bNzePgpg7d67FuMuXL2vz5s0ZzkmVur5L6miV3Kpbt655/ZPcLkRvGEaeXzkdpSNJffv2zbLdtFOJ+fv756m/pk2bmrcPHTpkMa5YsWLy8/OTJG3ZskVXrlzJNG7lypWKioqSJD3//PM5zic7Uu8Tyfq90rFjR3OBZMqUKQWSS1qJiYnm7bTrCv3b7Nmz08X+W3avLyv59VzeDan3lmT9mU0tzvn4+BR4TgAAAAAAAMgdijpALjzxxBP69ddfVbx4cUkpX/5/+eWXBdKXp6en+Qv8DRs2aMGCBRli4uPj1b9/fyUkJEiS3nrrrQwxqVMuhYSEKDo62mJ/y5cvt7rA/OHDh83TNOV0OrIHTcOGDeXs7Czp/0ZrWDJ06FBJKcWLwYMHm9esSXXz5k0NGzZMUsp6J6+//noBZKx0U3OdP3/eYtyjjz6qHj16SJKWLVumyZMnW203KChIS5cuzXVeZcqUMa/zsnTp0kwLMocOHdKIESOstlOqVCnzqChr15eV/Hou8yosLExr1qyxun7Qpk2bzNuWntkLFy6YCz7PPfdc/iYJAAAAAACAfENRB8il+vXra/369SpSpIiklC/lAwICCqSvr776yjw6pn///howYIC2bNmiI0eOaPHixfLx8TFPi/bCCy+obdu2Gdpo3LixJCk5OVlvvvmmDhw4oHPnzplfqYYNGyZPT0/17dtXc+fO1Z49e3Ts2DFt2bJFo0aNUuvWrSWlLGxfUIWF+4Wzs7P5/Uo7bV1mWrRooZdeekmStHr1arVq1UqrV6/W4cOHNW/ePDVq1EiXL1+WlDI6LPV+yG+p94kkvffee9q1a5f++usv832SdhRMQECAeTqxIUOGyNfXV3PmzNGBAwfM98yXX36pVq1aqXr16ub1iXLDzs5OvXv3liQdP35cTZo00dKlS3X48GFt3bpVQ4YMUbNmzeTi4qJHHnnEYjsODg5q0KCBpJQRNkuXLtXp06fN15eT9Xjy47nMq6ioKHXq1ElVq1bVkCFDtGLFCv322286cuSI1q5dq//85z/mYmCFChXUoUOHTNtJzdPBwcFiDAAAAAAAAO4BBu66yMhIQ5IRGRmZ7XNiY2ONwMBAIzY2tgAzQ6rt27cbkgxJhr+/v9XYrVu3Gi4uLoYkw2QyGfPmzcu0ne3bt1ttJ6v+jh49anh6eprjMnt17drV4j2SlJRkNGrUyOK5qby8vKz2IclwdnZOd533k5z87LNjzZo15nvj4sWLVmNv375ttGvXzuL7bmdnl+ecsnNPvvDCCxZzCAoKShd77do1o2nTplneM5KMfv36ZejL19fXkGT4+vpmmXtERITx1FNPWWy/ZMmSxs6dO7Nsc+3atYbJZMq0jbTvb3beq7w+l9m9fn9//wzPqmEYRlBQULbeew8PD+Pw4cMW22/evLkhyWjfvr3VPB40/O4FAAAAAAB3S3brBozUAfKoRYsWWrlypZycnGQYhl577TUtX7483/upU6eOzpw5o3HjxsnHx0clSpSQk5OTPD091bVrV61evVo//fRTujVD0rKzs9OmTZv0ySef6Mknn1TRokUzXTR++/bt+vrrr9WtWzfVrl1bZcqUkYODg4oXL646depo6NChCgwMzNUaMw+itm3bqmLFijIMI8vpx1xdXbVu3TotXrxYrVq1UtmyZeXk5KRKlSqpV69e2rNnj0aNGlXgOS9atEgTJ05Uw4YN5e7uLjs7y78qypcvr127dmnt2rXq3bu3qlatKjc3Nzk6OqpMmTJq3LixhgwZop07d1pdeyY73N3dtXfvXo0ZM0a1a9eWi4uLihYtqscff1xDhw7VH3/8oWbNmmXZTvv27bV161Z17txZnp6ecnR0zHVOeX0u88rLy0sHDx7UqFGj9Nxzz+nRRx9ViRIl5ODgoNKlS6tZs2aaNGmS/vzzT9WrVy/TNoKDg7Vr1y5J0qBBgwokTwAAAAAAAOQPk2FYmYgfBSIqKkru7u6KjIw0r8mSlbi4OAUFBalKlSoF9uUggIIxceJEDRs2TI888ohOnz5ttUgC3G1jx47ViBEj9Pjjj+vUqVOZFnsfVPzuBQAAAAAAd0t26wZ8swgABeztt99WhQoVdPbsWa1YscLW6QBmMTExmjJliiTJ39+fgg4AAAAAAMA9jqIOABQwV1dXjR49WlLKqAgGSOJeMWPGDIWGhqphw4Z64YUXbJ0OAAAAAAAAsuBg6wQA4EHQt29f3bhxQ/Hx8bp27Zo8PT1tnRKgYsWKyd/fX127dmWUDgAAAAAAQCFAUQcA7gJ7e3sNHz7c1mkA6QwaNMjWKQAAAAAAACAHmH4NAAAAAAAAAACgEKCoAwAAAAAAAAAAUAhQ1AEAAAAAAAAAACgEKOoAAAAAAAAAAAAUAhR1AAAAAAAAAAAACgGKOgAAAAAAAAAAAIUARR0AAAAAAAAAAIBCgKIOAAAAAAAAAABAIUBRBwAAAAAAAAAAoBCgqAMAAAAAAAAAAFAIUNQBAAAAAAAAAAAoBCjqAAAAAAAAAAAAFAIUdQAAAAAAAAAAAAoBijoAAAAAAAAAAACFAEUdAAAAAAAAAACAQoCiDgDcBWfOnJGTk5NcXFwUHBxsszx27Nghk8kkk8mkHTt22CyPwuBBeK/at28vk8kkf39/W6cCAAAAAACAbKCoA2Qi7Ze5o0aNshp7/fp1eXt7m+MHDhwowzDuTqLIlebNm5t/Xlm98sv777+vhIQEvfbaa6pQoYLV2KVLl+q5555T+fLl5eLiIi8vL7388svav39/vuUDSNKIESMkSV988YWuXLli42wAAAAAAACQFYo6QB4EBwfL19dXp0+fliS98847CggIyNdiQH7p27evTCaTKleubOtUHjj79u3T+vXr5eTkpI8++shiXGxsrNq3b69evXpp8+bNunHjhu7cuaPLly9r8eLFatKkiUaPHl2guY4aNSrfC1r3kosXL5qvb/78+bZOx+YaNWqkVq1a6fbt2/r8889tnQ4AAAAAAACy4GDrBIDC6vLly2rRooXOnz8vSfrggw80ceJEG2eFnKhfv77mzZtX4P2MHTtWktSjRw9VqlTJYlz//v21fv16SdKzzz6rd955R56enjpx4oQ+//xznT9/XqNGjZKHh4feeOONXOXSvHlzRpJl04PyXg0ZMkSbN2/WnDlzNGLECHl4eNg6JQAAAAAAAFhAUQfIhaCgILVo0UIXL16UJH388cfmL+5ReBQpUkS1atUq0D7OnDmjjRs3SpJefvlli3Hbtm3TsmXLJEkdO3bUqlWrZG9vL0lq0KCBOnXqpHr16uny5csaNmyYevTooYceeqhAc8eDoWXLlipbtqxCQkL07bffZjnlJAAAAAAAAGyH6deAHDp37px8fX3NBZ3Ro0dT0IFF8+bNk2EYKlu2rFq2bGkx7osvvpAkOTg4aObMmeaCTqrSpUtrwoQJkqSIiAjNnj274JLGA8Xe3l4vvviipP+7XwEAAAAAAHBvoqgD5MCZM2fk6+urv//+W5I0btw4jRw50mL8jh07zOt37NixQ5K0YsUK+fn5qUyZMnJ1ddWjjz6qDz/8UGFhYVn2HxMTo/Hjx+vpp59WyZIl5ezsrIoVK6p79+5au3ZtpuekrpGyYMECSdKlS5fMOaV9/du2bdvUs2dPValSRa6urnJzc5OXl5caNWqkoUOHatu2bVnmi5SftyR17txZDg6ZD46Mjo7W1q1bJaWMmqhYsWKmcV27dlXx4sUlSatWrcpVPpndk5I0f/58mUymdGv2ZHafpBYz00pKStKCBQvUoUMHeXp6ytnZWaVKlVKTJk00efJkxcbGWsynefPmMplMat68uSTpr7/+0ltvvaUaNWrIzc0tQ5/Xrl3TzJkz1b17d9WoUUNFihSRs7OzKlSooM6dO2v58uVKTk7OtC+TyaQqVaqY/9+vX78M15d2lIql9+rfcvNcWrr+4OBgvf/++6pevbpcXV1VqlQptW7dWhs2bLDaTlJSkubPn6/WrVurfPnycnJykru7u2rUqCE/Pz99/vnnCgwMtHh+t27dJKVMK7l3716rfQEAAAAAAMB2mH4NyKbAwED5+fnp+vXrkqTJkyfrvffey/b5ycnJeuWVV7Ro0aJ0+8+ePatJkyZp1apV2r17t8qXL5/p+ceOHVOHDh109erVdPuDg4P1008/6aefflLXrl21ePFiubi45PDq0nvvvfc0ZcqUDPsvX76sy5cv67ffftP8+fN18+bNPPVzv7t06ZKCgoIkpSxIb8mhQ4cUHx8vSfL19bUY5+TkpEaNGmnTpk06dOiQEhIS5OjomL9J59Dly5fVqVMn/fHHH+n2h4WFae/evdq7d68CAgK0bt06PfLII1bb+uWXX9S7d2/dunUr0+NJSUmqWLFipkWbq1evavXq1Vq9erXmzJmjlStXqmjRorm/sGzKz+dy79696tKlS7rnKi4uTps2bdKmTZs0adIkDR06NMN5MTExateunXbv3p1uf0JCgqKionTu3Dlt27ZNR48e1Y8//php3w0aNJC9vb2SkpK0YcMGNWnSJLtvAQAAAAAAAO4iijpANhw/flwtW7bUP//8I5PJpGnTpmnw4ME5amPEiBHat2+funTpoldffVVeXl66ceOGZsyYoXXr1uncuXN67733tHTp0gznBgcHy8/PT+Hh4TKZTOrbt69eeukllSpVSoGBgfryyy/1xx9/aOXKlerbt695bRZJGjRokLp3765PPvlEv/zyizw9PfXrr79azHPt2rXmgs4TTzyhgQMH6vHHH5e7u7siIiJ06tQpbdmyRQcPHszR9d+L/vzzT/n4+OjMmTOKi4tT6dKlVa9ePXXr1k09e/bMc8Ek7ZfsDRo0sBiXdgTFY489ZrXNxx57TJs2bVJiYqL++usveXt75ynHVF26dFH9+vU1c+ZMBQQESJJOnDiRIa5ChQrm7dDQUDVp0kR///23nJ2dNWDAAPn6+qpy5cqKiYnRpk2b9PXXX+vcuXNq27atjh49Knd390z7v3z5sl5++WW5ublpxIgRatq0qezt7XXo0CFzcSZ1WrAWLVqobdu2ql27tsqUKaPo6GhduHBB3333nfbv36/Nmzdr8ODB5tFpqU6cOKGrV6+qdevWkqSxY8eqc+fO6WLKli2b7fcsL8/lv127dk1dunSRnZ2dxo8fryZNmsjJyUl79uzRp59+qoiICP3vf/9T27ZtVbNmzXTnjho1ynyvdejQQb1799bDDz8sFxcXhYSE6NixY1q7dm2mI/JSubm5qWbNmjp+/Lh27tyZ7fcAAAAAAAAAd5mBuy4yMtKQZERGRmb7nNjYWCMwMNCIjY0twMyQavv27YYkQ5LRpUsXo1SpUoYkw2QyGbNmzcpVO5KMsWPHZohJTk42nnvuOUOS4eDgYISEhGSI6d69u7mN2bNnZzgeFxdnPPvss+aY9evXZ4jp06ePIcnw8vKymvMrr7xijouOjrYYFxoaarUda9K+J7l9zZs3L9f9+/r6Ztm+t7e3ERgYmOs+DMMwBg4caEgynJycjMTERItxw4YNM/d76NAhq21OmjTJHLtx48Yc55T2nty+fXuG4/7+/ubjWenVq5f5Xrlw4UKmMUePHjWKFCliSDKGDx+e4Xjan4Wnp6dx6dIli/0lJycbf/31l9WcRo4caX5Wz549m+F4UFBQtu+hrN6r/Hgu016/l5eXceXKlQwxu3fvNkwmkyHJ+O9//5vheKVKlQxJRvfu3a1eT1bPbL9+/QxJhpubm5GcnGw19kHB714AAAAAAHC3ZLduwJo69yHDMHQ74fZ9/zLu0mLeP//8s0JDQyVJM2fO1IABA3LVTr169TR8+PAM+00mk95//31JUmJiovbv35/u+NWrV83rp7Rp00avvfZahjacnZ01d+5c85ot06dPz1WOkszTy9WtW9fq9FUlS5bMdR+2ZmdnJz8/P3355ZfasmWLjh07pl27dmnKlCl6/PHHJaWMnnn22Wd1+fLlXPdz5coVSVKpUqVkb29vMS46Otq8ndWUYUWKFDFvx8TE5Dq3vLp48aKWL18uKeV+S7tWTVp16tQxj2qbP3++1TbHjx+vhx9+2OJxk8mk6tWrW21j5MiRKl26tAzD0OrVq63G5kVBPJfTpk1LNxIqVZMmTeTj4yNJGaZYk/7vmW3atKnV9rN6ZlNHKd2+fdvcJgAAAAAAAO4tTL92H4pNjJXPEh9bp1Hgfuv1m9wc3Qq8H5PJZC4grVmzRv3795eTk1OO2+nVq5fF6Y/q1atn3r5w4UK6Yzt27FBSUpIkZfrFcarKlSurVatW2rBhg/kca4UESzw8PCRJu3bt0vnz51WtWrUct5GVzKb1yqmKFSvm+tyVK1eqRIkSGfY3bdpUgwYN0oABA7RgwQLduHFD7777rlauXJmrfv755x9J0kMPPWQ1Li4uzryd1b3l7Oxs3o6Njc1VXvlh3bp1SkpKkpubm9q2bWs1tlmzZpo4caKuXr2qy5cvZ1q4cXJyUo8ePXKUQ3Jysq5fv67o6GglJCSY91esWFE3b97MsM5Pfsrv57JEiRJq3769xXbq1aunAwcOZPh8kFKe2cuXL2v58uV6/fXX5eaWu8/FtEWf69evmz8LAAAAAAAAcO+gqANkYeDAgdqxY4cCAwO1fv169ezZU8uXLzf/9X12WVsrJe2XqWlHbUjSyZMnzdupf61viY+PjzZs2KDbt2/rwoULqlGjRo5ylKRXX31VCxcuVGhoqGrVqqXOnTurdevWatq0aZajJLKrVq1a+dJObmVW0Enl6Oio2bNn68CBAzpz5oxWrVql4ODgTEdQZCUsLExS1kUdFxcX83Z8fLzV2Dt37pi3XV1dc5xTfjl8+LCklFEdOXkWrl+/nmlRp0aNGuneB0sMw9DixYs1Z84c/fbbb1YLWzdv3sx2XjmV389ljRo1ZGdnefBs6mfEvz8fJKlPnz4aM2aM9u3bpypVqqhHjx7y8/NTkyZNVKZMmexeUrr79NatW9k+DwAAAAAAAHcPRZ37kKuDq37r9Zut0yhwrg535wvtMmXKaMuWLWrWrJnOnTtnXvR84cKFVr+E/Tdrfz2ftp3Uv/5PlVoYkLJexL18+fKZnpcTfn5+mj59uj744APFxsZq+fLl5mm2KlSooA4dOmjgwIF68sknc9V+YeDg4KDXXntNH374oSRp586d6tWrV47bSS1SZDWiplixYubtrKZUS/tle1ZTtRWkkJCQXJ13+/btTPdnVfiSUkY0de3aVRs2bMhWXwU5kim/n8usRtekfkYkJydnODZixAgFBwdr3rx5CgkJ0YwZMzRjxgxJUs2aNdWtWzcNGjRI5cqVs9pH2vfL0dHRaiwAAAAAAABsg6LOfchkMt2VackeJB4eHtq2bZuaNm2qS5cuafHixXJ1ddWsWbMsTqlWEO5WX4MHD1aPHj20ZMkSbd68WXv37lVkZKSCg4P17bffatasWRo+fLjGjh2bq/bTjnLIrYoVK1odcZNX3t7e5u3g4OBctZE6SiKrAlvaqeSuXLmi+vXrW4z9+++/zduVKlXKVV75IbX4WLp0aW3fvj3b51laeyc7UwV+9tln5oKOr6+vBg8erLp166p8+fJydXU1Fz6aNWum3bt337V1t+7mZ0BmHB0dNWfOHA0ZMkRLly7Vtm3bdPjwYcXHx+vUqVM6deqUJk+erEWLFqlz584W20l7nxbkswUAAAAAAIDco6gDZFOlSpW0detWNWvWTFevXtXs2bPl6uqqqVOnFmi/aadmu3HjhtUv8tMubp7VouhZKVu2rN599129++67Sk5O1u+//65Vq1Zp+vTpioiI0GeffaYGDRpY/ZLYktq1a+cpN0maN2+e+vbtm+d2LMmPL+pTizrh4eFW49IWkP7880+rsanHHRwccjW9Xn4pVaqUpJTpwB5//PFcrd+UE4ZhaPbs2ZJS1j7atm2bxZFyuR2llhO2ei6t8fb21pgxYzRmzBjFxcVpz549WrJkiRYuXKiYmBj17NlT58+ft7hWTtr71JYFQwAAAAAAAFiW/bmjAKhatWraunWrebqladOm6aOPPirQPtOuP/Pbb9an1Tt48KCklKmcqlatmu5YXooUdnZ2qlu3rsaMGaOtW7ea969YsSLXbd7rAgMDzduenp65aiO1eBUZGWl1urIGDRrIyclJUspUb5bEx8frwIED5nMKYoqs7N4nderUkZSyxk/q+joFKSwszFwc6dGjh8WCTkxMjM6cOWOxnfwaVZNfz2VBcXFxUcuWLTV37lxNmjRJUsr0amvXrrV4ztmzZyWljKbKajo4AAAAAAAA2AZFHSCHHnvsMW3evNn8F/cTJkzQp59+WmD9NW/e3DwKYu7cuRbjLl++rM2bN2c4J1Xq+i537tzJUz5169Y1r3+S24XoDcPI86sgR+kkJiame6+bNWuWq3aaNm1q3j506JDFuGLFisnPz0+StGXLFl25ciXTuJUrVyoqKkqS9Pzzz+cqp6yk3ieS9XulY8eO5gLJlClTCiSXtBITE83badcV+rfZs2eni/237F5fVvLrubwbUu8tyfozm1qc8/HxKfCcAAAAAAAAkDsUdYBceOKJJ/Trr7+qePHikiR/f399+eWXBdKXp6en+Qv8DRs2aMGCBRli4uPj1b9/fyUkJEiS3nrrrQwxqVMuhYSEKDo62mJ/y5cvt7rA/OHDh83TNFlaH+Vetn37dkVERFg8npCQoNdff12nT5+WlFK8yO1UVA0bNpSzs7Ok/xutYcnQoUMlpRQvBg8ebF6zJtXNmzc1bNgwSSnrnbz++uu5yikraafmOn/+vMW4Rx99VD169JAkLVu2TJMnT7bablBQkJYuXZrrvMqUKWNe52Xp0qWZFmQOHTqkESNGWG2nVKlS5lFR1q4vK/n1XOZVWFiY1qxZY3X9oE2bNpm3LT2zFy5cMBd8nnvuufxNEgAAAAAAAPmGNXWAXKpfv77Wr1+v1q1b69atWxo6dKjc3Nw0cODAfO/rq6++0tatWxUeHq7+/ftrz549evHFF/XQQw/pzz//1BdffKHff/9dkvTCCy+obdu2Gdpo3LixJCk5OVlvvvmm3n77bZUuXdp8vHr16pKkYcOG6c0331Tnzp3VrFkzPfLIIypSpIhCQ0O1Z88eTZs2TVLKwvYFVVgoSAsWLFCnTp3UqVMnNW/eXI8++qiKFy+umJgYHTlyRLNmzTJPvVa2bFl9/fXXue7L2dlZrVu31urVq7V161aNHj3aYmyLFi300ksvadmyZVq9erVatWqld999V56enjpx4oQ+++wzXb58WVLK6LDU0VL5LfU+kaT33ntPH3/8sTw8PMyjcipXriwHh5RfHQEBATp8+LAuXLigIUOG6JdfftGrr76qmjVrytnZWaGhofrjjz+0ceNGbdu2Tc8//7x69uyZq7zs7OzUu3dvzZgxQ8ePH1eTJk30/vvvq0aNGoqMjNT69es1c+ZMFS1aVJ6enuapxP7NwcFBDRo00N69ezV37lzVqVNHTz31lHkqu5IlS2Z73Zv8eC7zKioqSp06dVLlypXVtWtX+fj4yMvLSw4ODrp27ZrWrFljXouoQoUK6tChQ6btpE6r6ODgYDEGAAAAAAAA9wADd11kZKQhyYiMjMz2ObGxsUZgYKARGxtbgJkh1fbt2w1JhiTD39/fauzWrVsNFxcXQ5JhMpmMefPmZdrO9u3brbaTVX9Hjx41PD09zXGZvbp27WrxHklKSjIaNWpk8dxUXl5eVvuQZDg7O6e7zsKkT58+WV6fJKN27drGqVOn8tzfmjVrzPfGxYsXrcbevn3baNeuncWc7Ozssrwfs5Kde/KFF16wmENQUFC62GvXrhlNmzbN1nvar1+/DH35+voakgxfX98sc4+IiDCeeuopi+2XLFnS2LlzZ5Ztrl271jCZTJm2kfb9zc57ldfnMrvX7+/vn+FZNQzDCAoKytZ77+HhYRw+fNhi+82bNzckGe3bt7eax4OG370AAAAAAOBuyW7dgOnXgDxq0aKFVq5cKScnJxmGoddee03Lly/P937q1KmjM2fOaNy4cfLx8VGJEiXk5OQkT09Pde3aVatXr9ZPP/2Ubs2QtOzs7LRp0yZ98sknevLJJ1W0aNFMF43fvn27vv76a3Xr1k21a9dWmTJl5ODgoOLFi6tOnToaOnSoAgMDC3RNm4I0bNgwffXVV3rhhRdUq1YtlStXTo6OjipatKiqVaumF198UT/88IOOHTsmb2/vPPfXtm1bVaxYUYZhZDn9mKurq9atW6fFixerVatWKlu2rJycnFSpUiX16tVLe/bs0ahRo/KcU1YWLVqkiRMnqmHDhnJ3d5edneVfFeXLl9euXbu0du1a9e7dW1WrVpWbm5scHR1VpkwZNW7cWEOGDNHOnTutrj2THe7u7tq7d6/GjBmj2rVry8XFRUWLFtXjjz+uoUOH6o8//sjW+kft27fX1q1b1blzZ3l6eppH6eRGXp/LvPLy8tLBgwc1atQoPffcc3r00UdVokQJOTg4qHTp0mrWrJkmTZqkP//8U/Xq1cu0jeDgYO3atUuSNGjQoALJEwAAAAAAAPnDZBhWJuJHgYiKipK7u7siIyPNa7JkJS4uTkFBQapSpUqBfTkIoGBMnDhRw4YN0yOPPKLTp09bLZIAd9vYsWM1YsQIPf744zp16lSmxd4HFb97AQAAAADA3ZLdugHfLAJAAXv77bdVoUIFnT17VitWrLB1OoBZTEyMpkyZIkny9/enoAMAAAAAAHCPo6gDAAXM1dVVo0ePlpQyKoIBkrhXzJgxQ6GhoWrYsKFeeOEFW6cDAAAAAACALDjYOgEAeBD07dtXN27cUHx8vK5duyZPT09bpwSoWLFi8vf3V9euXRmlAwAAAAAAUAhQ1AGAu8De3l7Dhw+3dRpAOoMGDbJ1CgAAAAAAAMgBpl8DAAAAAAAAAAAoBCjqAAAAAAAAAAAAFAIUdQAAAAAAAAAAAAoBijoAAAAAAAAAAACFAEUdAAAAAAAAAACAQoCiDgAAAAAAAAAAQCFAUQcAAAAAAAAAAKAQoKgDAAAAAAAAAABQCFDUAQAAAAAAAAAAKAQo6gAAAAAAAAAAABQCFHUAAAAAAAAAAAAKAYo6AAAAAAAAAAAAhQBFHQAAAAAAAAAAgEKAog4AAAAAAAAAAEAhQFEHAAAAAAAAAACgEKCoA9zDTCaTTCaTRo0aZetUAAAAAAAAAAA2RlEHyIGdO3eaCy0mk0n79u2zdUoAAAAAAAAAgAcERR0gBxYsWJDu/wsXLrRRJgAAAAAAAACABw1FHSCbYmNj9eOPP0qSihYtKklasWKF7ty5Y8u0AAAAAAAAAAAPCIo6QDatWrVK0dHRkqSpU6dKksLDw7VmzRpbpgUAAAAAAAAAeEBQ1AGyKXWqtSeeeEL9+vXTo48+mm4/AAAAAAAAAAAFiaIOkA3Xrl3Tli1bJEkvv/xyun83btyof/75x+r5V69e1UcffaS6devK3d1djo6OKleunGrXrq2ePXtq/vz5ioqKynFeycnJGjhwoEwmk0wmk9566y0ZhpEuZtWqVerSpYsqVqwoZ2dnFStWTFWrVlXTpk01YsQIHTx4MMf9AgAAAAAAAADuPgdbJwAUBosXL1ZSUpLs7OzUq1cvSVLv3r01cuRIJSQkaOnSpfrvf/+b6bm7d+9Whw4dMhRtQkJCFBISopMnT2rZsmUqXbq0OnTokO2cEhIS9Oqrr2rZsmWSpE8++URjxowxH09KSlLPnj31ww8/pDsvPj5eMTExCgoK0p49e7RhwwYdPnw42/0CAAAAAAAAAGyDog6QDd9//70kqXnz5qpQoYIkqUqVKmrcuLH27t2rhQsXZlrUuXPnjl566SVFRUWpWLFiGjhwoJ599lmVLVtW8fHxCgoK0r59+7Rq1aoc5XP79m1169ZNGzdulMlk0uTJk/Xuu++miwkICDAXdJo0aaLXX39d1apVU5EiRRQaGqrjx49r48aNioyMzMU7AgAAAAAAAAC42yjqIE+Skg0dDApTSHScyhZzUcMqJWVvZ7J1Wvnq999/1/HjxyX935RrqV5++WXt3btXR44cUWBgoLy9vdMd37t3r65evSpJWrJkSYaROI0aNVLPnj311Vdf6fbt29nKJyIiQh06dNDevXtlb2+v2bNnq2/fvhniVqxYIUny8fHR9u3b5eCQ/nFv2bKl3n//fYWFhWWrXwAAAAAAAACAbbGmDnJt48lrajJhm3p+d0DvLPtdPb87oCYTtmnjyWu2Ti1fLVy4UJLk6uqqbt26pTv2wgsvyMnJKV1cWtevXzdvN2vWzGIfDg4OKl68eJa53LhxQ82bN9fevXvl7OysH3/8MdOCTtq+GzdunKGgk1bJkiWz7BcAAAAAAAAAYHsUdZArG09e08BFR3UtMi7d/uuRcRq46Oh9U9hJTEzUkiVLJEkdO3bMUHgpWbKk2rVrJyll3Z3k5OR0xz08PMzb8+bNy1MuFy9eVJMmTfTHH3+oaNGiWr9+vbp06WIxPrXvNWvW6ObNm3nqGwAAAAAAAABgexR1kGNJyYZGrwmUkcmx1H2j1wQqKTmziMLl119/1Y0bNyRlnHotVer+K1euaPv27emONWnSRFWrVpUkvfvuu2rYsKHGjRunvXv3Kj4+Ptt5nD59Ws8884zOnTunUqVKaevWrWrRooXVc/r06SNJOnfunKpXr67+/ftr6dKlunLlSrb7BQAAAAAAAADcOyjqIMcOBoVlGKGTliHpWmScDgYV/rVaUqdUK1WqlNq0aZNpTIcOHVSiRIl08akcHR21Zs0aPf7445KkQ4cOafjw4WrSpIlKlCihNm3aaMmSJUpKSrKax4oVK8xr8wQEBKhhw4ZZ5t6/f38NHz5cDg4OioyM1Lx589SrVy9VqlRJ1atX15AhQ3ThwoUs2wEAAAAAAAAA3Bso6iDHQqItF3RyE3evioyM1OrVqyVJoaGhcnJykslkyvBycXFRRESEJGnlypW6detWuna8vb114sQJrVq1Sv3791f16tUlSbGxsfr111/Vu3dv+fj4KCQkxGIurVu3VpEiRSRJb731lgIDA7N1DZ999pnOnTunzz77TC1atJCbm5sk6fz585o8ebIee+wxffPNNzl6XwAAAAAAAAAAtkFRBzlWtphLvsbdq1asWKG4uJwVpmJiYrRy5coM++3t7dWlSxfNmTNHf/31l65evaq5c+eqXr16kqQjR47oP//5j8V2GzVqpHXr1snNzU0hISHy8/PTmTNnspWTl5eXhg8frq1btyoiIkJ79+7VO++8IxcXFyUkJGjQoEE6duxYjq4TAAAAAAAAyK2kZEP7z4fql9+Dtf986H2xjANwtzjYOgEUPg2rlJSHu4uuR8Zluq6OSVJ5dxc1rFLybqeWr1KnUvPw8NDkyZOzjP/ggw905coVLVy4UK+88orVWA8PD/Xr108vv/yyGjVqpKNHj2rt2rWKjY2Vq6trpuf4+vpqzZo16tChg65fv65nn31WO3fuVI0aNbJ9TY6OjmrcuLEaN24sX19fde3aVYZh6Mcff1SdOnWy3Q4AAAAAAACQGxtPXtPoNYHplnfwcHeRf0dvtanlYcPMgMKBog5yzN7OJP+O3hq46KhMUrrCjun//+vf0Vv2dqZMzi4cgoKCtHfvXklSt27d9NJLL2V5zoEDB/T1119r27ZtCg4OVoUKFbI8x9HRUb6+vjp69KgSExMVERFhsagjSS1atNAvv/yiTp066dq1a+bCTrVq1bJ/cf+fn5+fefvmzZs5Ph8AAAAAAADIiY0nr2ngoqMZ/lD8emScBi46qoCX61LYAbLA9GvIlTa1PBTwcl2Vd08/xVp5d5f74sN34cKFMoyUXy/du3fP1jmpccnJyVq0aJEkaffu3Tp37pzFc+Lj47Vz505JUtGiRVWmTJks+2nVqpV+/vlnOTs7Kzg4WM8++6wuXLiQIW7RokVKTEy02M6mTZvM21WqVMmyXwAAAAAAACC3kpINjV4TmOnMP6n7Rq8JZCo2IAuM1EGutanloVbe5XUwKEwh0XEqWyxlyrXCPEIn1ffffy9JKlu2rJo2bZqtcxo3biwPDw9du3ZN33//vYYNG6atW7dqzJgxatq0qdq3b68nnnhCZcqUUWxsrM6ePatvvvlGR48elSS99tprcnDI3iPZunVrrVy5Us8//7z+/vtvtWjRQjt37pSXl5c55pVXXtHQoUPVtWtXNW7cWNWqVZOLi4tu3LihzZs3KyAgQFJKMal37945eXsAAAAAAACAHDkYFJZuyrV/MyRdi4zTwaAwPV2t1N1LDChkKOogT+ztTPfdh+zevXt1/vx5SdLzzz8vO7vsDWizs7PT888/r5kzZ+rUqVM6cuSIpJSROzt37jSPyMlM586dNW7cuBzl2a5dO/3444/q1q2bLl26ZJ6KrVKlSuaYGzduKCAgwFzA+Td3d3ctW7Ys3TkAAAAAAABAfguJtlzQyU0c8KBi+jXgXxYuXGje7tatW47OTRu/cOFCDR06VD/99JMGDhyoRo0a6eGHH5aLi4tcXFxUuXJlvfDCC1q7dq1+/vlnq2vpWNKxY0etWLFCjo6OCgoK0rPPPqsrV65Ikk6ePKkJEyaoY8eO8vb2VqlSpWRvb68SJUqoUaNG8vf315kzZ9SmTZsc9wsAAAAAAADkRNliLlkH5SAOeFCZjNSFQ3DXREVFyd3dXZGRkSpevHi2zomLi1NQUJCqVKkiFxc+2AAAKGj87gUAAACA/JOUbKjJhG26HhmX6bo6JqWs171nWIv7YnkHIKeyWzdgpA4AAAAAAAAAoEDZ25nk39FbUkoBJ63U//t39KagA2SBog4AAAAAAAAAoMC1qeWhgJfrqrx7+tkQyru7KODlumpTy8NGmQGFh4OtEwAAAAAAAAAAPBja1PJQK+/yOhgUppDoOJUt5qKGVUoyQgfIJoo6AAAAAAAAAIC7xt7OpKerlbJ1GkChxPRrAAAAAAAAAAAAhQBFHQAAAAAAAAAAgEKAog4AAAAAAAAAAEAhQFEHAAAAAAAAAACgEKCoAwAAAAAAAAAAUAhQ1AEAAAAAAAAAACgEKOoAAAAAAAAAAAAUAhR1AAAAAAAAAAAACgGKOgAAAAAAAAAAAIUARR0AAAAAAAAAAIBCgKIOAAAAAAAAAABAIUBRBwAAAAAAAAAAoBCgqAMAAAAAAAAAAFAIUNQBAAAAAAAAAAAoBCjqAAAAAAAAAAAAFAIUdYACtmPHDplMJplMJu3YsSPX7YwaNcrcDgAAAAAAAADgwUNRB7AgbTEms1fRokX1yCOP6JVXXtG2bdtsnS4AAAAAAAAA4D5HUQfIpVu3bumvv/7SokWL5Ofnpz59+igpKcnWaQEAAAAAAAAA7lMOtk4AKAwGDhyoQYMGmf9vGIbCwsK0f/9+ffXVVwoJCdHChQtVqVIljR07Nt25zZs3l2EYdztlAAAAAAAAAMB9hqIOkA1ly5ZVrVq1Muz39fVVp06dVK9ePcXFxWnq1KkaOXKknJycbJAlAAAAAAAAAOB+xvRrQB55e3urffv2kqTo6Gj9+eefNs4IAAAAAAAAAHA/oqgD5IMqVaqYt+/cuZPu2I4dO2QymWQymbRjxw6LbVy5ckWDBw9W1apV5eLiIk9PT3Xq1ElbtmzJdh6rVq1Sly5dVLFiRTk7O6tYsWKqWrWqmjZtqhEjRujgwYM5vjYAAAAAAAAAwL2B6deAfHDp0iXz9sMPP5zj83fv3q0OHTooKirKvO/atWtas2aN1qxZo1GjRlk9PykpST179tQPP/yQbn98fLxiYmIUFBSkPXv2aMOGDTp8+HCO8wMAAAAAAMD9LynZ0MGgMIVEx6lsMRc1rFJS9nYmW6cFIA2KOkAe/fnnn1q7dq0kqVGjRipXrlyOzr98+bK5oGNnZ6c33nhD3bt3l7u7u44fP67x48dr1KhRql+/vsU2AgICzAWdJk2a6PXXX1e1atVUpEgRhYaG6vjx49q4caMiIyNzf6EAAAAAAAC4b208eU2j1wTqWmSceZ+Hu4v8O3qrTS0PG2YGIC2KOsib5CTp0j4p5oZUtJzk1Viys7d1VvkuJCREJ0+eNP/fMAxFRERo//79+uqrrxQbGyt3d3d99dVXOW57yJAh5hE6ixYtUs+ePc3H6tevrx49eqhp06ZWR9isWLFCkuTj46Pt27fLwSH9o92yZUu9//77CgsLy3F+AAAAAAAAuL9tPHlNAxcdlfGv/dcj4zRw0VEFvFyXwg5wj6Cog9wLXC1tHCZFXf2/fcU9pTYTJO9OtsurAAQEBCggICDTY3Z2dnrzzTf13nvv6ZFHHslRu9evX9eqVaskSR06dEhX0ElVrFgxzZo1Sz4+PlbbkaTGjRtnKOikVbJkyRzlBwAAAAAAgPtbUrKh0WsCMxR0JMmQZJI0ek2gWnmXZyo24B5gZ+sEUEgFrpZWvJq+oCNJUddS9geutk1eNpCcnKxly5YpICBAd+7cydG527dvV1JSkiSpX79+FuMaNmyomjVrWjzu4ZHylxJr1qzRzZs3c5QDAAAAAAAAHlwHg8LSTbn2b4aka5FxOhjEDDDAvYCiDnIuOSllhI7F+r2kjR+lxN0n/P39ZRhGutft27d1/PhxffDBB4qJidGUKVPUsmVL3b59O9vtnjhxwrzdoEEDq7ENGza0eKxPnz6SpHPnzql69erq37+/li5dqitXrmQ7FwAAAAAAADx4QqItF3RyEwegYFHUQc5d2pdxhE46hhQVnBJ3H3N1dVXt2rU1ceJEzZw5U5K0Z88eff7559luI+0aN2XLlrUaW65cOYvH+vfvr+HDh8vBwUGRkZGaN2+eevXqpUqVKql69eoaMmSILly4kO28AAAAAAAA8GAoW8wlX+MAFCyKOsi5mBv5G3cfeO2118zr1cydOzdXbZhMeZuT9LPPPtO5c+f02WefqUWLFnJzc5MknT9/XpMnT9Zjjz2mb775Jk99AAAAAAAA4P7SsEpJebi7yNI3UyZJHu4ualiFtZqBewFFHeRcUcsjRnIVdx+ws7NTjRo1JEnXrl1TaGhots576KGHzNs3blgvgmV1XJK8vLw0fPhwbd26VREREdq7d6/eeecdubi4KCEhQYMGDdKxY8eylRsAAAAAAADuf/Z2Jvl39JakDIWd1P/7d/SWvV3e/iAZQP6gqIOc82osFfdUxo/5VCapeIWUuAdIYmJiptvW1K5d27x96NAhq7FZHf83R0dHNW7cWFOmTNGSJUskSYZh6Mcff8xROwAAAAAAALi/tanloYCX66q8e/op1sq7uyjg5bpqU8vDRpkB+DcHWyeAQsjOXmozQVrxqlIKO0aag/+/0NNmfErcA+L27dsKDAyUlLLWTunSpbN13rPPPit7e3slJSVpwYIF6tq1a6Zxhw4d0smTJ3Odn5+fn3n75s2buW4HAAAAAAAA96c2tTzUyru8DgaFKSQ6TmWLpUy5xggd4N7CSB3kjncn6YWFUvF/VemLe6bs9+5km7xsZNSoUYqNjZUktW7dWvb22StoeXh4qHPnzpKk1atXa8WKFRliYmJi9J///MdqO4sWLbI6OmjTpk3m7SpVqmQrNwAAAAAAADxY7O1MerpaKXV+qoKerlaKgg5wD2KkDnLPu5P0WHvp0j4p5kbKGjpeje/LETohISEZRsrExcXpr7/+0sKFC7Vx40ZJkouLiz799NMctf3ll19q8+bNio6OVq9evbRz5051795dxYsX1/HjxzV+/HidPXtW9evX1+HDhzNt45VXXtHQoUPVtWtXNW7cWNWqVZOLi4tu3LihzZs3KyAgQJJUtGhR9e7dOxfvAAAAAAAAAADA1ijqIG/s7KUqTW2dRYELCAgwF0YsKVOmjBYtWpRunZzsqFy5slavXq1OnTopOjpaM2fO1MyZM9PFjBw5UiaTyWJRR5Ju3LhhNU93d3ctW7ZMlSpVylF+AAAAAAAAAIB7A0UdIJecnJxUsmRJ1axZU+3atVO/fv300EMP5aqt5s2b69SpUxo3bpzWr1+va9eu6aGHHlL9+vX19ttvq3Xr1ho1apTF80+ePKl169Zpz549On/+vG7cuKGIiAgVK1ZMjz32mFq3bq2BAweqXLlyubxaAAAAAAAAAICtmQzDMLIOQ36KioqSu7u7IiMjVbx48WydExcXp6CgIFWpUkUuLi4FnCEAAOB3LwAAAAAAuFuyWzewu4s5AQAAAAAAAAAAIJco6gAAAAAAAAAAABQCFHUAAAAAAAAAAAAKAYo6AAAAAAAAAAAAhQBFHQAAAAAAAAAAgEKAog4AAAAAAAAAAEAhQFEHAAAAAAAAAACgEKCoAwAAAAAAAAAAUAhQ1AEAAAAAAAAAACgEKOoAAAAAAAAAAIACd+PWDSUkJ9g6jUKNok4hYxiGrVMAAOCBwO9cAAAAAADyT7KRrPd3vK9uq7vpdOhpW6dTaDnYOgFkj729vSQpMTHRxpkAAPBgSEpKkiTZ2fE3MAAAAAAA5NWa82t0/OZxuTm4qZRrKVunU2jxLUUh4eDgIGdnZ0VGRto6FQAAHgjR0dFydHSUo6OjrVMBAAAAAKBQi4mP0ZSjUyRJ/zGKqeydWNsmVIhR1CkkTCaTSpQooejoaIWHh9s6HQAA7muxsbGKiopSsWLFZDKZbJ0OAAAAAACF2qzjs3Qz9qYeTkjQy+ePSgkUdXKL6dcKkYceekjx8fG6fv26oqKiVLRoUbm4uMjOzo4vnAAAyCPDMJSUlKTo6GhFRUXJ2dlZpUuXtnVaAAAAAAAUahcjL+r7099LkoaFhsvJ5z9S2cdsnFXhdc8WdWbMmKFJkybp+vXrevLJJzVt2jQ1bNjQYvwPP/ygESNG6OLFi6pRo4YmTJigdu3amY8bhiF/f3999913ioiI0DPPPKOAgADVqFHDHBMWFqa3335ba9askZ2dnbp166avv/5aRYsWTdfOl19+qVmzZunSpUsqXbq0Bg0apI8//rhg3og0TCaTypcvL1dXV0VFRenmzZtKTk4u8H4BAHiQODo6qkSJEipdurR5TTsAAAAAAJA7Ew9NVGJyoprejlUzu2JS849snVKhdk8WdZYvX673339f33zzjXx8fDRlyhS1bt1aZ86cUdmyZTPE79u3Tz179tS4cePUoUMHLVmyRF26dNHRo0dVq1YtSdLEiRM1depULViwQFWqVNGIESPUunVrBQYGysXFRZLUu3dvXbt2TZs3b1ZCQoL69eunN954Q0uWLDH39c4772jTpk364osvVLt2bYWFhSksLOzuvDH/n7u7u9zd3ZWcnKzExEQKOwAA5BM7Ozs5OjoyAhYAAAAAgHyw68ou7Q7eLQfD0Ieh4VL7ryUXd1unVaiZDMMwbJ3Ev/n4+KhBgwaaPn26JCk5OVmVKlXS22+/rY8+yljFe/HFF3Xr1i2tXbvWvK9Ro0Z66qmn9M0338gwDHl6emrIkCEaOnSoJCkyMlLlypXT/Pnz9dJLL+n06dPy9vbWoUOHVL9+fUnSxo0b1a5dO125ckWenp46ffq0nnjiCZ08eVKPPvporq8vKipK7u7uioyMVPHixXPdDgAAAAAAAAAA96L4pHh1Xd1Vl6IuqV9ElN53qya9tkWys7N1avek7NYN7rl3Lz4+XkeOHFHLli3N++zs7NSyZUvt378/03P279+fLl6SWrdubY4PCgrS9evX08W4u7vLx8fHHLN//36VKFHCXNCRpJYtW8rOzk6//fabJGnNmjWqWrWq1q5dqypVqqhy5cp6/fXX7/pIHQAAAAAAAAAA7mWLTi/SpahLKpWYpDciIqW2kyjo5IN77h28efOmkpKSVK5cuXT7y5Urp+vXr2d6zvXr163Gp/6bVcy/p3ZzcHBQyZIlzTEXLlzQpUuX9MMPP2jhwoWaP3++jhw5ou7du1u9pjt37igqKirdCwAAAAAAAACA+9E/t//Rt398K0l6LzxCRZ/qLVWsZ+Os7g/35Jo696rk5GTduXNHCxcu1COPPCJJmjNnjurVq6czZ85YnJJt3LhxGj169N1MFQAAAAAAAAAAm5hydIpuJ97WE3F31DHBXvLzt3VK9417bqRO6dKlZW9vrxs3bqTbf+PGDZUvXz7Tc8qXL281PvXfrGJCQkLSHU9MTFRYWJg5xsPDQw4ODuaCjiQ9/vjjkqTLly9bvKb//e9/ioyMNL/+/vtvi7EAAAAAAAAAABRWv4f8rtXnV0uSPgoNl13z/0lFy2ZxFrLrnivqODk5qV69etq6dat5X3JysrZu3aqnn34603OefvrpdPGStHnzZnN8lSpVVL58+XQxUVFR+u2338wxTz/9tCIiInTkyBFzzLZt25ScnCwfHx9J0jPPPKPExESdP3/eHHP27FlJkpeXl8VrcnZ2VvHixdO9AAAAAAAAAAC4nyQbyRp/cLwkqUt0jGq7V5UaDrBxVveXe3L6tffff199+vRR/fr11bBhQ02ZMkW3bt1Sv379JEmvvvqqKlSooHHjxkmS3nnnHfn6+urLL79U+/bttWzZMh0+fFizZs2SJJlMJr377rsaO3asatSooSpVqmjEiBHy9PRUly5dJKWMuGnTpo0GDBigb775RgkJCXrrrbf00ksvydPTU5LUsmVL1a1bV/3799eUKVOUnJyswYMHq1WrVulG7wAAAAAAAAAA8KD55dwvOhV6SkWTk/VOWIT08jzJ3tHWad1X7smizosvvqh//vlHI0eO1PXr1/XUU09p48aNKleunKSUqc7s7P5vkFHjxo21ZMkSffLJJxo+fLhq1Kihn3/+WbVq1TLHfPjhh7p165beeOMNRUREqEmTJtq4caNcXFzMMYsXL9Zbb70lPz8/2dnZqVu3bpo6dar5uJ2dndasWaO3335bzZo1U5EiRdS2bVt9+eWXd+FdAQAAAAAAAADg3hQdH60pR6dIkt4Mj1TpRztIVZvbNKf7kckwDMPWSTxooqKi5O7ursjISKZiAwAAAAAAAAAUepMOTdLCwIWqHJ+glTfC5Tj4oPSQ5WVLkF526wb33Jo6AAAAAAAAAACg8LgQcUFLTi+WJA0LC5djk/co6BQQijoAAAAAAAAAACBXDMPQhEMTlGgkqfmt22riVFZ65h1bp3XfoqgDAAAAAAAAAAByZcffO7Tv6j45GoY+CIuQWn8mObraOq37FkUdAAAAAAAAAACQY3eS7mjioYmSpFcjo/Tww02kxzvaOKv7G0UdAAAAAAAAAACQYwtPLdSVmCsqm5ioN6JuS20nSiaTrdO6r1HUAQAAAAAAAAAAOXL91nV9d3yWJOm9sAi5NXhDKvOojbO6/1HUAQAAAAAAAAAAOfLVka8UmxSnp+LuqL2KSM2H2TqlB4KDrRMAAAAAAAAAAACFx7GQY1oftF4mw9BHoWEytZ0iubjbOq0HAiN1AAAAAAAAAABAtiQlJ2ncb+MkSV1jbqlmmSelJ3vZOKsHB0UdAAAAAAAAAACQLSvPrdTpsNMqlpSst8MipHYTJTtKDXcL7zQAAAAAAAAAAMhS5J1ITTs6TZI0KCJSpZ7sJVWoZ+OsHiwUdQAAAAAAAAAAQJYC/ghQ+J1wVYuP14t37CS/UbZO6YFDUQcAAAAAAAAAAFj1V/hfWvbnMknSh6ERcnz2f1LRMjbO6sFDUQcAAAAAAAAAAFhkGIYmHJqgJCNJfrduq3GxylKD122d1gPJwdYJAAAAAAAAAACAe9fWy1v127Xf5GQYGhoWLvWaK9k72jqtBxIjdQAAAAAAAAAAQKbiEuP0xeFJkqS+EVGq+EgHqaqvjbN6cFHUAQAAAAAAAAAAmZp/ar6CY66qXGKiXrt1R3purK1TeqBR1AEAAAAAAAAAABlci7mmOSdmS5KGhEXI7Zn3pRIP2zirBxtFHQAAAAAAAAAAkMHkI5MVl3RHdePi1MaxtPTMf22d0gPPwdYJAAAAAAAAAACAe8uh64e08eJG2RmG/hcaLtPz8yVHV1un9cBjpA4AAAAAAAAAADBLTE7U+IPjJUndo2P0WKWm0mPtbZwVJIo6AAAAAAAAAAAgjZ/O/qSz4WdVPClJb0XektpMkEwmW6cFUdQBAAAAAAAAAAD/X+SdSE07Nk2SNDg8Ug81/I9U5hEbZ4VUFHUAAAAAAAAAAIAkafqx6YqMj1T1+Hi9YBSRmn1o65SQhoOtEwAAAAAAAAAAALZ3JuyMVpxZIUn6X2i4HNpOlVyK2zgrpMVIHQAAAAAAAAAAHnCGYWj8wfFKVrJa3bqthmWekp540dZp4V8o6gAAAAAAAAAA8IDbdGmTDt84LOfkZA0Ni5DaTpRMJlunhX+hqAMAAAAAAAAAwAMsNjFWXxz6QpLUPzJank++Ink+ZdukkCmKOgAAAAAAAAAAPMDmnpyr67evyyMxUf3iTJLfSFunBAso6gAAAAAAAAAA8IAKjgnWvBNzJUlDQ8Pl2uITya2kjbOCJRR1AAAAAAAAAAB4QH15+EvdSY5Xg9g4tSpWTarf39YpwQoHWycAAAAAAAAAAADuvt+u/abNlzbLzjD0UWi4TC8vkOzsbZ0WrGCkDgAAAAAAAAAAD5jE5ESN/22cJOmF6Bg98lgXyauxbZNClijqAAAAAAAAAADwgFl+ZrnORZ6Xe1KS3opOkFp9auuUkA0UdQAAAAAAAAAAeICEx4VrxrEZkqT/hkfKvdlQqbinjbNCdlDUAQAAAAAAAADgATLt2DRFJ0Tr0Tvx6uZYVmo0yNYpIZso6gAAAAAAAAAA8IA4HXpaP579UZL0UVi47NtOlBycbZwVsouiDgAAAAAAAAAADwDDMDT+4DgZMtQ25pbqP9xCqtHK1mkhByjqAAAAAAAAAADwANgQtEFHQ47JJTlZ70feltp8buuUkEMUdQAAAAAAAAAAuM/dTritLw9/KUl6PTJK5X0GSyWr2jgr5BRFHQAAAAAAAAAA7nOzT8xWSGyIKiQkqk9ycanp+7ZOCbngYOsEAAAAAAAAAABAwfk7+m8tODVfkvRBWLhc2s2UnIrYNinkCiN1AAAAAAAAAAC4j31x6AvFJyeoUWysWpStJ9V83tYpIZco6gAAAAAAAAAAcJ/aF7xP2/7eJnvD0LCwKJnaTpJMJlunhVyiqAMAAAAAAAAAwH0oITlB4w+OkyT1jIpW9Tr9pHLeNs4KeUFRBwAAAAAAAACA+9CS00sUFHVRJZOSNPCOg9T8f7ZOCXnkYOsEAAAAAAAAAABA/roZe1MBv8+UJL0TFqHifuMl1xK2TQp5xkgdAAAAAAAAAADuM18f/Vq3Em+r5p076lL8Eempl22dEvIBI3UAAAAAAAAAALiPnPjnhH4+97Mk6aPQcNm9skSyY4zH/YCfIgAAAAAAAAAA94lkI1njfvtcktQpOkZPPf6CVLG+jbNCfqGoAwAAAAAAAADAfWL1+dU6EXpSbsnJevdWktTS39YpIR9R1AEAAAAAAAAA4D4QHR+tKUe+kiS9GRGpMs0+koqWtXFWyE8UdQAAAAAAAAAAuA9888c3Co0LU+X4BL3s5Ck1HGDrlJDPHGydAAAAAAAAAAAAyJsLERe05PRiSdKwsHA59vhWsne0cVbIb4zUAQAAAAAAAACgEDMMQxMOTlCikaTmt26rSZXWUlVfW6eFAkBRBwAAAAAAAACAQmz739u179o+ORqGPoiKlZ77zNYpoYBQ1AEAAAAAAAAAoJC6k3RHEw9OkCT1iYzSw0+/K5WoZNukUGBYUwcAAAAAAAAA7nFJyYYOBoUpJDpOZYu5qGGVkrK3M9k6LdwDFpxaoOBbV1U2MVEDDHep8X9tnRIKEEUdAAAAAAAAALiHbTx5TaPXBOpaZJx5n4e7i/w7eqtNLQ8bZgZbu37rumYfnyVJej8sQm4dZ0uOLjbOCgWJ6dcAAAAAAACA/8fenYdHVR1uHH/vzGQnC1tI2MNuCLuAgAhC0IDiiiJKW61aRUFQVBYtiFYWEWWz4FqrFFTqikpaNjdAIrKGAIKETRICBLKQTDKZub8/qPxEQENIcmcm38/z+PSZO2fufSeNJrnvnHMAL5WcmqFhCzacUehIUmaOU8MWbFByaoZFyeANZqyfoUJ3kTo6nRpQ5zKp5QCrI6GCUeoAAAAAAAAAgBdye0xNWpIm8xzP/Xxs0pI0uT3nGgF/913md0remyybaWpcdp6MAc9JBkvy+TtKHQAAAAAAAADwQinp2WfN0PklU1JGjlMp6dmVFwpeocRToqnrpkiSBuXlq1Wne6VazS1OhcpAqQMAAAAAAAAAXigr7/yFTlnGwX/8+4d/64cTuxThdmt4cZDU63GrI6GSOKwOAAAAAAAAAAA4W3R46Ta8L+04+IcTzhOas2GWJGn48RxVT3xBCgq3OBUqCzN1AAAAAAAAAMALdYmrodjIYJ1vlxRDUmxksLrE1ajMWLDY3E1zlevKV/PiYt0S1Vpqe6vVkVCJKHUAAAAAAAAAwAvZbYYmDoyXpLOKnZ8fTxwYL7vtfLUP/M2O7B1avPM9SdK4YyfkGDBdMvj/vyqh1AEAAAAAAAAAL5WUEKt5QzsqJvLMJdZiIoM1b2hHJSXEWpQMlc00TU1ZN1kemUrKP6nOCbdLse2sjoVKxp46AAAAAAAAAODFkhJi1S8+Rinp2crKcyo6/NSSa8zQqVqWpi/VhqyNCvZ4NLrAlPr81epIsAClDgAAAAAAAAB4ObvNULemNa2OAYsUuAo0Y/10SdI9ObmK6T1RCmUvpaqI5dcAAAAAAAAAAPBir219TVmFR1XPVaI7gxtKne6yOhIswkwdAAAAAAAAAAC81IHcA3oz9R+SpMeyjyto8BuSzW5xKliFmToAAAAAAAAAAHip5757Ti6zRN0KC9WnybVSo25WR4KFKHUAAAAAAAAAAPBC3/z0jb44+IUcpqmxuUUyrnrG6kiwGKUOAAAAAAAAAABexuV2adq6KZKk23Pz1KT7aCki1uJUsBqlDgAAAAAAAAAAXuZf2/+lvXn7VcPt1v1GTemyB6yOBC/gsDoAAAAAAAAAAAD4f0cKjmjeppckSaOyTyj8+rckR6DFqeANmKkDAAAAAAAAAIAXmblhpgrcTiUUFen6uldIzROtjgQvQakDAAAAAAAAAICX2Hxksz758RNJ0rjj+bIlTbE4EbwJpQ4AAAAAAAAAAF7AY3o05dtnJUnX5+WrbecHpBpxFqeCN6HUAQAAAAAAAADAC3y8+2Nty96uMI9Ho1yh0uWPWB0JXsZhdQAAAAAAAAAAAKq63OJczVw/Q5I07HiOal09RwoMtTgVvA0zdQAAAAAAAAAAsNi8TfOUXZyjuGKXbq/RToq/wepI8EKUOgAAAAAAAAAAWOjHEz9q0faFkqSx2TkKGPC8ZBgWp4I3otQBAAAAAAAAAMAipmlqyrrJcsujK08WqHvbP0nRl1gdC16KUgcAAAAAAAAAAIus3L9S6zJTFOgx9VihIfUea3UkeDGH1QEAAAAAAAAAAKiKnCVOTU+ZKkn6U26uGlz5rBQSZW0oeDVm6gAAAAAAAAAAYIE3t72pnwoyFV1SontCm0rt77A6ErwcM3UAAAAAAAAAAKhkGfkZen3Lq5KkR7NPKHTIAsnGPAz8Nr5DAAAAAAAAAACoZM+vny6np1idCp1Kan6jVL+T1ZHgAyh1AAAAAAAAAACoRCkZKfrvvmWymabG5blkJE6yOhJ8BKUOAAAAAAAAAACVpMRToinf/k2SdEtevlr2HCNVq21xKvgKSh0AAAAAAAAAACrJezvf0+7cdEW63Rpuj5E632t1JPgQh9UBAAAAAAAAAACoCo47j2vuhlmSpBHHcxR108uSndv0KD1m6gAAAAAAAAAAUAnmbJyjvJICtSwq1qAGiVJcT6sjwcdQ6gAAAAAAAAAAUMG2H9uuf/+wWJI0NqdA9quftTgRfBGlDgAAAAAAAAAAFcg0TU359m8yJfXPP6lLuz4kRda3OhZ8EKUOAAAAAAAAAAAV6LP0z7Tx6BaFeDx6xF1N6jbC6kjwUezABAAAAAAAAABABTnpOqkXUp6TJN17IlcxA16RAoItTgVfxUwdAAAAAAAAAAAqyKtbXtWRouOq73Lpj7U6Sy2SrI4EH0apAwAAAAAAAABABdiXu09vbXtTkvT48TwF9X9OMgxrQ8GnUeoAAAAAAAAAAFABpq+bKpfpVo+CQvVud7dUq5nVkeDjKHUAAAAAAAAAAChnXx38Sl8e+kYO09TjRQ4ZvR63OhL8gMPqAAAAAAAAAAAA+JNid7Ge+3ayJOmO3Dw16fO8FFTN4lTwB8zUAQAAAAAAAACgHC3YvkD7Tv6kmiVu3V+tldRmkNWR4CeYqQMAAAAAAAAAQDnJKsjSy5v+Lkl6+HiOqg19VzIMi1PBXzBTBwAAAAAAAACAcjJz/QsqcBeprbNIA1sNlmLaWB0JfoRSBwAAAAAAAACAcrApa5OWpH8mSRqX75atz5MWJ4K/odQBAAAAAAAAAOAiuT1uTVn7jCTpxrx8JfR6QgqtYXEq+BtKHQAAAAAAAAAALtJHuz9S2okfVM3j0UMB9aSOf7I6EvyQw+oAAAAAAAAAAAD4stziXM1aP0OSNOx4jmoNekOy2S1OBX/ETB0AAAAAAAAAAC7C3ze+pOOuPDUpdmlIo/5Sw65WR4KfotQBAAAAAAAAAKCMdh3fpXd2LJIkjcl1KuCqZyxOBH9GqQMAAAAAAAAAQBmYpqlp3/5Nbpnqe7JA3S97RAqPsToW/BilDgAAAAAAAAAAZbB8/3Kty9qgQI+pR80oqev9VkeCn3NYHQAAAAAAAAAAAF9TWFKo6d9OliTdlZOr+gPflByB1oaC32OmDgAAAAAAAAAAF+jN1H8ow3lUMSUlujvmcqlpH6sjoQqg1AEAAAAAAAAA4AIcyj+k17e8KkkafeKkQpKmWpwIVQWlDgAAAAAAAAAAF+D5dVNVZJaoc6FTV3d6UIpqaHUkVBGUOgAAAAAAAAAAlNK3Gd9q2cFVspmmxrpCZPQYaXUkVCEOqwMAAAAAAAAAAOALXB6Xpq15WpI0ODdfLa76uxQQbHEqVCXM1AEAAAAAAAAAoBTe2/GuducfUJTbrQerd5Ba9rc6EqoYSh0AAAAAAAAAAH5HtjNbL22YJUkakZOvyAHPS4ZhcSpUNZQ6AAAAAAAAAAD8jtnrX1Se26lWRcW6OeHPUs2mVkdCFUSpAwAAAAAAAADAb9h2bJs++PEjSdK4QpvsVzxqbSBUWQ6rAwAAAAAAAAAA4K08pkdTVj8lU9I1+SfVse90Kaia1bFQRTFTBwAAAAAAAACA8/hsz2fafHyHQjwePRzWQmp9k9WRUIVR6gAAAAAAAAAAcA4nXSf1wrqpkqS/5OSpTv8XJMOwOBWqMkodAAAAAAAAAADO4eVN83TUlasGLpf+2GKwVCfe6kio4ih1AAAAAAAAAAD4lb05e/V22tuSpDEnPQq88gmLEwGUOgAAAAAAAAAAnOW5tc+oRB5dXlCoK3pOkEKirI4EUOoAAAAAAAAAAPBLXx38Sl8fTpHDNPV4QH0Z7W+3OhIgSXJYHQAAAAAAAAAAAG9R7C7WtDWTJEl/yMlT3KC3JBvzI+Ad+E4EAAAAAAAAAOB/3kp9U/sLs1SrxK374q6V6nW0OhJwGqUOAAAAAAAAAACSDp88rFc2z5ckPZJfrLC+T1ucCDgTpQ4AAAAAAAAAAJJeTJmqQtOlds4iXXPZ41JYTasjAWeg1AEAAAAAAAAAVHkbszbqs/3LZZimxqmGbJ3vtjoScBaH1QEAAAAAAAAAALCS2+PWlG/+Kkm6Kf+kWl/3mmSzW5wKOBszdQAAAAAAAAAAVdr7PyzW9rx9Cnd7NCKmt9TwMqsjAedEqQMAAAAAAAAAqLJyinI0e/0MSdKDeYWqefUUixMB50epAwAAAAAAAACosuZ8N0M5bqeaFRdr8KUjpfAYqyMB50WpAwAAAAAAAACoknZm79TiHz+UJI0rqSbHZQ9YnAj4bQ6rAwAAAAAAAAAAUNlM09Tkb56UR9JV+SfVJWm2ZA+wOhbwm5ipAwAAAAAAAACocj7f85k2HN+hYI9Hj9bsLDW90upIwO+i1AEAAAAAAAAAVCkFrgK9sG6yJOmevELFJk23OBFQOpQ6AAAAAAAAAIAq5eWNc5XlylN9l0t3tvmLFNXQ6khAqVDqAAAAAAAAAACqjH25+/TW9gWSpMeLAhV0+ShrAwEXwGF1AAAAAAAAAAAAKsu0byaqRKZ6FBSqd9/ZUkCw1ZGAUmOmDgAAAAAAAACgSvjywBf6+sj3cpimxoa3ltGyv9WRgAtCqQMAAAAAAAAA8HtF7iJNW/2UJOkPeSfVuP8LkmFYGwq4QJQ6AAAAAAAAAAC/99bW13Wg6Jhql5TovpZ3SDWbWh0JuGCUOgAAAAAAAAAAv5Z5MlOvbnlFkvRwoU1hvcdZnAgoG4fVAQAAAAAAAAAAqEgz1jytQtOtDk6nru01VQoMszoSUCbM1AEAAAAAAAAA+K3vMr9T8qGvZZimxgXFyUi4yepIQJlR6gAAAAAAAAAA/FKJp0RTvn5CknRL3kld0n+mZBjWhgIuAsuvAQAAAAAAAEAZuT2mUtKzlZXnVHR4sLrE1ZDdRmngLd7bvki7CjIU6XZrRNObpDrxVkcCLgqlDgAAAAAAAACUQXJqhiYtSVNGjvP0sdjIYE0cGK+khFgLk0GSsp3ZmrthpiRpRIFbUX0mWBsIKAcsvwYAAAAAAAAAFyg5NUPDFmw4o9CRpMwcp4Yt2KDk1AyLkuFns9dNVZ6nWC2LijWo+5NScKTVkYCLRqkDAAAAAAAAABfA7TE1aUmazHM89/OxSUvS5PacawQqw7aj2/TB3qWSpHH2OrK3v8PiRED5oNQBAAAAAAAAgAuQkp591gydXzIlZeQ4lZKeXXmhcJrH9GjyV+NkShqQf1Kd+s+SbNwKh3/gOxkAAAAAAAAALkBW3vkLnbKMQ/n6dPfH2pKXrhCPR4/Uv0qq28HqSEC5odQBAAAAAAAAgAsQHR5cruNQfvKL8/XCuqmSpPvyi1Un8VmLEwHli1IHAAAAAAAAAC5Al7gaio0MlnGe5w1JsZHB6hJXozJjQdL89S/qmLtAjVwu/aHLaCmsptWRgHJFqQMAAAAAAAAAF8BuMzRxYLwknVXs/Px44sB42W3nq31QEfac2KN/7VosSRrjiVRg53stTgSUP0odAAAAAAAAALhASQmxmje0o2Iiz1xiLSYyWPOGdlRSQqxFyaom0zQ19evxKpGpXgWF6pk0S7LZrY4FlDuH1QEAAAAAAAAAwBclJcSqX3yMUtKzlZXnVHT4qSXXmKFT+VbuW6612dsUYJp6vHZ3qeFlVkcCKgSlDgAAAAAAAACUkd1mqFtT9m2xkrPEqelrJkmS7sx3quHNz1mcCKg4LL8GAAAAAAAAAPBZ/9g0Tz+5clSnpET3tH9QCo+xOhJQYSh1AAAAAAAAAAA+6VD+Ib2+7U1J0qOuEIV2G25tIKCCsfwaAAAAAAAAAMAnPf/NX1UkjzoXOnV14izJHmB1JKBCMVMHAAAAAAAAAOBzvj20VssOp8hmmhob1V5Gsz5WRwIqHKUOAAAAAAAAAMCnuDwuTfl6vCRpcL5TLZJesDgRUDkodQAAAAAAAAAAPmVR6pva4zyq6m63Hoy/U4pqYHUkoFJQ6gAAAAAAAAAAfMbRwqOat+nvkqSHihyK7PmoxYmAyuOwOgAAAAAAAAAAAKU1a80zyjdLFF9UpBuvnCkFBFsdCag0zNQBAAAAAAAAAPiELVmb9dHBlZKk8aEtZG81wOJEQOWi1AEAAAAAAAAAeD2P6dGUr8ZKkq7LL1S7/rMsTgRUPkodAAAAAAAAAIDX+2jne0o9eVBhHo8ebn6rVLOp1ZGASkepAwAAAAAAAADwarnFuZr13fOSpGGFUq3eT1icCLCGw+oAAAAAAAAAAAD8lr9/O1XZniLFFbt0++VPS4FhVkcCLMFMHQAAAAAAAACA19p1fJfeSV8iSRobUE8BbW6xOBFgHUodAAAAAAAAAIBXMk1TU798XG5JfU8WqvuAuZJhWB0LsAylDgAAAAAAAADAK/13z+dKydmtII9HjzW6Roq+xOpIgKUodQAAAAAAAAAAXqfAVaDnv31GkvTnQrfq9X3a4kSA9Sh1AAAAAAAAAABe5/XvZymz5KTqukr058vGScGRVkcCLEepAwAAAAAAAADwKgfyDujNnYskSY8atRTc/g8WJwK8A6UOAAAAAAAAAMCrPPflWBXLVNdCpxKTZks2bmUDEqUOAAAAAAAAAMCLfHPgS31xbIscpqlxMb1k1OtgdSTAa1DqAAAAAAAAAAC8gsvt0rRvnpQkDSlwqelVz1mcCPAulDoAAAAAAAAAAK+wYPPL2lt8QjVL3BrWcaQUWsPqSIBXodQBAAAAAAAAAFguqyBL87e+Jkka5amm8C73WZwI8D4OqwMAAAAAAAAAAPDi10+qQG61dRbpuqSXJZvd6kiA12GmDgAAAAAAAADAUhszv9enmWtlmKbG1ewsW6PuVkcCvBKlDgAAAAAAAADAMm6PW5O/fFySdGNBsRKufsHiRID3otQBAAAAAAAAAFjm/bS3tcOZpXC3Rw8l3CuF17E6EuC1KHUAAAAAAAAAAJbIKcrRnA2zJUkPuoJUs8coawMBXs5hdQAAAAAAAAAAQNU0Z/UknTBdalZcrMGJMyV7gNWRAK/GTB0AAAAAAAAAQKXbeWyHFu9fJkkaXy1ejqZ9LU4EeD9KHQAAAAAAAABApTJNU5NXjZbHkK4ucKpz/9lWRwJ8AqUOAAAAAAAAAKBSff7DB9pwcr+CPR6Nbnm7FNXA6kiAT2BPHQAAAAAAAAB+ye0xlZKeraw8p6LDg9UlrobsNsPqWFVegatAL6RMlSTdU+xQ7BXjLU4E+A5KHQAAAAAAAAB+Jzk1Q5OWpCkjx3n6WGxksCYOjFdSQqyFyfDKt1OV5XGqvsulO3vNkBxBVkcCfAbLrwEAAAAAAADwK8mpGRq2YMMZhY4kZeY4NWzBBiWnZliUDPty9uqfez6UJD0e0lRBra6xOBHgWyh1AAAAAAAAAPgNt8fUpCVpMs/x3M/HJi1Jk9tzrhGoaNNWjVaJpB6FReqdNMfqOIDPodQBAAAAAAAA4DdS0rPPmqHzS6akjBynUtKzKy8UJElfpv9HX+f8IIdpamyTm2XUbGJ1JMDnUOoAAAAAAAAA8BtZeecvdMoyDuWjyF2kaasnSpL+UGSo8ZUTLE4E+CaH1QEAAAAAAAAAoLxEhweX6ziUj7e+e1EH3CdVu6RE913+rBQQYnUkwCcxUwcAAAAAAACA3+gSV0OxkcEyzvO8ISk2Mlhd4mpUZqwqLTM/Q6/uXChJejigvsLib7Q4EeC7KHUAAAAAAAAA+A27zdDEgfGSdFax8/PjiQPjZbedr/ZBeXvhi8dUKFMdnMW6dsA8yeBrX5W5PabVEXwapQ4AAAAAAAAAv5KUEKt5QzsqJvLMJdZiIoM1b2hHJSXEWpSs6vnu4GotPbZZhmlqXIP+Mmo1szoSLFLi9uiF/+7U3f/8Th6KnTJjTx0AAAAAAAAAficpIVb94mOUkp6trDynosNPLbnGDJ3KU+Ip0ZSvxkqSbikydUnisxYnglUycgo1ctEmpezNliR9+cMRXdkq2uJUvolSBwAAAAAAAIBfstsMdWta0+oYVdZ7G+dpl+uEIt1ujbjsCSkwzOpIsMCK7Yf16OLNOl7gUrUgh569MYFC5yJQ6gAAAAAAAAAAylW2M1tzU1+TJI2wRyuq7e0WJ0JlKy7xaOrSHXpjdbokqU29SM0Z0kGNa1HuXQxKHQAAAAAAAABAuZq9aozy5FHLYpcGXf93yWDZu6pk37GTGrFoo7YczJEk/blHnMb0b6kgh93iZL6PUgcAAAAAAAAAUG62ZW7QB4e/lQxpXOyVskfHWx0JlWjJ5kMa98FW5ReVKCo0QM8PaqfE+DpWx/IblDoAAAAAAAAAgHLhMT2a8sWjMg1pgNOtTv2eszoSKklhsVtPf7pNi1IOSJI6N66uWbd1UN2oEIuT+RdKHQAAAAAAAABAufh061vaXHREIR6PHuk0WgoKtzoSKsEPh/M0fOEG/XA4X4YhDb+ymUb2bS6H3WZ1NL9DqQMAAAAAAAAAuGj5xfl6YeMsSdJ9qq46nf5scSJUNNM09d76A5r4yTY5XR7VDg/SzMHt1aNZLauj+S1KHQAAAAAAAADARZv/1XgdU4kauUr0hwFzJMOwOhIqUJ7TpSc+TNUnmw9Jkno2r6UXbm2v2uFBFifzb5Q6AAAAAAAAAICLsufYTv3r4CrJkMbUukyBdTtYHQkVaMvBExqxaKP2HSuQ3Wbo0ata6r4rmshmo8iraJQ6AAAAAAAAAIAyM01TU1eMVIkh9S5yq+fVL1odCRXENE29sXqvpi7dLpfbVL2oEM0e0kGdGlW3OlqVQakDAAAAAAAAACizlTv/rbWFPynANPVY2wekkCirI6ECZJ8s1mOLN2vFjixJUlLrGE27ua0iQwMsTla1UOoAAAAAAAAAAMrEWeLUcylTJUl3eqqpYZcHLE6EirBuzzGNfGeTMnOdCnTY9Ndr4zW0a0MZ7JtU6Sh1AAAAAAAAAABl8sbXE3XILFZMSYnuuWqmZLNZHQnlyO0xNXflbs1a8YM8ptSkdpjmDumo+LoRVkersih1AAAAAAAAAAAX7GDOXr2+73PJkB6N6qjQBpdZHQnl6HCuUyPf2ahv92RLkgZ1qq+nr2+t0EBqBSvx1QcAAAAAAAAAXLDpyx5SsSF1LSrRVYNmWx0H5WjVjiyNXrxZ2SeLFRZo199uTNCNHepbHQui1AEAAAAAAAAAXKBvdi3RypPpcpimxrW+R0ZYTasjoRwUl3g0/T879OrX6ZKk1nUjNGdIBzWpXc3iZPgZpQ4AAAAAAAAAoNRcbpemffu0JGmIO0RNu42yNhDKxf5jBRqxaIM2H8yRJN3ZvbHGDWilIIfd4mT4JUodAAAAAAAAAECpvb3mWe31OFWzxK1hfV+QbNz093VLNh/S+A+2Kq+oRJEhAZo+qK2uah1jdSycA6UOAAAAAAAAAKBUDucf0vwf35cM6ZGIeIU37ml1JFyEwmK3nv50mxalHJAkXdqoumYP6aC6USEWJ8P5UOoAAAAAAAAAAEplxrIRKjSkdsUluvbmv1sdBxfhh8N5Gr5wg344nC/DkIZf2Uwj+zaXw26zOhp+A6UOAAAAAAAAAOB3rd+7Qktzf5BhmhrfYqhs1aKtjoQyME1T7353QE8t2Sany6Pa4UGaObi9ejSrZXU0lAKlDgAAAAAAAADgN5V4SjT5myckSbe4gxTfc6zFiVAWeU6Xxn2wVZ9uyZAkXdGitmbc0k61w4MsTobSotQBAAAAAAAAAPymd9c9r13uk4p0uzWi9zTJZrc6Ei7QloMnNHzhRu3PLpDDZujRq1vqLz2byGYzrI6GC+DVi+O99NJLaty4sYKDg9W1a1elpKT85vjFixerVatWCg4OVps2bfT555+f8bxpmpowYYJiY2MVEhKixMRE7dq164wx2dnZuuOOOxQREaGoqCjdfffdys/PP/383r17ZRjGWf98++235ffGAQAAAAAAAMBLHDt5RC/tXChJeiisuaKaJlqcCBfCNE299vUe3TxvjfZnF6h+9RC9d3833d+rKYWOD/LaUufdd9/VI488ookTJ2rDhg1q166drr76amVlZZ1z/Jo1azRkyBDdfffd2rhxo2644QbdcMMNSk1NPT3mueee0+zZszV//nytW7dOYWFhuvrqq+V0Ok+PueOOO7Rt2zYtW7ZMn376qb766iv95S9/Oet6y5cvV0ZGxul/OnXqVP5fBAAAAAAAAACw2OwVDynPMHVJcYlu7j/P6ji4ANkni3X3P9frb59tl8ttqn9CjD57qKc6NqxudTSUkWGapml1iHPp2rWrOnfurLlz50qSPB6PGjRooBEjRmjs2LPXaxw8eLBOnjypTz/99PSxyy67TO3bt9f8+fNlmqbq1q2r0aNH69FHH5Uk5eTkqE6dOnrzzTd12223afv27YqPj9d3332nSy+9VJKUnJysAQMG6ODBg6pbt6727t2ruLg4bdy4Ue3bty/Te8vNzVVkZKRycnIUERFRpnMAAAAAAAAAQEXbenC1bl9xvyTp7QY3qn2fpy1OhNL6ds8xjXxnow7nFinQYdOEa+N1R9eGMgxm53ij0vYGXjlTp7i4WN9//70SE/9/Gp/NZlNiYqLWrl17ztesXbv2jPGSdPXVV58en56erszMzDPGREZGqmvXrqfHrF27VlFRUacLHUlKTEyUzWbTunXrzjj3ddddp+joaF1++eX65JNPfvP9FBUVKTc394x/AAAAAAAAAMCbeUyPJn/xuCTpOpdD7XtNsDgRSsPtMTVz+Q+6/dVvdTi3SE1rh+njB3to6GWNKHT8gFeWOkePHpXb7VadOnXOOF6nTh1lZmae8zWZmZm/Of7n//29MdHR0Wc873A4VKNGjdNjqlWrphkzZmjx4sX67LPPdPnll+uGG274zWJnypQpioyMPP1PgwYNfu9LAAAAAAAAAACW+mj9bKW6cxXm8ejhK/4m2R1WR8LvyMxx6vZXv9XM5bvkMaVbOtXXkhGX65JYVozyF/xbeIFq1aqlRx555PTjzp0769ChQ5o+fbquu+66c75m3LhxZ7wmNzeXYgcAAAAAAACA18opPKGZ296QDGlYcCPVanGN1ZHwO1buOKzR723W8QKXwgLtevbGNrqhQz2rY6GceWWpU6tWLdntdh0+fPiM44cPH1ZMTMw5XxMTE/Ob43/+38OHDys2NvaMMT/vjRMTE6OsrKwzzlFSUqLs7OzzXlc6tf/PsmXLzvt8UFCQgoKCzvs8AAAAAAAAAHiTl1aM1HHDVBOXW7dfP9/qOPgNxSUePZe8Q699ky5JSqgXoTlDOiquVpjFyVARvHL5tcDAQHXq1EkrVqw4fczj8WjFihXq1q3bOV/TrVu3M8ZL0rJly06Pj4uLU0xMzBljcnNztW7dutNjunXrphMnTuj7778/PWblypXyeDzq2rXrefNu2rTpjKIIAAAAAAAAAHzVzoz1evfoqXuk4xpdq4CohhYnwvnsO3ZSg+avOV3o3Nm9sd4f1p1Cx4955UwdSXrkkUf0pz/9SZdeeqm6dOmimTNn6uTJk7rrrrskSX/84x9Vr149TZkyRZI0cuRI9erVSzNmzNA111yjd955R+vXr9crr7wiSTIMQ6NGjdLf/vY3NW/eXHFxcfrrX/+qunXr6oYbbpAkXXLJJUpKStK9996r+fPny+Vyafjw4brttttUt25dSdI///lPBQYGqkOHDpKkDz74QG+88YZee+21Sv4KAQAAAAAAAED5Mk1Tk1c9Io9hqJ/Lpsuu/JvVkXAeSzYf0rgPtiq/qERRoQGaPqid+sXX+f0Xwqd5bakzePBgHTlyRBMmTFBmZqbat2+v5ORk1alz6pty//79stn+f6JR9+7dtXDhQj355JMaP368mjdvro8++kgJCQmnxzz++OM6efKk/vKXv+jEiRO6/PLLlZycrODg4NNj/vWvf2n48OHq27evbDabbr75Zs2ePfuMbM8884z27dsnh8OhVq1a6d1339WgQYMq+CsCAAAAAAAAABXr842vaIPruII9Hj3WbaLkCLQ6En6lsNitSUu26Z3vDkiSOjeurlm3dVDdqBCLk6EyGKZpmlaHqGpyc3MVGRmpnJwcRUREWB0HAAAAAAAAAHSyOF/XLeyhLMOjEY4Y/eWO8+8jDmvszMzT8IUbtCsrX4YhDb+ymUb2bS6H3St3WsEFKG1v4LUzdQAAAAAAAAAAleflFaOVZXhUv8StP1073+o4+AXTNPXOdwf01CfbVFTiUe3wIM0a3F7dm9WyOhoqGaUOAAAAAAAAAFRx6Vlb9fbh1ZJhaGy9fgqq2dTqSPifXKdL4z/Yqk+3ZEiSrmhRWy/c2k61qgVZnAxWoNQBAAAAAAAAgCrMNE1NXTFSJYahK1yGeiU+Z3Uk/M/mAyc0YtFG7c8ukMNm6LGrW+renk1ksxlWR4NFKHUAAAAAAAAAoApbmfq21hQfUYBpakzncZKDGSBW83hMvf5NuqYl71CJx1T96iGaPaSDOjasbnU0WIxSBwAAAAAAAACqKKerUNM3vChJutMerYbtbrc4EY7lF+nRxZu1aucRSdKANjGaclNbRYYEWJwM3oBSBwAAAAAAAACqqH98MUY/qUR1Sty6Z+BLVsep8tb+eEyj3t2ow7lFCnLYNGFgvG7v0lCGwXJrOIVSBwAAAAAAAEClcntMpaRnKyvPqejwYHWJqyE7e4RUuoPZu/T6Tyslw9BjMb0UGn2J1ZGqLLfH1KwVuzRn5S6ZptS0dpheuqOjWsVEWB0NXoZSBwAAAAAAAEClSU7N0KQlacrIcZ4+FhsZrIkD45WUEGthsqpn+rLhKjIMdXFJV/WbYXWcKisjp1Aj39mklPRsSdKtl9bXU9e1Vmggt+9xNpvVAQAAAAAAAABUDcmpGRq2YMMZhY4kZeY4NWzBBiWnZliUrOpZvX2xVjoPyW6aGtfxYRmBoVZHqpJWbD+sAbO+Vkp6tsIC7Zp1W3s9N6gdhQ7Oi+8MAAAAAAAAABXO7TE1aUmazHM8Z0oyJE1akqZ+8TEsxVbBXCXFmpoyRZJ0u626mnW4y+JEVU9xiUdTl+7QG6vTJUkJ9SI0Z0hHxdUKszgZvB2lDgAAAAAAAIAKl5KefdYMnV8yJWXkOJWSnq1uTWtWXrAq6O2vntReuVTT7dawAS9JBiVaZdp79KRGLNqorT/lSJLu6tFYY/u3UpDDbnEy+AJKHQAAAAAAAAAVLivv/IVOWcahbA7n7NPL+5dKhvRwza4Kj2lrdaQq5eNNP+mJD1OVX1SiqNAATR/UTv3i61gdCz6EUgcAAAAAAABAhYsODy7XcSibF/77oAoMqZ3L1MCk2VbHqTIKiks06ZM0vbv+gCSpc+PqmnVbB9WNCrE4GXwNpQ4AAAAAAACACtclroZiI4OVmeM85746hqSYyGB1iatR2dGqjPW7lujzgn0yTFPj2w6TLSjc6khVws7MPD24cIN2Z+XLMKQRVzbTQ32by2G3WR0NPojvGgAAAAAAAAAVzm4zNHFgvKRTBc4v/fx44sB42W3s71IRSjwlmrL2aUnSICNC8Z0fsDiR/zNNUwvX7dd1c7/R7qx81Q4P0r/u7qpHrmpJoYMy4zsHAAAAAAAAQKVISojVvKEdFRN55hJrMZHBmje0o5ISYi1K5v/e+/pp/WA6Fen26KHE2ZJBeVaRcp0uDV+4UeM/3KqiEo96taitpSN7qnuzWlZHg49j+TUAAAAAAAAAlSYpIVb94mOUkp6trDynosNPLbnGDJ2KcyzvkObu+VCySSOqt1dUvUutjuTXNh04oRGLNuhAdqEcNkOPJ7XUPZc3kY3vcZQDSh0AAAAAAAAAlcpuM9StaU2rY1QZs//7oPJsUiuXR4OSXrI6jt/yeEy99s0ePZe8UyUeU/Wrh2jOkA7q0LC61dHgRyh1AAAAAAAAAMBPbU1frg/zdkmGofHxf5Y9JMrqSH7pWH6RRi/erC92HpEkXdMmVpNvaqPIkACLk8HfUOoAAAAAAAAAgB/ymB5N/voJmYahgWaoOnR7xOpIfmnNj0c16p1NysorUpDDpgkD43V7l4Yy2LcIFYBSBwAAAAAAAAD80EdrpijVLFCYx6OH+zwvUTKUqxK3R7NX7taclbtkmlKz6Gqae3sHtYqJsDoa/BilDgAAAAAAAAD4mZyTRzXrh3ckmzQsIl61G/W0OpJfycgp1MhFm5SyN1uSNPjSBpp4XbxCA7nljorFdxgAAAAAAAAA+Jm/L3tQ2TapSYlHtyfNszqOX1medliP/nuzThS4VC3IoWdvTND17etZHQtVBKUOAAAAAAAAAPiRnQe+0TsntkmGobHNb1dAWC2rI/mFohK3pi3dqTdWp0uS2tSL1JwhHdS4VpjFyVCVUOoAAAAAAAAAgJ8wTVNTvnhcHsNQP0+Qul0+zupIfmHv0ZMavmiDUn/KlSTdfXmcHk9qqSCH3eJkqGoodQAAAAAAAADATyxNeVHfe/IU7PHosSumSjab1ZF83sebftL4D7bqZLFbUaEBmnFLO/W9pI7VsVBFUeoAAAAAAAAAgB8ocOZoRtqbkk26J6y5YpsmWh3JpxUUl+ipT7bpvfUHJUldGtfQrCHtFRsZYnEyVGWUOgAAAAAAAADgB17+7whl2UzVL/Hozv7zrI7j03Zk5mr4wo3anZUvw5BG9Gmuh/o0k8POzCdYi1IHAAAAAAAAAHxc+qH1eit7g2QYGtvkJgWFx1odySeZpqmFKfv19JI0FZV4FB0epJm3tVf3prWsjgZIotQBAAAAAAAAAJ9mmqamrXxYJYahnu4A9er1lNWRfFJOoUvjP9iqz7ZmSJJ6t6ytGbe0U81qQRYnA/4fpQ4AAAAAAAAA+LBVG17WavcJBZimxlz+jGSzWx3J52zcf1wjFm3UweOFctgMjUlqpbsvj5PNZlgdDTgDpQ4AAAAAAAAA+ChnUb6e2/J3ySbdGdxIjVpcY3Ukn+LxmHr16z2a/p+dKvGYalAjRHOGdFT7BlFWRwPOiVIHAAAAAAAAAHzUP5aP1E82U3XcHt3Tf77VcXzK0fwijX5vs7784Ygk6Zo2sZpycxtFBAdYnAw4P0odAAAAAAAAAPBBPx3eqtePrJMMQ482vEahkQ2sjuQz1uw+qlHvblJWXpGCHDZNHNhaQ7o0kGGw3Bq8G6UOAAAAAAAAAPig6ctHqMgw1MXt0NVXTrY6jk8ocXs0a8UuzV21W6YpNY+uprm3d1TLmHCrowGlQqkDAAAAAAAAAD5mzaY3tKLkmOymqXHdJsiwc6v39/x0olAjF23U+n3HJUmDL22gp65rrZBAu8XJgNLj33QAAAAAAAAA8CEul1NTNs6SbNKQ4PpqdsmNVkfyesmpmRrz/hblFLpULcihyTe10XXt6lodC7hglDoAAAAAAAAA4EMWLB+lvTaParg9eiBpvtVxvJrT5dbkz7frrbX7JEnt6kdqzpCOalgz1OJkQNlQ6gAAAAAAAACAjzh8JE3zM7+RbIYern+VwqMaWx3Ja+3OytfwhRu0IzNPknTfFU00+qqWCnTYLE4GlB2lDgAAAAAAAAD4iBeWDVeBzVBbj13X9X3O6jheyTRNLf7+oCZ+vE2FLrdqhgVqxq3t1LtltNXRgItGqQMAAAAAAAAAPmD9lrf1ueuIDNPU+C7jZbMHWB3J6+Q5XXryo1R9vOmQJKlHs5p68db2io4ItjgZUD4odQAAAAAAAADAy5WUFGnK989LNunmoFi1bn2r1ZG8zpaDJzRi0UbtO1Ygu83QI/1a6P5eTWW3GVZHA8oNpQ4AAAAAAAAAeLn3lo/WDzaPIjwePXTVPKvjeBWPx9Qbq9M1LXmHXG5T9aJCNHtIe3VqVMPqaEC5o9QBAAAAAAAAAC+Wnb1bczO+kGyGHqrbR9VrNrM6ktc4ll+k0Ys364udRyRJSa1jNO3mtooMZWk6+CdKHQAAAAAAAADwYrP/M0x5NkOtPDYN6jvD6jheY83uoxr17iZl5RUp0GHThGvjdUfXhjIMlluD/6LUAQAAAAAAAAAvlbrtPX1QlCEZhsZ3ekx2R6DVkSxX4vZo1opdmrtqt0xTahZdTXNv76BWMRFWRwMqHKUOAAAAAAAAAHghj9ulySmTZdoMDQyIVoe2Q62OZLmfThRq5KKNWr/vuCTpts4NNGFgvEIDudWNqoHvdAAAAAAAAADwQh+veFxbbW6FeUw93O8lq+NYLjk1U2Pe36KcQpeqBTk0+aY2uq5dXatjAZWKUgcAAAAAAAAAvEzu8b2aefC/kt2mYXUuV+3arayOZBmny63Jn2/XW2v3SZLa1Y/UnCEd1bBmqMXJgMpHqQMAAAAAAAAAXubvyfcr225TE49Nt/d70eo4ltmdla/hCzdoR2aeJOm+K5po9FUtFeiwWZwMsAalDgAAAAAAAAB4kZ3bP9SiooOSYWhsh5EKCAixOlKlM01Ti78/qIkfb1Ohy62aYYGacWs79W4ZbXU0wFKUOgAAAAAAAADgJUx3iaZ8+7Q8NkP9HDXVrf2frY5U6fKcLj35Uao+3nRIktSjWU29eGt7RUcEW5wMsB6lDgAAAAAAAAB4iaWrxul7W4mCPaYeTZxjdZxKt+XgCY1YtFH7jhXIbjP0SL8Wur9XU9lthtXRAK9AqQMAAAAAAAAAXuDkiQOasf9zyW7T3dGXqW6dNlZHqjQej6k3VqdrWvIOudym6kWFaPaQ9urUqIbV0QCvQqkDAAAAAAAAAF7g5eT7lGW3qYHH0F39Zlkdp9Icyy/S6MWb9cXOI5Kk/gkxmnpTW0WGBlicDPA+lDoAAAAAAAAAYLE9O5fobed+yTA0tt2DCgoMszpSpViz+6hGvbtJWXlFCnTYNOHaeN3RtaEMg+XWgHOh1AEAAAAAAAAAC5nuEk1ZM1ElNkO9HNV1Rcf7rI5U4UrcHs1asUtzV+2WaUrNoqtp7u0d1ComwupogFej1AEAAAAAAAAACy3/8q/61uZSoGlqTN/ZVsepcD+dKNTIRRu1ft9xSdJtnRtowsB4hQZyuxr4PfxbAgAAAAAAAAAWKcg5qOf2fiLZbbqrVmc1iGlvdaQKlZyaqTHvb1FOoUvVghyafFMbXdeurtWxAJ9BqQMAAAAAAAAAFnkt+X5l2m2q6zF0dz//naXjdLk1+fPtemvtPklSu/qRmjOkoxrWDLU4GeBbKHUAAAAAAAAAwAL7dn2mNwv3Soahx9vcr5CgcKsjVYjdWfkavnCDdmTmSZLuu6KJRl/VUoEOm8XJAN9DqQMAAAAAAAAAlcx0l2jq13+Vy26ohz1KfToNszpSuTNNU4u/P6iJH29TocutmmGBmnFrO/VuGW11NMBnUeoAAAAAAAAAQCX74sun9I3dJYdpamyfmTIMw+pI5SrP6dKTH6Xq402HJEk9mtXUi7e2V3REsMXJAN9GqQMAAAAAAAAAlciZl6Fp6R9KDpv+VLOjGtftZHWkcrXl4AmNWLRR+44VyG4z9Ei/FhrWq6lsNv8qrgArUOoAAAAAAAAAQCX6x9L79JPDpjoeQ3+56iWr45Qbj8fUG6vTNS15h1xuU/WiQjR7SHt1alTD6miA36DUAQCgDNweUynp2crKcyo6PFhd4mrIzieOAAAAAAC/4+Du/+j1kz9KNpsebX23QoPCrY5ULo7lF2n04s36YucRSVL/hBhNvamtIkMDLE4G+BdKHQAALlByaoYmLUlTRo7z9LHYyGBNHBivpIRYC5MBAAAAALyax6PnvhqvIrtNXe0RurrzQ1YnKhdrdh/VqHc3KSuvSIEOmyZcG687ujb0u32CAG9gszoAAAC+JDk1Q8MWbDij0JGkzBynhi3YoOTUDIuSAQAAAAC83ddfTdIqe7EcpqlxV77g86VHidujGf/dqTteX6esvCI1i66mT4b30NDLGvn8ewO8FTN1AAAoJbfH1KQlaTLP8ZwpyZA0aUma+sXHsBQbAAAAAOAMxXmZmvrjvyWHTXfUaK+m9bpaHemi/HSiUCMXbdT6fcclSbd1bqAJA+MVGsgtZ6Ai8W8YAACllJKefdYMnV8yJWXkOJWSnq1uTWtWXjAAAAAAgNf759L7td9hU22Pofv7zbU6zkVJTs3UmPe3KKfQpfAghybf1EYD29W1OhZQJVDqAABQSll55y90yjIOAAAAAFA1ZPy4TK+c3CXZbHok/k5VC4myOlKZOF1uTf58u95au0+S1K5BlObc1kENa4ZanAyoOih1AAAopejw4HIdBwAAAACoAjweTf9qrJw2mzrawnVNl4etTlQmu7PyNHzhRu3IzJMk3XdFE42+qqUCHWzbDlQmSh0AAEqpS1wNxUYGKzPHec59dQxJMZHB6hJXo7KjAQAAAAC81Nqv/6ZltmLZTVPjr3xehuFbe7CapqnF3x/UxI+3qdDlVs2wQL0wuL16tahtdTSgSqJGBQCglOw2QxMHxks6VeD80s+PJw6Ml93mW7+gAwAAAAAqhiv/sKbsfleSdFv1NmpZv7vFiS5MntOlke9s0uP/3qJCl1s9mtXU0pE9KXQAC1HqAABwAZISYjVvaEfFRJ65xFpMZLDmDe2opIRYi5IBAAAAALzNgqXDlO6wqYZHeuCql6yOc0G2HDyha+d8o082H5LdZuixq1vq7T93VXQES44DVmL5NQAALlBSQqz6xccoJT1bWXlORYefWnKNGToAAAAAgJ8d3rNC8/N3SjabHr7kj4oI8Y2luj0eU2+sTte05B1yuU3ViwrR7CHt1amRb+QH/B2lDgAAZWC3GerWtKbVMQAAAAAA3sjj0YwvxqjAblNbWzVd13W01YlK5Vh+kUYv3qwvdh6RJPVPiNHUm9oqMjTA4mQAfkapAwAAAAAAAADl6LtvpmipvUiGaeqJXtNkM7x/F4w1u49q1LublJVXpCCHTX+9Nl53dG0ow2BVCsCbUOoAAAAAAAAAQDlx5Wdp8g8LpQCbbo1qrfiGV1gd6TeVuD2atWKX5q7aLdOUmkVX09zbO6hVTITV0QCcA6UOAAAAAAAAAJSTd5If0O4Am6JMacRVL1kd5zf9dKJQIxdt1Pp9xyVJQ7o00IRrWysk0G5xMgDnQ6kDAAAAAAAAAOXgaPoX+nvedslm08gWtysytJbVkc4rOTVTY97fopxCl8KDHJp8UxsNbFfX6lgAfgelDgAAAAAAAABcLI9HL37xmPJtNrW2henGyx63OtE5OV1uPfvZdr397T5JUrsGUZpzWwc1rBlqcTIApUGpAwAAAAAAAAAXaePqafrE5pQkPdFziuw271vCbHdWnoYv3KgdmXmSpPuuaKLRV7VUoMNmcTIApUWpAwAAAAAAAAAXwX3yqCbvfFsKsOumiJZq0/hKqyOdwTRNLf7+oCZ+vE2FLrdqhgXqhcHt1atFbaujAbhAlDoAAAAAAAAAcBEWL31AOwLsCjelkVf93eo4Z8hzuvTEh6n6ZPMhSVKPZjX14q3tFR0RbHEyAGVBqQMAAAAAAAAAZZS972vNzt0m2W0a0fxW1QiLtjrSaVsOntCIRRu171iB7DZDj/RroWG9mspmM6yOBqCMKHUAAAAAAAAAoCw8Hs1eOVp5dpta2UJ1a7fxVieSJHk8pt5Yna5pyTvkcpuqFxWi2UM6qFOj6lZHA3CRKHUAAAAAAAAAoAy2rn1eHxgFkgyNv/xvstvsVkfSsfwijV68WV/sPCJJ6p8Qo6k3t1VkSIDFyQCUB0odAAAAAAAAALhA7pNH9ez2N2UG2HVdeHN1iOtndSSt2X1Uo97dpKy8IgU5bJowMF63d2kow2C5NcBfUOoAAAAAAAAAwAX6MHm4tgXYVc2UHu4319IsJW6PZq3Ypbmrdss0pWbR1TT39g5qFRNhaS4A5Y9SBwAAAAAAAAAuQM7+NZqVs0Wy2/VA05tVK7yuZVkOHi/QqHc2af2+45KkIV0aaMK1rRUSaP1ScADKH6UOAAAAAAAAAJSWx6M5Kx7WCbtdzYwQDenxpGVRlm7N0Jj3tyjXWaLwIIcm39RGA9tZVzABqHiUOgAAAAAAAABQSmlrX9R7xklJhsb3mCSHrfJvsTpdbj39aZoWrtsvSWrfIEpzhnRQgxqhlZ4FQOWi1AEAAAAAAACAUvAUZGty2usyA+3qX62JOjftX+kZdmbmacSiDfrhcL4MQ7q/V1M90q+FAuy2Ss8CoPJR6gAAAAAAAABAKXySPFybA+0KNaXR/V6q1GubpqmFKfv19JI0FZV4VDs8SC/c2k49m9eu1BwArEWpAwAAAAAAAAC/I3f/Wr14YpNkt+v+JterTkT9Srt2ToFLYz/YoqWpmZKkXi1qa8at7VSrWlClZQDgHSh1AAAAAAAAAOC3mKb+vuJhZdvtijOCNbTHxEq79Pq92Rr5zib9dKJQAXZDY5Ja6c894mSzGZWWAYD3oNQBAAAAAAAAgN+w89vZWmTkSzI0rtsEBdgDKvyabo+pv6/arZkrdsntMdWoZqjmDOmgtvWjKvzaALwXpQ4AAAAAAAAAnIdZcFyTU1+WJ9CufmGN1a35wAq/ZmaOU6Pe3ahv92RLkm5oX1fP3JCg8OCKL5MAeDdKHQAAAAAAAAA4j8/+M0IbAu0KMaXH+s2t8Out2H5Yjy7erOMFLoUG2vXM9Qm6uVPl7d8DwLtR6gAAAAAAAACQdGrJr5T0bGXlORUdHqwucTVkr8J7t+QfXKcZ2Rskh133Nr5WsZGNKuxaRSVuTfl8h95cs1eS1LpuhOYM6aAmtatV2DUB+B5KHQAAAAAAAABKTs3QpCVpyshxnj4WGxmsiQPjlZQQa2Eyi5im5i8bpaMOuxoaQfpTz0kVdqkfj+RrxMKNSsvIlST9uUecxvRvqSCHvcKuCcA32awOAAAAAAAAAMBayakZGrZgwxmFjnRqb5dhCzYoOTXDomTW+XHdHP3LyJMkjb3sCQXaA8v9GqZpavH6Axo45xulZeSqRlig3rjzUk0YGE+hA+CcmKkDAAAAAAAAVGFuj6lJS9JknuM5U5IhadKSNPWLj6kyS7GZBcc1Zet8lQTadWVoQ/VscWO5XyPP6dITH6bqk82HJEndm9bUi4Pbq05EcLlfC4D/oNQBAAAAAAAAqrCU9OyzZuj8kikpI8eplPRsdWtas/KCWei//3lI6wLtCjKlx/vNLffzbz5wQiMWbdT+7ALZbYYe6ddC9/dqWmVKMwBlR6kDAAAAAAAAVGFZeecvdMoyztcV7P9W07PXSw6H7m40QPWj4srt3B6PqVe/3qPp/9mpEo+pelEhmj2kvTo1qlFu1wDg3yh1AAAAAAAAgCosOrx0y32VdpxP83j06vKROuxwqJ4RpLt6Tiq3Ux/JK9LoxZv11Q9HJEkD2sRoyk1tFRkSUG7XAOD/KHUAAAAAAACAKqxLXA3FRgYrM8d5zn11DEkxkcHqEuf/s0n2rpujN20nJRka03Wcgh3lU2R99cMRPfLeJh3NL1ZwgE0TB7bWbZ0byDBYbg3AhbFZHQAAAAAAAACAdew2QxMHxks6VeD80s+PJw6M9/v9XsyTxzR163yVGIYuD22g3i1uuuhzFpd4NOXz7frjGyk6ml+slnXCtWT45RrSpSGFDoAyodQBAAAAAAAAqrikhFjNG9pRMZFnzkyJiQzWvKEdlZQQa1GyyrPyPw9pdZBDAaY0NnHORZcu+48V6Jb5a/TyV3skSUMva6iPh/dQ8zrh5REXQBXF8msAAAAAAAAAlJQQq37xMUpJz1ZWnlPR4aeWXPP3GTqSVLh/jZ7L3iAFOHRnoyQ1qt70os738aaf9MSHqcovKlFEsEPPDWpbJYoxABWPUgcAAAAAAACApFNLsXVrWtPqGJXL49Yby0bpUIBDMUag7rl8UplPdbKoRE99sk2Lvz8oSercuLpm3tZB9aJCyistgCqOUgcAAAAAAABAlXXg21l6w1YgydDjXcYqNCC0TOfZdihHIxZt1J4jJ2UzpOF9muuhPs3ksLMDBoDyQ6kDAAAAAAAAoGo6eUzPbX1FxcEBuiy0vhJbDrrgU5imqTfX7NWUz3eo2O1RTESwZt7WXpc1qWIzngBUCkodAAAAAAAAAFXSV8kj9EVwgBymNK7vbBnGhe0flH2yWI//e7OWb8+SJCVeEq3nBrVTjbDAiogLAJQ6AAAAAAAAAKqeor1rNPX4BikgQH9oeLWa1Gh+Qa9f++MxjXp3ow7nFinQbtP4Aa30p+6NL7gYAoALQakDAAAAAAAAoGrxuPXm8pE6EBCgaCNQ9/WcVOqXlrg9mrVil+au2i3TlJrUDtPcIR0VXzeiAgMDwCmUOgAAAAAAAACqlJ/WzNSr9gJJNo3u/JjCAsJK9bqDxws06p1NWr/vuCTp1kvr66nrWis0kNusACoH/7UBAAAAAAAAUHXkH9G01FdVFBKgLqH11b/V4FK9bOnWDI15f4tynSWqFuTQ5Jva6Lp2dSs4LACciVIHAAAAAAAAQJXx1dIRWhUSIIcpje8763f3wHG63Hr60zQtXLdfktSuQZTm3NZBDWuGVkZcADgDpQ4AAAAAAACAKqEo/WtNydkkBQRoaKMkNa3R4jfH/3A4T8MXbtAPh/MlSff3aqrRV7VQgN1WCWkB4GyUOgAAAAAAAICXc3tMpaRnKyvPqejwYHWJqyG77bdnmOBX3CV6Y/nDOhgYoGgjUPdf/tR5h5qmqYUp+/X0kjQVlXhUq1qQXhzcTj2b1668vABwDpQ6AAAAAAAAgBdLTs3QpCVpyshxnj4WGxmsiQPjlZQQa2Ey33Jw9Qy97iiUZNNjXcYqLCDsnONyClwa+8EWLU3NlCRd0aK2ZtzSTrXDgyoxLQCcG/MEAQAAAAAAAC+VnJqhYQs2nFHoSFJmjlPDFmxQcmqGRcl8TF6mpqX9Q0U2m7qGNdDVLQedc9j6vdkaMPtrLU3NlMNmaPyAVnrzzs4UOgC8BjN1AAAAAAAAAC/k9piatCRN5jmeMyUZkiYtSVO/+BiWYvsdX34+XF+EBMhhSuP7zpJhnPn1cntM/X3Vbs1csUtuj6lGNUM1+7YOatcgyprAAHAelDoAAAAAAACAF0pJzz5rhs4vmZIycpxKSc9Wt6Y1Ky+Yj3H+uFJT8rZJAQ79ofEANane/IznM3OcevjdTVq755gk6Yb2dfXMDQkKDw6wIi4A/CZKHQAAAAAAAMALZeWdv9Apy7gqye3SP1Y8qp+CHIq2Ben+HhPPeHrF9sN6dPFmHS9wKTTQrqevT9DNHeudNZMHALwFpQ4AAAAAAADghaLDg8t1XFV04Jvn9FpAsSRDj3UZq9CAUElSUYlbUz7foTfX7JUkta4bodlDOqhp7WrWhQWAUqDUAQAAAAAAALxQl7gaio0MVmaO85z76hiSYiKD1SWuRmVH8w25hzRt+1sqDglU17BGurrFzZKkH4/ka8TCjUrLyJUk3dWjscb2b6Ugh93KtABQKjarAwAAAAAAAAA4m91maOLAeEmnCpxf+vnxxIHxsttYKuxcvvjsQX0ZEiiHKY3vO0uStHj9AQ2c843SMnJVIyxQr//pUk0c2JpCB4DPoNQBAAAAAAAAvFRSQqzmDe2omMgzl1iLiQzWvKEdlZQQa1Ey7+bc9V9NPblDkvTHuGtVO6ShRr27SY/9e4sKit3q1qSmlo7sqb6X1LE4KQBcGJZfAwAAAAAAALxYUkKs+sXHKCU9W1l5TkWHn1pyjRk651FSrDdWPa6fghyqYwtW94YjdM3sb7Q/u0B2m6GHE5trWO9mfP0A+CRKHQAAAAAAAMDL2W2GujWtaXUMn3Dg6yl6PaBEkqHOUffqjlc3qcRjql5UiGYPaa9OjdiDCIDvotQBAAAAAAAA4BfMEwc0ZedCFYcEqoGrjhatrivJVP+EGE29qa0iQwOsjggAF4VSBwAAAAAAAIBf+OLzB/V1SKDsprR9/x0Kctg1cWBrDenSQIbBcmsAfB+lDgAAAAAAAACfl5v2maYW7JICHArJ7qDo6k00Z0hHtYwJtzoaAJQbSh0AAAAAAAAAPi39cLbeWfa4DkU5FO4K0BVxI/TUtR0VHGC3OhoAlCtKHQAAAAAAAAA+yTRN/fv7g9r++Xh91PDU8mo3N3tYo3t3tjgZAFQMSh0AAAAAAAAAPifX6dKTH6bq+y2blNBwnVxGkDqHxemRXkOtjgYAFYZSBwAAAAAAAIBP2bD/uEa+s1EHsgs1Muo1vREaJIcpTeg3S4ZhWB0PACoMpQ4AAAAAAAAAn+D2mJr/5Y96YdkPcntMDYrcqORa2ZIcuqvZjWocGWd1RHgLj1vat0bKPyxVqyM16i7Z2GMJvo9SBwAAWMbtMZWSnq2sPKeiw4PVJa6G7DY+VQcAAADgbJk5Tj387iat3XNMknRzm+pqmPuO/hPgUIw9RPd0HWtxQniNtE+k5DFS7qH/PxZRV0qaJsVfZ10uoBxQ6gAAAEskp2Zo0pI0ZeQ4Tx+LjQzWxIHxSkqIrZBrUiIBAAAAvmlZ2mE99u/NOlHgUmigXZOua63OR2fpJtep58d0m6DQgFBrQ8I7pH0ivfdHSeaZx3MzTh2/9S2KHfg0Sh0AAFDpklMzNGzBhl//iq3MHKeGLdigeUM7lnuxY0WJBAAAAODiOF1uTf58u95au0+SlFAvQrNv66A486CGrf9YrpBg9Yhsob5NrrE4KbyCx31qhs5Zf23qf8cMKXms1OoalmKDz7JZHQAAAFQtbo+pSUvSzvsrtiRNWpImt+dcI8rm5xLpl4WO9P8lUnJqRrldCwAAAED5+OFwnq6fu/p0oXNvzzi9P6y7mtQK08rPH9DqkGAFyNC4Pi/IMJiBD53aQ+eXS66dxZRyfzo1DvBRlDoAAKBSpaRnn1Wu/JIpKSPHqZT07HK5nhUlEgAAAICyM01TC77dp4FzvtHOw3mqVS1Qb97VWU9cE68gh12Fm/6lae5TH8y6s/ktahTRyOLE8Br5h8t3HOCFWH4NAABUqqy88xc6ZRn3ey6kROrWtGa5XBMAAABA2ZwoKNaY97foP9tO3XS/okVtzbilnWqHB50aUHhCr679mzLCAhRrD9O9XR61MC28TrU65TsO8EKUOgAAoFJFhweX67jfU9klEgAAAICy+XbPMT387iZl5DgVYDc0JqmV/twjTjbb/y+tlv7fsfpH6KlbmmN6PKUQR4hVceGNGnWXIupKuRk69746xqnnG3Wv7GRAuWH5NQAAUKm6xNVQbGSwzrfitSEpNjJYXeJqlMv1KrtEAgAAAHBhStwevfDfnbr91W+VkeNUXK0wffhAD93Ts8kZhY558Hs9m7FCJYahntVbq0/jqy1MDa9ks0tJ0/734Nd/df7vcdLUU+MAH0WpAwAAKpXdZmjiwHhJ5/0VWxMHxstuK5+NTiu7RAIAAABQegeyCzT4lW81e+VueUzplk719emIy5VQL/LMgR63kpOHa11IsIJkaNyV02UY5fM3A/xM/HXSrW9JEbFnHo+oe+p4/HXW5ALKCcuvAQCASpeUEKt5Qztq0pK0M/a7iYkM1sSB8UpKiP2NV1+Yn0ukYQs2yNCZE/ArokQCAAAAUDqfbjmkcR9sVZ6zROFBDj17Uxtd167uOcfmrZun54wcSXbdG/8nNQhvULlh4Vvir5NaXSPtWyPlHz61h06j7szQgV8wTNM81+KCqEC5ubmKjIxUTk6OIiIirI4DAIBl3B5TKenZyspzKjr81GyZiipXklMzziqRYiugRPpZZb43AAAAwJcUFJfoqU+26b31ByVJHRpGafZtHdSgRui5X5Cfpan/vFz/qhakRoFR+uDWFQq0B1ZiYgCoeKXtDZipAwAALGO3GerWtGalXCspIVb94mMqpWip7AIJAAAA8BWpP+XooXc2as+RkzIM6cHezTQysbkC7OffJWL70oe1KOxUiTO+5xQKHQBVGqUOAACoMiqjREpOzdCwBRv066nQmTlODVuwQfOGdqTYAQAAQJVjmqbeWL1X05buULHbo5iIYL04uP3v/n7u2fOl/pb9nTzBQUqq00Xd619eSYkBwDtR6gAAAJQTt8fUpCVpZxU60qm9fAxJk5akqV98DEuxAQAAoMo4ml+kRxdv1hc7j0iS+sXX0XM3t1X1sN+ZcVNSrA+WPawtwUEKM+x67IoplZAWALwbpQ4AAEA5SUnPPmPJtV8zJWXkOJWSnl1py84BAAAAVvrqhyN65L3NOppfpCCHTU9eG6+hXRvKMH7/Q07Z3zyvFwOckuwa3u4BRYdGV3xgAPBylDoAAADlJCvv/IVOWcYBAAAAvqq4xKPn/7tTr3y1R5LUok41zRnSUS1jwkt3guP79OK2N5RbLUQtg6N1W5s/V2BaAPAdlDoAAADlJDo8uFzHAQAAAL7oxyP5GvnORqX+lCtJ+sNljfTENZcoOMBe6nNs+HyEPqoWIkl68soZcti4jQkAEqUOAABAuekSV0OxkcHKzHGec18dQ1JMZLC6xNWo7GgAAABAhTNNU+98d0BPL0lTocutqNAATbu5ra5uHXNB53GlLdEzBTulwEDdXL+v2ke3r5jAAOCDbFYHAAAA8Bd2m6GJA+MlnSpwfunnxxMHxstu+/31wwEAAABfcvxkse5f8L3GfbBVhS63ejSrqf+MuuKCCx0Vn9TCL8drd2CgomyBGtXjqQrJCwC+ilIHAACgHCUlxGre0I6KiTxzibWYyGDNG9pRSQmxFiUDAAAAKsaa3UfVf9bX+s+2wwqwGxo/oJXe/nNX1Ym48GWHM1c9rb8HeyRJj1z6mKKCo8o5LQD4NpZfAwAAKGdJCbHqFx+jlPRsZeU5FR1+ask1ZugAAADAnxSXeDTjvzv1ytd7ZJpSk9phmn1bByXUiyzbCY/s1PQf31dBWIjaV2uk61vdWr6BAcAPUOoAAABUALvNULemNa2OAQAAAFSIH4/ka9Q7m7T1pxxJ0pAuDfXXay9RaGAZbzeaplZ/9oD+GxYiu6Qnr5whm8EiQwDwa5Q6AAAAAAAAAErFNE29+90BTVqSpkKXW1GhAZp6U1slJVzg3jm/UrRpoZ4t+UkKCNDtTa5XyxotyykxAPgXSh0AAAAAAAAAv+tEQbHGvr9VydsyJUk9mtXUjFvan7Wf5AUrPK431jyjA9UCFG0P1YOXjSuHtADgnyh1AAAAAAAAAPymNbuP6pH3Nisz16kAu6FHr2qpe3s2ka0c9o3c/58xei301G3Kx7tNUFhA2EWfEwD8FaUOAAAAAAAAgHMqLvFoxrKdeuWrPTJNqUmtMM0e0kEJ9SLL5fzm/nWanLFSxaEh6l79El3VZEC5nBcA/BWlDgAAAAAAAICz7DmSr5HvbNLWn3IkSUO6NNBfr41XaGA53VJ0u7R86XCtDg1RgAyN7z1dhnHxM38AwJ9R6gAAAPg4t8dUSnq2svKcig4PVpe4GrKXwzIY3sCf3xsAAIC3Mk1T7353QJOWpKnQ5VZUaICm3tRWSQkx5Xqdk2tmaqojX5JDd1/yRzWKaFSu5wcAf0SpAwAA4MOSUzM0aUmaMnKcp4/FRgZr4sB4JSXEWpjs4vnzewMAAPBWJwqKNe6DrVqamilJ6t60pl64tb1iIoPL+UL7NW/zfGWFh6p+YJTu7ji8fM8PAH7KZnUAAAAAlE1yaoaGLdhwRukhSZk5Tg1bsEHJqRkWJbt4/vzeAAAAvNWaH48qaebXWpqaqQC7oXH9W2nB3V3Lv9AxTe38bIQWVAuRJI3v+ayCHeV8DQDwU5Q6AAAAPsjtMTVpSZrMczz387FJS9Lk9pxrhHfz5/cGAADgjYpLPJq6dIfueG2dMnOdalIrTB8M66H7ejWVrQKWvnWnfayn87fLbRjqF3OZeta/otyvAQD+qlxKnZKSEh09elRut7s8TgcAAIDfkZKefdYsll8yJWXkOJWSnl15ocqJP783AAAAb7PnSL5unrdG87/8UaYpDenSQJ8+dLna1I+smAs6c/XvL8ZrS3CQwgyHxvZ8tmKuAwB+qkx76uzcuVMfffSRVqxYoQ0bNuj48eOnn6tevbo6deqkPn366Prrr1erVq3KLSwAAABOyco7f+lRlnHexJ/fGwAAgLcwTVPvrT+gpz5JU6HLrajQAE29qU2F7114dPkEzQo5NfvnoY6jFB0aXaHXAwB/c0GlzqeffqqZM2dq1apVkk79x//XsrOztWzZMi1fvlzjx49Xnz59NGrUKF1zzTXlkxgAAACKDi/dmuOlHedN/Pm9AQAAeIPsk8Ua/8FWJW/LlCR1b1pTL9zavvz3zvm1Qxv13L4lyqsWqtbVGmhw/NCKvR4A+KFSlTrbtm3TQw89pC+++EKmaapdu3bq16+funfvrtatW6tmzZqKiIhQTk6Ojh07ptTUVK1Zs0bLly/XihUrtHLlSl155ZWaNWuWWrduXdHvCQAAwO91iauh2MhgZeY4z7n3jCEpJjJYXeJqVHa0i+bP7w0AAMBqX/5wRI8t3qysvCIF2A2Nvqql/tKzSYXsnXMGj1urP3tAS6uFyiZpQu/nZbfZK/aaAOCHDPNc021+JSAgQAEBAbrnnnt09913q127dqW+wKZNm/T666/r9ddfV0lJiYqLiy8qsD/Izc1VZGSkcnJyFBERYXUcAADgo5JTMzRswQZJOqP8+PnP8XlDO1b48hkVxZ/fGwAAgBWcLremLt2hN9fslSQ1i66mmYPbK6FeBe2d8+vrr5mrG9Pm6mBAgIY2u0ljekyqlOsCgK8obW9gK83J7rzzTu3atUuzZ8++oEJHktq3b685c+Zo586d+tOf/nRBrwUAAMD5JSXEat7QjmctkxETGezzpYc/vzcAAIDKtu1QjgbO+eZ0oXNn98b6dMTllVboKPeQXtkwUwcDAlTHUU3DuzxeOdcFAD9Uqpk6KF/M1AEAAOXJ7TGVkp6trDynosNPLUtmr+jlMyqJP783AACAiub2mHrt6z16/r875XKbqh0epOmD2qp3y+hKzfHjols0qGi7SgxDM3u9oL6N+1Xq9QHAF5S2NyjVnjoAAADwXnaboW5Na1odo0L483sDAACoSD+dKNTo9zbp2z3ZkqSr4uto6s1tVSMssFJzeHYu1dO5m1QSHKzetTupT6PESr0+APgbSh0AAAAAAADAj3y86Sc9+VGq8pwlCg2066mBrXXLpfVlGJU847n4pD5a/rg2VAtWiGHX+CumVH4GAPAzF1XqHDp0SBs2bNDhw4d1/PhxVa9eXXXq1FGnTp0UG8s65wAAAAAAAEBlySl0acLHqfp40yFJUoeGUZo5uL0a1QyzJE/2yqf1Qohbkl0PtntAsdW4XwgAF+uCS539+/dr3rx5+uijj/TDDz+cd1yLFi1044036v7771fDhg0vKiQAAAAAAACA81v74zGNfm+TDuU4ZbcZeqhPcz14ZVM57DZrAh3ephk//ls51ULVMjRWd7T5szU5AMDPGKZpmqUZ+OOPP2rMmDH6+OOP5Xa7JUlRUVG65JJLVLNmTUVERCgnJ0fHjh3T9u3blZOTI0my2+264YYbNG3aNDVp0qTi3okPKe2GRwAA/IzN4gEAAACcS1GJWy8s+0GvfLVHpik1rhmqFwe3V4eG1a0L5fEo5R+9dbfjuAxJCwb8S21rt7UuDwD4gNL2BqWaqTN27FjNmjVLRUVFateune68807169dP8fHx5xxvmqa2bdumZcuW6Z///Kfef/99ffrppxo1apSmTJlStncEAEAVlZyaoUlL0pSR4zx9LDYyWBMHxispgeULAAAAACtZ+QGsXYfzNPKdTUrLyJUkDenSQE9eE6+wIGu30S5e/5qe8WRJCtCtcddS6ABAOSrVTB2bzaZrrrlGkyZNUseOHS/4It9//70mTJig5OTk07N8qjJm6gAASis5NUPDFmzQr39Y//wn4ryhHcu92GFWEAAAAFA6Vn0AyzRN/XPNXk1ZukNFJR7VCAvU1Jva6KrWMRV2zVLLy9S8N3vq7xHBqmUP1ce3LlNEIPe/AOD3lLY3KFWps3r1avXo0eOiQ5XXeXwdpQ4AoDTcHlOXT1t5xh+Iv2RIiokM1jdj+pRb6cKsIAAAAKB0rPgAliRl5Tr16L+36KsfjkiSeresrecGtVV0eHC5X6ss9r4zWDc5t8llGJrec5qSmgywOhIA+ITS9gal2imtvIoYCh0AAEovJT37vIWOJJmSMnKcSknPLpfr/fxH6a+vmZnj1LAFG5ScmlEu1wEAAAB8ndtjatKStLMKHUmnj01akia3p1RbWZdacmqmrp75lb764YiCHDY9c31r/ePOzl5T6Jg7PtffTmyQyzDUo2ZbXR3X3+pIAOB3SlXq/Fpubm6px65fv74slwAAoMrLyjt/oVOWcb/Fqj9KAQAAAF9U2R/Ayi8q0eP/3qz7F3yv4wUuJdSL0GcPXa4/dGssw/CSpZKL8vTp8se0LiRYQbLpiV5TvScbAPiRMpU6N954o0pKSn53XGpqqpKSkspyCQAAqrzSftquPD6VV9l/lAIAAAC+rDI/gJWSnq3+s77Se+sPyjCkYb2b6oNhPdQsOvyiz12ecpZP1POhpz4Edl/b+9QgvIHFiQDAP5Wp1Fm1apXuueee3xyza9cu9evXT8ePHy9TMAAAqroucTUUGxms8322zdCp/W66xNW46GtV5h+lAAAAgK+rjA9gFZW4NWXpdg1+Za0OZBeqXlSI3rn3Mo1JaqVAR5lu6VWcg9/rhfQPlW23q2lIjO5se6/ViQDAb5XpJ8DAgQP19ttv66mnnjrn8/v371diYqIOHz6sKVOmXEw+AACqLLvN0MSB8ZJ0VrHz8+OJA+Nlt138kgaVOSsIAAAA8HUV/QGstEO5un7uar385R6ZpnTrpfWVPKqnujapWebMFcbt0nefPaAPwqtJkib0mqYAe4DFoQDAf5Wp1HnnnXfUsWNHPfPMM3rrrbfOeO7w4cNKTEzUgQMHNH78eD3++OPlEhQAgKooKSFW84Z2VEzkmWVKTGSw5g3tqKSE2HK5TmXOCgIAAAB8XUV9AMvtMfX3L3br+pe+0Y7MPNUMC9Qrf+ik5wa1U3iwdxYlztUzNcmeI0m6pclAdazT0eJEAODfDNM0y7TjcVZWlrp06aLMzEx9/vnn6tOnj7Kzs9WrVy9t27ZNI0aM0KxZs8o7r1/Izc1VZGSkcnJyFBERYXUcAIAPcHtMpaRnKyvPqejwU+VKeczQ+aXk1AwNW7BB0qk9dH7281XKs0QCAAAA/EFyaoYmLUk7Y3/K2MhgTRwYf8G/O+87dlKj39us9ftObWXQL76OptzURrWqBZVr5nKVvUezFyTq1cgw1XZU08e3/Ffhgd611w8A+IrS9gZlLnUkKS0tTT169JBhGPr00081atQorV+/XnfddZdef/31sp7W71HqAAC8VXn+UQr/VRklIwAAgK+42N+NTNPUopQD+ttnaSoodqtakEMTB8ZrUKf6Mgwv/h3LNPXDWwM02DygEsPQi71eUGLjflanAgCfVSmljiStXLlS/fv3V0lJiUzT1KBBg/TOO+/IZvOyDdu8CKUOAMCbccMev4XiDwAAoPxk5Tk19v2tWrkjS5LUNa6Gnr+lnRrUCLU42e9zb1qoP657SluCg9SnTlfNSnrN6kgA4NMqrdSRpLfeekt33nmnBgwYoI8//lh2u/1iT+nXKHUAAIAv+nmJvl//8sgSfQAAABfu860ZeuLDrTpe4FKgw6bHr26pP/eIk80XPlB18qj+9UZ3TY0IUpgRoI9vXqo6YXWsTgUAPq20vYGjNCdr0qTJ745xOBzatGmTmjdvfsZxwzD0448/luYyAAAA8FJuj6lJS9LOKnSkU3swGZImLUlTv/gYZnYBAAD8hpxCl576ZJs+3PiTJCk+NkIvDm6vljG+sxdN5tJHNbtagCRp1KWjKXQAoBKVqtTZu3dvqU526NChs4559dqfAAAAKJWU9Owzllz7NVNSRo5TKenZ6ta0ZuUFAwAA8CGrdx/Vo4s3KyPHKZshPdC7mR7q21yBDt/ZxsDcvUJ/O/KNCkJD1D6ymW69ZIjVkQCgSilVqZOenl7ROQAAAODFsvLOX+iUZRwAAEBV4nS5NXXpDr25Zq8kqXHNUM24tb06NapubbALVVyg//73YX0ZFiKHDD3V+3nZDN8ppADAH5Sq1GnUqFFF5wAAAIAXiw4PLtdxAAAAVcXmAyf0yHub9OORk5KkO7o21PgBlygsqFS35bxKzqpnNCWoRJJd97S+S02jmlodCQCqHN/76QEAAIBK1yWuhmIjg5WZ4zznvjqGpJjIYHWJq1HZ0QAAALySy+3RS6t2a87K3XJ7TEWHB2naoLa6smW01dHKJnOrXtz1ro6FhykuOFr3dnjQ6kQAUCUxPxIAAAC/y24zNHFgvKRTBc4v/fx44sB42W3spwgAALA7K0+D5q3RzOW75PaYuqZtrP4z6grfLXQ8bn23ZJjeDw+TJD3Ve7oC7YEWhwKAqqlUpU6HDh2UnJx8URf6/PPP1aFDh4s6BwAAAKyTlBCreUM7KibyzCXWYiKDNW9oRyUlxFqUDAAAwDu4PaZe+epHDZj9jTYfzFFEsEOzbmuvuUM6qHqY75YgRWvm6GkdlSTdEneNOtbpaHEiAKi6SrX82tGjR3XNNdeoS5cuuvvuuzV48GCFh4f/7utyc3O1aNEivf766/r+++9Vv379iw4MAAAA6yQlxKpffIxS0rOVledUdPipJdeYoQMAAKq69KMn9djizVq/77gk6YoWtTXt5jaKjQyxONlFyt6jlzfM1t7IMNV2hGnUZeOtTgQAVZphmua5lkU/Q0FBgZ599lm98MILKi4uVlBQkDp37qxu3brpkksuUc2aNRUREaHc3FwdO3ZMaWlpWrt2rdavX6+ioiIFBgZq9OjRGj9+vEJDQyvjfXm13NxcRUZGKicnRxEREVbHAQAAAAAAQBl5PKbeWrtXU5N3yOnyKCzQrievjddtnRvIMHz8gy+mqV3/vFq36pBKDEMv9Jqhfo2vsjoVAPil0vYGpSp1fnbo0CG99NJLeu2113TkyJFTJzjHD6efT1m7dm3de++9euCBB1S3bt0LfQ9+i1IHAAAAAADA9x3ILtDj/96itXuOSZK6Namp5wa1VYMa/vGhZvf6f+iP30/RluAgXVmnq2Zd/arvF1UA4KUqpNT5mcvl0urVq7Vy5Upt3LhRhw8fVk5OjqKiohQdHa2OHTvqyiuvVI8ePRQQEHBRb8QfUeoAAAAAAAD4LtM0tSjlgJ79LE0ni90KCbBr3IBWGtq1kWz+sixtboYW/qOnpkSFKMwWoI9vWqo6YXWsTgUAfqu0vUGp9tT5tYCAAPXu3Vu9e/cuaz4AAAAAAADA52TkFGrM+1v11Q+nVrHp3Li6pg9qp8a1wixOVo5MU4c+HaFZEUGSpFGXPkqhAwBeokylDgAAAAAAAFCVmKap9zf8pElLtinPWaJAh02PX91Sd/WIk91fZuf8j7ntQz2ds0kFoSHqENVSt7a6zepI8Dcet7RvjZR/WKpWR2rUXbLZrU4F+IQylTp79+5V48aNyzkKAAAAAAAA4H2y8pwa/8FWLd+eJUlq1yBKM25pp2bR1SxOVgEKsvXJqnFaHRGiQNk0qfd02Qyb1angT9I+kZLHSLmH/v9YRF0paZoUf511uQAfUaZSp0mTJmratKn69u2rxMRE9e3bV9WrVy/vbAAAAAAAAIBlTNPUki0ZmvBxqk4UuBRgNzQqsYXuu6KJHHb/LDqOLn1Uz4WdmjExrP0DiouMszgR/EraJ9J7f5T0q23eczNOHb/1LYod4HcYpmmavz/sTE2aNNHevXtPncAwZBiG2rdvr8TERCUmJqpnz54KCgoq76x+o7QbHgEAAAAAAMAax/KL9NePU/X51kxJUuu6EZpxazu1ivHjezm7luvhZfdpeVioLglvpIU3fCSHjd0bUE48bmlmwpkzdM5gnJqxM2orS7GhSiptb1CmUkeS0tPTtXz5ci1btkyrVq3SsWPHTp3QMBQUFKTu3bufLnkuvfTSsr0LP0WpAwAAAAAA4L2SUzP1xIdbdexksRw2Qw9e2UzD+zRTgJ/OzpEkFeXpv6920+hwQw4ZemfgYrWs0dLqVPAn6V9L/7z298f96VMprmfF5wG8TIWXOr+2ceNGLVu2TCtWrNA333wjp9N56gKGoZKSkvK4hN+g1AEAAAAAAPA+JwqK9dQn2/TRplMzCVrWCdeMW9spoV6kxckq3olPR+r6rGXKttv1l9Z3acSlj1gdCf5m67+l9+/+/XE3vy61GVTxeQAvU9reoNzmT3bo0EGXXHKJ2rdvrxYtWuj1118/XewAAAAAAAAA3uw/2zL15EepOpJXJJsh3derqUYlNleQowosA7X/W03fu0TZ4WFqGhqj+zoMtzoR/FG1OuU7DqiiLqrUMU1T69ev1/Lly7V8+XKtWbNGxcXFMk1TUVFR6t+/vxITE8srKwAAAAAAAFCusk8Wa+In27Rk86nZOU1rh2n6Le3UsWF1i5NVEpdTX3/2gD4JD5MhaVLv5xVoD7Q6FfxRo+6n9szJzZB0rsWj/renTqPulZ0M8CllKnXmz5+v5cuXa9WqVTpx4oRM0zznPjqGYZR3XgAAAAAAAKBcfLYlQxM+TtWxk8WnZ+eM7NtcwQFVYHbO/+R/MVlPBxZKcmhoi1vVrnY7qyPBX9nsUtI06b0/SjJ0ZrHzv/vISVNPjQNwXmXaU8dms8kwDLVq1UrXXnutEhMT1bNnTwUHB1dERr/DnjoAAAAAAADWOZJXpAkfp2ppaqakU3vnTL+lrdrWj7I2WGXL2KK/vX+D3g0PU/2gGnr/5qUKDQi1OhX8XdonUvIYKffQ/x+LqHeq0Im/zrpcgMUqfE8d0zS1Z88efffdd4qKilKNGjXUqVOnsp4OAAAAAAAAqFCmaerjTYf01JJtOlHgksNm6IHeTfVgn2ZVY++cX3KX6Lsl9+nd8DBJ0lO9nqPQQeWIv05qdY20b42Uf/jUHjqNujNDByilMs3U+e67787YR6eoqEiGYah69erq06ePEhMT1a9fP8XFxVVEZp/HTB0AAAAAAIDKdTjXqSc+3Krl27MkSfGxEZp+S1u1rhtpcTJrFH75nAbtekP7AwJ0c+MBeqrXNKsjAUCVVtreoEylzi85nU599dVXp0uezZs3yzRNGYahuLg49evXT/PmzbuYS/gdSh0AAAAAAIDKYZqm/v39QT3zaZpynSUKsBsa0ae5hvVuqgC7zep41sjaoRnvDtCbEWGKDgjXR4P+o/DAcKtTAUCVVmmlzq8dOXJE06dP19y5c+V0OmUYhtxud3lewudR6gAAAAAAAFS8QycKNf7Drfpi5xFJUpt6kZp+S1u1iqnC92PcJUr9x5W6w3FcHsPQ3D5z1KtBb6tTAUCVV+F76vxSenq6li9frmXLlmnVqlXKzs7Wz11RUFBQeVwCAAAAAAAAKBXTNPXOdwc0+bPtyisqUaDdplH9musvPZvIUVVn5/xP8ZpZ+quZJY8RqAH1r6TQAQAfU6ZS5/jx41qxYsXpJdfS09Ml6fSya+3bt1diYqISExPVs2fPcg0MAAAAAAAAnM+B7AKN+2Crvtl9VJLUuGaohl/ZXDd2rCe7zbA4ncWO7NS8jS9pd2SYajhCNbbHJKsTAQAuUJmWX3M4HDJN8/RsnLi4uNMlTt++fVWjRo1yD+pPWH4NAADA+7g9plLSs5WV51R0eLC6xNXgxg8AAD7E4zH1r3X7NHXpDp0sPnsrgNjIYE0cGK+khFgL0nkBj1upb1ypOxzZ8hiGZvZ+UX0bJVqdCgDwPxW6/FpUVJT69u17usiJi4src1AAAADAasmpGZq0JE0ZOc7Tx6r8jR8AAHzIniP5GvvBVqWkZ593TGaOU8MWbNC8oR2r5M/3otUz9YSZJY8RoP71e1PoAICPKtNMHVwcZuoAAAB4j+TUDA1bsEG//qX45zk6VfXGDwAAvsDl9uiVr/Zo1opdKi7xKCTArgC7oVxnyTnHG5JiIoP1zZg+VWtG7pEf9OKiJL0RGaaajjB9dHOyooKjrE4FAPiF0vYGVXtnOAAAAFRpbo+pSUvSzip0JJ0+NmlJmtwePgcFAIC32XowR9fNXa3p/9mp4hKPejavpWk3tzlvoSOd+vmekeP8zRk9fsfj1uZP7tGbEaGSpAmXT6bQAQAfVqpSp7CwsFwuVl7nAQAAAMpDSnr2GUuu/VqVvPEDAICXKyx2a8rn23X9S99oe0auokID9MKt7fTWn7uc84Ma55KVd/6f//6maM1s/dWTJY9h6Nr6fdSnUR+rIwEALkKpSp2mTZtq/vz5crvP3mSuNEpKSvTSSy+padOmZXo9AAAAUBFKe0OnKt34AQDAm63ZfVRJs77Sy1/tkceUBrarq+WP9NJNHevLMAxFhweX6jylHefzju7SSxvnKD0wQLUcYRp7+dNWJwIAXKRSlTp169bVAw88oMaNG+vJJ5/Url27SnXynTt3aty4cWrcuLFGjBihevXqXVRYAAAAoDxx4wcAAN+QU+jSmH9v0e2vrdO+YwWKiQjW63+6VHOGdFCtakGnx3WJq6HYyGCdb7ccQ1JsZLC6xNWolNyW8ri16eN79Wb4qWXXJvacosigSItDAQAuVqlKne+++04vv/yyiouLNXnyZLVq1UqNGjXSbbfdpkmTJmnu3Ll66623NHfuXE2aNEmDBw9Ww4YNFR8fr2nTpsnlcumVV15RSkrKBYV76aWX1LhxYwUHB6tr166/+/rFixerVatWCg4OVps2bfT555+f8bxpmpowYYJiY2MVEhKixMTEswqq7Oxs3XHHHYqIiFBUVJTuvvtu5efnn/N6u3fvVnh4uKKioi7ofQEAAMA7cOMHAADvl5yaocQXvtS76w9IkoZe1lDLHrlCfS+pc9ZYu83QxIHxknTWz/efH08cGC+77Xw//f2Hc+1c/dWTKdMwdF2Dvurd8EqrIwEAyoFhmmapd311Op16++23NXfuXG3duvXUCYyzfwj+fMq2bdtq+PDhuuOOOxQSEnJBwd5991398Y9/1Pz589W1a1fNnDlTixcv1s6dOxUdHX3W+DVr1uiKK67QlClTdO2112rhwoWaNm2aNmzYoISEBEnStGnTNGXKFP3zn/9UXFyc/vrXv2rr1q1KS0tTcPCpT1/2799fGRkZevnll+VyuXTXXXepc+fOWrhw4RnXc7lc6t69u2rXrq01a9boxIkTpX5vubm5ioyMVE5OjiIiIi7o6wIAAIDylZyaoWELNkjSGevw//xb7ryhHZWUEFvpuQAAqOqycp2a8PE2JW/LlCQ1qRWmqTe3LdWHLZJTMzRpSdoZe+fFRgZr4sD4qvFz/ehuTX/nar0VHqpoRzV9MCiZWToA4OVK2xtcUKnzS3v37tXKlSu1ceNGHT58WDk5OYqKilJ0dLQ6duyoK6+8Uo0bNy5rfnXt2lWdO3fW3LlzJUkej0cNGjTQiBEjNHbs2LPGDx48WCdPntSnn356+thll12m9u3ba/78+TJNU3Xr1tXo0aP16KOPSpJycnJUp04dvfnmm7rtttu0fft2xcfH67vvvtOll14qSUpOTtaAAQN08OBB1a1b9/S5x4wZo0OHDqlv374aNWoUpQ4AAIAPq+wbP26PqZT0bGXlORUdfmomUFX4xDAAAKVhmqbeW39Az362XbnOEjlshu7v1VTD+zRTcIC91Oepsj9vPW5t/Edf/cl+VKZh6KU+c3VFg15WpwIA/I7S9gaOsl6gcePG+vOf/1zWl/+m4uJiff/99xo3btzpYzabTYmJiVq7du05X7N27Vo98sgjZxy7+uqr9dFHH0mS0tPTlZmZqcTExNPPR0ZGqmvXrlq7dq1uu+02rV27VlFRUacLHUlKTEyUzWbTunXrdOONN0qSVq5cqcWLF2vTpk364IMPyuttAwAAwCJJCbHqFx9TKTd+KJD+j737jquyfv84/jqDfdhbHKCAijP3zrTSStOyPRxt+1Y2LCtbtue3nX3zl2XasJ2aq6zcI/dmKIgiex/G4Yz798cNKAoKCBw4XM/Hg8fhvs89PqcEzrnf9/W5hBBCiJodyy7iqZ/3selINgA923rz+rU9iWlT95tidVoNgzv5N/QQm72STR/wrJKGonFiQrtLJdARQggHU+9QpzFlZWVhtVoJDq46N2pwcDCHDx+udp+0tLRqt09LS6t8vmLdubY5c2o3vV6Pn59f5TbZ2dlMnTqVRYsW1brKxmQyYTKZKpcLCgpqtZ8QQgghhGg6TXHhp2KqtzNL5dPyS5m+aGeDT/XW6qeeEUII0WKYrTY+W3eUD9bEY7LYcHXS8thlnZk2NBy9rlYtoQVAxiE+2PUhx7w8CNIbeGLYHHuPSAghRAOTv4p1dPfdd3PLLbcwYsSIWu/z2muv4e3tXfnVrl27RhyhEEIIIYRojqw2hTlLD54V6MCpXj5zlh7EaqvX7MhnqQiQTg904FSAtHJ/aoOcRwghhLhQO47lMu6DDby1KhaTxcbQSH9WPTyCu0d0lECnLqxmdvx6B197ugPwwsVv4OUs0/4LIYSjaZZ/GQMCAtDpdKSnp1dZn56eTkhISLX7hISEnHP7isfzbZORkVHleYvFQk5OTuU2f/31F2+//TZ6vR69Xs+dd95Jfn4+er2e+fPnVzu2p556ivz8/Mqv48eP1+Y/gxBCCCGEcCDbEnPOClhOpwCp+aVsS8y54HM1dYAkhBBC1Ed+iZnZv+zjuk83EZteiJ+HM/+9oReL7hxIB38Pew+vxSn65zVma/NQNBqu6TCG4W1rf0OyEEKIlqNZhjrOzs707duXNWvWVK6z2WysWbOGwYMHV7vP4MGDq2wP8Mcff1RuHxERQUhISJVtCgoK2Lp1a+U2gwcPJi8vjx07dlRu89dff2Gz2Rg4cCCg9u7ZvXt35deLL76Ip6cnu3fvruy5cyYXFxe8vLyqfAkhhBBCiNYlo7DmQKc+251LUwZIQgghRF0pisKyvSe59L9r+XprMooC1/dty5pHL+baPm3RaKT3W52l7OStQ1+S4qSnjbM3Twx5wd4jEkII0UiaZU8dgEcffZQpU6bQr18/BgwYwHvvvUdRURHTpk0DYPLkyYSFhfHaa68BMGPGDC6++GLeeecdrrrqKr777ju2b9/OZ599BoBGo+Hhhx/m5ZdfJioqioiICJ599lnatGnDxIkTAejatStjx47l7rvv5tNPP8VsNvPAAw9w00030aZNm8ptTrd9+3a0Wi3du3dvov8yQgghhBCiJQrydG3Q7c6lKQMkIYQQoi6O5xTz3G/7+Ts2E4COAR68ck2PRu9r59DMJaxbcjc/eXqgAV6+5F0MzgZ7j0oIIUQjabahzo033khmZibPPfccaWlp9O7dm5UrVxIcHAxAcnIyWu2pQqMhQ4bwzTff8Mwzz/D0008TFRXFr7/+WiVseeKJJygqKuKee+4hLy+PYcOGsXLlSlxdT31w/vrrr3nggQcYPXo0Wq2WSZMm8cEHHzTdCxdCCCGEEA5pQIQfod6upOWXVjstmgYI8XZlQITfBZ+rKQMkIYQQojYsVhvzNyby7h/xlJitOOu0TB/Zifsv6YSLXmfv4bVouX8+y3POJYCO26NvoH9If3sPSQghRCPSKIoiE2k3sYKCAry9vcnPz5ep2IQQQgghWpGV+1OZvmgnQJVgp2KSmbm39WFs99ALPo/VpjDsjb/OGyBtmDUKnVamuBFCCNG4dh/P46mf93EotQCAgRF+vHJNDyKDpJrkQimJG3hsxRT+8HCnk1swiyf9jovOxd7DEkIIUQ+1zQ2aZU8dIYQQQgghHNHY7qHMva0PId5VK2RCvF0bLNAB0Gk1PD8+BjgVGFWoWH5+fIwEOkIIIRpVYamZF5Yc4JpPNnIotQAfdyfevK4n390zSAKdhmAqZNmK6fzh4Y4eDa+O/kACHSGEaAUaZPq1srIysrOzcXFxwc/vwqeLEEIIIYQQwlGN7R7KZTEhbEvMIaOwlCBPdcq1hg5YKgKkOUsPkpp/qndOiLcrz4+PabAASQghhDiToiisOpDG80sOkF5gAuDai8KYfVVX/A0SOjSUtBUzec3VBmi5r/tdxPjH2HtIQgghmsAFhTqLFi3igw8+YNeuXdhsNqZMmcL8+fMB+OWXX/jhhx945ZVXiIiIaJDBCiGEEEII4Qh0Wk2TNIRuqgBJCCGEqJCSV8Lzvx3gz0PpAHTwd+eViT0YFhVg55E5FlvcKp5J+4tCN1d6eoZz50X323tIQgghmki9Q5277rqLL774AkVRMBgMGI3GKs9HR0fz3Xff0adPH2bOnHnBAxVCCCGEEELUXVMFSEIIIVq3MouN+RsTef/PeErMVvRaDfdd3IkHRkXi6qSz9/AcS3EO365+mK2errii5ZXRH6LXNshkPEIIIVqAevXU+frrr5k/fz7du3fn33//JT8//6xtunXrRtu2bVmxYsUFD1IIIYQQQgghhBBCNE9bjmZz1QfreX3FYUrMVvqH+7J8xnBmjuksgU4jOLrsAd71UC/pPdZvJuHe4fYdkBBCiCZVrxj/s88+w2AwsGzZMtq1a1fjdj169ODQoUP1HpwQQgghhBBCCCGEaJ4yC028tvwQP+9KAcDfw5mnruzKpD5haDQ1T/VptSkyNWg9mff9yNN52zG5uDDErxs3xtxm7yEJIYRoYvUKdfbs2cPAgQPPGegA+Pn5kZ6eXq+BCSGEEEIIIVoWuUgnhBCtg9Wm8M3WY7y5KpbCUgsaDdwyoD2Pj+mMj7vzOfdduT+VOUsPkppfWrku1NuV58fHMLZ7aGMPvWUrTOP/1j7NAU8XPDVOvDjq/XOGZ0IIIRxTvUIdk8mEt7f3ebfLzMxEp5MyWyGEEEIIIRydXKQTQojWYe+JPGb/sp99KepU/N3DvHh5Yg96t/M5774r96cyfdFOlDPWp+WXMn3RTube1kf+ZtREUdj7yx38z6CGZs8MeYFgj2A7D0oIIYQ91CvUCQsLO++0aoqicPDgQSIiIuo1MCGEEEIIIUTLIBfphBDC8eUXm3l7dSyLth5DUcDTVc/jYzpz68AOtarKtNoU5iw9eNbfCgAF0ABzlh7kspgQqfKsRtHmj3my7ChWJyeuCB3KlZFX23tIQggh7ERbn51Gjx7N4cOH+e2332rcZuHChZw4cYLLLrus3oMTQgghhBBCNG/nu0gH6kU6q626LYQQQjR3iqLw884TjP7vPyzcogY611wUxprHLmby4PBaBzDbEnOqVHOedR4gNb+UbYk5DTRyB5JxmDd2vcdxJydC9Z48M/JNe49ICCGEHdUr1Jk5cyYuLi7ccsstvPfee5w8ebLyuZycHD799FPuv/9+PDw8eOihhxpssEIIIYQQQojmxV4X6aw2hc1Hsvltdwqbj2RLaCSEEI0gLr2QGz/bwqPf7yHLWEZkkIFv7x7Euzf2JsjTtU7Hyiis+W9FfbZrNSxlrP51Cr8Y3NAAr456Hy9nL3uPSgghhB3Va/q1qKgoFixYwOTJk3nsscd47LHH0Gg0LFiwgAULFgDg5OTE119/Tfv27Rt0wEIIIYQQQojmwx4X6aR/jxBCNK7CUjMf/pXA/A2JWGwKrk5aZoyO5s5hETjr63V/cK1DoLqGRY4u7c/ZzNEXAjruir6ZfqH97T0kIYQQdla/v8TA9ddfz7///sv111+Pp6cniqKgKAqurq6MHz+ezZs3M2nSpIYcqxBCCCGEEKKZaeqLdBX9e86sDqro37Nyf2qDnEcIIVojRVH4ZdcJRr2zls/WHcViU7gsJpg/H72Y6SM71TvQARgQ4Ueotys1TdamQQ3oB0T41fscjsaWuI7ZSb9SoNPRzT2M6QMft/eQhBBCNAP1qtSp0L17d7777jsURSE7OxubzUZAQABabf3/yIvWa8/xPDr4u+Pj7mzvoQghhBBCiFqquEiXll9abV8dDRDSQBfppMm2EEI0ngMn83lhyQH+TcoFINzfnefGxzCqS3CDHF+n1fD8+BimL9qJBqr8Lq/4jf38+Bj5/V2hJI8FK+9nm7srbmh5Y8z/cNI62XtUQgghmoELCnUqaDQaAgICGuJQopUyWaxcO3cTVptCgMGF6GADUUEGIoM9iQ4yEBXsiZ+HhD1CCCGEEM1NU16kq0v/nsGd/C/4fEII0RrkFZfxzuo4vt56DJsCbk46HhgVyV3DI3DR6xr0XGO7hzL3tj5nTaEZIlNonuXg0vv5wE39flb/J+jg1cG+AxJCCNFs1CvUyc3NZd++fXTq1ImwsLBqt0lJSeHIkSP07NkTHx+fCxmjaAUyC02EeLmSkldCltFEltHEpiPZVbYJMDgTGWQgOthTDXyCPIkONuBvcLHTqIUQQgghBDTdRTppsi2EEA3HalNY/O9x3lp1mNxiMwDjeoby9JVdaePj1mjnHds9lMtiQtiWmENGYSlBnmo1p1TonFKy51uezN+JxdmJ0YF9uLbrLfYekhBCiGakXqHO+++/z0svvcTWrVtrDHVSU1O55JJLePHFF5k9e/YFDVI4vra+7mx8chRGk4UjGUbiM4zEpxcSn2EkLr2QE7klZBnLyDLmsOVoTpV9/TyciQoyEBWsBj6RQQaigjwJMDij0cibQiGEEEKIptAUF+mkybYQQjSMHcdyeWHJAfal5AMQHWzghau7MaRT08zCotNqpKKyJvkneGfj8yR6uBCkc+OFUe/LtQ0hhBBVaBRFqW5K6nMaMGAAubm5xMfHn3O7yMhIAgMD2bx5c70H6IgKCgrw9vYmPz8fLy8vew+nRSgus5CQYSQ+vWrgczy3mJr+Bfu6OxEV5ElU+VRu0cGeRAYbCDS4yBsiIYQQQogWyGpTGPbGX+ft37Nh1qgGC5OsNkXuJhdCOIzMQhNvrDzMjztOAODpoueRy6K5fXAHnHTSH9nubDb++epSHtRkAvDZ6LkMbjvMzoMSQgjRVGqbG9SrUicpKYkBAwacd7suXbqwffv2+pxCiCrcnfX0bOtDz7Y+VdaXlFk5kqlW88RXhj6FJOcUk1tsZltSDtuSqlb2eLs5ER18avq2qPLHQE8Je4QQQgghmrOmbrK9cn/qWVPKhUrfByFEC2S22liwKYn3/4yn0GQB4Pq+bXlibBcCPWVK8+Yia/0bPGdLA52OKR0nSKAjhBCiWvUKdSoSo/Px8vIiLy+vPqcQolbcnHV0D/Ome1jVf4+lZisJGUYSMk4FPgkZRo5lF5FfYubfpFz+Tcqtso+Xq56oYM+zAp9gLwl7hBBCCCGai6bq37NyfyrTF+08qyIoLb+U6Yt2Mve2PhLsCCFahI0JWbyw5ADxGUYAeoR5M2dCN/q097XzyMTpbCe28/Sh+eS6udLZNZCHhjxn7yEJIYRopuo1/Vq7du0ICgpix44d59yub9++pKamcvLkyXoP0BHJ9Gv2U2q2cjSziPiMQuLT1cAnIcNIUnYRthp+Ejxd9WrPnoqp3MqDnxAvVwl7hBBCCCHspDGnRauY5u300Oh0jTHNmxBCNLSkrCJeWX6IPw6mA+oU5U+M7cIN/drJ767mxlTI518M4z03G65o+O7qn+nkG2nvUQkhhGhijTr92qBBg/j5559Zt24dI0aMqHab9evXs2vXLiZOnFifUwjRKFyddMS08SKmTdUfilKzlcSsolP9etKNxGUUciy7mMJSCzuT89iZnFdlH08XPZHl/XpOD3zaeEvYI4QQQgjR2Bqzyfa2xJwaAx1Qp31LzS9lW2KONPoWQjQ7BaVmPvorgS82JmK2Kui0Gm4b2J5HLovGx93Z3sMT1di95F4+dLUCGp7u94QEOkIIIc6pXqHO9OnT+emnn7juuuuYN28eEyZMqPL8b7/9xj333INGo+G+++5rkIEK0ZhcnXR0DfWia2jVsMdksZKUVXxazx71MSmriEKThV3Jeew6I+zxcNYRGexJdJBBDXrKA5823m5o5W4oIYQQQjRTFpuFfFM+hWWFmKwmSq2lmCzlj1YTNsWGVqNFixY0oEWLTqvDTe+Gu5M7HnoPPJzULze9W4u+ySWjsOZApz7bCSFEU7DaFBb/e5x3VseSXVQGwIjoQJ69qitRwZ52Hp2oScHOhczK34XVSc8VQQOYGHOrvYckhBCimatXqDNq1CgeeOABPvroI6699loCAgLo3LkzAHFxcWRmZqIoCtOnT+fyyy9v0AEL0ZRc9Do6h3jSOaTqG+Ayi42k7KIqU7jFpReSmFVEUZmVPcfz2HM8r8o+7s46ooJO69dTHviE+UjYI4QQQojGY7FZyCzOJLUotfIrrSiN9KJ0ck255JnyyC3NpaCsoMHOqdfqCXALIMA1QH10Vx/DDGG082xHe8/2BLgFNNvgJ8jTtUG3E0KIxrb5SDYvLjvIoVT1d3nHQA+evSqGkZ0Dm+3vWgFK9lFe2PYyJ92caas38Nzo9+X/lxBCiPOqV0+dCh9++CEvvfQSWVlZVdYHBAQwe/ZsZsyYccEDdETSU8dxma02kiqncVOncEtIN3I0y4jZWv2PmpuTjsjTqnqiyx/b+krYI4QQQojaKzIXcSTvCIn5iZVfSQVJJBcmY7FZan0cDycPXHWuuOpdcdW54qJ3wVWnTi+rKAoKCjbFhoKC1Wal2FJMkbmIYnMxxZZibIqtVudx07vRzrMdHbw6EOUTRbRfNJ19OxNmCLP7Ba2Knjpp+aVU9w5OeuoIIZqL5OxiXll+kFUH1L45Xq56Hr40mtsHd8BJp7Xz6MQ5Wc18/+UIXtIb0Suw6MpFdAvqZe9RCSGEsKPa5gYXFOoAWK1WduzYwbFjxwBo3749/fr1Q6fTXchhHZqEOq2P2WrjWHZx5fRtFVO5Hc0sosxa/YUPVyetGvZU9OsJ8iQqyEA7P3e5eCCEEEK0cjmlORzOPsyhnEMczlEfkwuSUaqNIMBJ60SIRwihHqGVj8Eewfi5+uHr4ouPiw8+rj54OXuh19armB8ARVEosZRQUFZAZnEmWSVZZJZkkl2STUZJBimFKSQXJpNalFpj+GNwMhDtG02Mfwy9AnvRK7AXIR4hTR70rNyfyvRFOwGq/FetGMXc2/owtntok45JCCEqFJaa+ejvBL7YkESZ1YZOq+HWge15+NJo/Dykb05LELfiUW5JW4VJq2Vmt7uY0k9ujBZCiNauyUIdUXcS6ogKFquNYznFxKcbqwQ+RzKNlFmqv9DhotfSKdBQPoWbGvREBXvSXsIeIYQQwiHZFBtH8o6wK2MXezL3sCtjF8cLj1e7baBbIB19OhLuFU6Ed4T65RVBsEcwWk3zuWPbbDWTYlQDnsT8ROJy44jLjeNI3hHMNvNZ2we5B9ErsBe9A3vTL6QfXfy6NMnrWbk/lTlLD5Kaf6p3Tqi3K8+Pj2mUQMdqU9iWmENGYSlBnq4MiPCT93dCiCqsNoUfdxznrVVxZBlNAAyPCuDZcTFES9+cFqM4D+QrOAAA+RBJREFUfjU3//MQR52dGO4dzUcTfmhWf6eFEELYh4Q6zZiEOuJ8LFYbx3NLqvTriU9Xwx5TDWGPc3nYExWkBj4VvXva+7mjl7J7IYQQosWwKTbic+PZkrqFralb2Z2xm0Jz4VnbdfDqQFe/rnTx66I++nfBz9XPDiM+B0WBsiIozQdTAZQWnPreWqZ+WcoqvzdbzSRaCogty2N/WRZ7SjM4bMrGekYFkrfenQF+MQwK7sfAsOG0D+iGppFmCmiqoKWpAyQhRMuz5Wg2Ly07yIGTat+ciAAPnrmqK6O6BNl92kpRB0XZvLBwOD+56QjUOPPjDX80v7/fQggh7KJJQp2TJ0/y999/k5KSQmlpabXbaDQann322fqewiFJqCPqy2pTOJ5TTHx50JNw2mONYY9OS8dAj8qqnorAJ9xfwh4hhBCiuUg1prLx5Ea2pm5la+pWck25VZ5307vRM6AnvYN60zuoNz0De+LlbMf3kTYrFJyEvGQoTAVjOhSmVX00pqshjmK9oFOVaDQccHFmt4sLu1xd2OHqQpG26nuYUIuFEWUKF+PGAJcgXLzCwKsNnP7o0wE8AqAZXvismOrtzA9mMtWbEAIgIcPI6ysO8+chtW+Op6ueGaOjmDw4HGe9fKZrURSFFV9fyRPWE2gU+L/RHzOg3Qh7j0oIIUQz0eihzqOPPspHH32E1ap+SDvzMBWNVDUaTeU2QiWhjmhoVptCSnllT0W/nvgMIwkZRkrM1f/8Oek0dAwwnOrXE6wGPh38PaShphBCCNHIbIqN/Vn7+ef4P6w7sY7Y3Ngqz7vp3egb3JdBoYPoH9KfaN/oC+p1Uy9WC+QmQmYs5CaVfyWqj3nJanVNbWn14OIFrl7g6q1+r3cBnQvonMq/dwKNDlBAsalVPopNDZCsJjCXQFkxZnMRB6xFbKGErToLu531WE4LatxsNgaXlDKyuIQRxSX420678cXFG/w7gl8n8O8E/pEQ3A0CotXz24HVpjDsjb+qVOicTgOEeLuyYdYomYpNiFYmy2jivT/j+Hbbcaw2BZ1Ww80D2vHIpdH4G1zsPTxRD8c3vM318V9QpNVyb8dreGD4i/YekmgoNisc26Te1GIIhg5DQCv9xoUQdVPb3KBenwz/+9//8t5776HRaBgzZgxdu3aVcEIIO9JpNbT3d6e9vzuXxgRXrrfZFFLySojPKCQu3aj27slQK3uKy6zEphcSm14IpFbu46TTEBHgURn0VDyG+3vIXWBCCCHEBSg2F7P55Gb+OaEGOTmlOZXPaTVaegb0ZEibIQwMHUiPgB44NVXIYLNBXhJkHIaMg5B5WP0+K04NU2qidQLvtmoljCEYPEOqPhqCwc1XDXKc3BusQsYJ6F3+dR9QXJrHv8n/qAFZxnYyyvL5y8Odvzzc0QL9bc5cXlzCpdmp+Jny4eQu9evM1xLYBUK6qyFPaC9o0wdcDA0y5nPZlphTY6ADoACp+aVsS8xhcCf/Rh+PEML+SsqszN+YyNx/jmA0WQC4tGswT17Rhcigxv+9JBpHWcoOHj/4fxS5ONHHLZT7hj5n7yGJhnJwCaycpVYxV/BqA2PfgJir7TcuIYTDqlelTrdu3YiPj2f16tWMHDmyEYbl2KRSR9hbRdiTkGE8FfhkGElIL6SorPrKHr1WQ3iAR5V+PVFBnkQESNgjhBBC1KTEUsKGlA2sTFzJuhPrKLWeunhvcDIwNGwoF7e9mGFhw/B19W38ASmKWmlTEWyc3AWpe9QeN9VxclerWPw6gm+4+uUXoT56hTW7O1AVReFgzkHWHV/H38f/5lDOocrndBod/f1iGOMZyWV44J1/AjLj1CCrutev0UJQDLTtB237Q9sBEBDV4NO3/bY7hRnf7T7vdu/f1JsJvcMa9NxCiObFalP4ZVcKb6+KJa1A/XvRs603T1/ZlUEdJdRt0UoLePWr4XzrYsMbHT9OWkGIQabVdAgHl8D3k6GmSVRv+EqCHSFErTXq9Guurq4MGTKEv/7664IG2VpJqCOaK0VROJlfqvbpST8V+CRkGCvvEDuTTqsh3N+dqPKgJzJYfYwI8MBF37wu9AghhBBNwWQ1sSFlA6uSVvHP8X8osZRUPtfW0JaR7UYyst1I+gT1afxqnNICOPEvJG9RH0/ugtK8s7fTuUBgNAR2haDyr8Auah8abcu9eeN44XH+OPYHq5JWcTD7YOV6J60TI9uNZEKnCQxpMxinglRI3w/pByBtn/rfKf/42Qf0CITw4RAxQv3y63jBIc/mI9ncPG/Lebf79u5BUqkjhAPbEJ/Fq8sPcTBVDZnDfNx4Ymxnxvdsg1amXmzZFIWV303k8bKjAHw87HVGdLrKzoMSDcJmhfe6V63QqUKjVuw8vK/Z3QgjhGieGjXUCQwM5PLLL+frr7++oEG2VhLqiJZGURRS80tP9espD3zi040UniPs6eDnXmUKt6ggTzoGeuDqJG9mhBBCOBabYmNH+g5+S/iNNclrMJqNlc+18WjDmPAxjIkYQ4xfDJoGrvSoojANkjerIc6xTWpQodiqbqNzhuDu0OaiU1+BXUDXxD17mtjxguOsPraa5YnLicuNq1zv5+rHVR2vYkKnCXT263xqh4JUSNkOx7fBie1q0HNaQAeAV1s13Im+HDqNUvsF1VFFT520/NKz7vEF6akjhKOLTSvktRWH+Cc2EwBPVz0PXBLJlCHh8rnJQSRtfIcb4+ZTrNVyV4crmTHyDXsPSTSUxPWwYNz5t5uyDCKGN/54Gor0BxLCbho11Ln22muJi4tj//79FzTI1kpCHeEoFEUhvcBEXHrhqcAnw0hceiGFpdWHPVoNdPD3IDLIUDmFW1SwgU6BBvnQIoQQosVJMaaw5MgSliQs4YTxROX6IPcgxoSPYWz4WHoE9Gi8IKckF5I2wNF/1K/shLO38ekA7QdDuwEQ1ledUkzv3DjjaSEO5xzmt4TfWJ64vEpvo86+nbk26lrGdxqPp7Nn1Z0sJkjZAYnr1K/j28BmPvW8Vq9e9Igeq375d6r1eFbuT2X6op1A1clbKv7VzL2tD2O7yzQ9QjiS9IJS3v0jju+3H8emqNNd3zaoAw+NjsLPo3X/jnYkJSnbuXX5bcQ7O9HPNZR51y9Hr3XsmyhalX0/wk93nn+7SZ9Dj+safzwNQfoDCWFXjRrq7N69m0GDBvHRRx9x1113XdBAWyMJdYSjUxSFjEIT8enGKoFPXHohBecIe9r7uRNZHvJUBD6dAg24OUvYI4QQovkoNhfzZ/Kf/JbwG9vStlWu93DyYEz4GK7udDUXBV2EVtMI05ZZTHB866kQ5+SuMypxNBDSXQ1x2g+CdoPAW/qw1MRsM7MxZSNLjizhn+P/YC4Padz0blwZcSU3dr6Rrv5dq9+5rBiOb4GENRC/GrLiqj4f0Bm6XaN+BXU571hW7k9lztKDpOaf6rsU6u3K8+NjJNARwoHkl5j5dO0RvtiYSKlZ/f19RfcQnhjbhYgADzuPTjQoUyHPfjWUX50V/NHxw6RVBBqC7T0q0ZAcrVJH+gMJYXeNGuqsW7eOlStX8sYbbzBp0iTGjRtH+/bt0dYw3/aIESPqegqHJqGOaK0URSHTqIY98emFxGUYSUg3EpdRSF6xudp9NBpo5+uu9usJ8iQqyEB0sCedgjxwd5Y7nIQQQjSdI3lHWBy7mKVHllZOr6ZBw4DQAUzoNIHR7Ufj7uTe8CcuTFNDg7hVcORvMBdVfT4gGjqOVL86DAU3n4YfQyuQb8pn2dFlfB/7PUfzj1au7xnQkxs638CY8DG46l1rPkD2EfX/U+wKOLYRbKfdyBIUcyrgCYiq8RBWm8K2xBwyCksJ8nRlQIRfo0251pTnEkJAqdnKgk1JfPLPEfJL1M8+fTv48tQVXegX7mfn0YkGpyj88t0EnitLRKsozBv5HgPCL7X3qERDq+ypk8rZQQi0qJ460h9IiGahUUMdrVaLRqNBUZTzTiWh0WiwWKq/M7+1klBHiKoURSHLWFbZpyc+o5C48uAn9xxhT1tftyr9eqKCDEQGGfBwkbBHCCFEwzBbzfyZ/CeLYxezI31H5fq2hrZMjJzI+E7jaWNo07AntdkgdRfErYa4lZC6u+rzHkHQ6RI1xIm4WCpxGpiiKGxP384PsT/wR/IfWMrDGW8Xb66NupZbutxCiEfIuQ9Smg+xK+HAz2olz+nTtLW5CHrfCt0ngbt9LuRKVZAQTcditfHjjhO892c8aQXqz1x0sIHHx3Th0q5BjdtnTdhN3Ma3uDXuS0q1Wh6MmMg9I16y95BEY6msboFqJ1FtKdUtjlZ1JEQL1aihzsiRI+v0xuPvv/+u6ykcmoQ6QtReVnllT0JF0FMe/GQXldW4T5iPmzp9W7Aa9EQFexIZZMAgYY8QQohaSjWm8kPcD/wU/1NlzxWtRsvItiO5sfONDGozqGGnV6toSHvwNzi8DApTqz7fpk95r5bLIaQX1FAhLxpWVkkWvyb8yg+xP3CySL1zVa/Rc3n45UyOmUy3gG7nP0hJHsQuh/0/w9G/T1Xw6Jyh85VqwNNpFOia5n1KRf+eGiZWkf49QjQQRVFYdSCNt1bFciRTrbBs4+3KI5dFc22ftlIZ58CMJ7Zx88opJDnpGerelk+u+71xpmQVzUe1fWjCYOzrLSPQAcfsDyREC9SooY64MBLqCHHhso0mtVdPhpGE9IrAx0iW0VTjPmE+bkQGnerXExWsVvZ4ujo14ciFEEI0Z3sy9/DVga9Yk7wGq2IFINAtkEnRk5gUNen8FRp1YTVD4rryIOd3KM469ZyzQb3QHz0GIi8DT5mD356sNivrU9az8ODCKn2U+gT1YXK3yYxsOxJdbaYiKcqCfT/A7q8hbd+p9YYQ6DsF+kxp1Morq01h2Bt/VanQOZ0GCPF2ZcOsUXLBWYgLsOlIFm+sjGXP8TwAfN2d+M8lkdw2qAOuTjJtkSNTSgt4YtFwVjrZCEbPD9f/ia+7v72HJZpCxQ06xnQwBEOHIS1rmjKp1BGiWZBQpxmTUEeIxpNbVEZ8hpG49EISMk5N5ZZZWHPYE+rtWlnVU9m7J9iAl4Q9QgjRKlhsFtYkr+Grg1+xN3Nv5foBIQO4qctNjGw3EidtA/1NsJSp1RoVQU5p3qnn3Hyh81UQMwE6Xgx6l4Y5p2hQh7IPsfDgQlYkrsCiqFU37TzbMTlmMhMjJ567787pUvfC7m9g3/dQnK2u0+ig8xXQ/06IGNngFVmbj2Rz87wt593u27sHMbiTXIQUoq72p+Tz5qpY1sVlAuDmpOOu4RHcPaKjfLZoDRSFhd+N482yZPSKwheXfEzvDhfbe1RC1I4j9QcSogWTUKcZk1BHiKaXV6yGPfHpVQOf9IKaw54QL9dT/XqCTwU+3m7ygUwIIRxBYVkhP8f/zDeHvqmcWstJ68SVEVdye8ztdPbr3DAnUhQ4vhX2LoYDv0BJ7qnnPAKhyzh1ao7w4aCTvzEtRXpROt/Ffsf3sd9TUFYAgL+rP7fH3M6NnW/E4Gyo3YEsZeqUe/9+Dsc2nFrv1xH63w19bgcXzwYZ82+7U5jx3e7zbvf+Tb2Z0Ft6NQlRW0czjbz3ZzxL9pRP06jVcMvA9jwwKpIgz1oGvaLF+3fdS9x9dDFWjYYno27i1iGz7T0kIerGUfoDCdGCNVmoU1RUREJCAgUFBdR0qBEjRlzIKRyOhDpCNB/5xWYSMsunbzutZ09FE9PqBHm6EF3epyc6uDzwCfLE210uxAkhREuQVZLFooOLWBy7GKPZCICviy83dL6Bm7rcRIBbQMOcKDMW9n6vVmLkJZ9abwiGmInqh+L2g+Vuxxau2FzMrwm/8uWBL0ktUnsheTp7cnOXm7mt6234uvrW/mAZh2D7fNjzHZjUoAgXb+g3FQbce8FTs0mljhAN63hOMR+siefnXSlYber1kKt7teGxy6Pp4O9h59HVj9WmsC0xh4zCUoI8XRkQ4SfTMdZC+pE/uWHtQ+TodFxl6MRr1/5Sp17UQjQbjtAfSIgWrNFDnaNHjzJjxgxWrlyJzWar+QQaDRaLpT6ncFgS6gjR/BWUmolPN5KQcapfT3x6YY1z0AMEerpU9uupDHyCDPh6ODfhyIUQQtQkxZjCl/u/5JeEXzBZ1UrNjt4duT3mdsZ1HFf7abPOpTBd7Zmy73tI3XNqvbMBul4NPa+HiIslyHFAZpuZ5UeX8/n+z0nMTwTATe/GpKhJTO02lWCPOvRFMhnVyq4tn0B2grpOq4fuk2DwAxDas15jrOipk5ZfWtPEKtJTR4haSMsv5aO/41n873HMVvWnaXSXIB65LJruYd52Hl39rdyfypylB6t85gn1duX58TGM7R5qx5E1b2WFaUz7/jL26iFa48qim9fi5uRu72EJUX8tvT+QEC1Yo4Y6qamp9O7dm8zMTNq0aYPFYiEjI4PBgwcTHx9PVlYWGo2GwYMH4+TkxN9//31BL8bRSKgjRMtVWGpWp25LP9WvJyHDSEpeSY37BBhcTvXrqezd44mfhD1CCNEkjuQd4fN9n7M8cTlWxQpAz4Ce3NnjTka2G4lWc4F9S6xmiF8NOxeqj+XnQKuHyEuh5w0QfQU4ywWe1sCm2Pgr+S/m7ZvHweyDADhrnbm+8/Xc2f1OAt0D63AwG8Svgk0fwrGNp9ZHXAxDH4JOo6GOd4Kv3J/K9EU7gWonVmHubX3k4q0QNcgsNDH3nyMs2nqMMot6c+vwqAAeuSyaPu3rUJXXDFX8bjjzApH8bjgPm5WXF17MYvLxVGDxuMW0C4ix96iEEEK0UI0a6syYMYMPP/yQp59+mpdffplp06bx1VdfYbWqH2BXrVrF9OnT6dSpEytWrECv19f/lTggCXWEcDxGk6U87CmsrOqJSz932OPv4VzZs6eiX09UsIEAgzTGFkKIhhCbE8vcPXNZk7ymct2g0EHc3eNu+of0v/BpUbLiYddC2P0tFGWcWt92gBrkdLsWPGQKq9ZKURQ2n9zM//b+j50ZaojionPhhs43cEf3O+o+zV/KTtj8ERz49VRw2KYPXPwERI+tU7gjd+MLUTe5RWX8b91RFmxKosSs/vwNCPfj0cujGdSx5f+er6jiq2lWAqniq9mvS+/i2ZytaBSFj/rOYkSP2+09JCGEEC1Yo4Y6Xbp0oaioiKSkJHQ63VmhDkBsbCw9e/bkxRdfZNasWfV7FQ5KQh0hWo+iirAn41S/nviMQo7n1Bz2+Hk4l0/fpgY+FcFPgMFZ5mUWQohaiMuNY+7uufyZ/CcAGjSMbj+aO3vcSfeA7hd2cJMRDv6qVuUcP603iUcg9LoJLrodAjtf2DmEQ1EUha1pW/lo10fsyVSn5HPVuXJzl5uZ2n0qfq5+dTtgXjJsmQvbvwBL+fuJkB4w4nHoMh60tas8k74ZQpxfQamZ/1ufyPwNiRhN6rTyvdr5MPPyaIZFBjjMe3Ppt1U/B3fO5/Y9/6VMq+H+kBFMH/OxvYckhBCihWvUUMfd3Z3Ro0ezdOlSAO68806+/PJLTCZTlaqcSy+9lMzMTPbs2VPToVolCXWEEMVlFo5kFJ02hZv6eDy3mJp+K/u4OxEd5ElksIHoIANRwWrgE2hwcZgPlEIIcSHic+OZu2cufxz7A1DDnLHhY7m317108ul0YQdPPwjbP4c9i6GsUF2n0ULkZdDndrVSQud0ga9AODJFUdh0chMf7/6YfVn7ALXnzq1db2VKzBR8XH3qdkBjplq5s20emIvUdYFdYcRM6HZNs5n7XsIj0RIVmSx8uSmJz9YdJb/EDEBMqBePXR7NqC5BDvfe+7fdKcz4bvd5t3v/pt5M6B3W+ANqAfLS93Ljsps5qddysVMAH9y85sKncxVCCNHq1TY3qNe8aE5OTnh4eFQuV3yflZVFSEhI5fqgoCC2bt1an1MIIYRDc3fW06OtNz3aVm2kWlJm5UjmqX498eWBz7GcYvKKzWxLymFbUk6VfbzdnIiqCHnK+/VEBRsI8pSwRwjROhzJO8LcPXNZnbQapbwbwOUdLmd6r+lE+kbW/8CWMji8FP79vGo/E98IuOg26H0LeLW5wNGL1kKj0TA0bChD2gxhfcp6Pt79MQezD/J/+/6Pbw9/y9RuU5kcMxn32jbXNgTCZXNg6AzY8gls/R9kHoKf7oS1b8AlT0PXCbWu3GkMMs2baGmMJgtfbU7i/9YnklNUBkBUkIFHL4tmTLcQtA4aSAZ5ujbodo7Oaipi1u9TOKnX0k7R8urEHyTQEUII0aTqVanTtWtX/Pz82LhR/XD77rvvMnPmTH777TfGjRtXuV2vXr1IS0sjPT294UbsAKRSRwhRV6Xm8rAn3XhadY+RY9lF2Gr4Le7lqq8Mek4PfIK9JOwRQjiGYwXH+Hj3x6xMXFkZ5lzW4TLu63Uf0b7R9T9w/gnY8SXsWHCqV45GC52vhP53qU3q7XihXDgGRVH45/g/fLz7Y2JzYwHwd/Xnvl73MSl6Ek7aOlZ+leTBts9g88dQmqeuC+0Fo56DyNF16rnTEKTpumhJCkrNLNiYxOcbE8krVitzwv3defjSaMb3auPw1WUVPXXS8kvP+pkF6alzpre/u4IFphO42RQWjZ5LdPvh9h6SEEIIB9Go06/ddtttLF++nIyMDPR6PXv37qV3797ExMSwePFi2rdvz4cffsgzzzzDpZdeyurVqy/oxTgaCXWEEA2l1GzlaGZRlX498elGks4R9ni66MuncCvv11Me+IR6u0rYI4RoETKLM/l0z6f8FP8T1vKG8aPajeL+3vfT2a+e/WwUBRLXqlNZxS4HxaauNwRD36nQZwp4y5QzouHZFBurklbx4a4POV54HIB2nu148KIHGRM+pu53f5cWqMHO5o+gzKiuaz8ERj8HHQY38OirJ03XRUuRX2xm/sZE5m9MpLBU7ZnTMdCDB0dFMr5nG/S61hPgVwSxQJVgR4LYqpaseYLZJ1YA8FbnqYwd9JidRySEEMKRNGqos2jRIiZPnsySJUsqK3OuvfZafv311yoXBDUaDWvXrmXo0KH1eAmOS0IdIURjM1msJGYVqRU96eVTuWUUkpRdjLWGtMfgoicyyFBe2WMgqjz0aePt5rBTTQghWpbCskK+2P8Fiw4toqS8QfzwsOE8eNGDdPXvWr+Dmkth/49q4/n0/afWhw+H/ndCl3HSK0c0CbPVzI/xP/Lpnk/JKVWnWu3q15WH+z7MkDZD6n7AoizY8K4aVFpN6rqoy2HUsxDaswFHfjZpui6au9yiMuZvTOTLjUkUmtQwJyrIwIOjo7iqR2irDRtlysRz23voR6ZtfYEyjYZ7fHrw4IRv7D0kIYQQDqZRQx2LxUJ6ejre3t4YDAYAiouLefLJJ/nhhx/Iycmha9euPP/881xzzTX1fxUOSkIdIYS9mCxWkrKKT5vCTX1MyirCUkPY4+6sIzLIUB74nJrGra2vhD1CiKZhspr47vB3zNs3j3xTPgA9A3vySJ9H6BfSr34HNWbA9vnw7/9BUaa6zskdet0MA+6GoHqGREJcoGJzMV8d/IovD3xJkbkIgIGhA3m076PE+MfU/YD5KbDuTdi5EBQroIFeN6nhTiNVn0nTddFcZRtN/N+GRL7alERRmVrp2TnYk4dGR3FFd8ftmVMXVpvCtsQcMgpLCfJ0ZUCEX6sNuU6XkRXLTUuvI1MLl2g8ee/WdWh19WpTLYQQQtSoUUMdcWEk1BFCNDdlFhtJ2UUkZBiJSy8kPsNIQrqRo1lGzNbq/0y4OmnpFGio7NkTWR72tPdzlw9+QogGYbVZWXp0KR/v/pi0ojQAOnp35KE+DzGq3aj6TRmZfgA2fwL7vger2gQbrzAYcA/0mQzufg34CoSov5zSHObtncfi2MWYbWY0aBjfaTwPXfQQwR7BdT9g9hH4+xXY/5O6rHeDIQ/A0Bng4tmgY5dKHdHcZBaamLf+KAs3H6PErIY5XUO9mDE6kstjJMwR52YqK2LaNyPYpykj0gqLrluJh5cE0kIIIRqehDrNmIQ6QoiWwmK1cSynWO3XUx72xGcYOZJppMxiq3YfZ72WjgEelb16KqZz6+DvgVMrmpdcCHFhNqVs4q3tb5GQlwBAsHsw/+n9H8Z3Go9eW8c7Y202SPhD7TOSuPbU+rC+MOh+iJkgU6yJZivFmMIHOz9geeJyANz0bkzrNo0p3abg7uRe9wOe2AGrZ0PyZnXZIwhGzYaLbgetrkHGLE3XRXORklfCvHVH+e7fZErN6nvXHmHePDQ6iku7Bkk/SXFeiqIw+/srWFqagrfVxreXfES7iEvsPSwhhBAOSkKdZkxCHSFES2e1KRzPKSa+vLInIUPt2ZOQYaz8wHwmJ52GiAAPooLUqp6Kvj0RAR446yXsEUKojuQd4e3tb7MhZQMAXs5e3N3jbm7qchOuete6Hcxqhn0/wMb3IfOwuk6jha5Xq2FOuwEgF/REC7Evcx9vbX+LXRm7AAhyD2JGnxmM6zgOraaOf0cVBQ4thT+fh5yj6rqgGLj8JYi8tEHGK03XhT0lZBj5dO0Rft2VUjnFcK92PswYHcklnVtmmCPTotnHgtUzeDv1L3SKwqdd7mTQoEfsPSQhhBAOrEFDnRdffBGABx54AD8/v8rl2tBoNDz77LO13r41kFBHCOGobDaFlLwS4jMKiU83Vvbtic8wUlw+b/mZdFoN4f7uar+e4FO9ezoGeuDq1DB3DAshmr+c0hw+2f0JP8b9iFWxotfquaXLLdzT8x68XbzrdrCyItj5FWz6CApOqOtcvNTp1QbeCz7tG/4FCNEEFEVh9bHVvLvjXVKMKQB09evK4/0fp39I/7of0FIG2z+Hf16H0jx1XafRMOZVCOpyweOVpuuiqe09kccnfx9h1cE0Kq50DO7oz/SRnRgeFdAiwxyQnyV72bDnC/6z6x1sGg1P+vTh1gkL7D0kIYQQDq5BQx2tVotGo+HQoUNER0dXLp9r14rnNRoNVmv1F/JaKwl1hBCtjc2mkFpQSnx5Vc/pfXsKTZZq99FqoIO/R3nIc6qyp1OgATdnCXuEcBRl1jK+PvQ1n+39DKPZCMDo9qN5pO8jdPDqULeDFWXDts9g2/+gJFddZwhWq3L6TQPXOoZDQjRTJquJrw99zby986r83Dza91Hae9UjtCzJhXVvw9b/gc0MGp0agI588oJ/bpqyukAqGVonRVHYfCSbT/45woaErMr1l8UEM31kJ/q097Xj6C5cRdXbmVdfpOqtcR1N2cZtq++gUKvhWo0PL9z6DxqdfAYRQgjRuBo01HnhhRfQaDQ8+OCD+Pn5VS7X1vPPP1/rbVsDCXWEEEKlKArpBabKyp5TFT6FFJRWH/ZoNNDO152oIAOR5UFPVJBa4ePhUsc+G0IIu2nQioO842q/nJ0LwFysrvONUBvA97oZnOo4bZsQLUR2STZz98zlh7gfsCk29Fo9t3W9jXt73ovB2VD3A+YchdXPwuFl6rJHIFz6AvS6BbTNe6pUqWRofWw2hT8OpfPJP0fYczwPUCvAJ/Rqw30jOxEd7GnfATaAiv5Up/+7Pp30p2ocOcZ0bv1xDCc0Vi6yaPi/m/7C2SPA3sMSQgjRCkhPnWZMQh0hhDg3RVHINJpISDcSX96vJy7dSHx6IbnF5hr3C/NxK6/oUcOeyPLp3LxcpQG6EM1JbE4sr297ne3p2wEIcgvioT4PMb7T+Lr1BsmMgw3vwr7vwVYeBIf0hGGPQMyEBmv6LkRzl5CbwDs73qnsRRXgFsAjfR+pX78dgIQ/YcUsyE5Ql8P6wZVvQljfBhx1w5FKhtalzGJjyZ6T/G/tEeIz1Eo1F72Wm/q34+4RHWnr627nETaczUeyuXnelvNu9+3dgxjcyb8JRuT4TFYTd383ml2WfMIsVr4Z+xV+Yf3sPSwhhBCtRKOGOuvWrUOn0zF06NALGmRrJaGOEELUX7bRVB70GElILw97MoxkGU017hPq7VrZq+f00MfbXcIeIZpSvimfj3d/zOLYxdgUG646V6Z1n8bUblNxd6rDRbiMQ7DuLdj/M5Ut2CNGqGFOx0vUkj4hWqF1J9bx5r9vcqzgGAC9Anvx1MCn6Obfre4Hs5TB1rmw9k0oMwIa6HM7jH4emtEd61LJ0HrkF5v5etsxFmxKIr1Afd/n6apn8uAOTBsaQYDBxc4jbHi/7U5hxne7z7vd+zf1ZkLvsMYfkINTFIUnf7uB5fmH8bTaWNRnFh17T7b3sIQQQrQijRrqaLVaRo4cyV9//XVBg2ytJNQRQoiGl1tURkKmsco0bvEZhZUf+qsT5OlS2avnVO8eT/w8nJtw5EI4PqvNyi8Jv/DBzg/INam9bi7rcBkz+82kjaFN7Q+Utl8Ncw7+RmWY0/lKGD4T2jbPCgIhmlqZtYyFBxfyv73/o8RSggYN10Zdy0N9HsLP1a/uByxIhT+fh72L1WVXb7jkGeh/Z7OohpNKBsd3PKeYzzck8v324xSXqf16g71cmDY0glsGtnfoimz599205v7zJJ8c+x29ojA3dAyDxrxj7yEJIYRoZWqbG9Sr+YCvry9t2tThA7gQQgjRyHw9nOnv4Uf/8KoXrPJLzCRkGEmoDHrUadxO5peSUWgio9DExoTsKvv4ezhXhj1R5VO4RQV5EmBwrlNPOSEE7M3cy6tbX+VA9gEAOnp35KmBTzEodFDtD5K6F9a+carPB0DXq2HE4xDas4FHLETL5qxz5s4edzK+03je3fEuy44u46f4n1h9bDX/6f0fbux8I3ptHT4GeoXCtZ9Bvztg+UxI2wcrHofdX8P496DNRY32Wmojo7D6Cp36bieaj93H85i37igr9qdiK8/xu4R4cvfwjozv1QZnffPu89QQBkT4EertSlp+6VnTC8KpSrQBEfUIbEUVv+/9gk+O/Q7AbJcODLr8bTuPSAghhKhZvSp1Ro8ejdFoZOvWrY0xJocnlTpCCGF/haVmjmQWEZ9eSEL5dG5x6YWcyC2pcR9fd6fKXj1Rp03nFuTpImGPEGfIKsnivR3v8duR3wAwOBmY3ms6N3e9GSdtLe+qTtmpVubELi9foYFu16hhTnBM4wxcCAezK2MXr259lcM5hwGI9InkqQFPMSB0QN0PZrPC9vmw5iUw5YNGCwPugUtmg6t9PtdIJYNjsdkU/jyUzv+tT2RbUk7l+uFRAdwzoiPDIgNa3Xuuip5RQJVgR3pGNZxdx9dz55r7MWtgmsWNRyevBSc3ew9LCCFEK9So06/99ttvXHPNNSxdupSrrrrqggbaGkmoI4QQzVdxmYUjGUXqFG7lVT3xGUaSc4qp6S+ml6ueqGBPooLKq3rKvw/1dm11Fx6EsNgsfHv4Wz7Z/QlGs9rAekKnCTzc92EC3GrZh+PEdrUyJ361uqzRQvdJ6jRrQV0aaeRCOC6rzcpP8T/x4a4PyTPlAXB5h8uZ2W8moYZ6XAwuTIfVs2HfD+qyIQSueB1iJjZ5T6uKnjrnq2Ro6J46VpvCtsQcMgpLCfJUKyWkZ0/9FZdZ+HlnCvM3JHI0qwgAJ52Gq3uFcdfwCLqGtu7PzSv3pzJn6cEqvaNCvV15fnyMBDoX6HheErf+NpFcrIwy2Xj3xtVovaU/kRBCCPto1FAnOTmZt99+m08//ZSpU6cyadIkwsPDcXOr/k6G9u3b1/UUDk1CHSGEaHlKzVaOZBrVqp7T+vYkZRdVTglyJoOL/rRePad694T5uKGVCz/CAe3O2M1LW14iLjcOgBj/GJ4e+DS9AnvV7gAnd8Ffr0DCH+qyRgs9b4Thj0FAVCONWojWI9+Uz0e7PuL7uO+xKTbc9G7c2/NeJsdMxklXj74kR/6C3x+DnKPqcuRlcOVb4BfRsAM/j6auZGjKC+yOHh4dzylm4ZZjfLctmYJSCwCernpuG9SBqUPCCfZytfMImw9H/7dgD/mmfG7/YQyJ1iJiysx8MfZL3NvVYXpYIYQQooE1aqij06kNMRVFOe8dyBqNBovFUtdTODQJdYQQwnGYLFYSs4oq+/UkZBQSl24kKasISw1pj5uTrryip3wKt/Lv2/q6y4dz0SLlm/J5b+d7/Bj3IwDeLt7M6DODayOvRVebRurpB+HvV071zNHooNfNMPxR8O/UiCNvJWxWOLYJjOlgCIYOQ5pFg3thP7E5sby69VV2ZqhBSEfvjsweOLt+U7KZS2HDf2HDu2AtA70rXPwEDH4Q9M4NPPKaNVXQUhEgnfkXvjECJEetzlAUhS1Hc/hyUyJ/HEyvvDmmvZ87U4eEc0P/dhhc6tX+V4haM1lN3PPzBHYWpxBssfBN36cJ6n27vYclhBCilWvUUCc8PLxO08kkJibW9RQOTUIdIYRwfGUWG8eyi8qncFMrexIyjBzNLKLMaqt2Hxe9lk6BBqKD1SncKqp82vu5o9c5fjNg0fIoisLSo0t5Z/s75JSqvQ8mdJrAo/0exc+1Fk2bs4/A36/C/p9Q76/XqJU5I2eBX8dGHXurcXAJrJwFBSdPrfNqA2PfgJir7TcuYXeKorDs6DLe3v525c/vlRFXMrPfTALdA+t+wKx4+P1RSFynLgd0hvHvqSFiE2nsSoaKqd5OD1lO15BTvTVleNRUSs1WftudwhcbkzicVli5flhkANOGhjOyc5Dc3CKahNVm5fHlU/kjezeeVhtftp9A9KWv2ntYQgghROOGOuLCSKgjhBCtl8Vq41hOMfHpalVPReiTkGmkzFJ92OOs19IxwKOyV09FZU8Hfw+cJOwRdnI07ygvb32Zf9P+BaCTdyeeGfQM/UL6nX/n3GOw7k3Y/S0oVnVdzEQY+ZT0zGlIB5fA95OhpsvCN3zV8MGOVAW1OPmmfD7c9SHfx36PgoLBycADFz3AjZ1vRK+tY7WEosDe72HV01Ccpa7rdwdcOgdcW/7nns1Hsrl53pbzbvft3YMY3Mm/3udpyvCoKZzMK2HRlmN8uy2Z3GIzoFYtX9snjKlDwokK9rTzCEVroigKr619km+PLcdJUfifWwz9b1jc5P3AhBBCiOpIqNOMSagjhBDiTFabwvGcYjXkySgkoXI6NyMlZmu1++i1GiICPIiuqOopn84tPMAdF71cRBWNo8RSwry98/jiwBdYbBZcda7c2+tepsRMOX9PjoJUWP827FgANvXCHtFj4ZKnIbSWfXdE7dis8F73qhU6VWjUip2H9zVc6CJVQS3agawDvLzlZfZn7wegi18Xnhn0TO17Yp2uJBf+eB52LlCXPdvAuP9C5ysacMRN77fdKcz4bvd5t3v/pt5M6F3/RutNFR41JkVR2JqYw8LNx1h5IA1r+RxrYT5uTBnSgRv7tcfbvR59nJoh6XXTsszf+RHv7vsfAG9ZvBk7+U9wkt5NQgghmofa5gYyUa0QQgjRDOi0GsIDPAgP8OCymODK9TabQkpeCfEZhZV9e+IzjCSkF1JUZq1cPvNYHfzdiQ7yJCrYUD6NmycdAz1wdZKwR9Tf+hPreWXrK6QYUwAY0XYETw98mjDDeS5eFmWp/Tb+/T+wlN953nEkXPIMtOvfuINurY5tOkegA6BAQYq6XcTwCz9fTVVBBanq+saoChINqltANxZduYif4n/i/Z3vczjnMLctv41JUZN4uM/D+Lj61P5gbr5w9QfQ4zpYOgNyjsK3N0G3a+CKN8EQ1GivozEFedbuwm9tt6tJRmH1FTr13a4p5ZeY+XnnCb7emkzCae9PBnX0Y+qQCC6LCXaowMNR+x45qqVxP1cGOk8UKYy9/ScJdIQQQrRIDVKpk5+fT0FBATUdqn379hd6CocilTpCCCEulKIonMwvJT5d7dVT0bcnPt1IoclS7T5ajdqEODLIs7xvjxr2dAo04OYsYY+oWUZxBq9ve50/jv0BQLB7ME8NeIpR7Uedu8+iyQibP4ZNH0BZ+cW9dgNh1LMNEySImu37EX668/zbTfpcvfB+IexRFSQaVU5pDu/ueJdfE34FwMfFh4f7PMw1Udeg1dRx2k9zCfzzGmz6SJ1u0c0XxrwKvW5ucdMdVUyLlpZfetakhtBw06K1xEqdvSfyWLTlGEv2nKTUrE4n6+6sY0LvMG4f1IGYNo73udcR+x45sk0nNvKfNdOxoDDFWMrM65dAUFd7D0sIIYSootGnX8vNzeW5557jhx9+IDMzs+YTaDRYLNVfXGqtJNQRQgjRWBRFIb3AVKWyJyGjkLh0I/kl5mr30Wigra8bUeWVPVFBau+eyCADHi5S1Nua2RQbP8b9yLs73sVoNqLT6Li1663c3/t+PJw8at7RUqZOu7T2DSgqf58Y2ksNcyIvbXEXclukxPWwYNz5t5uy7MIDtqY8l2hSO9N38vLWl4nPjQegZ2BPnh30LF386tH76uRuWPIApO1TlzuNgnHvgW+HBhtvU6i4kA9V69Ia8kJ+U4VHF6qkzMqSPSl8vTWZvSfyK9d3DvbktkHtmXhRGJ6ujjHF2pkcre+RozuUfYipv99CsWLhiqJiXh8zD22nUfYelhBCCHGWRg118vPzGTBgAAkJCeh0OpydnSkuLiY0NJS0tDQURUGj0VRW6CQmJtb/lTggCXWEEEI0NUVRyDSaKnv1VIQ+CRlGsovKatwvzMeNyCCDWtkT5Elk+XRuXg56kUackpifyAubXmBnhnrxskdAD54f/Dyd/TrXvJPNBgd/gTUvQW75+z+/jmqYEzMRtHW8w1/UX2X1TCpnTYkGNGj1TFNWBYkmZ7aZ+fbQt3y8+2OKLcVoNVpu7nIz/+n9Hzyd69jg3mqGzR/BP6+rUzE6uau/Hwbe26KquJpiyq2mCI9OV5e+MPHphXy9NZmfdp6gsFS9gdNZp+XKHiHcOqgD/Tr4nruK0wG0xGqq1up44XEmL7meLEsRA0pKmTvgWZz7TLb3sIQQQohqNWqo88wzz/Dqq68yZcoUPvnkE6ZPn87ChQuxWq0UFxezcOFCnn76acaPH8+XX355Ia/DIUmoI4QQojnJNpqq9Oqp+D6z0FTjPiFerqeqeoINRJX37XGUpsetmdlq5osDX/C/Pf+jzFaGm96Nhy56iJu73IzuXBddj/wNfz4PqXvUZY8gGDkL+kwBnfy7sIvKPjdQ7WXhhupzY69KHZtV7QlkTAdDMHQY0qKCgZYmvSidt7e/zcqklQAEugXyeP/HGRs+tu4X8LOPwJKH4NgGdTmsL1z9IQR3a+BRN566hCD11VT9WmpznuIyC7/vTeWH7SfYlpRTuV17P3duGdie6/u2xd/g0mBjau5+253CjO92n3e792/qzYTe5+k7JxpNRnEGU5bcwAlTNlFlZSzodCueo56z97CEEEKIGjVqqNOzZ0/S0tJITk7G1dWVadOm8dVXX2G1Wiu32bJlC8OGDeOTTz7hnnvuqd+rcFAS6gghhGgJcovKSMg81a+nondPWkHNjZkDPV3KAx4DUcGelY9+Hs5NOHJRX/sy9/H85ucrp1oa2mYozw5+ljDDOS5IndwNf74AR/9Wl509YegMGDQdXAyNPmZxHgeXwMpZVfvdeIXB2NcbJtCBpq0KqlDt62oDY99ouNclqrXp5CZe3foqxwqOATAodBCzB84m3Du8bgey2dRpGv94DkwFoHWCi5+AYY9IEHyaxg6PztUXRgFmje1Mck4xS/ekYizv2afVwOiuwdw2qAPDIwPQNtPpxRrzv51U6jR/eaV5TFt2MwlFJ2hnNrPAbxiB18yTKWCFEEI0a40a6hgMBoYPH86KFSsAuOOOO1iwYAFlZWXodKc+qA0fPpyysjK2bt1aj5fguCTUEUII0ZIVlJrLp247vW+PkZS8khr38fdwJjLIQFSwgehgT/X7IE8CDM4OP0VLS1BsLubDXR/yzeFvsCk2fFx8mDVgFldFXFXz/5+co/DXy7D/J3VZ6wT974IRM8EjoOkGL86vKSpamqoqqMq5amhP3pDnEtUyWU18sf8L5u2dR5mtDCetE3d0v4O7etyFq961bgcrOAm/z4TY39XlkB4wca76KBrV+frCnKmDvzs39GvHpD5tCfGu4//nJtbYVU4tpe9Ra1VkLuLu5ZPZlxdHkMXCAn04bW/9DfRyk5EQQojmrdFDnauvvppvvvkGgAceeIC5c+eSnp5OQMCpD/G33nory5YtIz8/v6ZDtUoS6gghhHBERpOlvJqnvKqnvHfP8Zyawx4fdyeiggxEBnlW9u2JCjYQ5OkiYU8T2ZiykRc3v8jJIrXiYVzHcTze/3H8XP2q38GYCevehO3zwWYBNNDjehg1G3zDm2zcohlq0qqgkzVs0AhVQaJGxwuO88q2V9iYshGAdp7teHrg0wwLG1a3AymKGhAvnwkluaDVw4jHYdijchG2EdW22mRYZAD/uSSSgRF+zbYq53Tnqj6ChutH1NR9j0TtmKwm7l99N9syduFjtfKlyZNO01aDq7e9hyaEEEKcV21zA319Dt6mTRtSUlIql9u3bw/A3r17GTVqVOX6o0ePotfX6xRCCCGEaGEMLnp6t/OhdzufKuuLyywczSwirqJfT3mVz7GcYvKKzfyblMu/SblV9vF01Vf26YkKPjWVW6i3q4Q9DSS3NJe3/n2LpUeXAtDGow3PDn625oux5hLY/DFseBfKjOq6yEth9PMQ2rOJRi2atZiroctVjVsVdGzTOQIdAAUKUtTtGrJ/j6hWO692zB09lz+O/cEb297geOFxpv85ncs6XMas/rMI9giu3YE0GuhxHUSMgN8fhUNL4Z/X4NAymPgxhPZq3BfSSmUU1q5C5/p+bRt0CrHGnBbNalOYs/RgtdUzCmrgMmfpQS6LCbngc47tHsrc2/qcVREU0gh9j0TtmG1mHv/nUbZl7MLDZuPTAhudpv4ogY4QQgiHU6/EpUePHmzcuLFyefjw4SiKwvPPP0///v3x9PRk0aJFbN26laFDhzbYYIUQQgjR8rg76+ke5k33sKofqEvNVo5mFhFfOY2bGvocyy6msNTCzuQ8dibnVdnH4KKnU3nPnorKnsggA2E+bi3i7uHmQFEUlicu541tb5BrykWDhlu73sqDFz2Iu5P72TvYbLDve1jzonqxHKDNRXDpHOh4cdMOXjR/Wl3jhinG9IbdTlwwjUbD5eGXMzRsKB/v/phvDn3DH8f+YGPKRu7vfT+3dr0VvbaWHzsNQXDDQjjwi1q1k74P5o1SK3ZGPC5VOw0k22hi6Z6TLNxyrFbbB3k23FRrjT0t2rbEnHNOJ6cAqfmlbEvMaZCgamz3UC6LCWnUvkeidmyKjec2PMvfJ9bhbFP4MKeYbrcuBZ929h6aEEII0eDqNf3avHnzuPfee1mzZg2XXHIJoAY7GzduRKfT4eXlRV5eHgC//vor48ePb9BBt3Qy/ZoQQghRM5PFSlJWcWVlT0XvnsSsIiy26t+2uDnpyvv0GIgMNhBdXuHT1tddLqycJqskizmb5/DP8X8AiPSJZM6QOfQMrKHSJmkDrJoNqbvVZe92amVO90mg1TbFkIWoKnE9LBh3/u2mLJNKHTuJzYnlpS0vsSdzDwDRvtE8O+hZegf1rtuBjJmw/DE4+Ju6HNRNrdppc1HDDriVKDVb+fNQOr/sTGFtXGaNf09P19B9YZpiWrTfdqcw47vd593u/Zt6M6F32AWdSzQfiqLw2tbX+Db2W/SKwnuZeVx8/WIIl5uMhRBCtCyN2lPHaDSyZ88ewsPDCQtT3whlZmZy5513smLFCqxWK76+vjz33HPMmDGj/q/CQUmoI4QQQtSd2WrjWHYRcenGysqehAwjRzOLKLPaqt3HRa+lU6BBncIt6NQ0bu393NHrWk8ooSgKKxJX8Oq2V8k35aPX6rmv533c0f0OnHROZ++QFQ9/PAexy9VlZ08Y/igMmg5Obk07eCFOV9lTJxVqak8uPXXszqbY+CX+F97d+S75JrW/6qSoSTzc52F8XH3qdrADv8DvM6E4CzQ6GPYIXPwE6F0afuAOxmZT2JaUwy87U1i+L5VCk6XyuZ5tvZnYOwyDi45ZP+0DGrcvjNWmMOyNv2qsommoAKm2fYK+vXtQg04pJ+xHURTe3fEuXxz4Ao2i8FpWDleNm6dOByqEEEK0MI0a6pxLcXEx+fn5BAcHo5U7OKsloY4QQgjRcCxWG8k5xeX9ek717TmSacRkqT7scdZp6RjoUV7d46lO5RZsoIO/B04OFvZkl2Tz8paX+TP5TwC6+nXl5WEvE+0bffbGRVmw9g3YPh9sFvUCar9pcPGTYAhs4pELUYODS+D7yeUL1VyGvuErtb9PQ7FZG7dPkAPLKc3h3R3v8mvCrwD4uPjwaN9HmRA5Aa2mDr9ri7Jg+eNw4Gd1ObArTPwEwvo0/KBbOEVROJxWyLK9J/l110lS8koqnwvzcWPiRW245qIwIoM8K9c39pRo0HRhS0V4lJZfWlPs26DVR8K+FEXhw10fMm/fPACezcrhhpGvQt8pdh6ZEEIIUT92C3XE+UmoI4QQQjQ+q03hRG4x8elG4jIKSUg3lk/nZqTEbK12H71WQ0SAB1HBBiKDPMt793gSHuCOi77lXcRdlbSKV7a8Qq4pF71Gzz297uGuHnfhpD2jOsdcCls/hfXvgKlAXRc9Fi57EQI7N/3AhTifg0tg5SwoOHlqnVcYjH29YQOdas/TBsa+0bDncXA703fy0paXSMhLAOCioIt4ZtAz1YfL53LwN/j9MSjKVEPnoTNg5JNStQMkZBhZtvcky/amkpBhrFzv6aLnyh6hXNMnjAHhfjX2n7PalEbtC9OU06JVTPMGjVt9JOzvk92fMHfPXACeysrhlv6PwIiZdh6VEEIIUX+NGupMmjSJO++8k7Fjx0o1Tj1IqCOEEELYj82mkJJXQkKGsbJvT3yGkYT0QorKqg97dFoNHfzd1Sncyvv1RAV50jHQA1en5hf25Jbm8srWV1iVtApQe1q8MuwVuvh1qbqhosD+n+DPOZCfrK4L6QGXvwIdL27iUQtRR41dQVNZEVRDB5CGrghycGabma8Pfs0nez6hxFKCTqPj9pjbmd5rOu5O7rU/UFE2rHgC9v+oLgd2gQmfQNu+jTPwZuxYdhHL9qaydM9JDqcVVq531msZGR3I1b3bcGnX4Gbxd6qpp0VriuojYV//2/M/Ptr9EQCPZ+cyueutarCvkQqsFkWqYYUQoopGDXW0Wi0ajYbg4GAmT57MtGnT6NxZ7uKsLQl1hBBCiOZHURRS80tPTeNW3rcnPsNIYaml2n20Gmjv565W9ZT37YkOVsMed2d9E78C1Zpja3hxy4vklOag0+i4q8dd3Nvz3rN75yRvgVVPQ8oOddmzDYx+FnreBHLTjmjtKnv3nKxhA+ndU19pRWm8vu111iSvASDYPZgnBzzJ6Paj0dTlYuyhpbDsUSjKAI0WhjwII58GJ9dGGnnzcCK3mN/3prJsbyr7UvIr1+u1GoZHBTCuZxsu6xaMl2s1/dLsyB7TojV29ZGwn//b93+8v/N9AB7NyWVauzFw7Tx5/9LSSDWsEEKcpVFDnY8++ogvvviCXbt2qQfRaBg0aBDTpk3jxhtvxNPT8zxHaN0k1BFCCCFaDkVRyCg0VYY8celGEsof80vMNe7X1tetvGePgcggdTq3yCAD3m6Nc6EtrzSP17a9xvLE5QBE+kTy8rCX6ebfreqGOYnwx3NwaIm67OQBwx6GwQ+Acx3ulhfCkSWuhwXjzr/dlGUQMbzxx+OA1p1Yx6tbXyXFmALA8LDhPDXwKdp5tqv9QYpzYMUs2Pe9uhzQWe2107ZfI4zYfhIyClm5P41VB9KrBDk6rYYhnfwZ1zOUMd1C8HF3tuMoz0+mRRMN4cv9X/LOjncAeCgnj7sD+sHNi0HfvP/9izNINawQQlSrSXrq7Nu3j/nz5/PNN9+QmZmJRqPBzc2NSZMmMXXqVC655JL6HtqhSagjhBBCtHyKopBlLCM+o/DUVG7lfXtyispq3C/Q06Uy6IkKMtCpfEq3AINz3e5SP83fyX/z4pYXySrJQqvRckf3O5jeazrOutMucJgK1Z45mz8Ga5l6Z/tFt8MlT4NnSL3OK4TD2vcj/HTn+beb9Dn0uK7xx+OgSiwlzNs7jy8OfIHFZsFF58I9Pe9harepVX9/nc/h32HZI+r0PQ5QtaMoCvtS8suDnDSOZBZVPqfRwIBwP8b3asMV3UPwN7SsfkIyLZq4EKdX6Nyfm8d0r+5w209yU0pLI9WwQghRoyYJdSpYLBaWLl3KF198wcqVK7FYLGg0GsLDw5k6dSrPPvvshZ7CoUioI4QQQji2nKIyEjKMlYFPxdfpF7HO5O3mdFpVT3noE+xJG2/XGsOefFM+b/77JkuOqFU3Ed4RvDL0FXoE9ji1kc0Ge76BNS+qFzwBIi6Gsa9BcLdqjiqEkEqdpnU0/yivbHmFbWnbAAj3CueZQc8wMHRg7Q9SnAMrn4S9i9XlgGiYOLfFVO1YbQr/JuWwcn8aqw+kcfK0vxdOOg1DIwMY2y2ES2OCCWhhQc6ZZFo0UVeKojB3z1zm7pkLqIHOfe6d0ExeAq5yTaXFkb+xQghRoyYNdU6XkZHBokWL+OKLLzhw4AAajQartfqmw62VhDpCCCFE61RYauZIZhHx6YUkZBo5kqFW9iTnFFPTOzJ3Z50a8gQaiAwufwwycKxkBy9veZGMkgw0aJjabSr/ueg/uOhOu9h3bLN6kTN1t7rsGwFjXoHOV0ojYSHOpfIu4lTOnhoG5C7ihqcoCr8n/s7b/75Ndmk2AFd1vIqZ/WYS4BZQ+wMdXg7LHj5VtTP4AbhkdrOs2skvMbM+PpO/DmXwd2wGucWnpvR0d9ZxSecgLu8WzCVdgppdjxwhmoqiKLy/830+3/85ADNy8rjLpR1MXQbufnYenagXqYYVQoga2S3UMZlM/Pzzz8yfP581a9ZIqFMNCXWEEEIIcbpSs5WjmUUkZBpJKA984tONJGUXYbae8VZNW4pL8DKcfbYD4EYwowIeYli7fkQGGYgI8MDFeFLtm3PgZ3UfFy8Y8TgMvBf0LfsObyGaTOV8/1BtBxCZ779RFJQV8OHOD1kcuxgFBU8nTx7s8yA3RN+ArrYBWnVVOxM+gXb9G2/gtXQ008hfhzNYcyiDf5NysNhO/dvycXfi0q7BjO0WwrCoAFydJDAUrZuiKLy1/S0WHlwIwOPZuUx2CoZpK8AQZOfRiXqTSh0hhKhRk4c6W7Zs4csvv2Tx4sUUFBSgKAq+vr7cfPPNfPTRRw1xCochoY4QQgghasNstXEsu7h8+rZCtqZtZp9pHlZtHoqiwZwzFFPm5aCovSfcKGW6fin36n/HhTIUNCR1mETJ0Cfp0CECDxe9nV+REC3MwSWwclbVef+9wmDs6xLoNLIDWQd4ccuLHMw+CEA3/248O+hZugXUYdrIaqt2ngYnt8YZdDXKLDb+TcphzaEM/jqcTlJ2cZXno4IMjOoaxKjOQfTt4Itep22ysQnRnNkUG69ufZXFsWo4Ozsrh5t0fjBtJXiH2Xl04oJINawQQtSoSUKd1NRUvvrqKxYsWEBsbCyKoqDVahk9ejR33HEHEydOxMVF7gY9k4Q6QgghhKiLInMRb29/mx/jfgSgnWc7HuwxG1drFPEZhRxJLyD0+DJuLphPMDkAbLV14UXzZA4o4ZXHCfNxO9Wv57TePT7udWhILkRrY7PCsU1qMGAIhg5D5CJTE7HarPwQ9wMf7PyAQnMhGjTc2PlGHuzzIF7OtfwcVZwDK5+Cvd+py/5Raq+dRqraURSFo1lFrI/LZH18FpuPZlNcdmrmCmedloEd/RjdJYhRXYJp7y8N3oU4k8Vm4YVNL/Dbkd/QKPB8VjaTNF5qhY5fhL2H1zo09t8+qYYVQohqNWqo8/333/Pll1/yxx9/YLPZUBSFjh07MnXqVKZMmUK7du0uaPCOTkIdIYQQQtTWltQtPL/xeU4WqZUCt3S5hRl9ZuDuVH4h8MQOtZLgxL8AWL3aEd9rFltchpKQVUR8upEjmUayjGU1niPA4EJkkAdRQZ5VAp9ATxc00ntHiKYjAVK1skqyeHv72/x+9HcA/F39mdl/JldFXFX731GxK2Dpw2BMK6/a+U95r50Lr9rJKy5jY0I26+PVICclr6TK8wEGF0Z1CWRUl2CGRQVgkKpJIWpkspp4fO3j/H38b3QKvJSVxXibO0xbDoGd7T281qHaKtU2MPaNhg1apBpWCCHO0qihjlarloS7u7szadIkpk2bxsiRI+s92NZGQh0hhBBCnE+xuZj/7vhv5bQjYYYwXhr6Ev1Dyu8uLzgJf845dfe5kwcMf1SdXqiahuC5RWWVvXoSMoyV/XtO5pfWOAZPFz0RgR50CjTQMcCDjoEGOgZ6EBHgIb0ehGhoTXURrQXbmrqVl7e8TFJBEgADQwby9KCn6ejdsXYHKMlVq3b2fKsu+0fBxE+g3YA6jaPUbGX38Tw2JWSxLj6LvSfyOK01Ds46Lf0jfBkRFcjwqEC6hHii1UpALsT5GMuMPPjXg2xP346zAm9lZDIKd5iyFILrMPWiqL/KCpozLxU2UgWN3MwghBBVNGqoM3jwYO644w5uuukmPD09L2igrZGEOkIIIYQ4l3/T/uXZjc+SYkwB4MbON/Jo30fV6hxzCWz6CDb8F8zlvRl63QKjnwOv0Dqfy2iycCRDDXriyx8TMgpJzimucpHydBqNOpVbx/Kwp1NF8BNoINhLqnuEqLOmvojWgpVZy/jywJd8tvczTFYTeq2ead2mcXfPu3HT17LqJnYlLJ2hVu2gUat2Rj1TY9WOyWJld3IeW47msPloFjuT8yiz2KpsEx1sYHhUIMOjAhgY4Y+bs1yUFKIuskuymf7ndA7lHMJDgQ/T0umv9SwPdGLsPbzWobLXzckaNpBeN0II0diapKeOqB8JdYQQQghRnWJzMR/s+oCvD30NQKhHKHOGzGFwm8GgKHDgF/jjechPVndoNxDGvgZhfRt8LCaLlWPZxRzNNHIks4ijmUUczTJyJMNIQamlxv08nHWnVfeolT0dAz3oGGCQi5xCVEcuotXL8cLjvLb1NdanrAfUasanBz7NiLYjaneAs6p2ImHCJ9B+ICaLlT3H89lyNJstR7PZcSwX0xkhTqCnC4M6+jMiKoDhUYGEeJ9dISmEqJ2TxpPc+8e9JBUk4adomHvyJDFOPmqgE9TV3sNrPRLXw4Jx599uyjKIGN744xFCiFZIQp1mTEIdIYQQQpxpZ/pOnt34LMmFamAzKWoSM/vNxOBsgJO71YuPyZvUjb3C4LIXofsktWymCSmKQnZRmRryZBo5mlXEkQz1MTmnGGtN5T1UVPd4qNU9QWroEx7gThtvt9Y3NZFMNyIqyEW0elMUhb+S/+K1ba+RXpwOwOj2o3lywJOEeITU7iCxK7EtnYHWmIaCht89rmV2wQTyzVX73gQYXBjU0Y9BHf0Z3MmfjgEeUpUoRAOIy41j+p/TySjOINSm4bOUFMJdfNXfeUFd7D281mXfj/DTneffbtLn0OO6xh+PEEK0QrXNDaRDoxBCCCGEHZVaSvlw14csPLgQBYUg9yBeHPIiQ8OGgjEDVjwJuxYBCujdYNjDMOQhcHa3y3g1Gg0BBhcCDC4MiPCr8lyZxUZyTjFHMo1VQ59MI3nFZlLySkjJK2F9fFaV/Zz1Wjr4udPB34OIAHfCAzwI9/cgPMCDUC9Xxwt8pHeKOJ0xvWG3a0U0Gg2jO4xmcJvBzN0zl4UHF7ImeQ2bTm7ivl73cVvX23DWOVfZR1EUjmUXs/1YLjuO5bA9yY30rBd5zmkR1+nWMa7oJ7pqNvGy+39w7zSUQZ38GdzRj06BBglxhGhgm09u5tF/HsVoNtLRpuV/J44T4upfXqEjgU6TMwQ37HaicciNQUIIpFLHLqRSRwghhBAAezL38MyGZyqbfk+MnMjj/R/HS+sKWz+FtW9CWaG6cY/r4dIXwLut3cZ7IXKKytSQJ7OII1nlj5lGjucUY7bW/Ha0IvAJD/AgoiLs8VeXQ1pi4CO9U8SZpFKnwcTlxvHylpfZlbELgA5eHfhPr0fwtPZkb0o+u5Pz2JmcS5ax7Kx9IwI8uM3vMDenv4O7KQMFDZrB/4FLZtstRBfCkf2a8CtzNs3Boljoa9Xx/okkvN0CYeoyCOxs7+G1TpXTgaZy9vsUaNHTgTpKECI3Bgnh8GT6tWZMQh0hhBCidTNZTXy8+2MWHFiATbER6BbIC0NeUHtBxK2GVU9BdoK6cZuL1A9q7Qfad9CNxGpTOJlXQmJWEceyi0jMKiYpu4ik7KLzBj4uei0d/N0J91cDnw7+HoQHqBU/IV6u6Jpb4CO9U0R1HPkiWhMrNVvZl5LH4kO/8HfGl5SRD4DFGI0pfRy2siAAnHVaerT1pl8HX/p28KVPB18CDC7qQUpyYdVs2K32NsOvE0z8BNoPssdLEsLhKIrCp3s+5ZM9nwBwhVnLyyeScDYEq+F1YLSdR9jKVd58AlX/JrXgm08cJQiRG4OEaBUk1GnGJNQRQgghWq/9WfuZvWE2R/OPAjC+43hmDZiFd2GmGubEr1Y39AiCS5+HXreAVmvHEduPxWrjZF4pidkVgU8RSVlFHMsuJjmnGMs5+vc46TS09XWnra8b7f3cK7/alX95uzmdvVNj38UpFRmiJo54Ea2RFZdZOJxWyMGTBRw4WcDeE3nEphWe+r2gLcXZ/2+c/Teg0VjRoKOX11Xc0/Ne+rcPw9XpPD/bcath6UNQmApoYND9MOoZqdoR4gKYrWbmbJ7Db0d+A+CuEngwLRmtV1uY/BsERNp5hAKoIQQJg7Gvt7y/RY4ShMiNQUK0GhLqNGMS6gghhBCtT5m1jE/3fMr8/fOxKlb8Xf15bvBzjArqB+vehC2fgs0MWicYdB+MeAJc5X1CTSxWGymVFT7FauCTrYY+KXkl56zwAfB2cyoPedxo5+dOe1MC7Q/Po13xYdposnDWWBv+Lk5pQCzOxZEuojWwjMJSDp4s4GBqQeVjYlYR1X2SDTA406utDz3b+tCznTd+XvnMO/g+a0+sBcDP1Y8ZfWYwMXIiWs15AvOSPFj1tFTtCNEA8krzmLl2JlvTtqLTaJldYOL6rFT152ryb+DTzt5DFKdzhOnKHCkIkRuDhGg1JNRpxiTUEUIIIVqXg9kHmb1hNgl56pRqV0RcwdP9n8Tn0O+wZg4UZaobRo2BMa/KnaoXyGpTSCsoJTm7mOO5xRzPUSt7knOKOZ5TQpbRdM79tdgIJZv22gzaaTIJ6z6CsOiLaOPjSlsfd0K8XXHW16N6Sj6Qi/NxhItoF6Cg1Ex8upH49ELiM4zEpRdyKLWwxp/ZIE8XYtp40TXUi55h3vRs50Mbb1c0mrOnXtyQsoE3tr1R2cMsxj+GpwY8Re+g3ucfWNxqWDoDCk8iVTtC1N2RvCM8+NeDHC88jpvOhbczcxmRnwVB3WDyr2AIsvcQhSNypPddcmOQEK2GhDrNmIQ6QgghROtgtpr5bN9nzNs7D6tixc/Vj2cGPcNlWm9Y8QScVJt54x+p3o0fdZl9B9xKFJdZOJ5TooY82UaS/5rHcZMHyUoQx5VASnE55/4ajXoxuY2PG2183Ghb/hhW8ejrhper/uwLy9I7RQgA8kvMJGQUEpduVEOcjELi042kFZRWu71WAx0DDcSEehHTxouYUDXICfQ898/qmcxWM98c/oZP93yK0WwE4KqOV/FIn0cI9gg+984leeW9dhapy74RcPUHEDGiTmMQorVZe3wts9bPoshcRJirPx8cO0p0cT6E9YNbfwB3P3sPUTgqRwpCHCmgEkKcU4OGOsnJyRc0mPbt21/Q/o5GQh0hhBDC8cXmxDJ7w2xic2MBuKzDZTzT7W781r8LexerGzl7wshZMOBe0DvbcbSt2BkfkhUFMvHmuBJUHvIEkaIEcDL0UlJMrqTklmCy2M57WIOLvjzkca0MekK9XQnO3UnIP08QosnFXXP6BewWNre7EOdRaraWT4lYXDk1YmL5V0ZhzdVyIV6uRAUbiAryJCrYQNdQLzoHe+Lm3HBBZ1ZJFh/u+pBf4n9BQcFN78bUblOZ2m0q7k7nqb6J/wOWPFRetQNcdDtc/hK4+TbY+IRwBIqiMH//fN7f+T4KCv08I/jvoa34mkshfDjc/C24eNp7mMKROVIQIjcGCdFqNGioo9Vqqy1hrw2NRoPFYqnXvo5KQh0hhBDCcZltZj7f9zn/2/M/LIoFHxcfZvd7grGpcbDuHTAXARq46FYY/bxMOWJvdbyLU1EUcorKSMkr4WReCSdySziZV0pKXnH5Ywk5RWW1OrUnRYRocgnR5BDkXEZIVB9COvYg2MuVEG9XQrxc8Te4oNPW7324EOfUAFO9FZaaOZFbwvEcNbhJzComqby/VWp+9VU3Fdp4uxIZ7El0kEENcYI9iQwy4OXqdCGvqk4OZB/g9a2vsztzNwCBboE8cNEDTOg0Ad25/luUFqhTZ/77f+qyRxBc+RbETFBL+YRo5Uotpbyw+QV+P/o7ANf79uCpXStwUmzQ+Uq4bj44udl5lMLhOVoQcnAJfD+5fOH01yM3BgnhSBo01AkPD693qAOQmJhY730dkYQ6QgghhGOKz41n9obZHMo5BMCodqN4NnAwAX+9BrlJ6kZtB8AVb0BYH/sNVJzSCHdxlpRZK0OfysfcEtIKSkkrKCU9v5SiMmutjqXTagjydFGDHi9XAj1dCPR0IcDgQoDBmQBPFwIN6jpXpxZwQUI0DweXwMpZVZtHe7WBsW9UXhBSFIXcYjMpuSWk5BVzIlcNMVPKw8yU3GIKSs99856Xq56IAA/CAzwI9/cgPMCdcH8PIoMMeDZheHMuiqLwx7E/eHfHu5wwngAg0ieSmf1mMjRs6Ll3PrYZlj4EWXHqcuer4Kq31f+WQrRSxwuO8+jaRzmccxidRseT3r25adcv6pN9p8KV74BOb9cxilbE0YKQav9+h6nTOLek1yGEqJH01GnGJNQRQgghHIvFZuHLA1/yye5PMNvMeDl78XTXqVy5ZxmaxH/UjTxD4dI50PMGuZO7ObHTXZyFpWbSC0pJyzepQU9BKWn5pZXfpxeUkllowlaHd+oGF3154ONcHvqcHQD5ujvj5+6Mp6serVQAtU4Hl2BafAeZeJOu+Fb5ylB8SQ8aRrrNk5N5JRTXInz0dXeira874QEeRPirj+r3Hvi4O13QzYFNqcxaxuLYxXy651MKygoAGNJmCI/2fZTOfp1r3tFcCuvfgQ3/BZsFXLzgsjnQZypotU0zeCGaib+S/+KZDc9QaC7E18WHt/TtGbh/mfrkxU/CyCflPZBoeo4WhDRApa0QovmSUKcZk1BHCCGEcBxH844ye8Ns9mfvB+Di0CE8X+ZG4I6vQLGCzhkGPwDDHwMXg51HK6rVTO/itFhtZBnL1Aqf/FNBT5ZR/co0lpFVaCLTaKKsFn1+TqfVgI+7M77uTvi6O1d+7+dx6ntfD2d8y7/3cXfG280JZ71cpG6OFEWh0GQhx1hGdlEZOUVl5BSZ1O+N6nJWURkZBaVkpKeSo9T+d1GgpwthPm609VV7Q7X1dadteZ+oMB83PFwc6477fFM+n+39jG8Of4PFZkGDhomRE3ngogcIcj/HdJnpB9ReOynb1eX2Q+DqDyAgqmkGLoQdWWwWPtj1AV/s/wKAXgE9eDuvlJD4NaDRwlXvQL877DxK0apJECKEaCEk1GnGJNQRQgghWj6rzcpXB7/io10fUWYrw9PJwJNBQxm/82c0xdnqRp2vgjEvg19H+w5WnF8Lvouz4oJ+VqGpPPQpOxX8FJ4KgLKNJvKKzRhN9e936aLX4uXmhKerHk9XJ7xc9Xi5qstebk54uuhPfV++3uCix81Zh7uzDncnPe4uOpx0Eg6dyWK1UWy2Yiy1UFBqpqDEQkGJufx7M/kllsrvK57PKzGTU2Qit8hMmbVuwZ4zZoI0uQSTS7Amj2BNDsGaXPVrzOOEdO5PGx+3Vjut3/HC47y/831WJa0CwE3vxuSYyUztNhWDcw2hmM0K2z6DNS+p/dN0znDxEzBkBuidm3D0QjSdrJIsHl/7ONvT1UDztk7X8OjBtTid3A16V7UnXddaTHMqhBBCCAl1mjMJdYQQQoiWLTE/kWc3PsuezD0ADPPrzgspxwhOO6BuENAZrngdOo2y4yhFnbWSuzhNFiv5xWZyi83kFJWRV1xGbrGZ3OIycotO+764jLzybQpKzTTkpwYnnQY3Jx3uznrcnXWVoY+bsx53J/V7FycdLnotznotzrryR70Wp/LvXU5bV/G8TqtBq9Gg1aj9iDQaTfk6yteftly+rU1RUBQFmwI2RcFmo3xd+SNU2cZstVFmsWG2KpRZbJRZreqjxUZZxboz1peYrRSXWSkps1JUZil/PLVcXGatc7VVddyddfh5OOPv4YyfhzN+Hi74Gyq+dyY4+1+CNz5HsCYXH4w1z4I06XPocd0Fj8cR7M7YzTvb32F35m4AfFx8uKvHXdzY+UZc9a7V75R7DJY9AkfWqMtB3WDcu9B+YNMMWogmsunkJmZvmE1WSRbuende7HY3Y/56FwpOgJsv3PQtdBhs72EKIYQQLUajhzpms5kPPviAH374gdjYWAoKCqo/gUaDxVL/uwEdkYQ6QgghRMtktVn5+tDXfLDrA0xWEx56N2Zpg5kYu06dqMvVG0Y+Df3vBF3zaAIuREOw2pRTFSSlZgpLLeVfauVIYamFQpOl8vuKbQpKzRSbrBSXBxeWujQJaqWcdBq83ZzUCii38mqo8mUvN33lc17lz/l7uOBnUIOc81bVJK6HBbW4Y37KMogY3jAvyAEoisKfyX/ywc4PSCpIAiDIPYjpvaYzMXIiem01U9ApCuz7AVbMgpIcdV2fyWpvNXe/phu8EI2gzFrG+zvf56uDXwEQ6RPJf8MnEfH7LCgzgn8k3PI9+Hey80iFEEKIlqVRQx2TycTo0aPZvHkztdndZrvwu84ciYQ6QgghRMuTXJDMsxufZWfGTgAGu4Yy5+h+Qk1FgAb6ToVRz4BHgF3HKURzVmaxUVJmpdhsqaxcKS47Ffqo69TvS802tSqmvDLGVFkBY6PMYj1VKWOxYSrfxmZTsCkK1vJKG2v5sroerJXfK1ht6jba0yp5NJrTv6/6WLFep9VUrRgqrxRyOr1y6PTqIp321PRzzqeqkyoePVzUCiWP8oolZ50WTWM1ErdZ4b3uUJBK1f5RFTTg1QYe3ueQVWoXymKzsPTIUj7Z8wlpRWkAdPDqwAMXPcDlHS5Hq6lmWsGibPjzOdi1SF1294fLX4ZeN0vDeNEiHck7wqx1s4jNjQXgxs43MhN/XFc9DYoNwoervegkvBRCCCHqrFFDnTfffJMnn3ySMWPG8MEHH/DKK6+wcOFCSktLiY+PZ+HChbz33ns88cQTzJkz54JeiCOSUEcIIYRoOWyKjW8Pf8t7O96j1FqKu9aZmYVlXJeRrFbntB8CV7wBoT3tPVQhhDi/g0vg+8nlC6d/FCwPGG74qtn3kbI3k9XE97HfM2/vPHJNuQB09evKgxc9yLCwYdWHcsc2q1OyZR5SlzsMhav+C0FdmnDkQtSfoih8H/s9b21/C5PVhK+LL3MGPcclh/6ArZ+qG/W+TZ1qUHpINZ5WMlWsEEK0Vo0a6vTv35+4uDiSk5Px9vZm2rRpfPXVV1it1sptli5dysSJE1m8eDHXXSfzMZ9OQh0hhBCiZTheeJznNj5X2fx3gOLCiyeOEmaxgldbuPxF6Hat3G0thGhZDi6BlbOg4OSpdV5hMPZ1CXTqoMhcxFcHvmLBwQUUmYsA6BXYi/t73c/gNoPPDnesZtj8Max9A8zFoNXDkAdhxBPg7G6HVyBE7aQXpfPilhdZd2IdAINDB/NKn5kE/v4YJKrrGP08DHtE3hM1pmp/d7eBsW/I724hhHAQjRrqeHt7M3DgQFavXg3AHXfcwYIFCygrK0OnO3WHQL9+/fDw8GDt2rX1eAmOS0IdIYQQonmzKTZ+iP2Bd3a8Q4mlBDe0PJqdzQ0FhWj1rjB0Bgx9WC7CCSFaLrnbu8Hkluby+b7P+S72O0xWEwA9A3syvdd0hrYZena4k5es9tqJXa4u+7SHK96CzmObeORCnJuiKPya8Ctv/fsWheZCnLROzOgzg9t9e6FdfDvkJ4OTB1zzqYQKja2yyvLMS3hSZSmEEI6ktrlBNZP+np/ZbCYwMLBy2c3NrfKkp+vcuTP79u2rzymEEEIIIezipPEk9/xxDy9vfZkSSwl9TRZ+On6CmwoK0cZMhAf+hUuelkBHCNGyaXUQMRx6XKc+SqBTb76uvszsP5MV167gtq634aJzYW/mXqb/OZ3blt/G+hPrq/ai9WkPN38LN32jVn3mJcO3N8J3t0Jukt1ehxCnSytKY/qa6Ty36TkKzYV08+/G4nGLmWLzQDt/rBro+EbAXX9KmNDYbFa1QqfaXmjl61Y+qW4nhBCiVahXqBMSEkJqamrlcmhoKACHDh2qst3JkyerTMkmhBBCCNFcKYrCj3E/cu2Sa9mauhVXBZ7MzmH+yZO08+8CU5bBDQvUi3FCCCHEGQLdA5k1YBYrJ61kcsxkXHWu7M3ay/1r7ueW329h3Yl1VcOdLlfBf7bCkIfUqdgOL4OPB8Lfr0JZsf1eiGjVFEXhp7ifuOa3a9iYshFnrTMP93mYRWMXEPXvV/DTnWApgU6j4Z6/ITjG3kN2fMc2VZ1y7SwKFKSo2wkhhGgV6hXqdO3alYSEhMrlIUOGoCgKb775JjabDYC1a9eyfv16Onfu3DAjFUIIIYRoJGlFaUz/czpzNs+hyFxE71ITP544ya1mJ7RXvQP3rFXvZBdCCCHOI8AtgMf7P86KSSuY2m0qbno39mfv5z9r/sONy25kZdJKrBV31LsY4PKX4L4NEDECLKVqz52P+sOBX6Dus6ULUW8JuQlMWzWNFza/gNFspGdgT34Y/wN3RoxH//X1sOkDdcNhj8CtP4Cbr30H3FoY0xt2OyGEEC1evXrqfPDBBzz88MNs2bKFAQMGYLPZ6NmzJ4cOHSIoKIg2bdqwb98+rFYrn3/+OVOnTm2Eobdc0lNHCCGEaB4q5op/8983MJqLcFYUHsrJ47bCYnT974SRT4G7n72HKYQQogXLLslmwYEFfBf7HSWWEgDaGtoytdtUJkROwFXvqm6oKHBoCayaDfnH1XXhw+GKNyC4m51GL1qDYnMxn+75lIUHF2JRLLjp3fhP7/9wW9fb0B3bpFbnGNPByR0mfAzdr7X3kFuXxPWwYNz5t5uyTG5CEkKIFq62uUG9Qp2srCxWrVpFv379KitxEhISmDRpUmUPHZ1OxwMPPMC7775bz5fguCTUEUIIIewvoziDFza9wPqU9QD0LDXxUlY2HdsOgbFvyHQiQgjREGxWdUogYzoYgqHDkFbbvye3NJfvDn/HN4e/Ic+UB4Cfqx+3dr2VGzvfiLeLt7phWbFaEbHhXbVyR6OF/nfJjQaiwSmKwprkNby+7XXSi9Uqj9HtRzOr/yxC3YNh/Tvwz6ug2CCwqzoNbaDMxtLkbFZ4rzsUpFJ9Xx0NeLWBh/e12t+vQgjhKBo11DmX2NhYcnJyiI6Oxt/fvyEP7TAk1BFCCCHsR1EUlh1dxmtbXqbQUoyTovBAbh6TNb7ox7wKXcaBRmPvYQohRMt3cIna3Pv0XhBebdTgvBU3Vi82F/NLwi98deArThap/23c9G5cF30dk2MmE+IRom6Yl6xW7Rxaoi67+cElT0PfqaBzss/ghcM4kneEt7a/xcaUjQCEGcJ4euDTjGg7Aoqy4Oe74chf6sa9b4Ur3wJnDzuOuJU7uAS+n1y+cPplvPL3rDd81ap/rwohhKOwW6gjzk9CHSGEEMI+skqymLN+Nv+kqo1ku5lMvJxbTOTgGTD4QXBytfMIhRDCQVRegDzz46ZcgKxgtplZnbSa+fvnE5cbB4Beo+ey8Mu4teut9ArspW549B9YMQsyD6vL/pFw2YvQ+Uq5CUHUWVZJFnN3z+Wn+J+wKlactE7c0f0O7upxlzoVYOI6+PkeKEwFvRtc9Q5cdKu9hy2ghqA8DMa+3up/nwohhKNo1FCnY8eOXH/99bzxxhvn3O6pp57i+++/58iRI3U9hUOTUEcIIYRoWoqisOLIMl7dPId8mwm9onB/bj7T2l2O/rIXwTvM3kMUQgjHUTlV0MkaNpCpgk6nKAobT25k/v75/Jv2b+X6HgE9uKXrLYzpMAYngJ0L4O/XoDhL3aDDULj8JQjra5dxi5al1FLKwoML+Xz/5xSZiwC4tP2lPNz3YTp4dQCLCda8CJs/BhQIiIbrF8h0tM2NTGkphBAOrba5gb4+B09KSiIzM/O822VlZZGUlFSfUwghhBBCNIjskmxeXvMQf2bvBaCrqYyX8KfzpP+D9oPsPDohhHBAxzadI9ABUKAgRd1Omnqj0WgYFjaMYWHDOJh9kG8OfcPyxOXsy9rHU+uf4p3t73BD5xu4vvv1BPS4ATa+p154P7YR5o2C7tfB6OfAt4O9X4pohiw2C8uOLuPj3R+TVpQGQHf/7szsP5O+weWBYPoBtTonfb+63HcqXP4KuBjsM2hRM61Ofm8KIYSoX6hTW6Wlpej1jXoKIYQQQogardr3Fa/s/C+5WNErCvcUmblr4Cyc+kyRuxqFEKKxGNMbdrtWJMY/hpeHvcwjfR/hh7gf+D72ezJLMvlk9yfM2zuPSztcyvXdrqdf32lo/n4F9nwH+3+EQ0th4L0w/DFw87H3yxDNgNVmZXnicj7d8ynJhckAhHqEMqPPDK6IuAKtRgs2G2z9FP58AawmcA+ACR9B5yvsO3ghhBBCnFOjJS5Wq5Xt27cTGBjYWKcQQgghhKhWbsFxXl1xNytLUwCIKjPzSshout74ilzsEkKIxmYIbtjtWiF/N3/u63Ufd3a/kz+O/cHXh75mb9ZeViSuYEXiCsK9wrku+jquvuhWfNe+qfZB2fQB7PwKhs5QAx5pat8qWW1WViWtYu6euSQVJAHg6+LLHd3v4KYuN6l9cwByk2DJQ5C4Vl2OGqMGOoYgu4xbCCGEELVX6546o0aNqvz+n3/+ISQkhC5dulS7rcViIT4+noyMDG655RYWLlzYMKN1ENJTRwghhGgkNhtr1s/hxaM/kaPVoFMU7tT4c9/Yj3EK7m7v0QkhROtQ2VMnFaju46b01KmPA9kH+DHuR5YfXU6xpRgAJ60Tl7a/lOvdI+i37Qs0mbHqxh5BMGKmOo2W3sV+gxZNxmw1syJpBfP3zedIvtrX2NvFm6ndpnJLl1twd3JXN7RZYds8WDMHzMWgd4Mxr0C/O0CjseMrEEIIIURtc4NahzparfbUThoNtdmtX79+/Pzzz7Rt27Y2p2g1JNQRQgghGl5e4lpe+/sxlutMAHSywiu9HqRbn7vlIoUQQjS1g0vg+8nlC6d/diz/fXzDVxBzdVOPyiEUmYtYnricH2J/4FDOocr1bQ1tudoQwbjY9bTLUafbwrsdXPwE9LoFdDI1uiMylhn5Kf4nFh5cSHqxOqWhp7MnU2KmcGvXWzE4n9YXJzMWfnsATmxTlzsMhas/BP9Odhi5EEIIIc7U4KHO2rVqSa6iKIwaNYqxY8cya9asard1dnambdu2tGvXrh5Dd3wS6gghhBANqDCNv1c8xIuF+8nS69AqCnf49mb62Lk4u3jae3RCCNF6HVwCK2dBwclT67zCYOzrEug0kOqqdwD6uLVhfEYyl+ek4mVTwK8TjHwKul8r1VEOIqM4g68Pfc0PsT9QaC4EIMAtgFu73soNnW/Ay/m0aw1WM2x8D9a+CdYycPaEy+ZA32lw2g28QgghhLCvBg91TnfJJZdwxRVX8MQTT1zQIFsrCXWEEEKIBmAxkb/xPd44+DlL3dWpZSK0brwy4k16dBhp37EJIYRQ2axwbBMY09UeOh2GSKjQCIrNxfx1/C+WHlnKltQt2BQbAM4aHZeUmLgiP5dhJSW4+HaC4Y9BzxtA52TnUYu6UhSFbWnbWBy7mL+T/8aiWACI8I5garepjOs4Dmedc9WdEtfB8sch87C6HHU5jHsXvGVGFSGEEKK5adRQR1wYCXWEEEKIC6AoELeKdWtmMceljAy9Hq0CUzpcwX9GvISLTnoHCCGEaL3Si9JZnricJUeWkJCXULne3aYwsriYy4uKGeYciMuwR6D3rdJzpwUoKCtgScISFscuJqkgqXJ9n6A+TO02lYvbXYxWc0bFTX4KrH4GDvysLrv7q1VyPa6XaWmFEEKIZqrJQp2ysjJ27NhBSkoKAGFhYfTt2xdnZ+fz7Nl6SagjhBBC1FNmHAUrn+Ct/D386qnOER/u4sdLl7xH7+CL7Dw4IYQQovlQFIXDOYdZdnQZq4+tJq0orfI5D5uNi4tLuNzmytC+9+Pa7w5wdrfjaMWZrDYrW1K3sPToUtYcW0OptRQAd7074zuN5/ro6+ns1/nsHS1lsOUTdao1cxFotNDvDrhkNrj7NfGrEEIIIURdNHqoY7FYmDNnDh9++CGFhYVVnvP09OShhx7iueeeQ6+XZoxnklBHCCGEqKPSfFj7Jhv2fMHz/t5k6PVogNs738SD/R7DVe9q7xEKIYQQzZZNsbEvax+rk1azOmkVacXplc+52mwMNCuMCBnExYNnEhwYY8eRtm6KohCbG8vSI0tZnricrJKsyueifKO4MfpGxnUah4eTR3U7Q+wK+OM5yI5X17UdAFe9DaG9mugVCCGEEOJCNGqoY7PZGDduHKtWrUJRFHx9fYmIiAAgMTGR3NxcNBoNY8eOZenSpWil8V4VEuoIIYQQtWSzwq6FGP96ibfdbPxUXp3T3j2Ul0a8Tp/gPnYeoBBCCNGy2BQbezP3sjpxBX8eWUqquepNml11BkZEjGVk50nE+MecPa2XaFCKohCXG8ea5DX8ceyPKlPm+bj4MDZ8LOM6jaNnQE80NU2blrwV/nwekjeryx6BcNmL0PMmkOsxQgghRIvRqKHOZ599xn333Ud4eDhvv/021157bZXnf/nlFx577DGOHTvGp59+yt133133V+DAJNQRQgghaiFpI6ycxaa8eJ4P9COtvPr3tq638VCfh3DTu9l5gEIIIUTLpigKcdmHWLfrM9aeWMtejRnltODAR+9B/7AhDAwZyMDQgXTw6lBzsCBqzabY2JO5hzXH1rDm/9m77zCpq3t/4O9tdJZioYmIFVGxS7ErKoleY5ox1xtTTMy9ibkxaqx0rEmMxkRj4k3zF01ibso1jWgsMQpixYrYUVGwIKz0LfP7YxBDREXZ3dlZXq/nmQfPmTPf85l9cIDve845z96Y5xc/v/q5msqaHDDwgByx5RHZd8C+qamqefsLvfxYcuOk5NE/FtvVnZIR/5XsfVLSuWeLvgcAoPm1aKizzz775L777svDDz+cLbbYYq1jnn766eywww7Zbbfdctttt73XKdo1oQ4AvIOFzybXj8uSWf+Xi3r3zK9ruydJNuu2WSbvPTl79t2zxAUC0CY1NSZzpiWL5yfd+iSDRiWVVaWuqnwUClnwxA35x50X5++LHsu0zp2y5F9WefTp0ifD+w3PiH4jsluf3dK/a38hzzqat2Repr8wPdNfmJ47Xrwjr614bfVzHas6ZlT/UTl484NzwMAD0qNjj3e+2IKnkn98O5l5dVJoKp6bs+t/JAecmdT2b+F3AgC0lBYNdXr27Jm99947f/rTn95x3BFHHJHbbrstCxcufK9TtGtCHQBYi5VLktsuSaZdmhnVhYzfZKO8sGp1zieHfDIn7XZSutQ4xBmAtXjkumTq6UndC2/21fZPxlyYDD2ydHWVq1efTP30y/LwrF9nRk0yo1OnzOzUMfX/EuBs0nmTDNtkWHbeZOfsvMnOGbrRUOfcrfLKslcy86WZuWf+PZn+wvQ8uejJNZ7vVtMt+222X0YPGp29+++9bn/HeXl2Mcx58NdJobHYt93hycHjk02HtMC7AABa07rmBtXv5+IrVqxIjx7v8s2RJN27d8+KFSvezxQAwIaiUCjenLhhQpYufjHf7t0zv1q1OmdAtwGZPGpy9uq3V4mLBKDNeuS65NrjkvzL9xXrXiz2H32VYOe92mir1Bzx7exy0Njscv8v8sW7f5xl85/MfR075s7OHXNnj40zq6IxLy97OTc+W9xCLEmqK6szpNeQ7LDxDhnSe0iG9B6SrXtu3e6Dnvqm+jy18Knc//L9mfnSzNz30n1rbKmWJJUVldlxox0zsv/IjOw/MsM2GZaaynfYWu2fzXswufVbySP/l9W/z7c+JNnv68nmw5v3zQAAbd77Wqmz7bbbpr6+Pk888USqqta+nL2xsTFbb711qqur8/jjj693oe2JlToAsMrce5K/nJE8f2fu6tQx4zbtk7mr/mpx9LZH5+Q9Tk7Xmq6lrRGAtqupMblkxzVX6Kyhorhi56QHbcW2PgqF5Om/J3f9KHn0T0mhMcsrKvJI1x6ZOXDn3N+tR+5f/FxeXf7qW15aWVGZLWq3yHa9tsvgnoMzuMfgDK4dnEG1g8ou7CkUCnltxWt5cuGTmb1gdh5d8Ggee+2xPLHwidQ31a8xtiIV2brX1tl1k10zvF/xTKJ33VbtnzU1JU/emNzx/eKvbxhyRLLfqUn/XZvpXQEAbUWLrtQ57LDDcvnll+erX/1qLr744tTUrPntkpUrV+ZrX/tann322Xz5y19+P1MAAO3Z6/OSGycnM6/O0oqKXLrxJrm6e+ckSb+u/TJp1KSM7D+yxEUC0ObNmfYOgU6SFJK6ucVxg/dttbLanYqKZMsDio+6F5P7/l86zbw6u732THab9fckSaHXoMwdelQe6LNlHl35Wh5d8GhmvzY7C5YvyFOLnspTi55a85KpSL+u/bJ57ebp361/+nXtl35d+63+7407b1yS0Gdp/dLMXzo/Ly99OfOXzs+cujl5tu7ZzHl9Tp6rey6v17++1td1q+mWHTbaIbtsukt23XTX7LTJTqnt8D6+xLlicXL/L5IZVySvPrGqsyLZ8SPJvqckfXZ4/28OAGgX1mmlzkEHHZQxY8bktNNOS5LMnTs3w4YNy8KFC9O/f/8cc8wxGTx4cJLkqaeeyq9+9au88MIL6d27d2bOnJkBAwa07LsoM1bqALDBql+e3HF58o+LkpWLc2/Hjhk7YFCeKyxPknx0m4/m1D1OTbcO3UpcKABl4cH/TX5z/LuP++iPkp0+1vL1bEgKheTZ6cnMq5OHf5+sXPzmc313Snb4cApDj8ornWtXr2h5pu6ZPL3o6Ty96OnUrax71ym6VHdJ706907tz7/Tu2Ds9O/VMt5pu6VLTJV2qu6RrTdd0remaDlUdUlVRlcqKylRVVKWqsiqVqUxDoSH1jfWpb6rPyqaVqW+sz/LG5albWZfXV76e11e+nroVdalbWZdXl7+al5e+nMX1i9+xpopUpH+3/tm217YZ0ntItuu9XYb0HpL+Xfun4l/OHHpPP8u59yT3/ix56Ldv/iw71ia7firZ6wtJ78Hv79oAQNlY19xgnUKdysrKfOYzn8mPf/zj1X133XVXPv7xj+fZZ599y19cCoVCNt988/zv//5v9thjj/V4G+2TUAeADU6hUNyu5fqzk9eeybKKinx34Lb5edXyFFJIny59MmnUpOw9YO9SVwpAOXn6H8nPjnj3cZ/+o5U6LWnlkmTWH5MHflXcpq2p4c3n+u1SPNNo2w8km26fVFSs3sbs6UVP5/nXn88LS17IvCXz8sLiF/Likhfz4uIXs7JpZcneTpfqLtm0y6bZtMumGdh9YAbVDsrmtZtnUPdBGVg7MB2rOjbPRHUvJA//Lrnv58lLj7zZv9HWyV5fTHb5ZNKxe/PMBQC0eS0e6iTFbdZ+/etf55ZbbsncuXOTJAMGDMgBBxyQj3/84+nQocN6vo32SagDwAZl/iPJ1DOKN3mSzOzVP+P6bJpnVixIknx46w/n63t+Pd07uGkBwHu0+kydF7P6APk1OFOn1S1dkMz6Q/Lwb5Onb00KTW8+12PzZNvDkm3HJFvsk9SsfXu1QqGQxfWLs2D5gjUeC5cvzNKGpVlSvyRL6pdkWcOyLKlfkhWNK9JUaEpjoTFNTat+LTSlurI6NZU1qamqSYfKDqmprEmHqg6p7Vib7h26p7ZDbWo7FP+7V6de2bTLpunTpU/Lnue35NVk1v8lD/4mmXN7Vv++re6c7HBUcWXOoFHFLe8AgA1Kq4Q6vD9CHQA2CEsXJDefm9z946TQlOXVHXPZ9vvlqiWPp6nQlE07b5oJoyZkv832K3WlAJSzR65Lrj1uVeOf/3m76qb40VcVV4rQ+pa8ksy6Lpn9l+SpvyeNK958rqZLMmjv4gqqLfZN+u3cPoO3QiF55fHksb8kj/01efaOpND45vMDRyTDPp7s+LGkc8+SlQkAlN665gbVrVgTALAhaKwvBjk3n5csX5gkeWC7gzO2w7I8vXh2kuTIrY7MaXuelh4de5SwUADahaFHFoObqacXt7N6Q23/ZMwFAp1S6rpxssfnio+VS4ordx77a/Hx+gvJEzcUH0nSsUdxhcoW+ySb7ZH0HZZ06FLa+t+vxS8lz/wjeea25Mmbk9eeXvP5vsOKZzzt8JGk58DS1AgAlC2hDgDQfJ64MfnrWcnLjyZJVvbZIZdvNzI/ef5vaVrZlI07b5wJIyfkgIEHlLZOANqXoUcmQw5P5kxLFs9PuvUpBgTtceVHuerQNdnuA8VHoZDMf6h4JtIz/0ieuT1ZsWjVapa/FMdXVCV9hib9d0sG7J70G5ZsvG3xOm1JY33xPJy59yYv3Js8d+fqvwetVtWhuBpp2zHF7ed6DSpNrbScpkafPwC0mnXefq3ife7nWlFRkYaGhncfuAGx/RoA7c6rTyZ/PfvNGzFdNsrDIz+fs1+dkScXPZUkOWLLI3LGXmdYnQMArKmpMXnx/mLA8+wdydx7ijfH16bH5skm27356Ll5UrtZ0mNAUtO55Wpc8XqyaG7y6uPJy7OTVx4r/vryo0nD8reO77PTqq3l9kkG75d0dHZgu/XIdW+zUvBCKwUBeE+a/Uyd96uioiKNjY3vPnADItQBoN1YXpfc+s3kju8nTfVJZXVW7vn5XLHRxvnxo1ensdCY3p16Z/zI8Tl484NLXS0AUA4KheIN8rn3vPl4aVay9JV3fl3n3kmPzZLu/ZJOPd76qOlcXD1RUZVUVicpJI0rk4aVxfN+6pcny14rbh+77LVk6avFOhbNLa4kejsdeyT9d0kGrFpVNGjvpEvvZvyB0GatPtPrX2+tOdMLgPeu2c/UGTNmTE4//fRmKQ4AKHNNjcnMq5MbJydLXi72bT06j4z4QsY+8sM8PuvPSZIPbPGBnDn8zPTq1KuExQIAZaWiorjypseANW+IL3ll1SqZ2W+ulln0fDF0qV+SLFtQfMx7oGXq6tQj6b1lcRu4Nx59dkh6DU7W48uwlKmmxuIKnbcEOlnVV5FMPaO4NaSt2ABoRusc6vTt2zf7779/S9YCAJSDOdOL/4B98f5ie6OtU3/IlPxw+dP5n2lnpqHQkN6demfsiLE5ZNAhpa0VAGg/um5cfGyx95r9hUJxdc2iuUnd3OLWbcvrkuWL/umxMGlYkTQ1FG/GN63aJr66Y1JVk1R1TGo6JZ16Jp17vfmo7ffm9m62UOOfzZm25pZrb1Eo/n6cM624FR8ANJN1DnUAgA3cwueSv01IHvpNsd2xNjngjMzeev+cPX1iZr82O0ly6KBDc/aIs9O7k21HaAYOHgbaIp9NbUtFxZshTN8dS10NG4q3O/fp/Y4DgHUk1AEA3tnKpcnt3yk+GpYlqUh2/3Tq9z8jP3r6//KDv3wqDYWG9OzYM2ePODtjthhT6oppLxw8DLRFPpugfLRkANutT/OOA4B1JNQBANauUCiuyrlhQlL3fLFv0N7JmAvyeKfOOfvvX82sBbOSJAdvfnDGjhibjTtvXMKCaVfe7uDhuheL/Q4eBkrBZxOUj5YOYAeNKl6v7sWs/VydiuLzg0at/1wA8E+c5AcAvNUL9yU/HpP85vhioNNj8+TjP0vDcf+XK1+ekaP/eHRmLZiV2g61uXDfC3PxARcLdGg+73rwcIoHDzc1tmZVwIbOZxOUjzcC2H898+aNAPaR69Z/jsqqYkCUJKn4lydXtcdcYGtGAJrdOq3UaWpqauk6AIC24PX5yU2Tk/uuTlJIarok+5ycjDoxTy55IWf/5VN5+NWHkyQHDDwg40eMzyZdNiltzbQ/Dh4G2iKfTVAe3jWArSgGsEMOX//AZeiRxRV6a10RdIGVewC0CNuvAQBJw4pkxhXJ37+ZrHy92DfsE8nBE9LQvU9+9vDPctnMy1LfVJ/uHbrnzL3OzBFbHpGKin/9ViI0AwcPA22RzyYoD60dwA49shgQtdTZPQDwL4Q6ALAhKxSS2X9J/npW8trTxb7+uyUfuDAZuFeeWvRUxv3l03nglQeSJPtttl8mjJyQTbtsWsKiafccPAy0RT6boDyUIoCtrLJCD4BWI9QBgA3VS7OSqWcmT91cbHfrk4yemAw7Jo0p5P899NN8977vZmXTynSv6Z7T9jotH9rqQ1bn0PIcPAy0RT6boDwIYAFo54Q6ALChWbogueX85K4fJYXGpKpDMvLEZN+Tk47di6tzbh+XB14urs7Ze8DemThyYvp27VviwtlgvHHw8LXHpXjQ8D/fPHXwMFAiPpugPAhgAWjnKktdAADQShobkjuvTL67W3LnD4uBzpAjki/fmYyekMaaLvnJQz/Jx6/7eB54+YF0q+mWSaMm5fsHf1+gQ+t74+Dh2n5r9tf2L/Y7eBgoBZ9N0Pa9EcAmWR24riaABaD8VRQKhbV9bYEWVFdXlx49emTRokWpra0tdTkAbAievLm41drLs4rtTYcW/zG75f5JUlydc9u41WfnWJ1Dm9HU6OBhoO3x2QRt3yPXJVNPT+peeLOvdkDx78ACWADaoHXNDYQ6JSDUAaDVLHgq+evYZPafiu3OvZODzk52+0xSVZ3Gpsb87JGf5bL7LsvKppXpVtMtp+15Wo7a+ihn5wBAqQmPYP34fwiAMrKuuYEzdQCgPVrxenLrt5I7Lk8aVyYVVcleX0j2Pz3p0jtJ8tTCVWfnrFqds8+AfTJh5ASrc3h3bpAAtLy1rjLoX9xWyioDWDeVVcngfUtdBQA0K6EOALQnTU3J/dckN04u3nBPkq0OSg47P9l0SJKkoakhP3v4Z7l85uVZ2bQy3Wu657S9TsuHtvqQ1Tm8OzcZAVreI9cl1x6XtxzyXvdisb+5z+8R1gMAlA2hDgC0F3OmJ1PPSF6cWWz33rIY5mx7WLIqrHly4ZMZd/u4PPjKg0mSfQfsmwkjJ6RP1z4lKpqy0to3GQE2RE2NxfD8Xz9rk1V9FcU/74cc3jzBi7AeAKCsCHUAoNwtfDa5YXzy8O+K7Y61yX5fT4b/Z1LdIUlxdc5PH/5pLp95eeqb6tO9pntO3+v0HLnVkVbntAet8Q3r1r7JCLChmjNtzYDlLQpJ3dziuPXdVkpYDwBQdoQ6AFCuVixObrs4mfbdpHFFUlGZ7HZccuDYpNsmq4c98doTGXf7uDz06kNJkv022y/jR4y3Oqe9aK1vWLfmTUaADdkb26c217i3I6wHAChLQh0AKDdNTckDv0z+NilZPK/Yt8W+yZjzk747rR72ltU5HbrnjL3OyL9t+W9W57QXrfkN69a6yQiwoeu2jl+6WNdxb0dYDwBQloQ6AFBOnr2j+K3ZF+4rtnttkRx6TjLkiNXn5iTJ4689nnG3j8vDrz6cpLg6Z8LICdm0y6YlKJoW0drfsG6tm4wAG7pBo4orLutezNo/4yuKzw8atX7zCOsBAMqSUAcAysHC55K/TUge+k2x3aF7st+pyYj/Sqo7rh7W0NSQnzz0k3z//u+vXp1z5l5n5ogtj7A6p71p7W9Yt9ZNRoANXWVVcQvNa49LUpE1P3NX/Vk+5oL1D+yF9QAAZUmoAwBt2colyW2XJNMuTRqWJ6lIdvtUctC4pNuaq24ef+3xjL19bB559ZEkyf6b7Z/xI8dbndNetfY3rFvrJiMAxa0zj77qbc5Mu6B5ttYU1gMAlCWhDgC0RU1NyYPXJn+bmLz+YrFv0D7Fc3P6DVtjaH1T/erVOQ1NDantUJsz9jrD6pz2rhTfsG6Nm4wAFA09sriF5pxpxYC+W59iwNJc4XmpwvqmxpZ7T6WYBwCglVUUCoW1fSWHFlRXV5cePXpk0aJFqa2tLXU5ALQ1z91ZPAtl7j3Fds9BxXNztv+3Nc7NSZLHXnssY28bm1kLZiVJDtjsgIwfOT6bdNmktaumtTU1Jpfs+O7fsD7pwfK9IQdAy3vkurWE9QNaJqxf61z9i+FSc87VWvMAADSjdc0NhDolINQBYK0WPV9cmfPgr4vtDt2SfU9JRnwpqem0xtD6pvr8+MEf54oHrli9OufM4Wfm8MGHW52zIXnkulXfsE7W+g3ro69y8wqAd9caYf3qP7P+9RZEM/+Z1VrzsH58QQQA3kKo04YJdQBYw8qlye3fKT4aliWpSHY9NjlofNL9rVtnzV4wO+NuH/fm6pyBB2T8CKtzNlit+Q1rAHg/Vq8ufeFtBjTT6tLWmof1YyUVAKzVuuYGztQBgFIpFIqrcv42MambW+zbfFTx3Jz+u7xleH1TfX704I/ygwd+kIamhvTo2CNn7nVmPjj4g1bnbMha+swFAFhfc6a9Q9CSJIXi34XmTEsG79v25+H9e7uVVHUvFvutpAKAdyXUAYBSeP7u4rk5z99VbPfcPDlkSjL0Q285Nyd56+qcAwcemPEjx2fjzhu3ZtW0VZVVbk4B0HYtnt+840o9D+9PU2Nxhc5azwIsJKko/v14yOG+nAIA70CoAwCtadHc5MZJyQO/KrZruib7nZKM+PJbzs1Jiqtz/ufB/8kP7/9hGgrF1Tln7XVWPjD4A1bnAADlodtbt5Ndr3Glnof3x0oqAGgWQh0AaA0rlybTvpvcfklSvzRJRbLLscnB45Lufdf6ktkLZmfs7WPz6IJHkyQHDTwo40aOszoHACgvg0YVz0ypezFrX6Wx6qybQaPKYx7eHyupAKBZCHUAoCUVCslDv0lumJDUPV/sGzgi+cAFSf9d1/qS+sZVq3MeKK7O6dmxZ84aflbGbDHG6hwAoPxUViVjLlx1lkpF1gxcVv3dZswF67/lVmvNw/tjJRUANIvKUhcAAO3W3HuSHx2a/Ob4YqDTY2DysZ8kn5v6toHOowsezSf/9Mlcfv/laSg05ODND87vPvQ7260BAOVt6JHJ0Vcltf3W7K/tX+wfemR5zcN798ZKqrzd32krktoBVlIBwLuoKBQKa1uTTAuqq6tLjx49smjRotTW1pa6HACaW90LyY2Tk/t/UWzXdE32/Voy8sSkpvNaX1LfWJ8rH7wyVz5w5erVOWcPPzuHbXGYMAcAaD+aGotnpiyeX1yRMWhUy6ycaa15eG8euW7VSqpkrSupBG8AbMDWNTcQ6pSAUAegnapfVjw357aLV52bk2Tnf08OHv/Wb4v+k1mvzsrY28fmsdceS5KM3nx0zh5xtrNzAABofx65Lpl6evGLUG+oHVDcGk+gA8AGbF1zA2fqAMD6KhSSh39bPDdn0XPFvoHDkzHnJwN2f9uX1TfW54cP/jD/88D/pKHQkF4de+WsEWflsEFW5wAAlIX2tiKoNd7P0COTIYe3r58bALQioQ4ArI+59yZTz0yeu6PYrt0sOWRSsuNHk3cIZv51dc4hgw7J2cPPzkadN2qNqgEAWF9rXXHSPxlzYXmuOGnN91NZlQzet3mvCQAbCNuvlYDt1wDagboXk5umJDOvLrZruiT7rDo3p0OXt31ZfWN9fvDAD/I/D/5PGguN6dWxV84eUTw7BwCAMrH6bJh/vaVSpmfDtLf3AwBlyPZrANAS6pcl0y9L/vHtpH5JsW/YMcVzc3oMeMeXPvzqwxl3+7g8/trjSZJDBx2as4afZXUOAEA5aWosrmh5SwCSVX0VydQziluMlcOWYu3t/QBAOyfUAYB1USgkj/w+uX58sujZYt9mexUPdN3s7c/NSZKVjSvzgwd+kB89+KM0FhrTu1PvnDX8LKtzAADK0Zxpa25R9haFpG5ucVw5bDHW3t4PALRzQh0AeDcvzCyem/PstGK7dkAyelKy08fe8dycJHnw5Qczftr4PLHwiSTJYVsclrOGn5XenXq3cNEAALSIxfObd1yptbf3AwDtnFAHAN7O6/OTGyevOjenkFR3TvY5KRn13+94bk6SLG9YnstnXp6fPfKzNBWa0rtT75w9/OwcusWhrVI6AAAtpFuf5h1Xau3t/QBAOyfUAYB/Vb88uWPVuTkrFxf7djo6GT0h6bHZu7585kszM+72cXmm7pkkyQcHfzBn7HVGenXq1YJFAwDQKgaNSmr7J3UvZu3n0FQUnx80qvnmbGosbn+2eH4xXBk0qvnOtynF+wEA3jehDgC8oVBIZl2XXD8uWTin2Ddgj+K5OQP3fNeXL2tYlkvvvTRXz7o6hRSySedNMm7EuBy4+YEtXDgAAK2msioZc2Fy7XFJKrJmELJqa94xFzRf6PLIdcnU09c896a2f7GGoUeu//Vb+/0AAOulolAorO1rGLSgurq69OjRI4sWLUptbW2pywEgSV68P5l6VjLntmK7e//kkEnJjh9LKivf9eV3zbsrE6ZNyHOvP5ck+dBWH8rX9/x6enTs0ZJVAwBQKmsNWwYUA5DmCFvemOPa4/LWFTSrwpajr2reuVr6/QAAb2tdcwOhTgkIdQDakNfnJTdO+adzczole3+1+OjQ9V1fvrR+ab59z7fzq9m/SpL06dInE0ZOyL6b7dvChQMAUHItuS1aU2NyyY5rhixrWLUt2kkPNu+cLfV+AIB3tK65ge3XANgw1S9Lpn8v+cfFSf2SYt+OH0tGT0x6DlynS0x/YXomTpuYF5YU/6H90W0+mlP2OCXdO3RvoaIBAGhTKquSwS30ZZ45094h0EmSQlI3tziuuWpoyfcDADQLoQ4AG5ZCIXnoN8nfJiaLilulvZdzc5Lk9ZWv56K7L8pvHv9NkqR/1/6ZOGpiRvYf2UJFAwCwwVk8v3nHAQDtglAHgA3H83cnU89Mnr+z2K7drLgyZ6ePJRUV63SJfzz/j0yaPinzlxb/8XzMdsfka7t/LV1qurRQ0QAAbJC69WnecQBAuyDUAaD9W/R8cWXOg78utmu6Jvt8LRn55aTDuoUxi1Ysyjfu+kaue/K6JMnA7gMzadSk7Nl33Vb3AADAezJoVPHMnLoXk6ztOORVZ+oMGtXalQEAJSTUAaD9WrE4uf07ybRLk4blSSqSXf49OWhcUttvnS9z87M3Z8odU/LyspdTkYr8x9D/yFd2/Uo6V3duudoBANiwVVYlYy5Mrj0uSUXWDHZWrTIfc0FxHACwwRDqAND+NDUl9/8iuXFysnhesW/Q3slh5yX9d1nnyyxcvjDn33l+/vz0n5MkW9RukSl7T8kum677NQAA4H0bemRy9FXJ1NOTuhfe7K/tXwx0hh5ZutoAgJIQ6gDQvsyZVjw358WZxXavLZJDpiTb/9s6n5uTJNc/c33OnXFuFixfkMqKynx6h0/nSzt/KZ2qO7VI2QAAsFZDj0yGHF78e+7i+cUzdAaNskIHADZQQh0A2ocFTyc3jE9mFc+8ScfaZL9Tk+H/mVR3XOfLvLrs1Zw749zcMOeGJMnWPbfOlL2nZMeNd2yJqgEA4N1VViWD9y11FQBAGyDUAaC8LV+U3PqtZMYVSePKpKIy2f0zyQFnJd02WefLFAqF/OXpv+T8O8/PwhULU1VRleN3Oj5fHPbFdKjq0HL1AwAAAMA6EuoAUJ4aG5L7rkpuOjdZ+kqxb8sDk8POTfrs8J4u9fLSlzPljim5+bmbkyTb9douU/aeku032r65qwYAAACA902oA0D5efKm5K9nJy89UmxvtE0xzNnm0Pd0bk6hUMh1T16XC++6MK+vfD3VldX54rAv5vgdj09NVU0LFQ8AAAAA749QB4Dy8crjyfVjk8emFtudeiYHnJnseXzyHkOYeUvmZdL0Sblt7m1JkqEbDc2Uvadk217bNnPRAAAAANA8hDoAtH1LFyR/vzC563+SpoaksjrZ8wvJ/qclXXq/p0sVCoX85vHf5KK7L8ri+sWpqazJl3b5Uj6zw2dSXemPRQAAAADaLnevAGi7GuuTu36U3HJ+snxhsW/bMcmh5yQbb/OeLzd38dxMnDYxd7x4R5Jk2CbDMmXUlGzZc8tmLBoAAAAAWoZQB4C2p1BIHvtrcau1Vx8v9m06NDnsvGSrA9/z5ZoKTfnV7F/l4nsuzrKGZelY1TFf2fUr+Y/t/yNVlVXNXDwAAAAAtAyhDgBty/yHk7+elTx1S7HdZePkoLOTXY9Lqt77H1vP1T2X8dPG5+75dydJdtt0t0zee3IG1Q5qxqJhLZoakznTksXzk259kkGjEiEiAAAAsB6EOgC0DYtfTm4+N7n3Z0mhKanqkIz4r2TfU5JOPd7z5RqbGnPNo9fk0nsvzfLG5elc3Tlf3e2r+eSQT6ayorIF3gD8k0euS6aentS98GZfbf9kzIXJ0CNLVxcAAABQ1oQ6AJRWw4rkju8n/7goWVFX7Nv+yOSQyUnvwe/rkk8vejrjbx+fmS/PTJLs1XevTBw1MQO7D2ymouEdPHJdcu1xSQpr9te9WOw/+irBDgAAAPC+CHUAKI1CIZl1XXLD+OS1Z4p9/XZODjs/2WLv93XJhqaGXPXIVbnsvsuysmllutZ0zcm7n5yPbfsxq3NoHU2NxRU6/xroJKv6KpKpZyRDDrcVGwAAAPCeCXUAaH0v3Jf89exkzu3Fdre+yegJybBjksr3F7488doTGXf7uDz06kNJklH9R2XiyInp161fc1UN727OtDW3XHuLQlI3tzhu8L6tVhYAAADQPgh1AGg9dS8mN05O7v9FkkJS3SkZ9d/J3l9NOnZ7X5esb6rPTx76Sa64/4rUN9Wne033fH3Pr+eorY9KRUVF89YP72bx/OYdBwAAAPBPhDoAtLyVS5Pp30tuuzipX1rs2+no4uqcHpu978s+uuDRjL99fGYtmJUk2W+z/TJ+xPj06dqnOaqG967bOv7eW9dxAAAAAP9EqANAy2lqSh763+RvE4tbTiXJZnsmYy5INtvjfV92ZePKXHH/FfnJQz9JQ6EhtR1qc8ZeZ+SILY+wOofSGjQqqe1fXJW21nN1KorPDxrV2pUBAAAA7YBQB4CW8dydydQzk7l3F9u1myWHTEp2/GiyHsHL/S/fnwm3T8iTi55Mkhwy6JCcNfysbNx54+aoGtZPZVUy5sLk2uOSVGTNYGfV7/sxFxTHAQAAALxHQh0AmtfCZ4srcx76TbFd0zXZ92vJyBOTms7v+7LLGpblu/d9Nz9/5OcppJDenXrn7OFn59AtDm2euqG5DD0yOfqqZOrpSd0Lb/bX9i8GOkOPLF1tAAAAQFkT6gDQPFYsLp6ZM/17ScPyJBXJrscmB41Luvddr0vf+eKdmTBtQp5f/HyS5N+2/Lectudp6dmp5/rXDS1h6JHJkMOTOdOSxfOLZ+gMGmWFDgAAALBehDoArJ+mxmTm1clN5xRvXifJoH2SMecl/XZer0svXrk4377n2/n1Y79OkvTp0ifjR47Pfpvtt75VQ8urrEoG71vqKgAAAIB2RKgDwPv35M3J9WOT+Q8V2722SA49JxlyxHqdm5Mktz5/ayZPn5z5S4tB0dHbHp2v7f61dOvQbT2LBgAAAIDyJNQB4L17+bHkhnHJY1OL7Y49kv1PS/b6QlLdcb0uvXD5wnzjrm/kD0/9IUkysPvATBo1KXv23XN9qwYAAACAsibUAWDdLXk1ueX85O4fJ4XGpLI62eP4ZP/Tk64brfflr3/m+pw749wsWL4glRWV+Y/t/yMn7npiOld3bobiAQAAAKC8CXUAeHcNK5IZP0hu/VayYlGxb7sPJodMTjbeZr0v/8qyV3LuHefmb8/+LUmyVY+tMnnvyRm2ybD1vjYAAAAAtBdCHQDeXqGQPPJ/yQ3jk4Vzin19d0oOPTfZcv9muHwhf3jqD7nwzgtTt7Iu1RXV+dxOn8sXh30xHao6rPf1AQAAAKA9EeoAsHbP35P89azkuTuK7W59k4PHJTt/MqmsWu/Lv7j4xUy6Y1Jun3t7kmT73ttnyt5Tsl3v7db72gAAAADQHgl1AFjTwueSGycnD15bbFd3Tvb+72TUfycdu6335ZsKTfn17F/n2/d8O0sblqZDZYf81y7/lc/s8JlUV/pjCQAAAADejrtnABSteD257eJk+mVJw/Ji387/nhw0NukxoFmmeLbu2UyYNiF3z787SbLLJrtk0t6TsmWPLZvl+gAAAADQngl1ADZ0TY3Jff8vuencZMlLxb5B+ySHnZP037VZpmhsaszPZ/0837vve1neuDydqzvnq7t9Ncdsd0yqmmErNwAAAADYEAh1ADZkT96U/HVs8tLDxXbvLZNDpiRDDk8qKppliideeyLjp43Pg688mCQZ3m94Jo6cmM26b9Ys1wcAAACADUVlqQt4J5dddlm22GKLdOrUKcOHD8+dd975juN//etfZ8iQIenUqVN22mmn/PnPf17j+UKhkPHjx6dfv37p3LlzRo8enccff3yNMQsWLMixxx6b2tra9OzZM8cff3wWL168+vnZs2fnwAMPTJ8+fdKpU6dsueWWGTt2bOrr65vvjQO0tJceTa7+ePL/PlwMdDr1TA47P/nSjGT7I5ol0KlvrM/37/9+Pv7Hj+fBVx5M95rumTRqUq485EqBDgAAAAC8D2021PnVr36Vk08+ORMmTMi9996bnXfeOYcddlheeumltY6fNm1aPvnJT+b444/Pfffdl6OOOipHHXVUHnroodVjvvGNb+TSSy/NFVdckRkzZqRr16457LDDsnz58tVjjj322Dz88MO54YYb8sc//jG33nprTjjhhNXP19TU5Ljjjsv111+f2bNn55JLLsmVV16ZCRMmtNwPA6C5LHkl+dMpyfdHJY9fn1RWJ8P/K/nv+5KRX0qqOzTLNA+/+nCO+dMxuXzm5WloasgBmx2Q333od/nINh9JRTOtAAIAAACADU1FoVAolLqItRk+fHj23HPPfO9730uSNDU1ZeDAgfnKV76SM8444y3jP/GJT2TJkiX54x//uLpvxIgR2WWXXXLFFVekUCikf//+OeWUU3LqqacmSRYtWpQ+ffrkpz/9aY455pjMmjUrQ4cOzV133ZU99tgjSTJ16tR88IMfzPPPP5/+/fuvtdaTTz45d911V/7xj3+s03urq6tLjx49smjRotTW1r6nnwvA+9KwIplxRXLrt5IVdcW+IUckoyclG2/dbNMsb1ie79///fzs4Z+lsdCYXh175Yy9zsgHBn9AmAMAAAAAb2Ndc4M2uVJn5cqVueeeezJ69OjVfZWVlRk9enSmT5++1tdMnz59jfFJcthhh60e//TTT2fevHlrjOnRo0eGDx++esz06dPTs2fP1YFOkowePTqVlZWZMWPGWud94oknMnXq1Oy///5v+35WrFiRurq6NR4AraJQSB7+XfK9PZMbxhcDnb7Dkk//MTnm6mYNdO576b58/A8fz48f+nEaC435wBYfyO+P+n0+uOUHBToAAAAA0AyqS13A2rzyyitpbGxMnz591ujv06dPHn300bW+Zt68eWsdP2/evNXPv9H3TmM23XTTNZ6vrq5O7969V495w6hRo3LvvfdmxYoVOeGEEzJ58uS3fT/nn39+Jk2a9LbPA7SI5+9O/npW8tyqULp7v+Tg8cmwY5LK5sv0l9YvzXfu/U5+8egvUkghm3TeJONGjMuBmx/YbHMAAAAAAG10pU45+NWvfpV7770311xzTf70pz/lW9/61tuOPfPMM7No0aLVj+eee64VKwU2OAufS37z+eR/Di4GOjVdkgPOTL5yT7LLvzdroDP9hen5yHUfyTWPXpNCCvnw1h/O74/6vUAHAAAAAFpAm1yps/HGG6eqqirz589fo3/+/Pnp27fvWl/Tt2/fdxz/xq/z589Pv3791hizyy67rB7z0ksvrXGNhoaGLFiw4C3zDhw4MEkydOjQNDY25oQTTsgpp5ySqqqqt9TWsWPHdOzY8d3eNsD6WV6X3HZxcsflScPyJBXFEOegsUnt2s8Ee7/qVtblorsvym8f/22SpH/X/pkwakJG9R/VrPMAAAAAAG9qkyt1OnTokN133z033njj6r6mpqbceOONGTly5FpfM3LkyDXGJ8kNN9ywevzgwYPTt2/fNcbU1dVlxowZq8eMHDkyCxcuzD333LN6zE033ZSmpqYMHz78bettampKfX19mpqa3vubBVhfjQ3J3T9Jvrtbctu3i4HOFvsmX/x7ctTlzR7o3Pzszfnw7z+c3z7+21SkIv8+5N/zuw/9TqADAAAAAC2sTa7USZKTTz45n/70p7PHHntkr732yiWXXJIlS5bks5/9bJLkuOOOy4ABA3L++ecnSb761a9m//33z0UXXZTDDz88v/zlL3P33Xfnhz/8YZKkoqIiJ510Us4555xss802GTx4cMaNG5f+/fvnqKOOSpJsv/32GTNmTL7whS/kiiuuSH19fU488cQcc8wx6d+/eFP06quvTk1NTXbaaad07Ngxd999d84888x84hOfSE1NTev/oIAN2xM3JtePTV56pNjuvVVy6DnJdh9IKiqadaoFyxfkghkX5C/P/CVJskXtFpk0alJ267Nbs84DAAAAAKxdmw11PvGJT+Tll1/O+PHjM2/evOyyyy6ZOnVq+vTpkyR59tlnU/lP50KMGjUq11xzTcaOHZuzzjor22yzTX7/+99nxx13XD3mtNNOy5IlS3LCCSdk4cKF2WeffTJ16tR06tRp9Zirr746J554Yg4++OBUVlbmox/9aC699NLVz1dXV+fCCy/MY489lkKhkEGDBuXEE0/M1772tVb4qQCs8tKjxTDniRuK7U49i+fm7PG5pLpDs05VKBQy9ZmpOX/G+XltxWuprKjMZ3b4TP5r5/9Kp+pO734BAAAAAKBZVBQKhUKpi9jQ1NXVpUePHlm0aFFqa2tLXQ5QTha/nNxyfnLPT5NCY1JZk+x1QrLfqUmX3s0+3UtLX8qUO6bkluduSZJs02ubTBk1JTtsvEOzzwUAAAAAG6p1zQ3a7EodAP5J/fJkxveTf3w7WVFX7BtyRHLI5GSjrZp9ukKhkN8+/ttcdPdFeb3+9VRXVueEYSfk8zt+PjVVtpoEAAAAgFIQ6gC0ZYVC8vBvkxsmJoueLfb12yU57Lxki71bZMpn657NpOmTcue8O5MkO260YybvPTnb9NqmReYDAAAAANaNUAegrXruruSvZyXPF8OVdO+fjJ6Q7HR08k9nijWXhqaG/PyRn+eymZdleePydKrqlBN3PTH/sf1/pKqyqtnng5JoakzmTEsWz0+69UkGjUr8/gYAAADKhFAHoK15bU5y46Tkod8U2zVdkn2+low8MenQpUWmnL1gdiZMm5CHX304STK87/BMGDUhA7sPbJH5oCQeuS6ZenpS98KbfbX9kzEXJkOPLF1dAAAAAOtIqAPQVixbmPzjomTGFUnjyiQVya7HJgeOTWr7tciUKxtX5gcP/CA/fvDHaSg0pHtN93x9z6/nqK2PSkVFRYvMCSXxyHXJtcclKazZX/disf/oqwQ7AAAAQJsn1AEotcb65O4fJ7dckCxbUOwbvH9y6DlJv2EtNu19L92XCdMm5OlFTydJRm8+OmcNPyubdNmkxeaEkmhqLK7Q+ddAJ1nVV5FMPSMZcrit2AAAAIA2TagDUCqFQvLon5IbxicLniz2bTIkOWRKss0hSQutlFlSvyTfufc7+eWjv0whhWzUaaOcPeLsHDLokBaZD0puzrQ1t1x7i0JSN7c4bvC+rVYWAAAAwHsl1AEohbn3JNePS+bcXmx33SQ58Kxk1+OSqpb7aL5t7m2ZPH1yXlzyYpLkw1t/OKfscUp6dOzRYnNCyS2e37zjAAAAAEpEqAPQmhY+m9w4OXnw18V2dedk1InJ3l9NOnZvuWmXL8w37vpG/vDUH5IkA7oNyISREzKy/8gWmxPajG59mnccAAAAQIkIdQBaw/JFyT++ndzx/aRxRZKKZOdPJgeNTXoMaLFpC4VC/vrMX3P+nednwfIFqayozLHbH5sTdzkxXWq6tNi80KYMGpXU9k/qXszaz9WpKD4/aFRrVwYAAADwngh1AFpSY31yz0+TW85Plr5a7Bu8X3LoOUm/nVt06nlL5uXcO87NLc/fkiTZuufWmTRqUoZtMqxF54U2p7IqGXNhcu1xSSqyZrCz6uyqMRcUxwEAAAC0YUIdgJZQKCSz/5LcMD559fFi38bbJYdOSbY5NKmoaLGpmwpN+d/H/jcX33NxFtcvTnVldU4YdkI+v+PnU1NV02LzQps29Mjk6KuSqacndS+82V/bvxjoDD2ydLUBAAAArCOhDkBzm3tvcv24ZM5txXaXjZMDz0p2+3RS1bIfu3Pq5mTitIm5e/7dSZJhmwzLpJGTsnWvrVt0XigLQ49MhhyezJmWLJ5fPENn0CgrdAAAAICyIdQBaC4Ln0tumpI88Ktiu7pTMvLLyd4nJZ1qW3TqhqaGXPXIVbl85uVZ0bginas75793/e98csgnU+WGNbypsioZvG+pqwAAAAB4X4Q6AOtreV1y28XJHZcnDcuLfcOOSQ4am/Qc2OLTP7rg0Yy/fXxmLZiVJBnZb2TGjxyfzbpv1uJzAwAAAACtR6gD8H41NiT3/jS5+fxk6SvFvkH7JIedk/TftcWnX9G4Ilfcf0V+8tBP0lhoTG2H2py252k5cqsjU9GCZ/YAAAAAAKUh1AF4rwqF5LG/JjeMS155rNi30TbJIZOT7T6QtEKgcs/8ezJx2sQ8U/dMkuTQQYfmzOFnZuPOG7f43AAAAABAaQh1AN6LF+9P/np28sw/iu0uGyUHnJns/pmkqqbFp1+8cnEuufeS/Gp28dyeTTpvkrNHnJ2DNz+4xecGAAAAAEpLqAOwLhY9n9x0TnL/L5MUkqqOycgvJft8LenUo1VKuPX5WzN5+uTMXzo/SfLRbT6ak/c4ObUdaltlfgAAAACgtIQ6AO9kxevJbZck07+XNCwv9u10dHLwuKTn5q1SwoLlC3LhnRfmz0//OUmyWbfNMnHUxAzvN7xV5gcAAAAA2gahDsDaNDYk912V3HxesuTlYt+gvZNDz0kG7NYqJRQKhfz56T/nwjsvzGsrXktlRWWOG3pcvrTLl9K5unOr1AAAAAAAtB1CHYB/Vigkj9+Q3DAuefnRYt9GWyeHTE62+2BSUdEqZcxbMi9T7piSW5+/NUmyTa9tMnnU5Oy48Y6tMj8AAAAA0PYIdQDe8OIDyfVjk6f/Xmx37p0ccGayx2eTqppWKaGp0JRfz/51Lr734iypX5Kaypp8cdgX87kdP5eaVqoBAAAAAGibhDoAdS8kN52TzLwmSSGp6pCM+K9kn5OTzj1brYynFz2didMm5t6X7k2S7LLJLpk0alK27Lllq9UAAAAAALRdQh1gw7Xi9eT2S5Np300alhX7dvxYcvD4pNegViujvqk+P3v4Z/n+zO9nZdPKdK7unJN2OynHDDkmlRWVrVYHAAAAANC2CXWADU9jQzLz58lN5yZLXir2bT4yOfScZLM9WrWUh155KBOnTczs12YnSfYesHfGjxif/t36t2odAAAAAEDbJ9QBNhyFQvLE35LrxyUvzyr29d4yGT0p2f7fkoqKVitlaf3SXDbzsvx81s/TVGhKz449c9qep+WILY9IRSvWAQAAAACUD6EOsGGY91By/djkqZuL7c69kv3PSPb4XFLdoVVLuX3u7Zlyx5TMXTw3SXL4lofntD1PS+9OvVu1DgAAAACgvAh1gPZt0dzkpnOS+3+RpJBUdUiGfzHZ95RisNOKXlv+Wr551zfzh6f+kCTp17Vfxo0Yl30327dV6wAAAAAAypNQB2ifltclt12c3HF50rC82LfDR5KDxye9B7dqKYVCIX96+k/5xp3fyGsrXktFKnLs9sfmK7t+JV1qurRqLQAAAABA+RLqAO1LY31y90+Sv1+QLH212Lf5qOTQc5LNdm/1cuYunpspd0zJ7XNvT5Js02ubTBw5McM2GdbqtQAAAAAA5U2oA7QPhUIy6w/J3yYmC54s9m20TXLIpGS7DyYVFa1aTmNTY6559Jp8977vZlnDsnSo7JD/3Pk/85kdP5OayppWrQUAAAAAaB+EOkD5e+7O5PpxyXN3FNtdN0kOOCPZ7dNJVesHKLMXzM7EaRPz0KsPJUl277N7JoyckME9WnfbNwAAAACgfRHqAOXr1SeTGyclj/xfsV3dORn1lWTv/046dm/1clY0rsgP7v9BfvLQT9JQaEj3mu752h5fy0e3+WgqKypbvR4AAAAAoH0R6gDlZ8mrya3fSO76UdJUn1RUJrscmxx4dlLbryQl3TXvrkyePjnP1D2TJBm9+eicOfzMbNpl05LUAwAAAAC0P0IdoHzUL0tmXJH849vJirpi39aHFM/N6bNDSUqqW1mXb9/97fzm8d8kSTbpvEnOGn5WRg8aXZJ6AAAAAID2S6gDtH1NTcmD1yY3Tknqni/29d0pOfScZMsDSlbW3+b8LefOODevLHslSfLxbT+ek3Y/KbUdaktWEwAAAADQfgl1gLbtyZuTG8Yl8x4stms3Sw4el+x0dFJZmnNq5i+Zn/NmnJebnrspSbJF7RaZMHJC9ui7R0nqAQAAAAA2DEIdoG2a/3Byw/jkib8V2x1rk31PTob/Z1LTuSQlNRWa8r+P/W8uvufiLK5fnOqK6nxup8/lhGEnpGNVx5LUBAAAAABsOIQ6QNtS90Jy87nJzGuSQlNSWZ3s+flkv9OSrhuVrKynFj2VSdMm5d6X7k2S7LTxTpk4amK27bVtyWoCAAAAADYsQh2gbVjxenL7d5Jp30salhX7hn4oOXhCstFWJSurvrE+P3roR/nhAz9MfVN9Old3zld3+2qO2e6YVFVWlawuAAAAAGDDI9QBSquxPrn3Z8ktFyRLXi72DRyeHHpOMnCvkpZ2/8v3Z+K0iXli4RNJkn0G7JNxI8alf7f+Ja0LAAAAANgwCXWA0igUktl/Tm6YkLz6eLGv91bJIZOSIUckFRUlK21J/ZJ8977v5ppZ16SQQnp17JXT9zo9Hxz8wVSUsC5ol5oakznTksXzk259kkGjEqvgAAAAANZKqAO0vufvSa4fmzw7rdjuslFywJnJ7p9JqmpKWtqtz9+aKXdMybwl85IkR251ZE7d49T06tSrpHVBu/TIdcnU04tnab2htn8y5sJk6JGlqwsAAACgjRLqAK1nwdPJjZOTh39bbFd3SkZ+Odn7pKRTbUlLe3XZq7nwrgvzl6f/kiQZ0G1Axo8Yn1EDRpW0Lmi3Hrkuufa4JIU1++teLPYffZVgBwAAAOBfCHWAlrd0QXLrN5M7r0ya6pNUJLv8e3Lg2UmPASUtrVAo5Lonr8s37/5mFq1YlMqKynxq+0/lS7t8KV1qupS0Nmi3mhqLK3T+NdBJVvVVJFPPSIYcbis2AAAAgH8i1AFaTv3y5M4fJLdelKxYVOzb6qDkkMlJ351KW1uS515/LpOnT84dL96RJNmu13aZNGpSdth4hxJXBu3cnGlrbrn2FoWkbm5x3OB9W60sAAAAgLZOqAM0v6am5KH/TW6ckix6ttjXZ8dimLP1waWtLUlDU0N+/sjPc9nMy7K8cXk6VnXMf+38Xzluh+NSU1naM31gg7B4fvOOAwAAANhACHWA5vX0rcn1Y5MX7y+2u/dPDhqb7HxMm9hG6ZFXH8nEaRMza8GsJMmefffMhJETMqh2UIkrgw1Itz7NOw4AAABgAyHUAZrHS7OSGyYkj/+12O7QPdnnpGTEl5IOpT+bZmn90lw+8/L8v1n/L02FpnTv0D2n7nFqPrz1h1NRUVHq8mDDMmhUUts/qXsxaz9Xp6L4/KBRrV0ZAAAAQJsm1AHWT92LyS3nJff9PCk0JZXVye6fTfY/Pem2SamrS5L84/l/5Jw7zskLS4pneIzZYkxO3+v0bNx54xJXBhuoyqpkzIXJtcclqciawc6qkHXMBW1idR8AAABAWyLUAd6f5XXJ7d9Jpl+WNCwr9m3/b8nBE5ONty5paW94Zdkr+cad38hfnvlLkqRf134ZO2Js9ttsvxJXBmTokcnRVyVTT0/qXnizv7Z/MdAZemTpagMAAABoo4Q6wHvTsDK5+8fJrd9Ilr5a7Bs4PDlkcrL5iNLWtkqhUMjvnvhdvnX3t/L6ytdTWVGZ/9j+P/LlXb6cLjWl3woOWGXokcmQw5M505LF84tn6AwaZYUOAAAAwNsQ6gDrplBIHv5tcuPk5LVnin0bbZOMnli8KdtGzqV5etHTmTx9cu6ef3eSZPve22fCqAnZYaMdSlwZsFaVVcngfUtdBQAAAEBZEOoA7+7pW5Mbxicv3Fdsd+uTHHBGsutxSVXb+BhZ2bgyP3roR7nygStT31SfztWd8+Vdvpxjtz821ZVto0YAAAAAgPXhTifw9uY/nPxtYvL49cV2h27JqP9ORn456ditpKX9s3vn35tJ0yflqUVPJUn2HrB3xo0YlwHdBpS4MgAAAACA5iPUAd5q0dzk5vOSmVcnKSSV1cnun032Py3ptmmpq1utbmVdLrnnkvz6sV8nSXp36p0z9jojY7YYk4o2sh0cAAAAAEBzEeoAb1q2MLnt4mTGFUnD8mLf0A8lB09INtqqpKX9s0KhkOvnXJ8L7rwgryx7JUnykW0+kpN3Pzk9OvYocXUAAAAAAC1DqAMkDSuSu/4nufWbybLXin2bj0oOmZwM3LO0tf2LFxe/mHNnnJu/P//3JMkWtVtk/Mjx2bNv26oTAAAAAKC5CXVgQ9bUlDz0m+SmycnCZ4t9mwxJRk9Mth2TtKEtzBqbGvOLR3+RS++7NMsalqW6sjqf3+nz+fxOn0/Hqo6lLg8AAAAAoMUJdWBD9eTNyd8mJC/eX2x375cceFay878nVW3ro+HRBY9m4rSJefjVh5Mku266ayaMnJCteradLeEAAAAAAFpa27pzC7S8eQ8mN0xInryx2O7QPdnnpGTEl5IOXUpa2r9a1rAs35/5/Vz1yFVpLDSme033nLT7SfnYth9LZUVlqcsDAAAAAGhVQh3YUCx8Lrn53OT+XyYpJJU1yZ7HJ/t9Pem6camre4vb596eKXdMydzFc5Mkhww6JGfudWY26bJJiSsDAAAAACgNoQ60d8teS/5xUTLjh0njimLfDh9JDh6X9N6ytLWtxavLXs037/5m/vTUn5Ikfbr0ydnDz86Bmx9Y4soAAAAAAEpLqAPtVf3y5M4fJv/4VrJ8UbFvi32TQyYlA3YvbW1rUSgU8n9P/l++dfe3smjFolSkIsduf2xO3PXEdK3pWuryAAAAAABKTqgD7U1TY/LAtcWt1hY9V+zbdGgyelKyzSFJRUVp61uLOXVzMnn65Nw5784kyXa9tsuEkROy0yY7lbgyAAAAAIC2Q6gD7UWhkDx5Y3LDxGT+g8W+2gHJgWcnOx+TVFaVtLy1qW+sz08e/kl+cP8PsrJpZTpVdcp/7fJf+dTQT6WmsqbU5QEAAAAAtClCHWgPXpiZ3DA+efrvxXbHHsm+X0uG/2dS07mkpb2dmS/NzKTpk/LEwieSJCP7jcy4keMysPvAElcGAAAAANA2CXWgnL32THLTOcmDvy62qzoke34h2e/UpEvvkpb2dl5f+Xq+c+93cu3sa1NIIb069sppe52Wwwcfnoo2uDUcAAAAAEBbIdSBcrR0QXLrt5K7rkwaVxb7djo6OWhs0mtQaWt7G4VCITc+e2POn3F+Xlr2UpLkQ1t9KKfucWp6dupZ2uIAAAAAAMqAUAfKSf2y5I7vJ7ddkqxYVOzb8oBk9KSk/y4lLOydvbj4xZw347zc8vwtSZLNu2+e8SPHZ3i/4aUtDAAAAACgjAh1oBw0NSb3/yK5+bykbm6xr89OySGTkq0PLm1t76ChqSFXz7o6l828LMsalqW6sjqf3eGzOWHYCelU3anU5QEAAAAAlBWhDrRlhUIy+y/JjZOTl2cV+3oMLG6zttPRSWVlaet7Bw+98lAmTZ+URxc8miTZbdPdMm7EuGzda+sSVwYAAAAAUJ6EOtBWPXtHcsOE5Lk7iu1OPZN9T0n2OiGpaburXBavXJxL77s0v3z0lymkkNoOtTllj1Ny1NZHpbKi7YZQAAAAAABtnVAH2pqXHk1unJTM/nOxXd05GfGfyd4nJZ17lrKyd1QoFPK3Z/+WC2ZckJeWvZQkOWLLI3LqHqdmo84blbg6AAAAAIDyJ9SBtmLR88kt5yczr0kKTUlFZbLrp5IDzkhq+5e6unf0wuIXct6M8/L35/+eJNm8++YZO2JsRvYfWeLKAAAAAADaD6EOlNrSBcltFyd3/jBpWF7s2/7fkoPGJ5tsW9ra3kVDU0OunnV1Lpt5WZY1LEt1ZXU+t+Pn8oWdvpBO1W13izgAAAAAgHIk1IFSqV+WzPhBctu3k+WLin2D9k5GT0oG7lna2tbBgy8/mMl3TM6jCx5Nkuy26W6ZMHJCtuy5ZYkrAwAAAABon4Q60NoaG5L7r0luPj95/YVi36Y7JKMnJtscklRUlLS8d/P6ytfz3fu+m18++ssUUkhth9qcsscpOWrro1JZUVnq8gAAAAAA2i2hDrSWQiF59E/JjZOTV2YX+3oMTA48Oxl2dFJZVdr63kWhUMgNc27IhXdemJeWvZQkOWLLI3LqHqdmo84blbg6AAAAAID2T6gDrWHOtOSGCcnzdxbbnXsl+3092eP4pKbtnz0zd/HcnDfjvNz6/K1Jks27b56xI8ZmZP+RJa4MAAAAAGDDIdSBljT/keTGScljU4vt6s7JyC8le3816dSjtLWtg4amhvz8kZ/n8vsvz7KGZamurM7xOx6fLwz7QjpWdSx1eQAAAAAAGxShDrSEhc8lt5yfzLwmSSGpqEp2Oy7Z//Sktl+pq1snD7z8QCZPn5zZrxW3ittt090yYeSEbNlzyxJXBgAAAACwYRLqQHNauiD5x0XJnVcmjSuKfUM/lBw0Ltl4m9LWto5eX/l6Lr330vxq9q9SSCE9OvbIKbufkg9t/aFUVlSWujwAAAAAgA2WUAeaw8qlyYzvJ7d9J1mxqNi3xb7J6EnJZruXtrZ1VCgUcsOcG3LBnRfk5WUvJ0mO3OrInLLHKendqXeJqwMAAAAAQKgD66OxIZn58+SWC5LXXyz29dkpGT0x2frgpKKipOWtq7mL5+a8Gefl1udvTZIMqh2UcSPGZXi/4SWuDAAAAACANwh14P0oFJJZf0hunJy8+nixr+fmxW3WdvxYUlke25TVN9Xn54/8PN+///tZ1rAs1ZXV+fxOn8/nd/p8OlZ1LHV5AAAAAAD8E6EOvFfP3JbcMCGZe3ex3WWjZL/Tkj0+m1SXTxDywMsPZNL0SXnstceSJLv32T3jR4zPlj23LHFlAAAAAACsjVAH1tW8h5IbJyWPX19s13RNRn45GfWVpFNtaWt7D15f+Xq+c+93cu3sa1NIIT069sgpu5+So7Y+KhVlsl0cAAAAAMCGSKgD72bhs8nN5yX3/zJJIamsTnb/THF1Tvc+pa5unRUKhVw/5/pceOeFeXnZy0mSI7c6MqfscUp6d+pd4uoAAAAAAHg3Qh14O0teTf5xUXLXlUnjymLfDh8unpuz0Valre09eu7153LujHNz+9zbkySDagdl3IhxGd5veIkrAwAAAABgXQl14F+tWJzM+H5y+6XJirpi3+D9ktGTkgG7lba292hl48r89OGf5ocP/DArGlekprImx+90fD6/0+fTsap8zv8BAAAAAECoA29qWJnc+7Pk799IlrxU7Os7LBk9MdnqoKTMzpu5a95dmXLHlDy96OkkyfB+wzN2+Nhs0WOL0hYGAAAAAMD7ItSBpqbkof9NbjonWTin2NdrcHLQ2GSHjySVlaWt7z16ddmr+fY93851T16XJOndqXdO2/O0fHDwB1NRZsEUAAAAAABvEuqw4SoUksf+mtw4OXnp4WJftz7J/qcnux2XVNWUtr73qKnQlN88/ptccs8lqVtZl4pU5Ojtjs5Xdv1KenTsUeryAAAAAABYT0IdNkxzpid/m5g8d0ex3bFHss9JyfAvJh26lrKy92X2gtmZcseU3P/y/UmSIb2HZNyIcRm2ybASVwYAAAAAQHMR6rBhmfdQcWXO438ttqs7JcP/M9n7q0mX3qWt7X1YWr80l8+8PD+f9fM0FhrTpbpLTtz1xHxyyCdTXel/bwAAAACA9sRdXzYMC55Obj4vefDXSQpJRVVxi7X9T0tq+5e6uvesUCjkpuduyvkzzs/8pfOTJIcMOiSn73l6+nTtU+LqAAAAAABoCUId2rfX5ye3fjO55ydJU0Oxb8ePJgeenWy0VWlre59eWPxCzp9xfm55/pYkyYBuA3LW8LOy32b7lbYwAAAAAABalFCH9mn5ouT2S5M7Lk/qlxb7th6dHDw+6bdzaWt7n+qb6vP/Hvl/ueL+K7KsYVmqK6vz2R0+my8M+0I6V3cudXkAAAAAALQwoQ7tS/2y5M4rk9u+nSx7rdi32Z7JwROSwfuWtrb1cO/8ezPljil5YuETSZLd++yecSPGZaue5bnaCAAAAACA906oQ/vQ2JDMvDq55YLk9ReKfZsMKa7M2e6DSUVFaet7n15b/louvufi/O6J3yVJenXslVP2OCVHbnVkKsr0PQEAAAAA8P4IdShvTU3JrP9LbjonebW4iiU9BiYHnpUM+0RSWVXa+t6nQqGQ3z/x+3z7nm9n4YqFSZKPbvPRnLTbSenZqWdJawMAAAAAoDSEOpSnQiF56ubkb5OSF2cW+7pslOz39WSPzyXVHUta3vp44rUnMuWOKbn3pXuTJNv02ibjRozLrpvuWuLKAAAAAAAoJaEO5ef5e5IbJyZP31psd+iWjPpKMvLLScfuJS1tfSytX5ofPPCDXPXwVWkoNKRzded8aecv5dihx6amsqbU5QEAAAAAUGJCHcrHy7OTm6Yks/5QbFd1SPb8fLLvKUnXjUtb23r6+3N/z3kzzssLS4rnAR008KCcsdcZ6detX4krAwAAAACgrRDq0PYtfC75+wXJzGuSQlNSUZns/MnkgDOSnpuXurr1Mm/JvFxw5wW58dkbkyT9uvbLmXudmQM3P7DElQEbtKbGZM60ZPH8pFufZNCosj2jDAAAAKA9EerQdi15Nbnt28mdVyaNK4p9Q45IDhqbbLp9aWtbTw1NDbl61tW5bOZlWdawLNUV1fnUDp/Kfw77z3Sp6VLq8oAN2SPXJVNPT+peeLOvtn8y5sJk6JGlqwsAAAAAoQ5t0IrFyR2XJ7dfmqx8vdg3aJ9k9MRk4J4lLa053P/y/ZkyfUpmvzY7SbLrprtm7Iix2bbXtiWuDNjgPXJdcu1xSQpr9te9WOw/+irBDgAAAEAJCXVoOxpWJPf8NPn7N5KlrxT7+g5LRk9Itjo4qagoaXnra+Hyhbnk3kvym8d/kyTp0bFHTt795By19VGprKgscXXABq+psbhC518DnWRVX0Uy9YxkyOG2YgMAAAAoEaEObcO8h5JffjJZ+Gyx3Xur5KCzk6EfTirLO/BoKjTl90/8Phffc3EWrliYJPnQVh/KyXucnN6depe2OIA3zJm25pZrb1FI6uYWxw3et9XKAgAAAOBNQh3ahl5bJPXLk+79kv1PT3b9j6SqptRVrbfZC2Znyh1Tcv/L9ydJtu65dcaNGJfd+uxW4soA/sXi+c07DgAAAIBmJ9ShbejYLTn218nG2yYdupS6mvW2eOXiXDbzslzz6DVpKjSlS3WXfGmXL+Xft//31FSWf1gFtEPd+jTvOAAAAACanVCHtqP/LqWuYL0VCoVMfWZqvnnXN/PyspeTJIcOOjRf3/Pr6du1b4mrA3gHg0Yltf2Tuhez9nN1KorPDxrV2pUBAAAAsIpQB5rJU4ueynl3nJcZ82YkSTbvvnnOHn52Rg1wAxQoA5VVyZgLk2uPS1KRNYOdiuIvYy4ojgMAAACgJIQ6sJ6WNSzLlQ9cmZ88/JM0NDWkY1XHfH6nz+ezO342Has6lro8gHU39Mjk6KuSqacndS+82V/bvxjoDD2ydLUBAAAAINSB9XHLc7fk/Bnn54UlxZuf+w7YN2cOPzMDuw8sbWEA79fQI5MhhydzpiWL5xfP0Bk0ygodAAAAgDZAqAPvw9zFc3PBjAtyy/O3JEn6du2bM/Y6IwcNPCgVFRWlLQ5gfVVWJYP3LXUVAAAAAPwLoQ68BysbV+ZnD/8sP3zgh1neuDzVFdX59A6fzgnDTkiXmi6lLg8AAAAAgHZMqAPraPoL03PejPPyTN0zSZI9++6Zs4efna16blXawgAAAAAA2CAIdeBdvLT0pXzrrm/lL8/8JUmyUaeNcuqep+bwwYfbag0AAAAAgFYj1IG30dDUkF88+otcNvOyLKlfksqKyhyz3TH58q5fTm2H2lKXBwAAAADABkaoA2sx86WZmXLHlDz22mNJkp023iljR4zN0I2GlrgyAAAAAAA2VEId+CevLX8tl9x7SX77+G+TJLUdavO13b+Wj2zzkVRWVJa4OgAAAAAANmRCHUjSVGjKbx//bS6595IsWrEoSfLhrT+ck3Y/Kb079S5xdQAAAAAAINSBzHp1Vs6545w88MoDSZJte22bsSPGZtdNdy1xZQAAAAAA8CahDhus11e+nu/d9738cvYv01RoSpfqLjlx1xPzySGfTHWl/zUAAAAAAGhb3Llmg1MoFPLHp/6Yi+6+KK8ufzVJMmaLMTl1j1PTp2ufElcHAAAAAABrJ9RhgzJ7weycN+O83PvSvUmSLWq3yJnDz8yo/qNKXBkAAAAAALwzoQ4bhNdXvp7LZl6WXz76yzQWGtO5unNOGHZCjht6XDpUdSh1eQAAAAAA8K6EOrRra9tq7ZBBh+Tre3w9/br1K3F1AAAAAACw7oQ6tFu2WgMAAAAAoD0R6tDu2GoNAAAAAID2SKhDu1EoFPKHp/6Qb9/97TW2Wjttz9PSt2vfElcHAAAAAADrR6hDu2CrNQAAAAAA2juhDmXtja3WfvHoL9JUaLLVGgAAAAAA7ZZQh7JkqzUAAAAAADY0Qh3Kjq3WAAAAAADYEAl1KBt1K+ty+czL19hq7YvDvpjjhh6XmqqaUpcHAAAAAAAtSqhDm/fGVmsX3X1RFixfkCQ5dNCh+fqeX7fVGgAAAAAAGwyhDm3a2rZaO2v4WRnZf2SJKwMAAAAAgNYl1KFNWttWa/+583/mU9t/ylZrAAAAAABskIQ6tClr22rtsC0Oy6l7nGqrNQAAAAAANmhCHdqM2Qtm59wZ5+a+l+5LkgzuMThn7nWmrdYAAAAAACBCHdqImS/NzKenftpWawAAAAAA8DaEOrQJwzYZlh032jH9uvWz1RoAAAAAAKyFUIc2obKiMlceemW61HQpdSkAAAAAANAmVZa6AHiDQAcAAAAAAN6eUAcAAAAAAKAMCHUAAAAAAADKgFAHAAAAAACgDAh1AAAAAAAAyoBQBwAAAAAAoAwIdQAAAAAAAMqAUAcAAAAAAKAMCHUAAAAAAADKgFAHAAAAAACgDAh1AAAAAAAAyoBQBwAAAAAAoAwIdQAAAAAAAMqAUAcAAAAAAKAMCHUAAAAAAADKgFAHAAAAAACgDAh1AAAAAAAAyoBQBwAAAAAAoAwIdQAAAAAAAMqAUAcAAAAAAKAMCHUAAAAAAADKgFAHAAAAAACgDAh1AAAAAAAAyoBQBwAAAAAAoAwIdQAAAAAAAMqAUAcAAAAAAKAMCHUAAAAAAADKgFAHAAAAAACgDAh1AAAAAAAAyoBQBwAAAAAAoAwIdQAAAAAAAMqAUAcAAAAAAKAMCHUAAAAAAADKgFAHAAAAAACgDAh1AAAAAAAAyoBQBwAAAAAAoAwIdQAAAAAAAMqAUAcAAAAAAKAMCHUAAAAAAADKgFAHAAAAAACgDAh1AAAAAAAAyoBQBwAAAAAAoAwIdQAAAAAAAMqAUAcAAAAAAKAMCHUAAAAAAADKgFAHAAAAAACgDAh1AAAAAAAAyoBQBwAAAAAAoAwIdQAAAAAAAMqAUAcAAAAAAKAMCHUAAAAAAADKgFAHAAAAAACgDAh1AAAAAAAAyoBQBwAAAAAAoAwIdQAAAAAAAMqAUAcAAAAAAKAMCHUAAAAAAADKgFAHAAAAAACgDAh1AAAAAAAAyoBQBwAAAAAAoAwIdQAAAAAAAMqAUAcAAAAAAKAMCHUAAAAAAADKgFAHAAAAAACgDFSXugAAYB00NSZzpiWL5yfd+iSDRiWVVaWuCgAAAIBWJNQBgLbukeuSqacndS+82VfbPxlzYTL0yNLVBQAAAECrsv0aALRlj1yXXHvcmoFOktS9WOx/5LrS1AUAAABAqxPqAEBb1dRYXKGTwlqeXNU39YziOAAAAADaPaEOALRVc6a9dYXOGgpJ3dziOAAAAADaPaEOALRVi+c37zgAAAAAyppQBwDaqm59mnccAAAAAGVNqAMAbdWgUUlt/yQVbzOgIqkdUBwHAAAAQLsn1AGAtqqyKhlz4arGvwY7q9pjLiiOAwAAAKDdE+oAQFs29Mjk6KuS2n5r9tf2L/YPPbI0dQEAAADQ6qpLXQAA8C6GHpkMOTyZMy1ZPL94hs6gUVboAAAAAGxghDoAUA4qq5LB+5a6CgAAAABKyPZrAAAAAAAAZUCoAwAAAAAAUAaEOgAAAAAAAGVAqAMAAAAAAFAGhDoAAAAAAABlQKgDAAAAAABQBoQ6AAAAAAAAZUCoAwAAAAAAUAaEOgAAAAAAAGWgTYc6l112WbbYYot06tQpw4cPz5133vmO43/9619nyJAh6dSpU3baaaf8+c9/XuP5QqGQ8ePHp1+/funcuXNGjx6dxx9/fI0xCxYsyLHHHpva2tr07Nkzxx9/fBYvXrz6+VtuuSUf+tCH0q9fv3Tt2jW77LJLrr766uZ70wAAAAAAAGvRZkOdX/3qVzn55JMzYcKE3Hvvvdl5551z2GGH5aWXXlrr+GnTpuWTn/xkjj/++Nx333056qijctRRR+Whhx5aPeYb3/hGLr300lxxxRWZMWNGunbtmsMOOyzLly9fPebYY4/Nww8/nBtuuCF//OMfc+utt+aEE05YY55hw4blN7/5TR544IF89rOfzXHHHZc//vGPLffDAAAAAAAANngVhUKhUOoi1mb48OHZc889873vfS9J0tTUlIEDB+YrX/lKzjjjjLeM/8QnPpElS5asEa6MGDEiu+yyS6644ooUCoX0798/p5xySk499dQkyaJFi9KnT5/89Kc/zTHHHJNZs2Zl6NChueuuu7LHHnskSaZOnZoPfvCDef7559O/f/+11nr44YenT58++fGPf7xO762uri49evTIokWLUltb+55+LgAAAAAAQPuyrrlBm1yps3Llytxzzz0ZPXr06r7KysqMHj0606dPX+trpk+fvsb4JDnssMNWj3/66aczb968Ncb06NEjw4cPXz1m+vTp6dmz5+pAJ0lGjx6dysrKzJgx423rXbRoUXr37v22z69YsSJ1dXVrPAAAAAAAAN6LNhnqvPLKK2lsbEyfPn3W6O/Tp0/mzZu31tfMmzfvHce/8eu7jdl0003XeL66ujq9e/d+23mvvfba3HXXXfnsZz/7tu/n/PPPT48ePVY/Bg4c+LZjAQAAAAAA1qZNhjrl4uabb85nP/vZXHnlldlhhx3edtyZZ56ZRYsWrX4899xzrVglAAAAAADQHrTJUGfjjTdOVVVV5s+fv0b//Pnz07dv37W+pm/fvu84/o1f323MSy+9tMbzDQ0NWbBgwVvm/fvf/55/+7d/y8UXX5zjjjvuHd9Px44dU1tbu8YDAAAAAADgvWiToU6HDh2y++6758Ybb1zd19TUlBtvvDEjR45c62tGjhy5xvgkueGGG1aPHzx4cPr27bvGmLq6usyYMWP1mJEjR2bhwoW55557Vo+56aab0tTUlOHDh6/uu+WWW3L44YfnwgsvzAknnLD+bxgAAAAAAOBdVJe6gLdz8skn59Of/nT22GOP7LXXXrnkkkuyZMmS1WfXHHfccRkwYEDOP//8JMlXv/rV7L///rnoooty+OGH55e//GXuvvvu/PCHP0ySVFRU5KSTTso555yTbbbZJoMHD864cePSv3//HHXUUUmS7bffPmPGjMkXvvCFXHHFFamvr8+JJ56YY445Jv37909S3HLtiCOOyFe/+tV89KMfXX3WTocOHdK7d+9W/ikBAAAAAAAbijYb6nziE5/Iyy+/nPHjx2fevHnZZZddMnXq1PTp0ydJ8uyzz6ay8s2FRqNGjco111yTsWPH5qyzzso222yT3//+99lxxx1XjznttNOyZMmSnHDCCVm4cGH22WefTJ06NZ06dVo95uqrr86JJ56Ygw8+OJWVlfnoRz+aSy+9dPXzP/vZz7J06dKcf/75qwOlJNl///1zyy23tOBPBAAAAAAA2JBVFAqFQqmL2NDU1dWlR48eWbRokfN1AAAAAABgA7euuUGbPFMHAAAAAACANQl1AAAAAAAAyoBQBwAAAAAAoAwIdQAAAAAAAMqAUAcAAAAAAKAMCHUAAAAAAADKgFAHAAAAAACgDAh1AAAAAAAAyoBQBwAAAAAAoAwIdQAAAAAAAMqAUAcAAAAAAKAMCHUAAAAAAADKgFAHAAAAAACgDAh1AAAAAAAAyoBQBwAAAAAAoAwIdQAAAAAAAMqAUAcAAAAAAKAMCHUAAAAAAADKgFAHAAAAAACgDAh1AAAAAAAAyoBQBwAAAAAAoAwIdQAAAAAAAMqAUAcAAAAAAKAMCHUAAAAAAADKgFAHAAAAAACgDAh1AAAAAAAAyoBQBwAAAAAAoAwIdQAAAAAAAMqAUAcAAAAAAKAMCHUAAAAAAADKgFAHAAAAAACgDAh1AAAAAAAAyoBQBwAAAAAAoAwIdQAAAAAAAMqAUAcAAAAAAKAMCHUAAAAAAADKgFAHAAAAAACgDAh1AAAAAAAAyoBQBwAAAAAAoAwIdQAAAAAAAMqAUAcAAAAAAKAMCHUAAAAAAADKgFAHAAAAAACgDAh1AAAAAAAAyoBQBwAAAAAAoAwIdQAAAAAAAMqAUAcAAAAAAKAMCHUAAAAAAADKgFAHAAAAAACgDAh1AAAAAAAAyoBQBwAAAAAAoAwIdQAAAAAAAMqAUAcAAAAAAKAMCHUAAAAAAADKgFAHAAAAAACgDAh1AAAAAAAAyoBQBwAAAAAAoAwIdQAAAAAAAMqAUAcAAAAAAKAMCHUAAAAAAADKgFAHAAAAAACgDAh1AAAAAAAAyoBQBwAAAAAAoAwIdQAAAAAAAMqAUAcAAAAAAKAMCHUAAAAAAADKgFAHAAAAAACgDAh1AAAAAAAAyoBQBwAAAAAAoAwIdQAAAAAAAMqAUAcAAAAAAKAMCHUAAAAAAADKgFAHAAAAAACgDAh1AAAAAAAAyoBQBwAAAAAAoAwIdQAAAAAAAMqAUAcAAAAAAKAMCHUAAAAAAADKgFAHAAAAAACgDAh1AAAAAAAAyoBQBwAAAAAAoAwIdQAAAAAAAMqAUAcAAAAAAKAMCHUAAAAAAADKgFAHAAAAAACgDAh1AAAAAAAAyoBQBwAAAAAAoAwIdQAAAAAAAMqAUAcAAAAAAKAMCHUAAAAAAADKgFAHAAAAAACgDAh1AAAAAAAAyoBQBwAAAAAAoAwIdQAAAAAAAMqAUAcAAAAAAKAMCHUAAAAAAADKgFAHAAAAAACgDAh1AAAAAAAAyoBQBwAAAAAAoAwIdQAAAAAAAMqAUAcAAAAAAKAMCHUAAAAAAADKgFAHAAAAAACgDAh1AAAAAAAAyoBQBwAAAAAAoAwIdQAAAAAAAMqAUAcAAAAAAKAMCHUAAAAAAADKgFAHAAAAAACgDAh1AAAAAAAAyoBQBwAAAAAAoAwIdQAAAAAAAMqAUAcAAAAAAKAMCHUAAAAAAADKgFAHAAAAAACgDAh1AAAAAAAAyoBQBwAAAAAAoAwIdQAAAAAAAMqAUAcAAAAAAKAMCHUAAAAAAADKgFAHAAAAAACgDAh1AAAAAAAAyoBQBwAAAAAAoAwIdQAAAAAAAMqAUAcAAAAAAKAMCHUAAAAAAADKgFAHAAAAAACgDAh1AAAAAAAAyoBQBwAAAAAAoAwIdQAAAAAAAMqAUAcAAAAAAKAMCHUAAAAAAADKgFAHAAAAAACgDAh1AAAAAAAAyoBQBwAAAAAAoAwIdQAAAAAAAMqAUAcAAAAAAKAMCHUAAAAAAADKgFAHAAAAAACgDAh1AAAAAAAAyoBQBwAAAAAAoAwIdQAAAAAAAMqAUAcAAAAAAKAMCHUAAAAAAADKgFAHAAAAAACgDAh1AAAAAAAAyoBQBwAAAAAAoAwIdQAAAAAAAMqAUAcAAAAAAKAMCHUAAAAAAADKgFAHAAAAAACgDAh1AAAAAAAAyoBQBwAAAAAAoAwIdQAAAAAAAMqAUAcAAAAAAKAMCHUAAAAAAADKgFAHAAAAAACgDAh1AAAAAAAAyoBQBwAAAAAAoAwIdQAAAAAAAMqAUAcAAAAAAKAMCHUAAAAAAADKgFAHAAAAAACgDAh1AAAAAAAAyoBQBwAAAAAAoAwIdQAAAAAAAMqAUAcAAAAAAKAMCHUAAAAAAADKgFAHAAAAAACgDAh1AAAAAAAAyoBQBwAAAAAAoAwIdQAAAAAAAMqAUAcAAAAAAKAMCHUAAAAAAADKgFAHAAAAAACgDAh1AAAAAAAAyoBQBwAAAAAAoAwIdQAAAAAAAMqAUAcAAAAAAKAMCHUAAAAAAADKgFAHAAAAAACgDAh1AAAAAAAAyoBQBwAAAAAAoAwIdQAAAAAAAMqAUAcAAAAAAKAMCHUAAAAAAADKgFAHAAAAAACgDAh1AAAAAAAAyoBQBwAAAAAAoAwIdQAAAAAAAMqAUAcAAAAAAKAMCHUAAAAAAADKgFAHAAAAAACgDAh1AAAAAAAAyoBQBwAAAAAAoAwIdQAAAAAAAMqAUAcAAAAAAKAMCHUAAAAAAADKgFAHAAAAAACgDAh1AAAAAAAAyoBQBwAAAAAAoAwIdQAAAAAAAMqAUAcAAAAAAKAMCHUAAAAAAADKgFAHAAAAAACgDAh1AAAAAAAAyoBQBwAAAAAAoAwIdQAAAAAAAMqAUAcAAAAAAKAMCHX4/+3deVyVZd7H8e9hxwVwBXHFItGGFDdCLXUkt9RMS0MxNSd1NCt1NFt5WmaqadEslclMK3czHTP1ScU1kAwl19SnXDNwQUAxQD3X84fDmY6gYXLEWz/v1+u8eHHdv+s+v+vYFeG3+74BAAAAAAAAAIAFEOoAAAAAAAAAAABYAKEOAAAAAAAAAACABRDqAAAAAAAAAAAAWAChDgAAAAAAAAAAgAUQ6gAAAAAAAAAAAFgAoQ4AAAAAAAAAAIAFEOoAAAAAAAAAAABYAKEOAAAAAAAAAACABRDqAAAAAAAAAAAAWAChDgAAAAAAAAAAgAUQ6gAAAAAAAAAAAFgAoQ4AAAAAAAAAAIAFEOoAAAAAAAAAAABYAKEOAAAAAAAAAACABRDqAAAAAAAAAAAAWAChDgAAAAAAAAAAgAUQ6gAAAAAAAAAAAFgAoQ4AAAAAAAAAAIAFEOoAAAAAAAAAAABYAKEOAAAAAAAAAACABRDqAAAAAAAAAAAAWAChDgAAAAAAAAAAgAUQ6gAAAAAAAAAAAFjADRvqTJo0SXXq1JGPj48iIyP17bffXrF+wYIFCgsLk4+Pj8LDw7Vs2TKn48YYvfTSS6pWrZp8fX0VHR2tffv2OdVkZGSob9++8vPzU0BAgAYNGqQzZ844jufm5mrAgAEKDw+Xh4eHunfvXmLrBQAAAAAAAAAAuJIbMtSZN2+eRo0apbi4OG3ZskUNGzZUhw4ddOzYsSLrExMTFRMTo0GDBmnr1q3q3r27unfvrh07djhq/vnPf2rixImKj49XcnKyypYtqw4dOig3N9dR07dvX+3cuVMrV67U0qVLtX79eg0ePNhx/MKFC/L19dWTTz6p6Oho130AAAAAAAAAAAAAl7AZY0xpN3GpyMhINWvWTB988IEkyW63q2bNmhoxYoTGjRtXqL53797KycnR0qVLHWN33323GjVqpPj4eBljFBwcrNGjR+tvf/ubJCkrK0uBgYGaMWOGHnnkEe3evVsNGjTQ5s2b1bRpU0nSihUr1LlzZx05ckTBwcFO7zlgwABlZmZq8eLFV72+7Oxs+fv7KysrS35+flc9HwAAAAAAAAAA3DyKmxvccFfq5OfnKyUlxelKGDc3N0VHRyspKanIOUlJSYWunOnQoYOjfv/+/UpLS3Oq8ff3V2RkpKMmKSlJAQEBjkBHkqKjo+Xm5qbk5ORrWlNeXp6ys7OdXgAAAAAAAAAAAFfjhgt1Tpw4oQsXLigwMNBpPDAwUGlpaUXOSUtLu2J9wdffq6latarTcQ8PD1WsWPGy71tcr7/+uvz9/R2vmjVrXtP5AAAAAAAAAADAreeGC3VuRs8++6yysrIcr8OHD5d2SwAAAAAAAAAAwGJuuFCncuXKcnd3V3p6utN4enq6goKCipwTFBR0xfqCr79Xc+zYMafj58+fV0ZGxmXft7i8vb3l5+fn9AIAAAAAAAAAALgaN1yo4+XlpSZNmmj16tWOMbvdrtWrVysqKqrIOVFRUU71krRy5UpHfUhIiIKCgpxqsrOzlZyc7KiJiopSZmamUlJSHDUJCQmy2+2KjIwssfUBAAAAAAAAAAD8ER6l3UBRRo0apf79+6tp06Zq3ry5JkyYoJycHA0cOFCS9Oijj6p69ep6/fXXJUlPPfWUWrdurXfeeUf333+/5s6dq++++04ffvihJMlms+npp5/Wa6+9ptDQUIWEhOjFF19UcHCwunfvLkmqX7++OnbsqMcff1zx8fE6d+6cnnjiCT3yyCMKDg529LZr1y7l5+crIyNDp0+fVmpqqiSpUaNG1+3zAQAAAAAAAAAAt54bMtTp3bu3jh8/rpdeeklpaWlq1KiRVqxYocDAQEnSoUOH5Ob234uMWrRoodmzZ+uFF17Qc889p9DQUC1evFh/+tOfHDVjx45VTk6OBg8erMzMTLVq1UorVqyQj4+Po2bWrFl64okn1K5dO7m5ualnz56aOHGiU2+dO3fWwYMHHd9HRERIkowxLvksAAAAAAAAAAAAJMlmSCOuu+zsbPn7+ysrK4vn6wAAAAAAAAAAcIsrbm5wwz1TBwAAAAAAAAAAAIUR6gAAAAAAAAAAAFgAoQ4AAAAAAAAAAIAFEOoAAAAAAAAAAABYAKEOAAAAAAAAAACABXiUdgMAAFiS/YJ0MFE6ky6VC5Rqt5Dc3Eu7KwAAAAAAANzECHUAALhau5ZIK56Rso/+d8wvWOr4ptSgW+n1BQAAAAAAgJsat18DAOBq7FoizX/UOdCRpOxfLo7vWlI6fQEAAAAAAOCmR6gDAEBx2S9cvEJHpoiD/xlbMe5iHQAAAAAAAFDCCHUAACiug4mFr9BxYqTsny/WAQAAAAAAACWMUAcAgOI6k16ydQAAAAAAAMBVINQBAKC4ygWWbB0AAAAAAABwFQh1AAAortotJL9gSbbLFNgkv+oX6wAAAAAAAIASRqgDAEBxublLHd/8zzeXBjv/+b7jGxfrAAAAAAAAgBJGqAMAwNVo0E3q9ankV8153C/44niDbqXTFwAAAAAAAG56HqXdAAAAltOgmxR2v3QwUTqTfvEZOrVbcIUOAAAAAAAAXIpQBwCAP8LNXQq5p7S7AAAAAAAAwC2E268BAAAAAAAAAABYAKEOAAAAAAAAAACABRDqAAAAAAAAAAAAWAChDgAAAAAAAAAAgAUQ6gAAAAAAAAAAAFgAoQ4AAAAAAAAAAIAFEOoAAAAAAAAAAABYAKEOAAAAAAAAAACABRDqAAAAAAAAAAAAWAChDgAAAAAAAAAAgAUQ6gAAAAAAAAAAAFgAoQ4AAAAAAAAAAIAFEOoAAAAAAAAAAABYAKEOAAAAAAAAAACABRDqAAAAAAAAAAAAWAChDgAAAAAAAAAAgAUQ6gAAAAAAAAAAAFgAoQ4AAAAAAAAAAIAFEOoAAAAAAAAAAABYAKEOAAAAAAAAAACABRDqAAAAAAAAAAAAWAChDgAAAAAAAAAAgAUQ6gAAAAAAAAAAAFgAoQ4AAAAAAAAAAIAFEOoAAAAAAAAAAABYAKEOAAAAAAAAAACABRDqAAAAAAAAAAAAWAChDgAAAAAAAAAAgAUQ6gAAAAAAAAAAAFgAoQ4AAAAAAAAAAIAFEOoAAAAAAAAAAABYAKEOAAAAAAAAAACABRDqAAAAAAAAAAAAWAChDgAAAAAAAAAAgAUQ6gAAAAAAAAAAAFgAoQ4AAAAAAAAAAIAFEOoAAAAAAAAAAABYAKEOAAAAAAAAAACABRDqAAAAAAAAAAAAWAChDgAAAAAAAAAAgAUQ6gAAAAAAAAAAAFgAoQ4AAAAAAAAAAIAFEOoAAAAAAAAAAABYAKEOAAAAAAAAAACABRDqAAAAAAAAAAAAWAChDgAAAAAAAAAAgAUQ6gAAAAAAAAAAAFgAoQ4AAAAAAAAAAIAFEOoAAAAAAAAAAABYAKEOAAAAAAAAAACABRDqAAAAAAAAAAAAWAChDgAAAAAAAAAAgAUQ6gAAAAAAAAAAAFgAoQ4AAAAAAAAAAIAFEOoAAAAAAAAAAABYAKEOAAAAAAAAAACABRDqAAAAAAAAAAAAWAChDgAAAAAAAAAAgAUQ6gAAAAAAAAAAAFgAoQ4AAAAAAAAAAIAFEOoAAAAAAAAAAABYAKEOAAAAAAAAAACABXiUdgO3ImOMJCk7O7uUOwEAAAAAAAAAAKWtIC8oyA8uh1CnFJw+fVqSVLNmzVLuBAAAAAAAAAAA3ChOnz4tf3//yx63md+LfVDi7Ha7jh49qvLly8tms5V2O0Cpyc7OVs2aNXX48GH5+fmVdjsArhF7Gri5sKeBmwf7Gbi5sKeBmwf7Gb9ljNHp06cVHBwsN7fLPzmHK3VKgZubm2rUqFHabQA3DD8/P35wATcR9jRwc2FPAzcP9jNwc2FPAzcP9jMKXOkKnQKXj3sAAAAAAAAAAABwwyDUAQAAAAAAAAAAsABCHQClxtvbW3FxcfL29i7tVgCUAPY0cHNhTwM3D/YzcHNhTwM3D/Yz/gibMcaUdhMAAAAAAAAAAAC4Mq7UAQAAAAAAAAAAsABCHQAAAAAAAAAAAAsg1AEAAAAAAAAAALAAQh0AAAAAAAAAAAALINQB4FIZGRnq27ev/Pz8FBAQoEGDBunMmTNXnJObm6vhw4erUqVKKleunHr27Kn09PQia0+ePKkaNWrIZrMpMzPTBSsAUMAV+/n7779XTEyMatasKV9fX9WvX1/vvfeeq5cC3JImTZqkOnXqyMfHR5GRkfr222+vWL9gwQKFhYXJx8dH4eHhWrZsmdNxY4xeeuklVatWTb6+voqOjta+fftcuQQAv1GSe/rcuXN65plnFB4errJlyyo4OFiPPvqojh496uplAFDJ/4z+raFDh8pms2nChAkl3DWAy3HFnt69e7e6desmf39/lS1bVs2aNdOhQ4dctQTc4Ah1ALhU3759tXPnTq1cuVJLly7V+vXrNXjw4CvOGTlypL788kstWLBA69at09GjR9WjR48iawcNGqS77rrLFa0DuIQr9nNKSoqqVq2qmTNnaufOnXr++ef17LPP6oMPPnD1coBbyrx58zRq1CjFxcVpy5YtatiwoTp06KBjx44VWZ+YmKiYmBgNGjRIW7duVffu3dW9e3ft2LHDUfPPf/5TEydOVHx8vJKTk1W2bFl16NBBubm512tZwC2rpPf02bNntWXLFr344ovasmWLvvjiC+3Zs0fdunW7nssCbkmu+BldYNGiRdq0aZOCg4NdvQwA/+GKPf3jjz+qVatWCgsL09q1a7Vt2za9+OKL8vHxuV7Lwo3GAICL7Nq1y0gymzdvdowtX77c2Gw28/PPPxc5JzMz03h6epoFCxY4xnbv3m0kmaSkJKfayZMnm9atW5vVq1cbSebUqVMuWQcA1+/n3xo2bJhp27ZtyTUPwDRv3twMHz7c8f2FCxdMcHCwef3114us79Wrl7n//vudxiIjI82QIUOMMcbY7XYTFBRk3nrrLcfxzMxM4+3tbebMmeOCFQD4rZLe00X59ttvjSRz8ODBkmkaQJFctZ+PHDliqlevbnbs2GFq165txo8fX+K9AyjMFXu6d+/eJjY21jUNw5K4UgeAyyQlJSkgIEBNmzZ1jEVHR8vNzU3JyclFzklJSdG5c+cUHR3tGAsLC1OtWrWUlJTkGNu1a5deeeUVffrpp3Jz419lgKu5cj9fKisrSxUrViy55oFbXH5+vlJSUpz2opubm6Kjoy+7F5OSkpzqJalDhw6O+v379ystLc2pxt/fX5GRkVfc3wCunSv2dFGysrJks9kUEBBQIn0DKMxV+9lut6tfv34aM2aM7rzzTtc0D6AQV+xpu92ur776SnfccYc6dOigqlWrKjIyUosXL3bZOnDj429CAbhMWlqaqlat6jTm4eGhihUrKi0t7bJzvLy8Cv3yGBgY6JiTl5enmJgYvfXWW6pVq5ZLegfgzFX7+VKJiYmaN2/e797WDUDxnThxQhcuXFBgYKDT+JX2Ylpa2hXrC75ezTkBlAxX7OlL5ebm6plnnlFMTIz8/PxKpnEAhbhqP7/55pvy8PDQk08+WfJNA7gsV+zpY8eO6cyZM3rjjTfUsWNHff3113rwwQfVo0cPrVu3zjULwQ2PUAfAVRs3bpxsNtsVXz/88IPL3v/ZZ59V/fr1FRsb67L3AG4Vpb2ff2vHjh164IEHFBcXp/bt21+X9wQAAM7OnTunXr16yRijKVOmlHY7AK5SSkqK3nvvPc2YMUM2m6202wFwjex2uyTpgQce0MiRI9WoUSONGzdOXbp0UXx8fCl3h9LiUdoNALCe0aNHa8CAAVesqVu3roKCggo9CO78+fPKyMhQUFBQkfOCgoKUn5+vzMxMp/+7Pz093TEnISFB27dv1+effy5JMsZIkipXrqznn39eL7/88h9cGXDrKe39XGDXrl1q166dBg8erBdeeOEPrQVA0SpXrix3d3elp6c7jRe1FwsEBQVdsb7ga3p6uqpVq+ZU06hRoxLsHsClXLGnCxQEOgcPHlRCQgJX6QAu5or9vGHDBh07dszprhYXLlzQ6NGjNWHCBB04cKBkFwHAwRV7unLlyvLw8FCDBg2caurXr6+NGzeWYPewEq7UAXDVqlSporCwsCu+vLy8FBUVpczMTKWkpDjmJiQkyG63KzIysshzN2nSRJ6enlq9erVjbM+ePTp06JCioqIkSQsXLtT333+v1NRUpaam6qOPPpJ08T9ehw8f7sKVAzef0t7PkrRz5061bdtW/fv319///nfXLRa4RXl5ealJkyZOe9Fut2v16tVOe/G3oqKinOolaeXKlY76kJAQBQUFOdVkZ2crOTn5sucEUDJcsael/wY6+/bt06pVq1SpUiXXLACAgyv2c79+/bRt2zbH78upqakKDg7WmDFj9L//+7+uWwwAl+xpLy8vNWvWTHv27HGq2bt3r2rXrl3CK4BlGABwoY4dO5qIiAiTnJxsNm7caEJDQ01MTIzj+JEjR0y9evVMcnKyY2zo0KGmVq1aJiEhwXz33XcmKirKREVFXfY91qxZYySZU6dOuXIpwC3PFft5+/btpkqVKiY2Ntb88ssvjtexY8eu69qAm93cuXONt7e3mTFjhtm1a5cZPHiwCQgIMGlpacYYY/r162fGjRvnqP/mm2+Mh4eHefvtt83u3btNXFyc8fT0NNu3b3fUvPHGGyYgIMD8+9//Ntu2bTMPPPCACQkJMb/++ut1Xx9wqynpPZ2fn2+6detmatSoYVJTU51+Jufl5ZXKGoFbhSt+Rl+qdu3aZvz48a5eCgDjmj39xRdfGE9PT/Phhx+affv2mffff9+4u7ubDRs2XPf14cZAqAPApU6ePGliYmJMuXLljJ+fnxk4cKA5ffq04/j+/fuNJLNmzRrH2K+//mqGDRtmKlSoYMqUKWMefPBB88svv1z2PQh1gOvDFfs5Li7OSCr0ql279nVcGXBreP/9902tWrWMl5eXad68udm0aZPjWOvWrU3//v2d6ufPn2/uuOMO4+XlZe68807z1VdfOR232+3mxRdfNIGBgcbb29u0a9fO7Nmz53osBYAp2T1d8DO8qNdvf64DcI2S/hl9KUId4PpyxZ6eNm2auf32242Pj49p2LChWbx4sauXgRuYzZj/PIwCAAAAAAAAAAAANyyeqQMAAAAAAAAAAGABhDoAAAAAAAAAAAAWQKgDAAAAAAAAAABgAYQ6AAAAAAAAAAAAFkCoAwAAAAAAAAAAYAGEOgAAAAAAAAAAABZAqAMAAAAAAAAAAGABhDoAAADATaxOnTqy2WyaMWNGabcClLijR4+qfPny6tq1q9P42rVrZbPZ1KZNm2Kfa+bMmbLZbJo8eXIJdwkAAACUHEIdAAAAAIAljRkzRmfPntU//vGPaz5Xnz59FB4erhdffFEZGRkl0B0AAABQ8gh1AAAAAACWs3nzZs2ePVs9e/ZUeHj4NZ/Pzc1NcXFxysjI0GuvvVYCHQIAAAAlj1AHAAAAAGA5EyZMkCQNGjSoxM7ZrVs3ValSRdOmTdOZM2dK7LwAAABASSHUAQAAAODkyJEjGjFihEJDQ+Xj4yN/f3+1bNlS//rXv3ThwoUi5xhj9PHHH6tp06YqU6aMKlWqpE6dOikxMfEPPd9Ekg4cOCCbzaY6derIbrdr4sSJuuuuu1SmTBlVq1ZNQ4cOddwmKy8vT6+++qrCwsLk6+ur4OBgPfXUU8rJybns+efOnat27dqpYsWK8vb2Vu3atfXYY49p7969RdYXPJ/owIEDWrNmjdq3b68KFSrI19dXjRs31qeffnrF9Xz++efq2LGjqlSpIi8vL1WvXl2xsbHatWuXU92aNWtks9kUFhYmY0yR58rNzVWlSpVks9mc5ttsNtlsNknSwoUL1apVK/n5+als2bJq2bKlli1bdtn+zp8/r48++kht2rRxfCYhISH661//qsOHDxc5Z9WqVeratasCAwPl6empChUqKDQ0VLGxsVq/fr1TbV5ent566y01adJE5cuXl5eXl4KCgtSsWTONHTv2qm55lp6ers8//1zBwcG67777ij1Pko4fP64WLVrIZrOpd+/eysvLcxzz9PRUnz59lJ2drc8+++yqzgsAAABcD4Q6AAAAABw2b96shg0b6oMPPlB+fr66d++uFi1aaMuWLRo6dKjuv/9+5efnF5o3fPhwDRo0SFu3blXz5s3Vvn17HT58WPfee6+WLl16zX3FxsZq3Lhxql69ujp06CC73a5//etfio6OVk5OjqKjo/X222+rXr16io6O1tmzZzVx4kQ9/PDDhc5ljFH//v0VExOj9evXKyIiQj169JCPj4+mT5+uiIgIrVix4rK9fPzxx2rXrp0yMjLUsWNHNWrUSFu3blX//v0dV4/81vnz59W7d289/PDDWrt2re644w51795dVapU0axZs9S0aVOn92vbtq3Cw8O1Z88erVq1qsge5syZo4yMDLVt21YNGjQodDwuLs6x9s6dOys0NFSJiYnq0qWLFi1aVKj+9OnTuu+++/T4448rJSVFd911l7p16yZvb2/Fx8crIiJCW7dudZrzySefqH379vrqq68UEhKinj176t5775Wfn5/mzp2rL774wlFrt9t1//33a+zYsfq///s/3XPPPXrooYcUHh6u48eP66233tKhQ4cu+5lfatmyZcrPz9ef//xnubkV/9favXv3KioqSklJSRo7dqzmzp0rb29vp5qCkGjx4sXFPi8AAABw3RgAAAAAN63atWsbSWb69Om/W5ubm+uoHzp0qMnPz3cc+/HHH02dOnWMJPPcc885zfv3v/9tJJly5cqZb775xunYO++8YyQZSaZ169ZX1fv+/fsdc2+77TZz4MABx7ETJ06Y0NBQI8mEh4eb5s2bmxMnTjiO//TTT6ZChQpGktm4caPTeadMmWIkmcqVK5utW7c6xu12u4mLizOSTEBAgDl27JjTvILPxtPT03z55ZdOx6ZPn24kGX9/f3P27FmnY88995yRZCIjI81PP/3kdGzBggXG3d3dVKhQwZw6dcoxPnXqVCPJdOvWrcjPpkmTJkaSWbhwodN4wecVEBBgNm3a5HSsYG133HFHofP16dPHSDJdunQx6enpTsfGjx9vJJnQ0FBz/vx5x3hISIiRZDZs2FDofOnp6WbLli2O79etW2ckmYiICJOdnV2ofvPmzU5/fr8nNjbWSDKTJk0q8viaNWsK/TO3fv16U7FiRePu7m7i4+Mve+6TJ08am81mypQpY/Ly8ordEwAAAHA9cKUOAAAAAEnSggULdPDgQQUHB2vChAny9PR0HKtbt67efvttSdL777+v3Nxcx7H33ntPkjRixAi1aNHC6ZyjRo1Ss2bNrrm3iRMnqnbt2o7vK1WqpL/+9a+SpB07dmjatGmqVKmS43hISIhiY2MlSatXr3Y6V8E6XnrpJTVq1MgxbrPZFBcXp7vuukuZmZmaOnVqkb2MGDFCXbp0cRobMGCAwsLClJWVpe+++84xnpGRofHjx8vHx0cLFy5USEiI07yHHnpIQ4YM0alTpzRz5kzHeN++fVWpUiUtXbpUBw8edJqzadMmpaSkqGbNmnrggQeK7PGVV15RZGSk09izzz4rf39/7d271+l2art379acOXMUHBys2bNnq2rVqk7znn76aXXu3Fn79u3T8uXLHePp6eny9/dXq1atCr1/1apVFRER4VQrSffcc4/Kly9fqL5p06ZOf36/p+Cqofr16xerfs6cObrvvvuUn5+vL7/8UkOGDLlsbcWKFRUUFKSzZ8/qhx9+KHZPAAAAwPVAqAMAAABAkrR27VpJ0iOPPFLollSS1KNHD1WoUEGnT59WSkqKpIu3FktMTJR0MYgoSp8+fa6pLw8PD7Vv377QeGhoqCSpVq1a+tOf/nTZ40ePHnWMHTlyRD/++KMkqX///oXm2Gw2DRw4UNLFZ9sUpWvXrkWOFwQMP//8s2NszZo1+vXXX9WyZUtVr169yHkFzxoq+BwlydfXV4MHD5bdbteUKVOc6idNmiRJGjp0qNzd3Yvdo7e3t+rWrVuox2XLlskYo06dOhUZuFyux+bNmysrK0uPPvqoUlJSZLfbi5wrSY0bN5a7u7s+/vhjTZo0Sb/88stla4ujICQqThD0j3/8wxGSbdiwQZ06dfrdOQXnLXgfAAAA4EZBqAMAAABA0n//ov/Sq0kK2Gw2x7GC2hMnTjiu2qlTp06R84oaP3HihAYMGFDo9cYbbxSqrVatmjw8PAqNlytXTtLFUKcoBQHFb68qKui7UqVK8vPzK3Lebbfd5lR7qcu9X8H5fvt+P/30k6SLVwvZbLYiX7169ZIkHT9+3Ol8w4YNk4eHh6ZNm+Y45/Hjx7VgwQJ5e3vr8ccfL7KPP9rjtGnTLtvj2LFjC/U4efJk1a1bV5999pmaNm2qgIAAtWvXTn//+98LPR/ntttu0/jx43Xu3Dk98cQTCg4OVp06dRQTE6NZs2YV+ZymK8nKynJaz+V88803ev755+Xt7a3169c7XZl1JQXnPXXq1FX1BQAAALha4d+MAAAAAKAE2Wy2QmNnzpzRJ598Umi8devWGjdunNOYm9uV/1+03zte0q7m/QquXrn99tvVsmXLK9aGhYU5fV+jRg316NFD8+fP17x589S/f3999NFHysvLU79+/VSlSpUS7bFRo0Zq2LDhFWt/e0u3+vXra8+ePfr666+VkJCgxMREbdiwQQkJCXrllVc0bdo0xy3wpIu3revVq5eWLFmijRs3auPGjZo7d67mzp2ruLg4bdiwQdWqVStWzwEBATp+/Liys7OvWHfnnXfK09NT3333nUaMGKGFCxfK19f3d89fEBpVqFChWP0AAAAA1wuhDgAAAABJctwerODKjaLs37/fqbZSpUry9vZWXl6eDh48qAYNGhSac+DAgUJjderUkTGmBLq+OgV9nzx5UtnZ2UVe6VGw/svdLu1q1KxZU5JUr149zZgx46rnP/nkk5o/f74mTZqk2NhYxcfHS5KeeOKJa+7t0h5btmypDz744Krmenh4qHPnzurcubMkKTs7W++++65efvllDRkyRA8++KDKli3rqA8MDNTjjz/uuMrohx9+0GOPPaakpCSNGzeuyKCvKFWrVtXx48d18uTJK9YFBARoyZIl6tKli5YvX65OnTpp6dKljqu8LqfgvIGBgcXqBwAAALheuP0aAAAAAEn/fW7KvHnznG7PVWDRokU6deqUypcvryZNmkiSPD09FRUVJUmaPXt2keedM2eOaxr+A2rUqOG4vVpRIYsxxjHetm3ba36/du3aycvLS2vXrtWxY8euen7Lli3VpEkTbd68WS+88IIOHTqkZs2aqXnz5tfcW4GCZ8wsWbKkyD/3q+Hn56f/+Z//UUBAgM6ePau9e/desT4sLEzPPPOMJCk1NbXY79O4cWNJ0q5du4rV04oVK9S+fXutW7dO0dHRV7yt2smTJ5WWlqYyZco4npMEAAAA3CgIdQAAAABIkh5++GHVqlVLR48e1ahRo3T+/HnHsf3792v06NGSLt5Gy8fHx3HsySeflCRNnDhRmzZtcjrne++9p+Tk5OvQffH97W9/kyS9+uqr+v777x3jxhi99tprSk1NVUBAwBWfWVNcgYGBGjFihHJyctS1a1dt3769UE1eXp6WLFmiH374ochzPPXUU5LkeN5QSV6lI0kRERHq2bOnDh8+rB49ehR5ZVVOTo5mzZql9PR0SdLZs2f17rvvFnoOkCRt2LBBmZmZcnd3V40aNSRJCQkJWrZsmc6dO+dUa4zR0qVLJUm1a9cuds8FgVtSUlKx6suUKaMvv/xSPXr0UHJystq0aeNYy6USExMlSa1atZKnp2exewIAAACuB26/BgAAANwCXn31Vcetu4oyefJkNW7cWJ9//rk6duyoKVOmaNmyZbr77rt1+vRpJSQkKDc3Vx06dFBcXJzT3AcffFCDBw/Whx9+qFatWumee+5RtWrVtH37du3evVsjR47U+PHj5eXl5eplFsuQIUOUmJiozz77TE2bNlXr1q1VtWpVbdmyRXv27JGvr69mz559xWfWXI033nhDv/zyi2bPnu14bk3dunXl4eGhI0eOKDU1VTk5OVq+fHmh5+pIUu/evTVmzBilp6erSpUq6t27d4n09VvTp09XZmamli9frnr16qlhw4YKCQmRMUYHDhzQ999/r/z8fO3evVuBgYHKz8/X6NGjNWbMGIWHhys0NFSenp46cOCAI9h7/vnnHZ/htm3bNHLkSPn5+alx48YKDg7Wr7/+qi1btujgwYPy9/fXK6+8Uux+O3fuLE9PTyUkJOjChQtyd3f/3TleXl6aP3++Bg4cqM8++0z33nuvVq1a5bj9XIFVq1ZJkrp3717sfgAAAIDrhVAHAAAAuAX89NNPV3xWTsED55s1a6bU1FS9+eabWr58uRYtWiRvb29FRETo0Ucf1V/+8hd5eBT+NSI+Pl7NmjXTlClTtGnTJvn4+Kh58+aaPHmy48qPypUru2RtV8tms+nTTz9Vp06d9OGHHyolJUU5OTkKCgrSgAEDNG7cONWrV6/E3s/Dw0OzZs1SbGysPvroIyUnJ2vHjh0qW7asqlWrpq5du6pbt2669957i5zv5eWlNm3aaN68efrLX/4ib2/vEuutQPny5fX1119r3rx5mjlzplJSUpSamio/Pz9Vq1ZNffv2Vbdu3Ry3ritXrpzi4+O1bt06bd26VStXrlR+fr6Cg4PVo0cPDRs2TH/+858d5+/atauysrK0YcMG7du3T5s2bZKvr69q1qypcePGafjw4Y6reoojMDBQDz/8sGbPnq2vv/7acQu53+Pu7q5PPvlE5cqV05QpU3TPPfdo1apVuv322yVJ586d0+zZs+Xn56d+/fpdxScIAAAAXB82UxpPJwUAAABwy3jsscc0ffp0vfPOOxo1alRpt2M5mZmZqlGjhnJzc7V///5CV5bcqjZv3qzmzZurR48eWrhwYYmcc+HChXrooYc0cuRIvfvuuyVyTgAAAKAk8UwdAAAAANds586dysnJcRqz2+2aOnWqZsyYIR8fH8XExJRSd9b2+uuvKycnR7169SLQ+Y1mzZqpT58+WrRokbZt23bN57Pb7Xr55ZdVsWJFvfDCCyXQIQAAAFDyuFIHAAAAwDUbMGCA5s+fr4iICFWvXl05OTnatWuXDhw4IHd3d02dOlUDBw4s7TYtIzExUR9//LH279+vhIQElSlTRtu3b1fdunVLu7Ubys8//6x69eqpTZs2Wrp06TWda+bMmerXr58mTZqkYcOGlVCHAAAAQMki1AEAAABwzZYvX66pU6cqJSVFJ06c0Pnz51W1alW1bNlSTz/9tO6+++7SbtFSZsyYoYEDB8rX11cNGzbUm2++edln7gAAAAC4dRDqAAAAAAAAAAAAWADP1AEAAAAAAAAAALAAQh0AAAAAAAAAAAALINQBAAAAAAAAAACwAEIdAAAAAAAAAAAACyDUAQAAAAAAAAAAsABCHQAAAAAAAAAAAAsg1AEAAAAAAAAAALAAQh0AAAAAAAAAAAALINQBAAAAAAAAAACwgP8HLVqvSst/9GIAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 2000x2000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(20,20))\n",
    "x_min = log_strikes[0] - (log_strikes[-1] - log_strikes[0]) * 0.3\n",
    "x_max = log_strikes[-1] + (log_strikes[-1] - log_strikes[0]) * 0.1\n",
    "lins = np.linspace(x_min, x_max, num=1000)\n",
    "plt.plot(lins,[w_6(x) for x in lins], label='Knots = 3 (1600 iterations)') # actually w3\n",
    "plt.plot(lins,[w_4(x) for x in lins], label='Knots = 4 (0 iterations)') # actually w3\n",
    "plt.plot(lins,[w_5(x) for x in lins], label='Knots = 5 (0 iterations)') # actually w3\n",
    "plt.scatter(log_strikes, his, label='Asks')\n",
    "plt.scatter(log_strikes, lows, label='Bids')\n",
    "plt.ylabel('Total variance (w(k))')\n",
    "plt.xlabel('Log-moneyness (k)')\n",
    "plt.legend(loc='upper left', prop={'size':20})\n",
    "plt.savefig('diffknots.png')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.0000)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import smilecorrector_gsvi_jo as smilenet\n",
    "importlib.reload(smilenet)\n",
    "params =  (0, 0.4, -0.6, 0, 0.2)\n",
    "f = lambda x: svi(x, *params)\n",
    "g = g_svi(*params)\n",
    "rnm = smilenet.f_g_to_rnm(f, g)\n",
    "# rnm = lambda x: -x / (f(x) ** 0.5) - f(x)**0.5 / 2 \n",
    "xs = torch.tensor(np.linspace(-2,2,num=100))\n",
    "plt.plot(xs, rnm(xs), label='r')\n",
    "plt.plot(xs, g(xs), label='g')\n",
    "plt.plot(xs, f(xs), label='v')\n",
    "plt.legend(loc='upper left')\n",
    "print(smilenet.diff_integ(rnm, -100, 100, delta=1.0e-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2641.9601335607513\n"
     ]
    }
   ],
   "source": [
    "print(2640.25 * np.exp(0.005252 * 45 /365 ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4246575342465753\n",
      "tensor([-6.7841e-01, -6.3585e-01, -5.9503e-01, -5.5581e-01, -5.1807e-01,\n",
      "        -4.8170e-01, -4.4661e-01, -4.1271e-01, -3.7992e-01, -3.4817e-01,\n",
      "        -3.1739e-01, -2.8754e-01, -2.5855e-01, -2.4156e-01, -2.3875e-01,\n",
      "        -2.3595e-01, -2.3317e-01, -2.3038e-01, -2.2761e-01, -2.2484e-01,\n",
      "        -2.2208e-01, -2.1933e-01, -2.1659e-01, -2.1385e-01, -2.1113e-01,\n",
      "        -2.0840e-01, -2.0569e-01, -2.0298e-01, -2.0029e-01, -1.9759e-01,\n",
      "        -1.9491e-01, -1.9223e-01, -1.8956e-01, -1.8690e-01, -1.8424e-01,\n",
      "        -1.8159e-01, -1.7895e-01, -1.7632e-01, -1.7369e-01, -1.7107e-01,\n",
      "        -1.6845e-01, -1.6585e-01, -1.6324e-01, -1.6065e-01, -1.5806e-01,\n",
      "        -1.5548e-01, -1.5291e-01, -1.5034e-01, -1.4778e-01, -1.4523e-01,\n",
      "        -1.4268e-01, -1.4014e-01, -1.3760e-01, -1.3507e-01, -1.3255e-01,\n",
      "        -1.3004e-01, -1.2753e-01, -1.2502e-01, -1.2253e-01, -1.2004e-01,\n",
      "        -1.1755e-01, -1.1507e-01, -1.1260e-01, -1.1013e-01, -1.0767e-01,\n",
      "        -1.0522e-01, -1.0277e-01, -1.0033e-01, -9.7894e-02, -9.5464e-02,\n",
      "        -9.3040e-02, -9.0622e-02, -8.8209e-02, -8.5802e-02, -8.3401e-02,\n",
      "        -8.1006e-02, -7.8617e-02, -7.6233e-02, -7.3855e-02, -7.1482e-02,\n",
      "        -6.9115e-02, -6.6754e-02, -6.4398e-02, -6.2048e-02, -5.9704e-02,\n",
      "        -5.7364e-02, -5.5031e-02, -5.2702e-02, -5.0380e-02, -4.8062e-02,\n",
      "        -4.5750e-02, -4.3443e-02, -4.1142e-02, -3.8845e-02, -3.6554e-02,\n",
      "        -3.4269e-02, -3.1988e-02, -2.9713e-02, -2.7443e-02, -2.5178e-02,\n",
      "        -2.2918e-02, -2.0663e-02, -1.8413e-02, -1.6169e-02, -1.3929e-02,\n",
      "        -1.1694e-02, -9.4647e-03, -7.2400e-03, -5.0203e-03, -2.8054e-03,\n",
      "        -5.9547e-04,  1.6096e-03,  3.8098e-03,  6.0052e-03,  8.1958e-03,\n",
      "         1.0382e-02,  1.2563e-02,  1.4739e-02,  1.6910e-02,  1.9077e-02,\n",
      "         2.1239e-02,  2.3397e-02,  2.5550e-02,  2.7698e-02,  2.9842e-02,\n",
      "         3.1981e-02,  3.4115e-02,  3.6245e-02,  3.8371e-02,  4.0491e-02,\n",
      "         4.2608e-02,  4.4720e-02,  4.6827e-02,  4.8930e-02,  5.1029e-02,\n",
      "         5.3123e-02,  5.5213e-02,  5.7299e-02,  5.9380e-02,  6.1457e-02,\n",
      "         6.3529e-02,  6.5597e-02,  6.7661e-02,  6.9721e-02,  7.1777e-02,\n",
      "         7.3828e-02,  7.5875e-02,  7.7918e-02,  7.9957e-02,  8.1991e-02,\n",
      "         8.4022e-02,  8.6048e-02,  8.8070e-02,  9.0088e-02,  9.2102e-02,\n",
      "         9.4112e-02,  9.6119e-02,  9.8121e-02,  1.0012e-01,  1.0211e-01,\n",
      "         1.0410e-01,  1.0609e-01,  1.0807e-01,  1.1005e-01,  1.1202e-01,\n",
      "         1.1399e-01,  1.1596e-01,  1.1792e-01,  1.1988e-01,  1.2184e-01,\n",
      "         1.2379e-01,  1.2574e-01,  1.2768e-01,  1.2962e-01,  1.3156e-01,\n",
      "         1.3349e-01,  1.3542e-01,  1.3734e-01,  1.3926e-01,  1.4118e-01,\n",
      "         1.4309e-01,  1.4500e-01,  1.4691e-01,  1.4881e-01,  1.5071e-01,\n",
      "         1.5261e-01,  1.5450e-01,  1.5639e-01,  1.5827e-01,  1.6016e-01,\n",
      "         1.7508e-01,  1.9343e-01,  2.1145e-01,  2.2915e-01,  2.4654e-01,\n",
      "         2.6363e-01,  2.8044e-01,  2.9697e-01,  3.1323e-01,  3.2923e-01,\n",
      "         3.4498e-01,  3.6048e-01,  3.7575e-01])\n",
      "(203,)\n",
      "(203,)\n",
      "Mid shape (203,)\n",
      "9.00380559592238e-05\n",
      "(203,) (203,)\n",
      "torch.Size([203]) torch.Size([612, 1])\n",
      "torch.Size([1, 612])\n",
      "0.0 0.0 nan\n",
      "Epoch: 0\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 0.003224904958206244\n",
      "MAPE:  0.0012456894435916852\n",
      "Delta:  0.03508776860137868\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.0065824177130030526 0.508849512783904 nan\n",
      "Epoch: 1\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 0.0015839136414486006\n",
      "MAPE:  0.000734621860249657\n",
      "Delta:  0.03485680625182721\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.004455269477052881 0.44724581267709795 nan\n",
      "Epoch: 2\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 0.0008755148976685796\n",
      "MAPE:  0.00045170241559975644\n",
      "Delta:  0.0347015097868659\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.0032744327441232013 0.39810419084390747 nan\n",
      "Epoch: 3\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 0.0005269687477604432\n",
      "MAPE:  0.0002907366013830584\n",
      "Delta:  0.034587882026949276\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.002532359351188118 0.3528329737747279 nan\n",
      "Epoch: 4\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 0.00034103679740178156\n",
      "MAPE:  0.00019860861575758524\n",
      "Delta:  0.034500293080460535\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.0020382762967914303 0.31004973975391137 nan\n",
      "Epoch: 5\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 0.00023529842712085179\n",
      "MAPE:  0.00013924791015344713\n",
      "Delta:  0.03442997195084228\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.0017186305764204102 0.2801962648069284 nan\n",
      "Epoch: 6\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 0.00016936868672664385\n",
      "MAPE:  0.00010218973291495902\n",
      "Delta:  0.034370799548302265\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.0015018909043938988 0.2593153741820504 nan\n",
      "Epoch: 7\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 0.00012544878235340172\n",
      "MAPE:  7.443537013335815e-05\n",
      "Delta:  0.03431917835708392\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.0013419094453844815 0.2410614459945235 nan\n",
      "Epoch: 8\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 9.520791748103845e-05\n",
      "MAPE:  5.448591071735153e-05\n",
      "Delta:  0.034273125127488716\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.0012148162008100982 0.22302295571341757 nan\n",
      "Epoch: 9\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 7.39743663170981e-05\n",
      "MAPE:  3.9895351464942047e-05\n",
      "Delta:  0.03423148957983145\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.0011154121733267797 0.2087106523094504 nan\n",
      "Epoch: 10\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 5.853512806887831e-05\n",
      "MAPE:  2.969683093844072e-05\n",
      "Delta:  0.034193307359642995\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.0010444111611042084 0.20106009752660947 nan\n",
      "Epoch: 11\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 4.676604951061707e-05\n",
      "MAPE:  2.288711510326484e-05\n",
      "Delta:  0.03415759548780152\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.0009863266294657391 0.1936734823344497 nan\n",
      "Epoch: 12\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 3.7708705846870575e-05\n",
      "MAPE:  1.699632677741439e-05\n",
      "Delta:  0.034123904941773385\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.0009348427062120246 0.18474588102313594 nan\n",
      "Epoch: 13\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 3.074217776294819e-05\n",
      "MAPE:  1.2551057826401725e-05\n",
      "Delta:  0.03409200445813109\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.00089135308306032 0.17631447857720128 nan\n",
      "Epoch: 14\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 2.532188672034635e-05\n",
      "MAPE:  9.602867317270904e-06\n",
      "Delta:  0.03406161644484963\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.0008551439291093477 0.16917089248324113 nan\n",
      "Epoch: 15\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 2.1038160544505828e-05\n",
      "MAPE:  7.207935022133005e-06\n",
      "Delta:  0.03403248886033117\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.0008251770589348117 0.1631970991178865 nan\n",
      "Epoch: 16\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.76047937728661e-05\n",
      "MAPE:  5.196728765950865e-06\n",
      "Delta:  0.034004406031265165\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.0007994211699846598 0.15779557463866944 nan\n",
      "Epoch: 17\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.4826835223081425e-05\n",
      "MAPE:  3.7129845153160374e-06\n",
      "Delta:  0.03397722218921102\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.000776870997608925 0.15182619986591994 nan\n",
      "Epoch: 18\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.2575733175122802e-05\n",
      "MAPE:  2.492142744585958e-06\n",
      "Delta:  0.03395082627071291\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.0007562573578031584 0.145084350561277 nan\n",
      "Epoch: 19\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.0751191094578205e-05\n",
      "MAPE:  1.6640473745832683e-06\n",
      "Delta:  0.033925150708542184\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.0007392519782106755 0.1405239591977986 nan\n",
      "Epoch: 20\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 9.240391155875962e-06\n",
      "MAPE:  1.0019386440743764e-06\n",
      "Delta:  0.0339000714737698\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.0007246317410656289 0.1360439787888451 nan\n",
      "Epoch: 21\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 7.983291577465341e-06\n",
      "MAPE:  6.477998501873212e-07\n",
      "Delta:  0.03387550640595551\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.000711453838185383 0.13211419592187157 nan\n",
      "Epoch: 22\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 6.9285854298986575e-06\n",
      "MAPE:  3.1821974021047383e-07\n",
      "Delta:  0.033851405546902524\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.0007008303253540626 0.13117694436394012 nan\n",
      "Epoch: 23\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 6.019714764440035e-06\n",
      "MAPE:  8.162548777317262e-09\n",
      "Delta:  0.033827681455339396\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.0006921591963109375 0.1315934728222149 nan\n",
      "Epoch: 24\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 5.22755959318821e-06\n",
      "MAPE:  0.0\n",
      "Delta:  0.033804267314530206\n",
      "Breaking and plotting at epoch 24 with bounds loss tensor(5.2276e-06, grad_fn=<MulBackward0>) and arb loss tensor(0., grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<function smilecorrector_gsvi_jo_mw_ar.SmileNet.train.<locals>.<lambda>(k, buckets=tensor([-0.8784, -0.4819, -0.2202, -0.0131,  0.1585,  0.3049,  0.8758],\n",
       "       grad_fn=<AsStridedBackward0>), fs=[<function p_to_f.<locals>.<lambda> at 0x000001F92B36F600>, <function p_to_f.<locals>.<lambda> at 0x000001F92B36ED40>, <function p_to_f.<locals>.<lambda> at 0x000001F92B36EC00>, <function p_to_f.<locals>.<lambda> at 0x000001F92B36F6A0>, <function p_to_f.<locals>.<lambda> at 0x000001F92B36F880>, <function p_to_f.<locals>.<lambda> at 0x000001F92B36F7E0>])>"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import smilecorrector_gsvi_jo_mw_ar as smilenet\n",
    "import torch\n",
    "importlib.reload(smilenet)\n",
    "# For first try, we pass our boundaries as each strike price\n",
    "# boundaries = processed['strike_price'].apply(np.log).to_numpy()\n",
    "# ind = np.array([i for i in range(0,boundaries.shape[0],3)])\n",
    "# boundaries = boundaries[ind]\n",
    "# strikes = boundaries.copy()\n",
    "R = 0.0056 # Rate for > 122 day\n",
    "F = 2266.349134 # for ID 102434, Exp date 05/31/2022\n",
    "T = 5 * 31 / 365\n",
    "S = F * np.exp(-R * T)\n",
    "print(T)\n",
    "log_strikes = torch.tensor((processed['strike_price'].apply(np.log).to_numpy()- np.log(F))) #   \n",
    "print(log_strikes)\n",
    "S = torch.tensor(S).reshape(1,1)\n",
    "T = torch.tensor(T).reshape(1,1)\n",
    "R = torch.tensor(R).reshape(1,1)\n",
    "params = (0, 0.4, -0.6, 0, 0.2)\n",
    "# his, lows = svi_with_noise(log_strikes, *params)\n",
    "# mids = torch.tensor(his + lows) / 2\n",
    "# mids = mids * T\n",
    "his = processed['vol_high'].to_numpy() ** 2 * T.item()\n",
    "lows = processed['vol_low'].to_numpy() ** 2 * T.item()\n",
    "# mids = torch.tensor(((processed['vol_high'].to_numpy() + processed['vol_low'].to_numpy()) / 2))\n",
    "mids = (his + lows) / 2\n",
    "print(mids.shape)\n",
    "mids = mids\n",
    "print(mids.shape)\n",
    "print('Mid shape', mids.shape)\n",
    "# print(mids)\n",
    "low = min(mids**2)/2\n",
    "print(low)\n",
    "print(his.shape, lows.shape)\n",
    "# datum, log_strikes = pipeline.get_datum('2022-0') \n",
    "model = smilenet.SmileNet(5, log_strikes, mids, low)#, low)\n",
    "datum = torch.tensor(np.vstack([ his.reshape(-1,1) , lows.reshape(-1,1) , log_strikes.reshape(-1,1), np.log(S), T, R])).double()\n",
    "print(log_strikes.shape, datum.shape)\n",
    "print(datum.T.shape)\n",
    "model.train(datum.T.double(), log_strikes, epochs=1601)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def remove(processed, frac, F):\n",
    "    spreads = abs((processed['vol_high'] - processed['vol_low']).to_numpy())\n",
    "    weights = spreads / sum(spreads)\n",
    "    selection = np.random.choice(processed.index.to_numpy(), replace=False, size=int(weights.shape[0] * frac),  p=weights)#\n",
    "    return processed.loc[~processed.index.isin(sorted(selection)), :]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4246575342465753\n",
      "tensor([-0.5558, -0.3799, -0.3482, -0.3174, -0.2875, -0.2586, -0.2416, -0.2388,\n",
      "        -0.2332, -0.2304, -0.2276, -0.2248, -0.2221, -0.2193, -0.2166, -0.2139,\n",
      "        -0.2111, -0.2084, -0.2057, -0.2030, -0.1976, -0.1949, -0.1922, -0.1896,\n",
      "        -0.1842, -0.1816, -0.1763, -0.1737, -0.1711, -0.1685, -0.1658, -0.1632,\n",
      "        -0.1607, -0.1581, -0.1555, -0.1529, -0.1503, -0.1478, -0.1452, -0.1401,\n",
      "        -0.1376, -0.1351, -0.1326, -0.1300, -0.1250, -0.1225, -0.1200, -0.1176,\n",
      "        -0.1151, -0.1126, -0.1101, -0.1077, -0.1052, -0.1028, -0.1003, -0.0979,\n",
      "        -0.0955, -0.0930, -0.0906, -0.0882, -0.0858, -0.0810, -0.0786, -0.0762,\n",
      "        -0.0739, -0.0715, -0.0691, -0.0644, -0.0620, -0.0597, -0.0574, -0.0550,\n",
      "        -0.0527, -0.0504, -0.0481, -0.0457, -0.0434, -0.0411, -0.0388, -0.0366,\n",
      "        -0.0343, -0.0320, -0.0297, -0.0274, -0.0252, -0.0229, -0.0207, -0.0184,\n",
      "        -0.0162, -0.0139, -0.0117, -0.0095, -0.0072, -0.0050, -0.0028,  0.0016,\n",
      "         0.0038,  0.0060,  0.0082,  0.0104,  0.0126,  0.0147,  0.0169,  0.0191,\n",
      "         0.0212,  0.0234,  0.0255,  0.0277,  0.0298,  0.0320,  0.0362,  0.0384,\n",
      "         0.0405,  0.0426,  0.0447,  0.0468,  0.0489,  0.0510,  0.0531,  0.0552,\n",
      "         0.0573,  0.0594,  0.0615,  0.0635,  0.0656,  0.0677,  0.0697,  0.0718,\n",
      "         0.0738,  0.0759,  0.0779,  0.0800,  0.0820,  0.0840,  0.0860,  0.0881,\n",
      "         0.0901,  0.0921,  0.0941,  0.0961,  0.0981,  0.1001,  0.1021,  0.1041,\n",
      "         0.1061,  0.1081,  0.1100,  0.1120,  0.1140,  0.1160,  0.1179,  0.1199,\n",
      "         0.1218,  0.1238,  0.1257,  0.1277,  0.1296,  0.1316,  0.1335,  0.1354,\n",
      "         0.1373,  0.1393,  0.1412,  0.1431,  0.1450,  0.1469,  0.1488,  0.1507,\n",
      "         0.1526,  0.1545,  0.1564,  0.1583,  0.1602,  0.1751,  0.1934,  0.2114,\n",
      "         0.2636,  0.2804,  0.2970,  0.3132,  0.3450,  0.3605,  0.3758])\n",
      "(183,)\n",
      "(183,)\n",
      "Mid shape (183,)\n",
      "9.00380559592238e-05\n",
      "(183,) (183,)\n",
      "torch.Size([183]) torch.Size([552, 1])\n",
      "torch.Size([1, 552])\n",
      "0.0 0.0 nan\n",
      "Epoch: 0\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 0.0002182856873137\n",
      "MAPE:  0.00011393477046502946\n",
      "Delta:  0.021322035486881472\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.02700706307142897 0 nan\n",
      "Epoch: 1\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 0.0\n",
      "MAPE:  0.0\n",
      "Delta:  0.02074618992967602\n",
      "Breaking and plotting at epoch 1 with bounds loss tensor(0., grad_fn=<MulBackward0>) and arb loss tensor(0., grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import smilecorrector_gsvi_jo_mw_ar as smilenet\n",
    "import torch\n",
    "importlib.reload(smilenet)\n",
    "# For first try, we pass our boundaries as each strike price\n",
    "# boundaries = processed_90['strike_price'].apply(np.log).to_numpy()\n",
    "# ind = np.array([i for i in range(0,boundaries.shape[0],3)])\n",
    "# boundaries = boundaries[ind]\n",
    "# strikes = boundaries.copy()\n",
    "R = 0.0056 # Rate for > 122 day\n",
    "F = 2266.349134 # for ID 102434, Exp date 05/31/2022\n",
    "T = 5 * 31 / 365\n",
    "S = F * np.exp(-R * T)\n",
    "print(T)\n",
    "processed_90 = remove(processed, 0.10, F)\n",
    "log_strikes_90 = torch.tensor((processed_90['strike_price'].apply(np.log).to_numpy()- np.log(F))) #   \n",
    "print(log_strikes_90)\n",
    "S = torch.tensor(S).reshape(1,1)\n",
    "T = torch.tensor(T).reshape(1,1)\n",
    "R = torch.tensor(R).reshape(1,1)\n",
    "params = (0, 0.4, -0.6, 0, 0.2)\n",
    "# his_90, lows_90 = svi_with_noise(log_strikes_90, *params)\n",
    "# mids_90 = torch.tensor(his_90 + lows_90) / 2\n",
    "# mids_90 = mids_90 * T\n",
    "his_90 = processed_90['vol_high'].to_numpy() ** 2 * T.item()\n",
    "lows_90 = processed_90['vol_low'].to_numpy() ** 2 * T.item()\n",
    "# mids_90 = torch.tensor(((processed_90['vol_high'].to_numpy() + processed_90['vol_low'].to_numpy()) / 2))\n",
    "mids_90 = (his_90 + lows_90) / 2\n",
    "print(mids_90.shape)\n",
    "mids_90 = mids_90\n",
    "print(mids_90.shape)\n",
    "print('Mid shape', mids_90.shape)\n",
    "# print(mids_90)\n",
    "low = min(mids_90**2)/2\n",
    "print(low)\n",
    "print(his_90.shape, lows_90.shape)\n",
    "# datum, log_strikes_90 = pipeline.get_datum('2022-0') \n",
    "model = smilenet.SmileNet(5, log_strikes_90, mids_90, low)#, low)\n",
    "datum = torch.tensor(np.vstack([ his_90.reshape(-1,1) , lows_90.reshape(-1,1) , log_strikes_90.reshape(-1,1), np.log(S), T, R])).double()\n",
    "print(log_strikes_90.shape, datum.shape)\n",
    "print(datum.T.shape)\n",
    "w_90 = model.train(datum.T.double(), log_strikes_90, epochs=1601)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(log_strikes, [w_90(i) for i in log_strikes])\n",
    "plt.scatter(log_strikes, his)\n",
    "plt.scatter(log_strikes, lows)\n",
    "print(sum([max(abs(w_90(log_strikes[i]) - mids[i]) - abs(his[i] - lows[i])/2, 0) for i in range(log_strikes.shape[0])])/ log_strikes.shape[0]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4246575342465753\n",
      "tensor([-0.3799, -0.3482, -0.3174, -0.2586, -0.2416, -0.2360, -0.2332, -0.2276,\n",
      "        -0.2248, -0.2221, -0.2139, -0.2111, -0.2084, -0.2057, -0.2030, -0.1976,\n",
      "        -0.1949, -0.1922, -0.1896, -0.1869, -0.1842, -0.1816, -0.1737, -0.1711,\n",
      "        -0.1685, -0.1658, -0.1632, -0.1607, -0.1555, -0.1529, -0.1401, -0.1351,\n",
      "        -0.1326, -0.1300, -0.1275, -0.1250, -0.1225, -0.1200, -0.1176, -0.1151,\n",
      "        -0.1126, -0.1101, -0.1077, -0.1028, -0.1003, -0.0979, -0.0955, -0.0930,\n",
      "        -0.0882, -0.0858, -0.0786, -0.0762, -0.0739, -0.0691, -0.0668, -0.0644,\n",
      "        -0.0620, -0.0597, -0.0574, -0.0550, -0.0527, -0.0504, -0.0457, -0.0434,\n",
      "        -0.0411, -0.0388, -0.0366, -0.0343, -0.0320, -0.0297, -0.0274, -0.0229,\n",
      "        -0.0184, -0.0162, -0.0139, -0.0117, -0.0095, -0.0072, -0.0050, -0.0028,\n",
      "        -0.0006,  0.0016,  0.0038,  0.0060,  0.0082,  0.0104,  0.0126,  0.0147,\n",
      "         0.0169,  0.0191,  0.0212,  0.0234,  0.0255,  0.0277,  0.0298,  0.0341,\n",
      "         0.0362,  0.0384,  0.0405,  0.0447,  0.0468,  0.0510,  0.0531,  0.0552,\n",
      "         0.0573,  0.0594,  0.0615,  0.0635,  0.0677,  0.0718,  0.0738,  0.0759,\n",
      "         0.0779,  0.0800,  0.0840,  0.0860,  0.0881,  0.0921,  0.0941,  0.0961,\n",
      "         0.0981,  0.1001,  0.1021,  0.1041,  0.1061,  0.1081,  0.1100,  0.1120,\n",
      "         0.1140,  0.1160,  0.1179,  0.1199,  0.1218,  0.1238,  0.1257,  0.1277,\n",
      "         0.1316,  0.1335,  0.1354,  0.1373,  0.1393,  0.1412,  0.1431,  0.1450,\n",
      "         0.1469,  0.1488,  0.1507,  0.1526,  0.1545,  0.1564,  0.1583,  0.1602,\n",
      "         0.1751,  0.1934,  0.2114,  0.2291,  0.2636,  0.2804,  0.2970,  0.3132,\n",
      "         0.3292,  0.3605,  0.3758])\n",
      "(163,)\n",
      "(163,)\n",
      "Mid shape (163,)\n",
      "9.00380559592238e-05\n",
      "(163,) (163,)\n",
      "torch.Size([163]) torch.Size([492, 1])\n",
      "torch.Size([1, 492])\n",
      "0.0 0 nan\n",
      "Epoch: 0\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 0.0\n",
      "MAPE:  0.0\n",
      "Delta:  0.04440838352012527\n",
      "Breaking and plotting at epoch 0 with bounds loss tensor(0., grad_fn=<MulBackward0>) and arb loss tensor(0., grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import smilecorrector_gsvi_jo_mw_ar as smilenet\n",
    "import torch\n",
    "importlib.reload(smilenet)\n",
    "# For first try, we pass our boundaries as each strike price\n",
    "# boundaries = processed_80['strike_price'].apply(np.log).to_numpy()\n",
    "# ind = np.array([i for i in range(0,boundaries.shape[0],3)])\n",
    "# boundaries = boundaries[ind]\n",
    "# strikes = boundaries.copy()\n",
    "R = 0.0056 # Rate for > 122 day\n",
    "F = 2266.349134 # for ID 102434, Exp date 05/31/2022\n",
    "T = 5 * 31 / 365\n",
    "S = F * np.exp(-R * T)\n",
    "print(T)\n",
    "processed_80 = remove(processed, 0.20, F)\n",
    "log_strikes_80 = torch.tensor((processed_80['strike_price'].apply(np.log).to_numpy()- np.log(F))) #   \n",
    "print(log_strikes_80)\n",
    "S = torch.tensor(S).reshape(1,1)\n",
    "T = torch.tensor(T).reshape(1,1)\n",
    "R = torch.tensor(R).reshape(1,1)\n",
    "params = (0, 0.4, -0.6, 0, 0.2)\n",
    "# his_80, lows_80 = svi_with_noise(log_strikes_80, *params)\n",
    "# mids_80 = torch.tensor(his_80 + lows_80) / 2\n",
    "# mids_80 = mids_80 * T\n",
    "his_80 = processed_80['vol_high'].to_numpy() ** 2 * T.item()\n",
    "lows_80 = processed_80['vol_low'].to_numpy() ** 2 * T.item()\n",
    "# mids_80 = torch.tensor(((processed_80['vol_high'].to_numpy() + processed_80['vol_low'].to_numpy()) / 2))\n",
    "mids_80 = (his_80 + lows_80) / 2\n",
    "print(mids_80.shape)\n",
    "mids_80 = mids_80\n",
    "print(mids_80.shape)\n",
    "print('Mid shape', mids_80.shape)\n",
    "# print(mids_80)\n",
    "low = min(mids_80**2)/2\n",
    "print(low)\n",
    "print(his_80.shape, lows_80.shape)\n",
    "# datum, log_strikes_80 = pipeline.get_datum('2022-0') \n",
    "model = smilenet.SmileNet(5, log_strikes_80, mids_80, low)#, low)\n",
    "datum = torch.tensor(np.vstack([ his_80.reshape(-1,1) , lows_80.reshape(-1,1) , log_strikes_80.reshape(-1,1), np.log(S), T, R])).double()\n",
    "print(log_strikes_80.shape, datum.shape)\n",
    "print(datum.T.shape)\n",
    "w_80 = model.train(datum.T.double(), log_strikes_80, epochs=1601)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(log_strikes, [w_80(i) for i in log_strikes])\n",
    "plt.scatter(log_strikes, his)\n",
    "plt.scatter(log_strikes, lows)\n",
    "print(sum([max(abs(w_80(log_strikes[i]) - mids[i]) - abs(his[i] - lows[i])/2, 0) for i in range(log_strikes.shape[0])])/ log_strikes.shape[0]) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4246575342465753\n",
      "tensor([-0.2416, -0.2360, -0.2332, -0.2304, -0.2276, -0.2221, -0.2111, -0.2084,\n",
      "        -0.2057, -0.2030, -0.2003, -0.1922, -0.1896, -0.1816, -0.1763, -0.1711,\n",
      "        -0.1685, -0.1632, -0.1607, -0.1581, -0.1503, -0.1427, -0.1401, -0.1326,\n",
      "        -0.1300, -0.1275, -0.1250, -0.1176, -0.1126, -0.1052, -0.1028, -0.0930,\n",
      "        -0.0906, -0.0882, -0.0858, -0.0834, -0.0810, -0.0786, -0.0762, -0.0739,\n",
      "        -0.0715, -0.0691, -0.0668, -0.0644, -0.0597, -0.0574, -0.0550, -0.0527,\n",
      "        -0.0481, -0.0457, -0.0434, -0.0411, -0.0388, -0.0366, -0.0343, -0.0320,\n",
      "        -0.0274, -0.0252, -0.0229, -0.0207, -0.0184, -0.0162, -0.0139, -0.0117,\n",
      "        -0.0095, -0.0072, -0.0028, -0.0006,  0.0038,  0.0082,  0.0104,  0.0126,\n",
      "         0.0147,  0.0169,  0.0212,  0.0234,  0.0255,  0.0298,  0.0320,  0.0362,\n",
      "         0.0384,  0.0426,  0.0447,  0.0489,  0.0531,  0.0552,  0.0573,  0.0594,\n",
      "         0.0615,  0.0635,  0.0656,  0.0677,  0.0718,  0.0738,  0.0759,  0.0779,\n",
      "         0.0800,  0.0820,  0.0840,  0.0860,  0.0921,  0.0941,  0.0961,  0.0981,\n",
      "         0.1001,  0.1021,  0.1041,  0.1061,  0.1081,  0.1100,  0.1120,  0.1140,\n",
      "         0.1160,  0.1179,  0.1199,  0.1218,  0.1238,  0.1257,  0.1296,  0.1316,\n",
      "         0.1335,  0.1354,  0.1373,  0.1393,  0.1412,  0.1431,  0.1450,  0.1469,\n",
      "         0.1488,  0.1507,  0.1526,  0.1545,  0.1564,  0.1583,  0.1602,  0.1751,\n",
      "         0.1934,  0.2114,  0.2291,  0.2465,  0.3292,  0.3450,  0.3758])\n",
      "(143,)\n",
      "(143,)\n",
      "Mid shape (143,)\n",
      "9.00380559592238e-05\n",
      "(143,) (143,)\n",
      "torch.Size([143]) torch.Size([432, 1])\n",
      "torch.Size([1, 432])\n",
      "0.0 0 nan\n",
      "Epoch: 0\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 0.0\n",
      "MAPE:  0.0\n",
      "Delta:  0.03635069999937265\n",
      "Breaking and plotting at epoch 0 with bounds loss tensor(0., grad_fn=<MulBackward0>) and arb loss tensor(0., grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import smilecorrector_gsvi_jo_mw_ar as smilenet\n",
    "import torch\n",
    "importlib.reload(smilenet)\n",
    "# For first try, we pass our boundaries as each strike price\n",
    "# boundaries = processed_70['strike_price'].apply(np.log).to_numpy()\n",
    "# ind = np.array([i for i in range(0,boundaries.shape[0],3)])\n",
    "# boundaries = boundaries[ind]\n",
    "# strikes = boundaries.copy()\n",
    "R = 0.0056 # Rate for > 122 day\n",
    "F = 2266.349134 # for ID 102434, Exp date 05/31/2022\n",
    "T = 5 * 31 / 365\n",
    "S = F * np.exp(-R * T)\n",
    "print(T)\n",
    "processed_70 = remove(processed, (1.0 - 0.70), F)\n",
    "log_strikes_70 = torch.tensor((processed_70['strike_price'].apply(np.log).to_numpy()- np.log(F))) #   \n",
    "print(log_strikes_70)\n",
    "S = torch.tensor(S).reshape(1,1)\n",
    "T = torch.tensor(T).reshape(1,1)\n",
    "R = torch.tensor(R).reshape(1,1)\n",
    "params = (0, 0.4, -0.6, 0, 0.2)\n",
    "# his_70, lows_70 = svi_with_noise(log_strikes_70, *params)\n",
    "# mids_70 = torch.tensor(his_70 + lows_70) / 2\n",
    "# mids_70 = mids_70 * T\n",
    "his_70 = processed_70['vol_high'].to_numpy() ** 2 * T.item()\n",
    "lows_70 = processed_70['vol_low'].to_numpy() ** 2 * T.item()\n",
    "# mids_70 = torch.tensor(((processed_70['vol_high'].to_numpy() + processed_70['vol_low'].to_numpy()) / 2))\n",
    "mids_70 = (his_70 + lows_70) / 2\n",
    "print(mids_70.shape)\n",
    "mids_70 = mids_70\n",
    "print(mids_70.shape)\n",
    "print('Mid shape', mids_70.shape)\n",
    "# print(mids_70)\n",
    "low = min(mids_70**2)/2\n",
    "print(low)\n",
    "print(his_70.shape, lows_70.shape)\n",
    "# datum, log_strikes_70 = pipeline.get_datum('2022-0') \n",
    "model = smilenet.SmileNet(5, log_strikes_70, mids_70, low)#, low)\n",
    "datum = torch.tensor(np.vstack([ his_70.reshape(-1,1) , lows_70.reshape(-1,1) , log_strikes_70.reshape(-1,1), np.log(S), T, R])).double()\n",
    "print(log_strikes_70.shape, datum.shape)\n",
    "print(datum.T.shape)\n",
    "w_70 = model.train(datum.T.double(), log_strikes_70, epochs=1601)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(log_strikes, [w_70(i) for i in log_strikes])\n",
    "plt.scatter(log_strikes, his)\n",
    "plt.scatter(log_strikes, lows)\n",
    "print(sum([max(abs(w_70(log_strikes[i]) - mids[i]) - abs(his[i] - lows[i])/2, 0) for i in range(log_strikes.shape[0])])/ log_strikes.shape[0]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4246575342465753\n",
      "tensor([-0.2875, -0.2304, -0.2193, -0.2166, -0.2139, -0.2084, -0.1976, -0.1949,\n",
      "        -0.1842, -0.1790, -0.1737, -0.1711, -0.1685, -0.1632, -0.1581, -0.1503,\n",
      "        -0.1427, -0.1326, -0.1300, -0.1275, -0.1200, -0.1176, -0.1151, -0.1077,\n",
      "        -0.1052, -0.1003, -0.0979, -0.0955, -0.0930, -0.0882, -0.0858, -0.0810,\n",
      "        -0.0786, -0.0762, -0.0739, -0.0715, -0.0691, -0.0668, -0.0597, -0.0550,\n",
      "        -0.0527, -0.0504, -0.0481, -0.0457, -0.0434, -0.0411, -0.0388, -0.0366,\n",
      "        -0.0343, -0.0320, -0.0274, -0.0252, -0.0229, -0.0184, -0.0139, -0.0095,\n",
      "        -0.0028,  0.0038,  0.0082,  0.0126,  0.0147,  0.0169,  0.0191,  0.0212,\n",
      "         0.0234,  0.0255,  0.0298,  0.0362,  0.0384,  0.0405,  0.0426,  0.0489,\n",
      "         0.0510,  0.0531,  0.0552,  0.0573,  0.0594,  0.0656,  0.0718,  0.0738,\n",
      "         0.0759,  0.0779,  0.0800,  0.0820,  0.0840,  0.0881,  0.0901,  0.0921,\n",
      "         0.0961,  0.1001,  0.1021,  0.1041,  0.1061,  0.1100,  0.1120,  0.1140,\n",
      "         0.1160,  0.1179,  0.1199,  0.1218,  0.1238,  0.1257,  0.1277,  0.1296,\n",
      "         0.1316,  0.1335,  0.1354,  0.1373,  0.1393,  0.1412,  0.1450,  0.1469,\n",
      "         0.1488,  0.1526,  0.1545,  0.1564,  0.1602,  0.1934,  0.2114,  0.2291,\n",
      "         0.2465,  0.3450])\n",
      "(122,)\n",
      "(122,)\n",
      "Mid shape (122,)\n",
      "9.00380559592238e-05\n",
      "(122,) (122,)\n",
      "torch.Size([122]) torch.Size([369, 1])\n",
      "torch.Size([1, 369])\n",
      "0.0 0 nan\n",
      "Epoch: 0\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 0.0\n",
      "MAPE:  0.0\n",
      "Delta:  0.009917021071087585\n",
      "Breaking and plotting at epoch 0 with bounds loss tensor(0., grad_fn=<MulBackward0>) and arb loss tensor(0., grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjcAAAGdCAYAAADuR1K7AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8g+/7EAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAf20lEQVR4nO3de3BU9f3/8deGkATFTcotayARbalEpNAGE8J0htbsGJSOpOKIGQSkGSkV0BpKAUUy2nbSilZQUMaZOgxVCoVaWpHi0GCVysoleOEWxnaUq5uAmA2iJDH5/P7wx9qVEMFvTpJ983zMnGE4+zm7n8+ZwD7ncHbxOeecAAAAjEjo6AkAAAC0JeIGAACYQtwAAABTiBsAAGAKcQMAAEwhbgAAgCnEDQAAMIW4AQAApiR29AQ6QnNzs44eParLLrtMPp+vo6cDAADOg3NOJ0+eVEZGhhISzn195qKMm6NHjyozM7OjpwEAAL6GQ4cOqV+/fud8/KKMm8suu0zS5yfH7/d38GwAAMD5qKurU2ZmZvR9/Fwuyrg5809Rfr+fuAEAIM581S0l3FAMAABMIW4AAIApxA0AADCFuAEAAKYQNwAAwBTiBgAAmELcAAAAU4gbAABgCnEDAABMIW4AAIApxA0AADCFuAEAAKYQNwAAwBTiBgAAmELcAAAAU4gbAABgCnEDAABMIW4AAIApxA0AADCFuAEAAKYQNwAAwBTiBgAAmELcAAAAU4gbAABgCnEDAABMIW4AAIApxA0AADCFuAEAAKYQNwAAwBTiBgAAmELcAAAAU4gbAABgCnEDAABMIW4AAIApxA0AADCFuAEAAKYQNwAAwBTiBgAAmELcAAAAU4gbAABgCnEDAABMIW4AAIApxA0AADClXeJmyZIl6t+/v1JSUpSXl6dt27a1On716tUaOHCgUlJSNHjwYK1fv/6cY6dOnSqfz6eFCxe28awBAEA88jxuVq1apdLSUpWVlWnnzp0aMmSICgsLVVNT0+L4LVu2qLi4WCUlJXrzzTdVVFSkoqIi7d69+6yxf/3rX/XGG28oIyPD62UAAIA44Xnc/P73v9ddd92lyZMn65prrtHSpUt1ySWX6Nlnn21x/KJFizRq1CjNmjVL2dnZ+tWvfqXvfe97Wrx4ccy4I0eOaMaMGXr++efVtWtXr5cBAADihKdx09DQoMrKSgWDwS9eMCFBwWBQoVCoxWNCoVDMeEkqLCyMGd/c3KwJEyZo1qxZGjRo0FfOo76+XnV1dTEbAACwydO4OX78uJqampSenh6zPz09XeFwuMVjwuHwV47/3e9+p8TERN1zzz3nNY/y8nKlpqZGt8zMzAtcCQAAiBdx92mpyspKLVq0SMuWLZPP5zuvY+bOnatIJBLdDh065PEsAQBAR/E0bnr16qUuXbqouro6Zn91dbUCgUCLxwQCgVbHb968WTU1NcrKylJiYqISExN14MABzZw5U/3792/xOZOTk+X3+2M2AABgk6dxk5SUpJycHFVUVET3NTc3q6KiQvn5+S0ek5+fHzNekjZu3BgdP2HCBL3zzjt66623oltGRoZmzZqll19+2bvFAACAuJDo9QuUlpZq0qRJGjZsmHJzc7Vw4UKdOnVKkydPliRNnDhRffv2VXl5uSTp3nvv1ciRI/XYY49p9OjRWrlypXbs2KFnnnlGktSzZ0/17Nkz5jW6du2qQCCgq6++2uvlAACATs7zuBk3bpyOHTum+fPnKxwOa+jQodqwYUP0puGDBw8qIeGLC0gjRozQihUrNG/ePN1///0aMGCA1q5dq2uvvdbrqQIAAAN8zjnX0ZNob3V1dUpNTVUkEuH+GwAA4sT5vn/H3aelAAAAWkPcAAAAU4gbAABgCnEDAABMIW4AAIApxA0AADCFuAEAAKYQNwAAwBTiBgAAmELcAAAAU4gbAABgCnEDAABMIW4AAIApxA0AADCFuAEAAKYQNwAAwBTiBgAAmELcAAAAU4gbAABgCnEDAABMIW4AAIApxA0AADCFuAEAAKYQNwAAwBTiBgAAmELcAAAAU4gbAABgCnEDAABMIW4AAIApxA0AADCFuAEAAKYQNwAAwBTiBgAAmELcAAAAU4gbAABgCnEDAABMIW4AAIApxA0AADCFuAEAAKYQNwAAwBTiBgAAmELcAAAAU4gbAABgCnEDAABMIW4AAIApxA0AADCFuAEAAKYQNwAAwBTiBgAAmELcAAAAU4gbAABgCnEDAABMIW4AAIApxA0AADCFuAEAAKYQNwAAwJR2iZslS5aof//+SklJUV5enrZt29bq+NWrV2vgwIFKSUnR4MGDtX79+uhjjY2Nmj17tgYPHqxLL71UGRkZmjhxoo4ePer1MgAAQBzwPG5WrVql0tJSlZWVaefOnRoyZIgKCwtVU1PT4vgtW7aouLhYJSUlevPNN1VUVKSioiLt3r1bkvTJJ59o586devDBB7Vz50698MIL2r9/v26++WavlwIAAOKAzznnvHyBvLw8XXfddVq8eLEkqbm5WZmZmZoxY4bmzJlz1vhx48bp1KlTWrduXXTf8OHDNXToUC1durTF19i+fbtyc3N14MABZWVlfeWc6urqlJqaqkgkIr/f/zVXBgAA2tP5vn97euWmoaFBlZWVCgaDX7xgQoKCwaBCoVCLx4RCoZjxklRYWHjO8ZIUiUTk8/mUlpbW4uP19fWqq6uL2QAAgE2exs3x48fV1NSk9PT0mP3p6ekKh8MtHhMOhy9o/OnTpzV79mwVFxefs+LKy8uVmpoa3TIzM7/GagAAQDyI609LNTY26rbbbpNzTk8//fQ5x82dO1eRSCS6HTp0qB1nCQAA2lOil0/eq1cvdenSRdXV1TH7q6urFQgEWjwmEAic1/gzYXPgwAFt2rSp1X97S05OVnJy8tdcBQAAiCeeXrlJSkpSTk6OKioqovuam5tVUVGh/Pz8Fo/Jz8+PGS9JGzdujBl/Jmzeffdd/fOf/1TPnj29WQAAAIg7nl65kaTS0lJNmjRJw4YNU25urhYuXKhTp05p8uTJkqSJEyeqb9++Ki8vlyTde++9GjlypB577DGNHj1aK1eu1I4dO/TMM89I+jxsbr31Vu3cuVPr1q1TU1NT9H6cHj16KCkpyeslAQCATszzuBk3bpyOHTum+fPnKxwOa+jQodqwYUP0puGDBw8qIeGLC0gjRozQihUrNG/ePN1///0aMGCA1q5dq2uvvVaSdOTIEf3973+XJA0dOjTmtV555RX94Ac/8HpJAACgE/P8e246I77nBgCA+NMpvucGAACgvRE3AADAFOIGAACYQtwAAABTiBsAAGAKcQMAAEwhbgAAgCnEDQAAMIW4AQAAphA3AADAFOIGAACYQtwAAABTiBsAAGAKcQMAAEwhbgAAgCnEDQAAMIW4AQAAphA3AADAFOIGAACYQtwAAABTiBsAAGAKcQMAAEwhbgAAgCnEDQAAMIW4AQAAphA3AADAFOIGAACYQtwAAABTiBsAAGAKcQMAAEwhbgAAgCnEDQAAMIW4AQAAphA3AADAFOIGAACYQtwAAABTiBsAAGAKcQMAAEwhbgAAgCnEDQAAMIW4AQAAphA3AADAFOIGAACYQtwAAABTiBsAAGAKcQMAAEwhbgAAgCnEDQAAMIW4AQAAphA3AADAFOIGAACYQtwAAABTiBsAAGAKcQMAAEwhbgAAgCnEDQAAMKVd4mbJkiXq37+/UlJSlJeXp23btrU6fvXq1Ro4cKBSUlI0ePBgrV+/PuZx55zmz5+vyy+/XN26dVMwGNS7777r5RIAAECc8DxuVq1apdLSUpWVlWnnzp0aMmSICgsLVVNT0+L4LVu2qLi4WCUlJXrzzTdVVFSkoqIi7d69OzrmkUce0RNPPKGlS5dq69atuvTSS1VYWKjTp097vRwAANDJ+ZxzzssXyMvL03XXXafFixdLkpqbm5WZmakZM2Zozpw5Z40fN26cTp06pXXr1kX3DR8+XEOHDtXSpUvlnFNGRoZmzpypX/ziF5KkSCSi9PR0LVu2TLfffvtXzqmurk6pqamKRCLy+/1ttFIAAOCl833/9vTKTUNDgyorKxUMBr94wYQEBYNBhUKhFo8JhUIx4yWpsLAwOv69995TOByOGZOamqq8vLxzPmd9fb3q6upiNgAAYJOncXP8+HE1NTUpPT09Zn96errC4XCLx4TD4VbHn/n1Qp6zvLxcqamp0S0zM/NrrQcAAHR+F8WnpebOnatIJBLdDh061NFTAgAAHvE0bnr16qUuXbqouro6Zn91dbUCgUCLxwQCgVbHn/n1Qp4zOTlZfr8/ZgMAADZ5GjdJSUnKyclRRUVFdF9zc7MqKiqUn5/f4jH5+fkx4yVp48aN0fFXXnmlAoFAzJi6ujpt3br1nM8JAAAuHolev0BpaakmTZqkYcOGKTc3VwsXLtSpU6c0efJkSdLEiRPVt29flZeXS5LuvfdejRw5Uo899phGjx6tlStXaseOHXrmmWckST6fTz//+c/161//WgMGDNCVV16pBx98UBkZGSoqKvJ6OQAAoJPzPG7GjRunY8eOaf78+QqHwxo6dKg2bNgQvSH44MGDSkj44gLSiBEjtGLFCs2bN0/333+/BgwYoLVr1+raa6+NjvnlL3+pU6dOacqUKaqtrdX3v/99bdiwQSkpKV4vBwAAdHKef89NZ8T33AAAEH86xffcAAAAtDfiBgAAmELcAAAAU4gbAABgCnEDAABMIW4AAIApxA0AADCFuAEAAKYQNwAAwBTiBgAAmELcAAAAU4gbAABgCnEDAABMIW4AAIApxA0AADCFuAEAAKYQNwAAwBTiBgAAmELcAAAAU4gbAABgCnEDAABMIW4AAIApxA0AADCFuAEAAKYQNwAAwBTiBgAAmELcAAAAU4gbAABgCnEDAABMIW4AAIApxA0AADCFuAEAAKYQNwAAwBTiBgAAmELcAAAAU4gbAABgCnEDAABMIW4AAIApxA0AADCFuAEAAKYQNwAAwBTiBgAAmELcAAAAU4gbAABgCnEDAABMIW4AAIApxA0AADCFuAEAAKYQNwAAwBTiBgAAmELcAAAAU4gbAABgCnEDAABMIW4AAIApxA0AADCFuAEAAKZ4FjcnTpzQ+PHj5ff7lZaWppKSEn388cetHnP69GlNmzZNPXv2VPfu3TV27FhVV1dHH3/77bdVXFyszMxMdevWTdnZ2Vq0aJFXSwAAAHHIs7gZP3689uzZo40bN2rdunV67bXXNGXKlFaPue+++/Tiiy9q9erVevXVV3X06FHdcsst0ccrKyvVp08fPffcc9qzZ48eeOABzZ07V4sXL/ZqGQAAIM74nHOurZ903759uuaaa7R9+3YNGzZMkrRhwwbddNNNOnz4sDIyMs46JhKJqHfv3lqxYoVuvfVWSVJVVZWys7MVCoU0fPjwFl9r2rRp2rdvnzZt2nTe86urq1NqaqoikYj8fv/XWCEAAGhv5/v+7cmVm1AopLS0tGjYSFIwGFRCQoK2bt3a4jGVlZVqbGxUMBiM7hs4cKCysrIUCoXO+VqRSEQ9evRou8kDAIC4lujFk4bDYfXp0yf2hRIT1aNHD4XD4XMek5SUpLS0tJj96enp5zxmy5YtWrVqlV566aVW51NfX6/6+vro7+vq6s5jFQAAIB5d0JWbOXPmyOfztbpVVVV5NdcYu3fv1pgxY1RWVqYbbrih1bHl5eVKTU2NbpmZme0yRwAA0P4u6MrNzJkzdeedd7Y65qqrrlIgEFBNTU3M/s8++0wnTpxQIBBo8bhAIKCGhgbV1tbGXL2prq4+65i9e/eqoKBAU6ZM0bx5875y3nPnzlVpaWn093V1dQQOAABGXVDc9O7dW7179/7Kcfn5+aqtrVVlZaVycnIkSZs2bVJzc7Py8vJaPCYnJ0ddu3ZVRUWFxo4dK0nav3+/Dh48qPz8/Oi4PXv26Prrr9ekSZP0m9/85rzmnZycrOTk5PMaCwAA4psnn5aSpBtvvFHV1dVaunSpGhsbNXnyZA0bNkwrVqyQJB05ckQFBQVavny5cnNzJUk/+9nPtH79ei1btkx+v18zZsyQ9Pm9NdLn/xR1/fXXq7CwUAsWLIi+VpcuXc4rus7g01IAAMSf833/9uSGYkl6/vnnNX36dBUUFCghIUFjx47VE088EX28sbFR+/fv1yeffBLd9/jjj0fH1tfXq7CwUE899VT08TVr1ujYsWN67rnn9Nxzz0X3X3HFFXr//fe9WgoAAIgjnl256cy4cgMAQPzp0O+5AQAA6CjEDQAAMIW4AQAAphA3AADAFOIGAACYQtwAAABTiBsAAGAKcQMAAEwhbgAAgCnEDQAAMIW4AQAAphA3AADAFOIGAACYQtwAAABTiBsAAGAKcQMAAEwhbgAAgCnEDQAAMIW4AQAAphA3AADAFOIGAACYQtwAAABTiBsAAGAKcQMAAEwhbgAAgCnEDQAAMIW4AQAAphA3AADAFOIGAACYQtwAAABTiBsAAGAKcQMAAEwhbgAAgCnEDQAAMIW4AQAAphA3AADAFOIGAACYQtwAAABTiBsAAGAKcQMAAEwhbgAAgCnEDQAAMIW4AQAAphA3AADAFOIGAACYQtwAAABTiBsAAGAKcQMAAEwhbgAAgCnEDQAAMIW4AQAAphA3AADAFOIGAACYQtwAAABTiBsAAGAKcQMAAEwhbgAAgCmexc2JEyc0fvx4+f1+paWlqaSkRB9//HGrx5w+fVrTpk1Tz5491b17d40dO1bV1dUtjv3www/Vr18/+Xw+1dbWerACAAAQjzyLm/Hjx2vPnj3auHGj1q1bp9dee01Tpkxp9Zj77rtPL774olavXq1XX31VR48e1S233NLi2JKSEn3nO9/xYuoAACCO+Zxzrq2fdN++fbrmmmu0fft2DRs2TJK0YcMG3XTTTTp8+LAyMjLOOiYSiah3795asWKFbr31VklSVVWVsrOzFQqFNHz48OjYp59+WqtWrdL8+fNVUFCgjz76SGlpaec9v7q6OqWmpioSicjv9//fFgsAANrF+b5/e3LlJhQKKS0tLRo2khQMBpWQkKCtW7e2eExlZaUaGxsVDAaj+wYOHKisrCyFQqHovr179+rhhx/W8uXLlZBwftOvr69XXV1dzAYAAGzyJG7C4bD69OkTsy8xMVE9evRQOBw+5zFJSUlnXYFJT0+PHlNfX6/i4mItWLBAWVlZ5z2f8vJypaamRrfMzMwLWxAAAIgbFxQ3c+bMkc/na3Wrqqryaq6aO3eusrOzdccdd1zwcZFIJLodOnTIoxkCAICOlnghg2fOnKk777yz1TFXXXWVAoGAampqYvZ/9tlnOnHihAKBQIvHBQIBNTQ0qLa2NubqTXV1dfSYTZs2adeuXVqzZo0k6cztQr169dIDDzyghx56qMXnTk5OVnJy8vksEQAAxLkLipvevXurd+/eXzkuPz9ftbW1qqysVE5OjqTPw6S5uVl5eXktHpOTk6OuXbuqoqJCY8eOlSTt379fBw8eVH5+viTpL3/5iz799NPoMdu3b9dPfvITbd68Wd/85jcvZCkAAMCoC4qb85Wdna1Ro0bprrvu0tKlS9XY2Kjp06fr9ttvj35S6siRIyooKNDy5cuVm5ur1NRUlZSUqLS0VD169JDf79eMGTOUn58f/aTUlwPm+PHj0de7kE9LAQAAuzyJG0l6/vnnNX36dBUUFCghIUFjx47VE088EX28sbFR+/fv1yeffBLd9/jjj0fH1tfXq7CwUE899ZRXUwQAAAZ58j03nR3fcwMAQPzp0O+5AQAA6CjEDQAAMIW4AQAAphA3AADAFOIGAACYQtwAAABTiBsAAGAKcQMAAEwhbgAAgCnEDQAAMIW4AQAAphA3AADAFOIGAACYQtwAAABTiBsAAGAKcQMAAEwhbgAAgCnEDQAAMIW4AQAAphA3AADAFOIGAACYQtwAAABTiBsAAGAKcQMAAEwhbgAAgCnEDQAAMIW4AQAAphA3AADAFOIGAACYQtwAAABTiBsAAGAKcQMAAEwhbgAAgCnEDQAAMIW4AQAAphA3AADAFOIGAACYQtwAAABTiBsAAGAKcQMAAEwhbgAAgCnEDQAAMCWxoyfQEZxzkqS6uroOngkAADhfZ963z7yPn8tFGTcnT56UJGVmZnbwTAAAwIU6efKkUlNTz/m4z31V/hjU3Nyso0eP6rLLLpPP5+vo6XS4uro6ZWZm6tChQ/L7/R09HbM4z+2D89w+OM/tg/McyzmnkydPKiMjQwkJ576z5qK8cpOQkKB+/fp19DQ6Hb/fzx+edsB5bh+c5/bBeW4fnOcvtHbF5gxuKAYAAKYQNwAAwBTiBkpOTlZZWZmSk5M7eiqmcZ7bB+e5fXCe2wfn+eu5KG8oBgAAdnHlBgAAmELcAAAAU4gbAABgCnEDAABMIW4uAidOnND48ePl9/uVlpamkpISffzxx60ec/r0aU2bNk09e/ZU9+7dNXbsWFVXV7c49sMPP1S/fv3k8/lUW1vrwQrigxfn+e2331ZxcbEyMzPVrVs3ZWdna9GiRV4vpdNZsmSJ+vfvr5SUFOXl5Wnbtm2tjl+9erUGDhyolJQUDR48WOvXr4953Dmn+fPn6/LLL1e3bt0UDAb17rvvermEuNCW57mxsVGzZ8/W4MGDdemllyojI0MTJ07U0aNHvV5Gp9fWP8//a+rUqfL5fFq4cGEbzzrOOJg3atQoN2TIEPfGG2+4zZs3u29961uuuLi41WOmTp3qMjMzXUVFhduxY4cbPny4GzFiRItjx4wZ42688UYnyX300UcerCA+eHGe//CHP7h77rnH/etf/3L//e9/3R//+EfXrVs39+STT3q9nE5j5cqVLikpyT377LNuz5497q677nJpaWmuurq6xfGvv/6669Kli3vkkUfc3r173bx581zXrl3drl27omN++9vfutTUVLd27Vr39ttvu5tvvtldeeWV7tNPP22vZXU6bX2ea2trXTAYdKtWrXJVVVUuFAq53Nxcl5OT057L6nS8+Hk+44UXXnBDhgxxGRkZ7vHHH/d4JZ0bcWPc3r17nSS3ffv26L5//OMfzufzuSNHjrR4TG1trevatatbvXp1dN++ffucJBcKhWLGPvXUU27kyJGuoqLioo4br8/z/7r77rvdD3/4w7abfCeXm5vrpk2bFv19U1OTy8jIcOXl5S2Ov+2229zo0aNj9uXl5bmf/vSnzjnnmpubXSAQcAsWLIg+Xltb65KTk92f/vQnD1YQH9r6PLdk27ZtTpI7cOBA20w6Dnl1ng8fPuz69u3rdu/e7a644oqLPm74ZynjQqGQ0tLSNGzYsOi+YDCohIQEbd26tcVjKisr1djYqGAwGN03cOBAZWVlKRQKRfft3btXDz/8sJYvX97qf2B2MfDyPH9ZJBJRjx492m7ynVhDQ4MqKytjzlFCQoKCweA5z1EoFIoZL0mFhYXR8e+9957C4XDMmNTUVOXl5bV63i3z4jy3JBKJyOfzKS0trU3mHW+8Os/Nzc2aMGGCZs2apUGDBnkz+Thzcb8jXQTC4bD69OkTsy8xMVE9evRQOBw+5zFJSUln/QWUnp4ePaa+vl7FxcVasGCBsrKyPJl7PPHqPH/Zli1btGrVKk2ZMqVN5t3ZHT9+XE1NTUpPT4/Z39o5CofDrY4/8+uFPKd1XpznLzt9+rRmz56t4uLii/Y/gPTqPP/ud79TYmKi7rnnnrafdJwibuLUnDlz5PP5Wt2qqqo8e/25c+cqOztbd9xxh2ev0Rl09Hn+X7t379aYMWNUVlamG264oV1eE2gLjY2Nuu222+Sc09NPP93R0zGlsrJSixYt0rJly+Tz+Tp6Op1GYkdPAF/PzJkzdeedd7Y65qqrrlIgEFBNTU3M/s8++0wnTpxQIBBo8bhAIKCGhgbV1tbGXFWorq6OHrNp0ybt2rVLa9askfT5p08kqVevXnrggQf00EMPfc2VdS4dfZ7P2Lt3rwoKCjRlyhTNmzfva60lHvXq1UtdunQ565N6LZ2jMwKBQKvjz/xaXV2tyy+/PGbM0KFD23D28cOL83zGmbA5cOCANm3adNFetZG8Oc+bN29WTU1NzBX0pqYmzZw5UwsXLtT777/ftouIFx190w+8deZG1x07dkT3vfzyy+d1o+uaNWui+6qqqmJudP3Pf/7jdu3aFd2effZZJ8lt2bLlnHf9W+bVeXbOud27d7s+ffq4WbNmebeATiw3N9dNnz49+vumpibXt2/fVm/A/NGPfhSzLz8//6wbih999NHo45FIhBuK2/g8O+dcQ0ODKyoqcoMGDXI1NTXeTDzOtPV5Pn78eMzfxbt27XIZGRlu9uzZrqqqyruFdHLEzUVg1KhR7rvf/a7bunWr+/e//+0GDBgQ8xHlw4cPu6uvvtpt3bo1um/q1KkuKyvLbdq0ye3YscPl5+e7/Pz8c77GK6+8clF/Wso5b87zrl27XO/evd0dd9zhPvjgg+h2Mb1RrFy50iUnJ7tly5a5vXv3uilTpri0tDQXDoedc85NmDDBzZkzJzr+9ddfd4mJie7RRx91+/btc2VlZS1+FDwtLc397W9/c++8844bM2YMHwVv4/Pc0NDgbr75ZtevXz/31ltvxfz81tfXd8gaOwMvfp6/jE9LETcXhQ8//NAVFxe77t27O7/f7yZPnuxOnjwZffy9995zktwrr7wS3ffpp5+6u+++233jG99wl1xyifvxj3/sPvjgg3O+BnHjzXkuKytzks7arrjiinZcWcd78sknXVZWlktKSnK5ubnujTfeiD42cuRIN2nSpJjxf/7zn923v/1tl5SU5AYNGuReeumlmMebm5vdgw8+6NLT011ycrIrKChw+/fvb4+ldGpteZ7P/Ly3tP3vn4GLUVv/PH8ZceOcz7n/f7MEAACAAXxaCgAAmELcAAAAU4gbAABgCnEDAABMIW4AAIApxA0AADCFuAEAAKYQNwAAwBTiBgAAmELcAAAAU4gbAABgCnEDAABM+X9JnGEujayxKgAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import smilecorrector_gsvi_jo_mw_ar as smilenet\n",
    "import torch\n",
    "importlib.reload(smilenet)\n",
    "# For first try, we pass our boundaries as each strike price\n",
    "# boundaries = processed_60['strike_price'].apply(np.log).to_numpy()\n",
    "# ind = np.array([i for i in range(0,boundaries.shape[0],3)])\n",
    "# boundaries = boundaries[ind]\n",
    "# strikes = boundaries.copy()\n",
    "R = 0.0056 # Rate for > 122 day\n",
    "F = 2266.349134 # for ID 102434, Exp date 05/31/2022\n",
    "T = 5 * 31 / 365\n",
    "S = F * np.exp(-R * T)\n",
    "print(T)\n",
    "processed_60 = remove(processed, 0.40, F)\n",
    "log_strikes_60 = torch.tensor((processed_60['strike_price'].apply(np.log).to_numpy()- np.log(F))) #   \n",
    "print(log_strikes_60)\n",
    "S = torch.tensor(S).reshape(1,1)\n",
    "T = torch.tensor(T).reshape(1,1)\n",
    "R = torch.tensor(R).reshape(1,1)\n",
    "params = (0, 0.4, -0.6, 0, 0.2)\n",
    "# his_60, lows_60 = svi_with_noise(log_strikes_60, *params)\n",
    "# mids_60 = torch.tensor(his_60 + lows_60) / 2\n",
    "# mids_60 = mids_60 * T\n",
    "his_60 = processed_60['vol_high'].to_numpy() ** 2 * T.item()\n",
    "lows_60 = processed_60['vol_low'].to_numpy() ** 2 * T.item()\n",
    "# mids_60 = torch.tensor(((processed_60['vol_high'].to_numpy() + processed_60['vol_low'].to_numpy()) / 2))\n",
    "mids_60 = (his_60 + lows_60) / 2\n",
    "print(mids_60.shape)\n",
    "mids_60 = mids_60\n",
    "print(mids_60.shape)\n",
    "print('Mid shape', mids_60.shape)\n",
    "# print(mids_60)\n",
    "low = min(mids_60**2)/2\n",
    "print(low)\n",
    "print(his_60.shape, lows_60.shape)\n",
    "# datum, log_strikes_60 = pipeline.get_datum('2022-0') \n",
    "model = smilenet.SmileNet(5, log_strikes_60, mids_60, low)#, low)\n",
    "datum = torch.tensor(np.vstack([ his_60.reshape(-1,1) , lows_60.reshape(-1,1) , log_strikes_60.reshape(-1,1), np.log(S), T, R])).double()\n",
    "print(log_strikes_60.shape, datum.shape)\n",
    "print(datum.T.shape)\n",
    "w_60 = model.train(datum.T.double(), log_strikes_60, epochs=1601)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiwAAAGdCAYAAAAxCSikAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8g+/7EAAAACXBIWXMAAA9hAAAPYQGoP6dpAABWbElEQVR4nO3deXhU5f3+8fc5M5kMSxI2SQKyRFAwgOyE4IK1tKCIYl2QyqKlalGpFutPsGrk6wIqKlUQFXdRQawgII0iLlUIRAkoIYCIYRGyCNEkBLLNnN8fMZHAJJnJNpPkfl3XXDQnz8w8c6rOzbN8HsOyLAsRERGRAGb6uwMiIiIiVVFgERERkYCnwCIiIiIBT4FFREREAp4Ci4iIiAQ8BRYREREJeAosIiIiEvAUWERERCTg2f3dgdrgdrs5dOgQISEhGIbh7+6IiIiIFyzLIjc3lw4dOmCalY+hNIrAcujQITp16uTvboiIiEg1HDhwgNNPP73SNo0isISEhAAlHzg0NNTPvRERERFv5OTk0KlTp7Lv8cpUK7AsWLCAxx9/nPT0dPr27cszzzzDkCFDPLbdvn07999/P5s3b2bfvn089dRT3HHHHeXazJ49m/fee4+dO3fSrFkzhg0bxqOPPkqPHj286k/pNFBoaKgCi4iISAPjzXIOnxfdLl26lOnTpxMXF0dSUhJ9+/Zl5MiRZGZmemx/7NgxzjjjDObMmUNERITHNp9//jm33norGzduZO3atRQVFfHHP/6RvLw8X7snIiIijZDh62nNMTExDB48mPnz5wMlC147derEtGnTmDFjRqXP7dq1K3fccccpIywn++mnn2jfvj2ff/45F1xwQZV9ysnJISwsjOzsbI2wiIiINBC+fH/7NMJSWFjI5s2bGTFixG8vYJqMGDGChISE6vXWg+zsbADatGnj8fcFBQXk5OSUe4iIiEjj5VNgOXz4MC6Xi/Dw8HLXw8PDSU9Pr5UOud1u7rjjDs4991x69+7tsc3s2bMJCwsre2iHkIiISOMWcIXjbr31VpKTk1myZEmFbWbOnEl2dnbZ48CBA/XYQxEREalvPu0SateuHTabjYyMjHLXMzIyKlxQ64vbbruN1atX87///a/S/djBwcEEBwfX+P1ERESkYfBphMXhcDBw4EDWrVtXds3tdrNu3TpiY2Or3QnLsrjttttYvnw5n3zyCVFRUdV+LREREWl8fK7DMn36dCZPnsygQYMYMmQI8+bNIy8vjxtuuAGASZMm0bFjR2bPng2ULNRNSUkp+98HDx5k69attGzZku7duwMl00BvvfUW77//PiEhIWXrYcLCwmjWrFmtfFARERFpuHze1gwwf/78ssJx/fr14+mnnyYmJgaACy+8kK5du/Lqq68CsHfvXo8jJsOHD+ezzz4r6UQFBWNeeeUVrr/++ir7U1fbml1ui8TULDJz82kf4mRIVBtsps4qEhERqQ2+fH9XK7AEmroILPHJacxalUJadn7ZtcgwJ3FjohnVO7JW3kNERKQpq7M6LE1FfHIaUxcnlQsrAOnZ+UxdnER8cpqfeiYiItI0KbCcxOW2mLUqBU/DTqXXZq1KweVu8ANTIiIiDYYCy0kSU7NOGVk5kQWkZeeTmJpVf50SERFp4hRYTpKZW3FYqU47ERERqTkFlpO0D3HWajsRERGpOQWWkwyJakNkmJOKNi8blOwWGhLl+WBGERERqX0KLCexmQZxY6IBTgktpT/HjYlWPRYREZF6pMDiwajekSycMICIsPLTPhFhThZOGKA6LCIiIvXM59L8TcWo3pH8ITpClW5FREQCgAJLJWymQWy3tv7uhoiISJOnKSEREREJeAosIiIiEvAUWERERCTgKbCIiIhIwFNgERERkYCnwCIiIiIBT4FFREREAp4Ci4iIiAQ8BRYREREJeAosIiIiEvAUWERERCTgKbCIiIhIwFNgERERkYCnwCIiIiIBT4FFREREAp7d3x1oClxui8TULDJz82kf4mRIVBtspuHvbomIiDQYCix1LD45jVmrUkjLzi+7FhnmJG5MNKN6R/qxZyIiIg2HpoTqUHxyGlMXJ5ULKwDp2flMXZxEfHKan3omIiLSsCiw1BGX22LWqhQsD78rvTZrVQout6cWIiIiciIFljqSmJp1ysjKiSwgLTufxNSs+uuUiIhIA6XAUkcycysOK9VpJyIi0pQpsNSR9iHOWm0nIiLSlCmw1JEhUW2IDHNS0eZlg5LdQkOi2tRnt0RERBokBZY6YjMN4sZEA5wSWkp/jhsTrXosIiIiXlBgqUOjekeycMIAIsLKT/tEhDlZOGGA6rCIiIh4SYXj6tio3pH8ITpClW5FRERqQIGlHthMg9hubf3dDRERkQZLU0IiIiIS8BRYREREJOApsIiIiEjAU2ARERGRgKfAIiIiIgFPgUVEREQCngKLiIiIBDwFFhEREQl4CiwiIiIS8BRYREREJOApsIiIiEjAU2ARERGRgKfAIiIiIgFPpzU3IC63RWJqFpm5+bQPcTIkqg020/B3t0REROqcAksDEZ+cxqxVKaRl55ddiwxzEjcmmlG9I/3YMxERkbqnKaEGID45jamLk8qFFYD07HymLk4iPjnNTz0TERGpHwosAc7ltpi1KgXLw+9Kr81alYLL7amFiIhI41CtwLJgwQK6du2K0+kkJiaGxMTECttu376dK6+8kq5du2IYBvPmzavxazYlialZp4ysnMgC0rLzSUzNqr9OiYiI1DOfA8vSpUuZPn06cXFxJCUl0bdvX0aOHElmZqbH9seOHeOMM85gzpw5RERE1MprNiWZuRWHleq0ExERaYh8DixPPvkkN954IzfccAPR0dE899xzNG/enJdfftlj+8GDB/P4449z7bXXEhwcXCuv2ZS0D3HWajsREZGGyKfAUlhYyObNmxkxYsRvL2CajBgxgoSEhGp1oDqvWVBQQE5OTrlHYzUkqg2RYU4q2rxsULJbaEhUm/rsloiISL3yKbAcPnwYl8tFeHh4uevh4eGkp6dXqwPVec3Zs2cTFhZW9ujUqVO13rshsJkGcWOiAU4JLaU/x42JVj0WERFp1BrkLqGZM2eSnZ1d9jhw4IC/u1SnRvWOZOGEAUSElZ/2iQhzsnDCANVhERGRRs+nwnHt2rXDZrORkZFR7npGRkaFC2rr4jWDg4MrXA/TWI3qHckfoiNU6VZERJokn0ZYHA4HAwcOZN26dWXX3G4369atIzY2tlodqIvXbKxspkFst7Zc3q8jsd3aKqyIiEiT4XNp/unTpzN58mQGDRrEkCFDmDdvHnl5edxwww0ATJo0iY4dOzJ79mygZFFtSkpK2f8+ePAgW7dupWXLlnTv3t2r1xQREZGmzefAMm7cOH766Sfuv/9+0tPT6devH/Hx8WWLZvfv349p/jZwc+jQIfr371/289y5c5k7dy7Dhw/ns88+8+o1RUREpGkzLMtq8DXdc3JyCAsLIzs7m9DQUH93R0RERLzgy/d3g9wlJCIiIk2LAouIiIgEPAUWERERCXgKLCIiIhLwFFhEREQk4CmwiIiISMBTYBEREZGAp8AiIiIiAc/nSrfScLnclg5PFBGRBkmBpYmIT05j1qoU0rLzy65FhjmJGxPNqN6RfuyZiIhI1TQl1ATEJ6cxdXFSubACkJ6dz9TFScQnp/mpZyIiIt5RYGnkXG6LWatS8HRgVOm1WatScLkb/JFSIiLSiCmwNHKJqVmnjKycyALSsvNJTM2qv06JiIj4SIGlkcvMrTisVKediIiIPyiwNHLtQ5y12k5ERMQfFFgauSFRbYgMc1LR5mWDkt1CQ6La1Ge3REREfKLA0sjZTIO4MdEAp4SW0p/jxkSrHouIiAQ0BZYmYFTvSBZOGEBEWPlpn4gwJwsnDFAdFhERCXgqHFeF/333Ey2ddgZ0bu3vrtTIqN6R/CE6QpVuRUSkQVJgqcTujFxueTOJQpebJ67uy5i+HfzdpRqxmQax3dr6uxsiIiI+05RQJTq0asbQM9pSWOxm2ttbmP/JbixLBdZERETqmwJLJVoE23l+4kD+el4UAHM/+o47l31DQbHLzz0TERFpWhRYqmAzDe69NJqHxvbGZhq8l3SQiS8l8nNeob+7JiIi0mQosHhpwtAuvHL9YEKC7SSmZnHFs+v54aej/u6WiIhIk6DA4oMLzjqN/9wyjI6tmrH3yDH+tHADG3844u9uiYiINHoKLD46KzyEFbeeS//OrfjlWBETX9rEu5t/9He3REREGjUFlmo4LSSYt28cyuhzIilyWfxz2TfM/XAXbrd2EImIiNQFBZZqcgbZeOba/ky7qDsA8z/9nmlLtpBfpB1EIiIitU2BpQZM0+DOP/Zg7tV9CbIZfPBtGte+sJGfcgv83TUREZFGRYGlFlw18HTemBJDq+ZBbD3wC2MXrGdXeq6/uyUiItJoKLDUkqFntGX5LecS1a4FB385zlULN/D5dz/5u1u1zuW2SNhzhPe3HiRhzxFcWrcjIiL1wLAaQa35nJwcwsLCyM7OJjQ01K99+TmvkJsXbyYxNQubafDAZb2YOLSLX/tUW+KT05i1KoW07Pyya5FhTuLGROvEZxER8Zkv398aYallrVs4WDwlhisHnI7LbXHfimQeXJ3S4Eci4pPTmLo4qVxYAUjPzmfq4iTik9P81DMREWkKFFjqgMNuMvfqc7hrZA8AXvoylZvf+Jq8gmI/96x6XG6LWatS8BS5Sq/NWtXwQ5mIiAQuBZY6YhgGt/6uO/P/3B+H3eTjHZlc/VwCadnH/d01nyWmZp0ysnIiC0jLzicxNav+OiUiIk2KAksdu/ScDiy5aSjtWjpIScth7IL1JB/M9ne3fJKZW3FYqU47ERERXymw1IMBnVuz/JZzObN9SzJyCrj6uQQ+2p7u7255rX2Is1bbiYiI+EqBpZ50atOc/9wyjPPPbMfxIhc3L97Mi1/8QEPYpDUkqg2RYU6MCn5vULJbaEhUm/rsloiINCEKLPUo1BnEK9cP5rqYzlgWPPTBDv61Ipkil9vfXauUzTSIGxMNcEpoKf05bkw0NrOiSCMiIlIzCiz1zG4zeWhsb+67NBrDgLc27ecvr35FTn6Rv7tWqVG9I1k4YQARYeWnfSLCnCycMEB1WEREpE6pcJwfrU3J4PYlWzhW6OLM9i15+frBdGrT3N/dqpTLbZGYmkVmbj7tQ0qmgTSyIiIi1eHL97cCi58lH8xmymtfkZFTQNsWDl6YNIiBXVr7u1siIiJ1TpVuG5DeHcN4/9bz6NUhlCN5hYxftJFV3xzyd7dEREQCigJLAIgIc/LOzbGMODucwmI3097ewjPrdjeIHUQiIiL1QYElQLQItvP8xIH89bwoAJ5Y+x13LvuGgmKXn3smIiLifwosAcRmGtx7aTQPje2NzTR4L+kgE19K5Oe8Qn93TURExK8UWALQhKFdeOX6wYQE20lMzeKKZ9fzw09H/d0tERERv1FgCVAXnHUa/7llGB1bNWPvkWNc8ewGNv5wxN/dEhER8QsFlgB2VngIK249l/6dW5F9vIiJL21i2dcH/N0tERGReqfAEuBOCwnm7RuHMvqcSIpcFne9+y2Pf7gTt1s7iEREpOlQYGkAnEE2nrm2P9Mu6g7Agk/3MO3tLeQXNawdRC63RcKeI7y/9SAJe47gUugSEREv2f3dAfGOaRrc+ccedGnbgpnvfcsH29I4+MtxFk0axGkhwf7uXpXik9OYtSqFtOz8smuRYU7ixkTrHCIREamSRlgamKsGns4bU2Jo1TyIrQd+YeyC9exKz/V3tyoVn5zG1MVJ5cIKQHp2PlMXJxGfnOannomISEOhwNIADT2jLctvOZeodi04+Mtxrly4gc+/+8nf3fLI5baYtSoFT5M/pddmrUrR9JCIiFSqWoFlwYIFdO3aFafTSUxMDImJiZW2X7ZsGT179sTpdNKnTx/WrFlT7vdHjx7ltttu4/TTT6dZs2ZER0fz3HPPVadrtcvtgtQvYNu7JX+6A2fNSFS7Fiy/ZRgxUW04WlDMX179ijc27vN3t06RmJp1ysjKiSwgLTufxNSs+uuUiIg0OD4HlqVLlzJ9+nTi4uJISkqib9++jBw5kszMTI/tN2zYwPjx45kyZQpbtmxh7NixjB07luTk5LI206dPJz4+nsWLF7Njxw7uuOMObrvtNlauXFn9T1ZTKSthXm947VL4z5SSP+f1LrkeIFo1d/DGlBiuHHA6LrfFfSuS+b8AG63IzK04rFSnnYiINE2G5eMJezExMQwePJj58+cD4Ha76dSpE9OmTWPGjBmntB83bhx5eXmsXr267NrQoUPp169f2ShK7969GTduHPfdd19Zm4EDB3LxxRfz0EMPVdknX46n9krKSnhnEpwykWGU/HHN6xB9mfev53bBvg1wNANahkOXYWDaat7PX1mWxbOf7eHxD3cBMOLs9vz72v60CPb/muqEPUcYv2hjle3evnEosd3a1kOPREQkUPjy/e3TCEthYSGbN29mxIgRv72AaTJixAgSEhI8PichIaFce4CRI0eWaz9s2DBWrlzJwYMHsSyLTz/9lO+++44//vGPHl+zoKCAnJycco9a43ZB/N2cGlb47Vr8DO+nh+phpMYwDG79XXfm/7k/wXaTj3dkcvVzCaRlH6+196iuIVFtiAxzlka9UxiU7BYaEtWmPrslIiINjE+B5fDhw7hcLsLDw8tdDw8PJz093eNz0tPTq2z/zDPPEB0dzemnn47D4WDUqFEsWLCACy64wONrzp49m7CwsLJHp06dfPkYldu3AXIOVdLAgpyDJe2qUjpSc/Lr5aSVXK/l6aVLz+nA2zcNpV1LBylpOYxdsJ5tP2bX6nv4ymYaxI2JBjgltJT+HDcmGptZUaQREREJkF1CzzzzDBs3bmTlypVs3ryZJ554gltvvZWPP/7YY/uZM2eSnZ1d9jhwoBbL1R/NqJ12tT1S46UBnVuz/JZzOSu8JRk5BVzzfAIfbfccJuvLqN6RLJwwgIgwZ7nrEWFOFk4YoDosIiJSJZ8WObRr1w6bzUZGRvkv64yMDCIiIjw+JyIiotL2x48f55577mH58uWMHj0agHPOOYetW7cyd+7cU6aTAIKDgwkOrqNiaS3Dq27jTTtfRmqizve6e97o1KY5704dxq1vJvHF7sPcvHgz91x8Nn89PwrD8M9IxqjekfwhOoLE1Cwyc/NpH1IyDaSRFRER8YZPIywOh4OBAweybt26smtut5t169YRGxvr8TmxsbHl2gOsXbu2rH1RURFFRUWYZvmu2Gw23G63L92rHV2GQWgHTp3AKGVAaMeSdpWprZGaagp1BvHK9YO5LqYzlgUPr9nBv1YkU+Tywz39lc00iO3Wlsv7dSS2W1uFFRER8ZrP20imT5/O5MmTGTRoEEOGDGHevHnk5eVxww03ADBp0iQ6duzI7NmzAbj99tsZPnw4TzzxBKNHj2bJkiV8/fXXvPDCCwCEhoYyfPhw7rrrLpo1a0aXLl34/PPPef3113nyySdr8aN6ybTBqEd/3SVkUH5K59cv2FFzqt7lU1sjNSfycbeR3Wby0NjenHFaSx76IIW3Nu3nQNYx5v95AGHNgrx/XxERET/zObCMGzeOn376ifvvv5/09HT69etHfHx82cLa/fv3lxstGTZsGG+99Rb33nsv99xzD2eeeSYrVqygd+/eZW2WLFnCzJkzue6668jKyqJLly48/PDD/O1vf6uFj1gN0ZeVbF2Ov7v8tE5oh5Kw4s2W5tKRmpw0PK9jMUp+X9VITamUlRX059FK+2MYBlPOi6Jzm+bcvmQLX+w+zFULN/Dy9YPp1Ka5d+8tIiLiZz7XYQlEtV6HpVRN66eU1XMBjyM13tZzqaW6MMkHs5ny2ldk5BTQtoWDFyYNYmCX1lW/v4iISB3w5ftbgaWueRwZ6ej9SI3bVVK3pcIFvL+O1NyxzaswlZ6dz5TXvmL7oRwcdpMnru7LmL4dvPssIiIitUiBJdDUZKQm9YuSYnNVmbza691GeQXF3L5kKx/vKFnwe+cfzuK2i7r7bQeRiIg0TXVW6VaqybSVhIk+V5X86cu0Uh3sNmoRbOf5iQP563lRADyx9jvufOcbCooD53BHERGREymwBLq62G1EyRbjey+N5uEremMzDd7bcpCJLybyc15hNTopIiJStxRYAl1t1YWpwHUxXXjl+sGEBNtJ3JvFFc+uZ89PR6vd3briclsk7DnC+1sPkrDnSECdSC0iInVPa1gagtrabVSJ7zJy+curX/Hjz8cJaxbEcxMGBszpyfHJacxalUJadn7ZtcgwJ3FjolXWX0SkAdMalsamtC5M6ElfzqEdfAsrblfJIt5t75b8ecI5RmeFh7D8lnPp37kV2ceLmPTyJt75uhbPaKqm+OQ0pi5OKhdWoGS309TFScQnp/mpZyIiUp80wtKQ1GS3kZeF5/KLXPxz2Tes/rYkCNxyYTf++ccemH4oo+9yW5z36CenhJVSBiUHKH5590Uq8y8i0gBphKWxqu5uo9IppZNrueSklVxPWVl2yRlk4+lr+zPtou4APPvZHm57O4n8ovrfQZSYmlVhWIGSybG07HwSU7Pqr1MiIuIXCiyNndtVMrLi8XiAX6/Fzyg3PWSaBnf+sQdPXN2XIJvBmm3pjHthIz/lFtRLl0tl5lYcVqrTTkREGi4FlsZu34ZKquQCWJBzsKTdSa4ceDqLp8TQqnkQ3xz4hbEL1rMrPbfu+nqS9iHOWm0nIiINlwJLY1fDwnMxZ7Rl+S3nEtWuBQd/Oc6VCzfw+Xc/1WIHKzYkqg2RYc7KNnQTGeZkSFSbeumPiIj4jwJLY1cLheei2rVg+S3DiIlqw9GCYv7y6le8sXFfLXWwYjbTIG5MNHBqFZrSn+PGRGvBrYhIE6DA0tjVUuG5Vs0dvDElhisHnI7LbXHfimRmrdpe5wXcRvWOZOGEAUSElZ/2iQhzsnDCANVhERFpIrStuSmoxcJzlmXx7Gd7ePzDXQD8vmd7nh7fnxbB9trrrwcut0ViahaZufm0DymZBtLIiohIw6bTmuVUHuuwdIRRc6pVJXf1t4d+PTDRTXRkKC9dP4jIsGa12GEREWnsFFjEs5oUnvNgy/6fufH1rzl8tJD2IcG8NHkwfU4Pq8UOi4hIY6bAInXnpNBzILQfU15P4ruMozQLsjHv2n6M7BXh716KiEgD4Mv3d90uPJDGxcO0UqfQDrx70aPcujmcL3Yf5m+LN3PPxWfz1/OjMAytMRERkdqhXULinUrK+4eumMQrMRlMGNoZy4KH1+zgnuXJFLnc/umriIg0OgosUjUvyvvbP5rBg2PO5r5LozEMeDtxPze88hXZx4vqtasiItI4KbBI1bws72/sT2DKeVEsmjiI5g4bX35/mCsXbuBA1rF666qIiDROCixSNR/L+4+IDuedm2OJCHXyfeZRxi5Yz+Z9/jtR2eW2SNhzhPe3HiRhz5E6L3YnIiK1T4tupWrVKO/fu2MYK249lymvfcX2QzmMX7SJuVf35bK+Heqok57FJ6cxa1UKadm/negcGeYkbky0quSKiDQgGmGRqlWzvH9EmJN3bo5lxNnhFBa7+fvbW3h63W7qayd9fHIaUxcnlQsrAOnZ+UxdnER8clq99ENERGpOgUWqZtpg1KO//lDBMYSj5ngsQtci2M7zEwfy1/OiAHhy7Xe/Vsh11V1/KZkGmrUqpZJlwjBrVYqmh0REGggFFvFO9GUlZw6FnjSNEtqhyrOIbKbBvZdG8/AVvbGZBu9tOciEFzeRlVdYZ91NTM06ZWTlRBaQlp1PYqr/1taIiIj3tIZFvBd9GfQcXe3y/tfFdKFzm+bc8mYSX+39mbEL1vPy9YPp3r5lrXc1M7fisFKddiIi4l8aYRHfmDaIOh/6XFXypy9nEbldnG/fyXsjjtIpxGB/1jGueHY9X+4+XOvdbB/irNV2IiLiXwosUj9SVsK83vDapZz58V9YUXgTg4JSyc0vZvIriby1aX+tvt2QqDZEhjkrWyZMZJiTIVFtavV9RUSkbiiwSN3zUNa/rZHLYnMWY80vcbkt7lm+jYdW194iWJtpEDcmGqhwmTBxY6KxmTrvSESkIVBgkbpVSVl/p1HIU0EL+UeLDwF48ctUbn5jM3kFxbXy1qN6R7JwwgAiwspP+0SEOVk4YYDqsIiINCCGVV9FMeqQL8dTSz1L/QJeu7TKZivPXc4/Py+gsNhNdGQoL10/iMiwZrXSBZfbIjE1i8zcfNqHlEwDaWRFRMT/fPn+1giL1C0vy/pfFpHF2zcOpW0LBylpOYxdsJ5tP2bXShdspkFst7Zc3q8jsd3aKqyIiDRACixSt3wo6z+wS2tW3HouZ4W3JCOngGueTyA+Ob1u+yciIg2CAovULR/L+ndq05x3pw7jgrNO43iRi6lvbua5z/fUWzl/EREJTAosUreqUdY/1BnEy5MHMSm2C5YFc/67k7v/8y2Fxe566bKIiAQeBRape9Uo62+3mfzf5b15YEw0pgHvfP0jk19O5JdjdVfOX0REApd2CUn9cbuqVdb/052Z3PZWEnmFLs5o14KXrh9MVLsW9dBhERGpS758fyuwSIOw89AvTHl5AwePWrQKNnhu4mCGdj+tTt9T26FFROqWL9/fOvxQAl/KSnrG383yojxuNO7km4LuTHxxA48MM7n6sjF18pbxyWnMWpVS7sTnyDAncWOiVXBORMQPtIZFAtsJZf3bG9ksdTzIaDOBIuzctcHk0cWrcNdSOf9S8clpTF2cVC6sAKRn5zN1cRLxyWm1+n4iIlI1BRYJXB7K+juNIp4Jms8023IAFiab3PrmZo4XumrlLV1ui1mrUjwcJPBbL2atqr0zj0RExDsKLBK49m0od2BiKdOwuDNoGU8GPYuDIv67PYNxLySQmZPv4UV8k5iadcrIyoksIC07n8TUrBq/l4iIeE+BRQJXFWX9/2T7ksWOR2gdbPHtj9lcvmA9KYdyavSWmbnehR5v24mISO1QYJHA5UVZ/yHmLlZcEUK301qQlp3PVc9t4OMU784v8qR9iLPqRj60ExGR2qHAIoHLy7L+Xc45j/emnsu53dtyrNDFjW98zYtf/FCtcv5DotoQGeas7B2JDCvZ4iwiIvVHgUUClw9l/cOaB/HqDUMYP6QzlgUPfbCDf61IpsjlWzl/m2kQNya6snckbky06rGIiNQzBRYJbD6U9Q+ymTxyRW/uHX02hgFvbdrPX179iuzjRT695ajekSycMICIsPLTPhFhThZOGKA6LCIifqBKt9Iw+FjWf21KBrcv2cKxQhfd27fk5cmD6dy2uU9vqUq3IiJ1S6X5RYDkg9n89bWvSc/Jp00LBy9MHMigrlp7IiISKHz5/taUkDRavTuG8f5t59KnYxhZeYX8edEmVmw56O9uiYhINSiwSKMWHupk6Y2DGdnVTqHLzR1Lt/LkhzurtYNIRET8p1qBZcGCBXTt2hWn00lMTAyJiYmVtl+2bBk9e/bE6XTSp08f1qxZc0qbHTt2cNlllxEWFkaLFi0YPHgw+/fvr073RH6TspLmz/ZjYdo4/mZbCcDTn+5h2vOryS+qnXL+IiJS93wOLEuXLmX69OnExcWRlJRE3759GTlyJJmZmR7bb9iwgfHjxzNlyhS2bNnC2LFjGTt2LMnJyWVt9uzZw3nnnUfPnj357LPP+Pbbb7nvvvtwOlWcS2rghIMTTcNiRtASHrM/j51iVu81Gf/v//JTboG/eykiIl7wedFtTEwMgwcPZv78+QC43W46derEtGnTmDFjxintx40bR15eHqtXry67NnToUPr168dzzz0HwLXXXktQUBBvvPFGtT6EFt3KKdwumNfb41lECa6z+VvRP8imJR1bOXn5+iH0iAiplbfVziIREe/V2aLbwsJCNm/ezIgRI357AdNkxIgRJCQkeHxOQkJCufYAI0eOLGvvdrv54IMPOOussxg5ciTt27cnJiaGFStW+NI1kfIqODgRINa2g+WO++lqpHPwl3yuXLiBz3Z5HiH0RXxyGuc9+gnjF23k9iVbGb9oI+c9+gnxyWk1fm0RkabOp8By+PBhXC4X4eHlz3gJDw8nPT3d43PS09MrbZ+ZmcnRo0eZM2cOo0aN4qOPPuKKK67gT3/6E59//rnH1ywoKCAnJ6fcQ6ScKg5OPMNMZ7njfmLauzhaUMxfXv2K1zbsrfbbxSenMXVx0iknPadn5zN1cZJCi4hIDfl9l5DbXVI6/fLLL+cf//gH/fr1Y8aMGVx66aVlU0Ynmz17NmFhYWWPTp061WeXpSHw4uDE1sZR3risFVcNPB23BXErtxP3fjLFPpbzd7ktZq1KwdPcaum1WatScLm1M0lEpLp8Cizt2rXDZrORkVH+b68ZGRlERER4fE5ERESl7du1a4fdbic6Orpcm7PPPrvCXUIzZ84kOzu77HHgwAFfPoY0BV4enOg441wev+oc/t+oHgC8lrCPv77+Nbn53pfzT0zNOmVk5UQWkJadT2Jqlvf9FxGRcnwKLA6Hg4EDB7Ju3bqya263m3Xr1hEbG+vxObGxseXaA6xdu7asvcPhYPDgwezatatcm++++44uXbp4fM3g4GBCQ0PLPUTK8eHgRMMwuOXC7iy8bgDOIJPPdv3EVQsT+PHnY169VWZuxWGlOu1ERORUPk8JTZ8+nUWLFvHaa6+xY8cOpk6dSl5eHjfccAMAkyZNYubMmWXtb7/9duLj43niiSfYuXMnDzzwAF9//TW33XZbWZu77rqLpUuXsmjRIr7//nvmz5/PqlWruOWWW2rhI0qT5cPBiQAX94nknZtjOS0kmF0ZuYxdsJ6k/T9X+TbtQ7zbfu9tOxEROVW1zhKaP38+jz/+OOnp6fTr14+nn36amJgYAC688EK6du3Kq6++WtZ+2bJl3Hvvvezdu5czzzyTxx57jEsuuaTca7788svMnj2bH3/8kR49ejBr1iwuv/xyr/qjbc1SKR8PTjz0y3GmvPY1O9JycNhNnri6L2P6dqiwvcttcd6jn5Cene9xHYtByUnPX959kbY4i4icQIcfitRQXkExf397C+t2lmx3nv6Hs5h2UXcMw3PgKN0lBJQLLaWtF04YwKjekac8T0SkKdPhhyI11CLYzgsT+jOljwOAJ9d+x/SlWyko9lzOf1TvSBZOGEBEWPlpn4gwp8KKiEgt0AiLiCcpKyH+bsg5xJvFF3F/8Q24sDHoNIvnb/4DbVsGe3yaKt2KiHhPU0IiNVF6BtEJkztfuHpzS9Ht5NKCzi0tXr7pQrq3b+m/PoqINAKaEhKpLrerZGTlpOWz59uSWe6Io5ORyf6jBlc8u54vdx/2Tx9FRJogBRaRE1VyBlF38xArHPcxyNhFbn4xk19J5K1NnosbiohI7VJgETlRFWcQtTVyedPxMFd0Lcbltrhn+TYeWl2zsvsut0XCniO8v/UgCXuOqIS/iIgHdn93QCSgeHEGUbBRzJN/bE1UaiRPrv2OF79MZe+RY/z72n60CPbtX6n45DRmrUopV9o/MsxJ3Jho7SwSETmBRlhETuTlGURG13P5++/P5Jnx/XHYTT7ekcHVzyWQln3c67fSCc8iIt5TYBE5kQ9nEAGM6duBJTcNpV1LBylpOVw+fz3bfsyu8m10wrOIiG8UWERO5uMZRAM6t2b5LefSIzyEzNwCrn5+Q5WjIzrhWUTEN1rDIuJJ9GXQc7TXZxB1atOcd6fGcttbW/j8u5/42+Ik/t+oHkwd3s1jOX+d8Cwi4huNsIhUxLRB1PnQ56qSPys5MBEgxBnESxP7M7lXEACPxe/in8s8l/PXCc8iIr5RYBGpLSkrsT9zDrP2XM2D9pex4eI/SYeY8PR/ycorLNd0SFQbIsOclS3tJTKspLS/iIgosIjUjtJy/r8WnZto/5hXgh4jhGN8lWlw+VMfsTsjt6y5zTSIGxMNVLi0l7gx0TqHSETkVwosIjVVQTn/C2zbWO64n85GBgeOGvzp2Q18/t1PZb/XCc8iIt7T4YciNZX6Bbx2aYW/zrJC+FvhHSRaZ2MzDe6/NJrJw7qW/V4nPItIU6XDD0XqUxXl/NsYubzhmM1VZ5SU849buZ3730+m2OUGSqaHYru15fJ+HYnt1lZhRUTEAwUWkZryspz/4yNaM+PinhgGvJ6wjxte/Yqc/KJ66KCISMOnwCJSUz6U8//b8G48N2EgzYJsfLH7MH96dgP7juTVZ29FRBokBRaRmvKxnP/IXhEs+1ssEaFOvs88ytgF632uaKsTnkWkqdGiW5HakrKyZLfQr1ubAQjtWBJWTirnD5CRk8+Nr3/Ntz9mE2QzeOSKPlw9qFOVb6MTnkWksfDl+1uBRaQ2uV1el/MHOF7o4s5lW1mzLR2AqRd2464/9sCsYOFt6QnPJ/9LW9pa26FFpCHRLiERf/GxnH8zh4354/oybYADgIWf7WHq4s0cKyw+pa1OeBaRpkyBRcSfUlZiPt2HO1OuYl7QAhwU8WFKBlfPiyct+3i5pjrhWUSaMgUWEX85qZz/WNt63nY8RFuy2Z5lcPm8dXz74y9lzXXCs4g0ZQosIv5QQTn/geZuVjjuo4dxgMzjBtc8n8CabWmATngWkaZNgUXEH/ZtKL+b6ASdzMO863iA35lbyC9yc8ubScz/ZDeDu7bWCc8i0mQpsIj4QxXl/EOM47wYNJe/9CxZfDv3o+/457JvuOeSnoBOeBaRpkeBRcQfvCjnbzMs7h/ehoev6I3NNFix9RCvbtjHo1f10QnPItLk2P3dAZEmqbScf04aJ69jKWGU/L7LMK6LstG1bQumLt7M5n0/k5GTz0uTB5N9vEgnPItIk6ERFhF/8LGc/7nd27H81nPp2rY5P/58nGueTyC/yKUTnkWkyVBgEfGX6Mvgmtch9KRpnNAOJddPKuff7bSWLL/lXIae0YajBcVMee0rXv4yFW+LVev8IRFpyFSaX8TffCznX1js5r4VySz9+gAA18V05oHLehFkq/jvHzp/SEQCkc4SEmnkLFcxL676jEc25mNhcG63tjx73UDCmged0lbnD4lIoNJZQiKNWcpKjH/34catV7Io6Amak8/6PUe4Yt6HpB7OK9dU5w+JSGOhwCLSkJxUzn+ELYl3HQ/QgcP8kGMw9ulPSdhzpKy5zh8SkcZCgUWkoaignH+0uZ8VwffR1/ie7EKDiS9tYulX+wGdPyQijYcCi0hDUUk5//ZGNksdDzLG3ECx2+Lu/2zjkTU7aNci2KuX1vlDIhLoFFhEGooqyvk7jSKeDprPHX2KAHjhfz/w8vpUwkODdf6QiDR4CiwiDYUX5fwNA+4Y1panx/fHYTdZtzOTIJuJReXnDwGq0SIiAU2l+UUaCh/K+V9m2ji9dTNuen0zP/58nFCnnSCbyZG8wrLWEb/WYQE479FPyi3ObdMiiIcu780l53So4w8lIuId1WERaUhKdwkB5UPLr+MlJ1XIPfjLcaa8+hU703MJtpvcdMEZdG/fsuz8obUp6R5rtJS68fyu/Gt0r7r4JCIiqsMi0mj5WM6/Y6tmvDt1GCPObk9BsZtnPvme1MN5DD2jZM1KRTVaSi36Yi8Prt5eyx9CRMR3GmERaYh8LOfvclvMWZPCoi/3AnBZdztXntuXya9t9urtRveJ4OnxA3TIoojUKpXmF5HyUlZC/N0syTqLe4v/QjF2zrHtpY37Zz6z+nv1Ei2CbTx+5Tla1yIitUZTQiLymxOq415r/4zXg+YQxlG+dXVll9WJYcY2r14mr8DFLW9t4eEPNEUkIvVPgUWkMfNQHXeYLYUVjvs5wzhEGu3YYp2Fgdvrl1z0xV4e/iClDjorIlIxBRaRxqyC6rhRZjrLHXEMM5M5TjBWhaXlPFv0RSprvk2rrV6KiFRJgUWkMaukOm6YkcdrQY8y3raOU8vKVe2ud79RgTkRqTcKLCKNWRXVcYMMF4/YX+LiyKOUThuFkufVFFFeoYvrXtyo0CIi9UKBRaQxK62OW8lpQkbzNix0PcArQY/TkmPk0ILTjZ84z9ha5ctv/CGLc2Z9yJpvPR/KKCJSWxRYRBoz0wajHv31B0+nCVlwPAtyDvE721bedcyiIz9xwArnG+tMxpnrqnwL7R4SkfqgwCLS2FVUHTckEpqVP6W5p3mA94PvY5Cxi1xasMz9O/5gfOXV26gqrojUJRWOE2kqTq6Oa7nh9cs8Ni2w7PyreArvuoYDMMzYRoLVC8uLv+NMOa8r912q84dEpGp1XjhuwYIFdO3aFafTSUxMDImJiZW2X7ZsGT179sTpdNKnTx/WrFlTYdu//e1vGIbBvHnzqtM1EamIaYOo86HPVSV/5v1UYdNgo5jH7c/zL/tiDNxssPowyNjFRcbXVb7NS19qpEVEap/PgWXp0qVMnz6duLg4kpKS6Nu3LyNHjiQzM9Nj+w0bNjB+/HimTJnCli1bGDt2LGPHjiU5OfmUtsuXL2fjxo106KDS3yJ1roodRIYBN9rX8FLQXFpyjK+ss/ne6sSN5qoqX/qlL/dy65ubtYNIRGqNz1NCMTExDB48mPnz5wPgdrvp1KkT06ZNY8aMGae0HzduHHl5eaxevbrs2tChQ+nXrx/PPfdc2bWDBw8SExPDhx9+yOjRo7njjju44447vOqTpoREqsHtgrlnwrEjVTb9zt2RKUV3ccBqT0uOcYm5kXfcF1X5PJ0/JCKVqbMpocLCQjZv3syIESN+ewHTZMSIESQkJHh8TkJCQrn2ACNHjizX3u12M3HiRO666y569ap67rugoICcnJxyDxHxkWmDS570qulZ5kHed9zHEGMHR2nOu+4L+b1R9UnP2kEkIrXFp8By+PBhXC4X4eHlh5LDw8NJT0/3+Jz09PQq2z/66KPY7Xb+/ve/e9WP2bNnExYWVvbo1KmTLx9DREr1Hguxt3nVtI2Ry2LHI1xr+wQ3JuusgcQY270qMqcdRCJSU37f1rx582b+/e9/8+qrr2IY3pUHnzlzJtnZ2WWPAwcO1HEvRRqxkQ/D0Fu9auowXMy2v8j99tcxcbPJ6kV/43stxhWROudTYGnXrh02m42MjPLnk2RkZBAREeHxOREREZW2/+KLL8jMzKRz587Y7Xbsdjv79u3jzjvvpGvXrh5fMzg4mNDQ0HIPEamBUY9A7DSvmhoG/MUezytBjxFCHknWWeyyujDF/KDK5yq0iEh1+RRYHA4HAwcOZN2636pfut1u1q1bR2xsrMfnxMbGlmsPsHbt2rL2EydO5Ntvv2Xr1q1ljw4dOnDXXXfx4Ycf+vp5RKS6Rj4EV78GQS29aj7c9i3LHXF0NdI5yGkscV/EVeZnVT7vpS/38vAHKTXsrIg0NT5PCU2fPp1Fixbx2muvsWPHDqZOnUpeXh433HADAJMmTWLmzJll7W+//Xbi4+N54okn2LlzJw888ABff/01t91WMm/etm1bevfuXe4RFBREREQEPXr0qKWPKSJe6TUWZu6H6Cu8at7dPMQKx30MM5PJoxn/cV/A74ykKp+36ItU1nybVsPOikhT4nNgGTduHHPnzuX++++nX79+bN26lfj4+LKFtfv37yct7bf/EA0bNoy33nqLF154gb59+/Luu++yYsUKevfuXXufQkRqj2mDa171el1LKyOP14IeZYJtLRYmn1oDiDWSGWLswKxkQe7tS7fwxXc/qVaLiHhFpflFpGLx98DGBV43f6N4BA8UT8aFjf7GbmYHvcC84iuJdw+t8Dmq1SLSdNV5aX4RaSJ8WIwLMNH+Ma8HzSGMo2yxzuQvhXczzfY+M21vVvgc1WoREW8osIhI5XxcjHuubTsrHPdzhnGIQ7TjqqI4OhuZ3GNbXOnzVKtFRCqjwCIiVfNxMW6Umc5yx/2cb37LcZxMLf4H+TiYaVYeWrTtWUQqosAiIt7xcTFumHGMV4Ie43pbPABPuq5hO1HcZb5d6fMUWkTEEwUWEfHNqEe8Di12w80DQa/ziP1F7BSz0n0uH1pDmGb+p9LnKbSIyMkUWETEdz6EFoA/2z/hjaDZtCKXb61uLHVfxGzbC8SayRVufVZoEZETKbCISPX4uIMo1raDlY77OMs4QCatiXPdwBXmerYG/5VR5kaPz3npy73c+uZm1WoREQUWEamB0h1Ezdt51byzmcl7jjhGmokUEsT/K76ZJ4uv4Wn7ggq3Pn+wLZ1zZn3Imm8P1WbPRaSBUeE4Eak5twv2bYD1T8P3H1Xd3DJ4xjWWp4qvBiDW3M58+9P8x3U+j7gmVPi8G8/vyr9G96q1bouIf6lwnIjUL9MGUefDhGVerW0xDYvb7ct5PuhJWnCcBHcvLi96kHPN5ErrtahWi0jTpcAiIrXLhwW5I21fs9xxP12MdH602nNV0QN0MI5UGlq0GFekaVJgEZHa50NoOcs8yPuO+8qKzN1WfDu/0LLSInMKLSJNjwKLiNQNH3YRtTLyeCXoMW6yrQbgWddYNhHNM7Z5DDVTPG59VmgRaVoUWESk7pTuInKEVNnUbri5J+gt5gUtIJhCPnEP4Cn3NTxsf4nE4Kketz4rtIg0HQosIlK3eo2FGfvgwnvA5qiy+Vjbet51zCKSI/xgdWBs4YNsc3djYdDTHrc+v/TlXm5Z/LVqtYg0ctrWLCL1x+2CZX+BHSuqbPqTFcothXfwldUTAzf/tL/DVHMlL7ou8bj1OdhmcMvvunPbRWdiM4066LyI1DZtaxaRwGTaYNxrXi3IPc3I4U3Hw1xn+xgLk8eLr2Vq8R1ca/vU4y6iApfFUx/vVpE5kUZKgUVE6p+Xu4gchouHg15mtn0RDor40D2EsUUPcqH5Dc/Y/+1xMW5egYtb3trCwx9obYtIY6LAIiL+4cPW5/H2T3nH8X+/rWspehDTgO3BN1R4DpGKzIk0LgosIuI/PoSWfuYeVgffwzAzmWM4ubXodp4svppn7PMrPIdIu4hEGg8FFhHxLx/qtbQ1cnk9aA4321YCsMh1KROLZ/In2xcVVsdVaBFpHBRYRMT/fDj12W64mRm0hIVBT9GC42x092JM4cMMMr/jP0H3E2smn7K2RVufRRo+bWsWkcDh46nP37s7cFPRdH6wOhBEMXH217jOto5cnPy/opuIdw8t195pN3nymr5cck6HuvoEIuIDbWsWkYbJx1Ofu5uHeN9xH6PMRIqwc2/xFO4qvhkHLo+F5vKL3dpBJNJAKbCISGDyckFuiHGchUHzuNv+NiZu3nUN58rCB/jROo2b7B943P6sHUQiDY8Ci4gELi8X5BoGTLWv4o2g2bQhh+1WFKMLH+Fj9wDG2Dd53P6sxbgiDYsCi4gEttIFubbgKpuea9vOquB/0df4nhxacGPRP5ldNB47bo9TRFqMK9JwaNGtiDQMPpxDVGjZmF38Z15xXQzAQGMX8x3PEEEWq10x3F48DfcJf1/TYlwR/9CiWxFpfErPIfJiishhuIgLeoOFQU8RwjE2Wz24pGA2n7vP8ThFpMW4IoFPgUVEGpbSKSJHSJVNL7Z9xWrHPfQyUvmZEG4o+n/MLbqaoAp2ES36QlNEIoFKU0Ii0jC5XfC/ufDFXHAVVto03wriweKJvOkaAcBQcztPBy3gNH7RFJGIH/ny/a3AIiINmw9rW953xTKz6EaO4aQdv/B00HyG2VI4bgXxj6KppxSaG3NOBPOuHYDNNOqo8yJNm9awiEjT4cPalsttCax03EsPYz+HacWEonv4d/EVOCj2OEW06tt0ou//L/PW7tI0kYifaYRFRBqP7SvgvZvAVVBps+OWg7jiybzj+h0AseZ2ngp6lnB+9jhFBJomEqkLGmERkaap11j4VxqcPbbSZs2MQh4LWsTcoIU0I58Edy8uLpjDukoKzWknkYh/KbCISOPiwxTRVbYvWO34V9kuor8W/ZO4oskYwMKgpz2e/qyy/iL+oSkhEWm8vJwiKrDsPF48jhddowHoaeznmaBnONM8CECOderpz5f0DueZPw/UglyRGtAuIRGRUj7sIvrMdQ7/LJrKYcJwUsD99jcYb/sEwwDLglWuodxRfFvZ+hataxGpGa1hEREp5cMU0YW2b1kTPIPzzW/JJ5h7iv/KLUW3k221wDDgMvvGcutbSte13Pqmis2J1DWNsIhI0+HlFJHbMnjRdQmPF4+jCDsdOMxTjmeJMXcCGm0RqS2aEhIRqYgPU0TfuqP4e9E09loRGLi50baGO+3vEGwUA3gsODe6TzhPj9faFhFvaEpIRKQiPkwRnWOmstpxD+Nsn2Jh8oLrUi4vfIgUd2cAmhlFLAx6mqftT5ftJPpgWwa97o9nzbeH6vRjiDQ1GmERkaZr+wpYfjMU51fZdK1rADOKbuQIYQRRzHT7Mm6yrcZmlPwnVKMtIr7TlJCIiLfcLvj8MVg/r8rgctgKZWbRX1nrHgTAYGMnTwQ9R2czE9DaFhFfKbCIiPjKy9OfLQuWuYYzq3gSeTSjBce5z/4G42yfYfw6kKLRFhHvKLCIiFSX2wXvToGU5ZU2O+A+jTuL/kaidTYAvzO38EjQS0QaWYBGW0S8ocAiIlJTXmyBdlkGL7pG80Tx1RQSRAjHuMf+JtfaPi0bbSm0bMwvvpz5rj+VBReNtkhD4nJbJKZmkZmbT/sQJ0Oi2tTaP7sKLCIitcHL0Zbd7o7cVXQTW60zATjXTGaOfRGdzJ/K2pw8TaTRFmkI4pPTmLUqhbTs39Z3RYY5iRsTzajekTV+fQUWEZHa5OVoyyuui5lbfDX5BNOMfO62L2GSbS3mrzuJPE0T3Xh+V/41uld9fAoRn8QnpzF1cRInh4TSsZWFEwbUOLQosIiI1DYvR1v2usO5u+hGNlnRAAwydvFY0POcYaaXtTl5mkgHKYq/nTztM7BLa4Y//mm5kZUTGUBEmJMv776oRv/cKrCIiNQVL0Zb3JbBm67fM6d4PHk0w0Eht9uXc6NtNQ7DVdbuxGkiTRGJv3ia9mnTIoisvKIqn/v2jUOJ7da22u+tSrciInWl11j4VxpEX1FhE9OwmGj/mA+D7+YC8xsKcfB48TguKZzNJnfPsnallXJn2t7UQYriF6XTPiePpHgTVgAyc6suulhbFFhERHxl2uCaV+Hq18AWXGGz043DvBb0KE8FLaAt2Xxvnc64wvv5Z9HNHLFCADAMuMn+Ac/Y/42Jmw+2ZdDz3v8yb+0uBRepUy63xaxVKaesUfFF+xBnrfWnKpoSEhGpCS/XtmRbLXi0eBxvuUYA0IpcZtrf5mrb52WLck9e2xJkGtz6u25M+/1ZWt8iteLEtSqHcwt48IMd1Xodf6xhqdYIy4IFC+jatStOp5OYmBgSExMrbb9s2TJ69uyJ0+mkT58+rFmzpux3RUVF3H333fTp04cWLVrQoUMHJk2axKFDOjhMRBqAE0db7BX/bTPMyOORoJf5jyOOnsY+fiGEu4tv4prC+9nu7gKAw3AxPeg9dgZP5u+2d3G5Xcxb971GXKRWxCencd6jnzB+0UZuX7K1RmEFIG5MdL0GaZ8Dy9KlS5k+fTpxcXEkJSXRt29fRo4cSWZmpsf2GzZsYPz48UyZMoUtW7YwduxYxo4dS3JyMgDHjh0jKSmJ++67j6SkJN577z127drFZZddVrNPJiJSn3qNhXsOwfAZYNgrbDbQ3M1qx7+4176Y5uTztdWDMYUPc0/RX8qmiSoKLjoFWqqrorUq3mjTwlHu54gwZ61safaVz1NCMTExDB48mPnz5wPgdrvp1KkT06ZNY8aMGae0HzduHHl5eaxevbrs2tChQ+nXrx/PPfecx/f46quvGDJkCPv27aNz585V9klTQiISULycJjpkteGRoutY7Y4FIIQ87rD/h0m2tQSdsJvo5KkiVcqVyvi6RbkipdM+n9/1Ozbv+9nvlW4r/muAB4WFhWzevJmZM2eWXTNNkxEjRpCQkODxOQkJCUyfPr3ctZEjR7JixYoK3yc7OxvDMGjVqpXH3xcUFFBQ8NuWwpycHO8/hIhIXSudJto+ttIt0B2MLOY7nmGS+yNmFU1iuxXFg8WTeMv1e+6zv8GFtm+B30ZcbrO/XxJctv2Jntv/q/UtcoqabFE+0YnTPg67WaOty7XFpymhw4cP43K5CA8PL3c9PDyc9PR0j89JT0/3qX1+fj53330348ePrzBtzZ49m7CwsLJHp06dfPkYIiL1w4st0ABDzF2sdNzLHPsLtCWbPVZHri+awQ2Fd7HLfXpZuxOniqYay3h63Xda39JEudwWCXuO8P7WgyTsOYLLbdV4i/KJ/DXtUxmfRljqWlFREddccw2WZbFw4cIK282cObPcqE1OTo5Ci4gEJi9HW2yGxbX2z7jEtolniq/gFdcoPnX357PCvlxhfsn0oHc53TgMnDri8vS6P/HMJ99z64XduP0PPTTi0sh5GkWJCA0mv9hdoy3K940+m3YhwbU+7VNbfBphadeuHTabjYyMjHLXMzIyiIiI8PiciIgIr9qXhpV9+/axdu3aSueygoODCQ0NLfcQEQloXo62hBrH+VfQW3zk+H9cYm7CwuQ99wVcVPAEDxZNIOvXhblQfsTlVvNd5n+6m7P+tUYjLo1YRaMo6TkF/HLM95EUKJn+iQxzcv25UVzeryOx3dqeElZy8otIOeTf5Rc+BRaHw8HAgQNZt25d2TW32826deuIjY31+JzY2Nhy7QHWrl1brn1pWNm9ezcff/wxbdv6f65MRKTWebkFGuAMM51nHf9mheM+Ys3tFBLES65LGF7wFM8Uj+WY9VvBupODi6aKGoeTp30Ki901LvR2Mk9blC3L4sefj7Fiy0HuXbGNUfP+R98HPuKGRf/D+uF/JYvK/cDnXUJLly5l8uTJPP/88wwZMoR58+bxzjvvsHPnTsLDw5k0aRIdO3Zk9uzZQMm25uHDhzNnzhxGjx7NkiVLeOSRR0hKSqJ3794UFRVx1VVXkZSUxOrVq8utd2nTpg0Oh6OirpTRLiERaXDcLvj8MfjiCXBX/jdjy4L/uc/h0eJrSbG6AtCGHG60f8Ak20e0MMpPM524q8gwTP4QHc7E2K4MPePUvzlLYKqtxbMna9PCQVZeYdnPkWFO7h19Np3btODrfVl8ve9nNu/9mfScU3cUdTIyWeX4F63CwmDUoxBd8/IjdX744fz583n88cdJT0+nX79+PP3008TExABw4YUX0rVrV1599dWy9suWLePee+9l7969nHnmmTz22GNccsklAOzdu5eoqCiP7/Ppp59y4YUXVtkfBRYRabB8CC5uy2CVeyhPFl/NPqtkWr01ufzVvoZJto8IMY6Xa3/yduhgu8HU4dpZFEhO3oI8JKoNa1PSmbo4qdZHUkq3KH+x+ye+2ptFZk4Badn5fPPjLxwrLD9qYjcNerV2M/CXeAaZuxhkfkd745cTXg245vUahxad1iwi0tD4EFyKLZP33ecyv3gsqVbJLo4wjjLF/l8m2z4izMgr177IMvnINZDF7j+wyR2NYZhaoBsAKls8W931KJUZflY7MnML2JmWe0oYCjGOM9DYxSBzFwON7+gXlkcz11E4nlXBqxkQ2gHu2FYy1VlNCiwiIg2Vj8FltTuWp4uv4AerAwDNyeca22dMsa2hk3n4lOcUWDbedw3jnuIbcWPnj700XeQPpYtna3sUJbSZHbtpcuSEaR9POhmZDDJ2MdD5I4OKt3KW8WPZmVY+mbwaos6vXodRYPF3d0REas6H4OKyDFa7h7Kw+DJ2WiXnEpm4ucTcxM321fQxU099eQtWu4ZyR/Ftvx60CL8/W+GlLtRW5VlvBNtNCord5a5VPr1TQ1e+BH2uqvbTFVhERBoLHxfnfunuzQuuS/nCfU7Z9SHGDibYP2aUmYjDKL9WwWVBvGtw2XSRG5Mgm8HUC87QlFEtqKvFs067gVl8nGME89tenxK+T+/UgEZYfKPAIiKNXmlw+d9csIqrbJ7i7syLxaNZ6Y6l+Ncaoe34hfG2TxlvX0cH49Qvr0LLZLu7K6vcsbzuGqkpIx/UxeJZAzc9jANYGGRYrfmFlpwcTqBkemeg4wCDurZmUOoLnGUcqN70jo+90xqWalBgEZEmw8uDFUulW615u/gi3nZdRCatgZLpot+bSVxj+4wLzW/KHbRY9jYWbHF3Z67rGja5ozENk/5dWjMkqg3DurVTgDlBXSyebckx8nBinVQuzU4x/YzvGWjupr/5PQPM3bU3veM17RKqNgUWEWlytq+A92+FwqNeNS+ybKx1D+QN1x9IcPcqu96WbC63recq2/+INvd7fG6+ZbLFfSZfWz3Z4O7FJnc0NtNsUmtePI2g2EzDq8WzJm6GmDtpzy9k0opEd0/cZUHEIow8juGkyMNpOZ2MTPobuxlg7qafuZuzjf0EewiYdcOAZq0hyAk5h367HNoRRs1pGHVYAo0Ci4g0SW4XpH4BX78Eu9aAu+qpIoDd7o684xrOctd5HKZV2fWzjb1cZktgtLmJzmZmhc8vtEzWugaw2P1HNrmjAZOu7ZpzzumtuHLA6Qzr3q5RBRhPIyiRYU7uG302D36wo9LFsyPNRO61v8ExmrHF3Z0k60wS3T3Za516qKCTAnoa++lnfk+suYP+5m7aG9l18pmqdsIoSs/RsG8DHM2AluHQZViNpoFOpMAiItLU+LA4t1SxZfI/9zn8x3UBa90DKSSo7He9jFQusW3iEjORKDO9wtfItwz2uE/nAO1JdPcsW/vSv3MYwXYbBS43nVo3bxBBxpd1KAaUu1Y6inKa9Qs/chpbrW50IYP2xi8kW1Ec49SjGLqQTj+zZHpngLmbHsYBbIbLtzNzauzXT9KsTflFubU4ilIZBRYRkaaqNLisnwfF3m+b/cVqwQeuGP7rjiHBHY2L3/4GfZZxgN+ZW7nQ3Mog8zuPa17K3t6C3e5IthMFGBy02pVNI1mYnNm+BS2ddpx2G+1aBmMYYBgGHVs3q/HamIqmbbz5fVXrUCqb1hlg7GKAuZsfrA584+7GEcJO6Vtz8jnH3MMA43v6m7vpZ3xPOzPHwxLaulLF9E4djqJURoFFRKSpO3G6aOdqsNxVP+dXR6wQPnINYo07hg3uXuXCS0uOcZ6ZzAXmt8SYOzjDSMPw4lu3ZB1MN4oI5hjBZaMxxSet27Ab0LdTyehMfrELp91G2xYOjuQVlv3crmUwplk+5KxNSfc4bRM3JppRvSMrnNaJGxMNwNTFSRgVhJKRZiJxQa8TRh4pVle+cZ/BRvfZrHf35riHkRM7xfQ09tPX/IG+xh76md/TzTiErc537pQ6efynfqZ3qkOBRUREfuN2wadzYP2TXq9zKfWL1YL/uc/hM1dfPnf3PWX0oB3ZDDF3MsTcwWBzF2cZP1Y6AlOuWxbsdkeQQVucFHIcB1mEYgHtyDnhWghtyT2pjVk2erPN3oejhdYpoyBf/Ro4brogihf+l3pKIPnK3RMXJq2aBxGTv564oNfpYGRhWXCItqx39WKVaxgtjOPssLqw32p/yq4dgCjjEP2MPfQ193CO+QPRxj6cRu2X1i+vglAybBokv1tni2RrmwKLiIicqprTRWVPtwySra585u7HBnc0W9xnUoCjXBsHhZxt7KePmUofI5VeZirdjDSaGZWXiq+JLKsl7xRfyGX2DeXqyxyy2jCraBJrrSH8wUgsCySl9rvbcU/RX8nDycVmIqlWJHusDuy0OpNDC4/vFU4W55g/0M/cQx9jD33NHwgzjtXZZyvPy1DidgXUKEplFFhERKRiJ04XfRcPruqFiQLLzrdWNxLdPdnk7skW95nk0vyUdgZuOnCEbuYhzjDS6GYcooNxhEjjCJFGFq046tW0UkVO/BY78XVy3cFkWK15yXUJg81dZFityaANB6z2/GBFst9qX26660R2iuluHCLa2MfZ5j7ONvZztrmPtkZu9TvqNS+2EzegUFIZBRYREfFOaXj5alFJePFxyqjcS1kG+6xwkq2uJLuj2GZFkeLuwi+EVPo8JwVEGD8TxlFCjWOEkUeokUcIx3DgIsgoxk4xQbgwcePGpBgbx61gjuIkj2YctUr+zLOcZBFCptXaY3g6WTPyiTLSiTLS6GakEWWmcZbxI92NgwQb1b8XlTtxOqfhrDepCwosIiLiu1oaeTlZlhXCHqsDe9yR/GB14AcrgnSrLelWGw572FFTm1pyjPbGL0QYWYTzM+HGz3Q0DtPNOESUmU4EWTUa3alcFSMlAPF3N5j1JnVBgUVERGqmNLzs/R+krMI68l2dbMHNt4LItFqTQWuyrRZk04JsqwU5NCfXak4RdoqwUYyNIsuOCxP7ryMtzY0CWpBPS+M4Lcgv+9+tOEq4URJOWhq1fyLyb34NJMd//vXnaoyUNJKpnepSYBERkdpVXAiJz0Pye5D+bY2mjgKRhadjBU+8XsnUDTT5kZLqUmAREZG6c+Loy94NcPArvwcYy8Lj1I4FGIaJZVkYHk78sTAwfh0lKQknVvnfgXdbhZv4SEl1KbCIiEj9OTHA/Lwfsn+Eg5vBXXdbmU/kYdzj1+snBI4Nz1QcSLwZJVEgqRMKLCIi4l8nhxisX4PM17U+GmM1a4PRf0LloyApK6uetlEoqXcKLCIiEphODjKWG/IOQ/FxsDeDFqcBVvlrzdvBsZPamCa06gRRw6HreSXBoqrAoUAScBRYREREJOD58v1dv6dYi4iIiFSDAouIiIgEPAUWERERCXgKLCIiIhLwFFhEREQk4CmwiIiISMBTYBEREZGAp8AiIiIiAU+BRURERAKe3d8dqA2lxXpzcnL83BMRERHxVun3tjdF9xtFYMnNzQWgU6dOfu6JiIiI+Co3N5ewsLBK2zSKs4TcbjeHDh0iJCQEwzCqfkIDlJOTQ6dOnThw4IDOS6oluqd1Q/e19ume1g3d19rn6z21LIvc3Fw6dOiAaVa+SqVRjLCYpsnpp5/u727Ui9DQUP2LVct0T+uG7mvt0z2tG7qvtc+Xe1rVyEopLboVERGRgKfAIiIiIgFPgaWBCA4OJi4ujuDgYH93pdHQPa0buq+1T/e0bui+1r66vKeNYtGtiIiING4aYREREZGAp8AiIiIiAU+BRURERAKeAouIiIgEPAWWAJWVlcV1111HaGgorVq1YsqUKRw9erTK5yUkJHDRRRfRokULQkNDueCCCzh+/Hg99LhhqO59hZKKjBdffDGGYbBixYq67WgD4us9zcrKYtq0afTo0YNmzZrRuXNn/v73v5OdnV2PvQ48CxYsoGvXrjidTmJiYkhMTKy0/bJly+jZsydOp5M+ffqwZs2aeuppw+LLfV20aBHnn38+rVu3pnXr1owYMaLK/x+aIl//WS21ZMkSDMNg7Nix1XtjSwLSqFGjrL59+1obN260vvjiC6t79+7W+PHjK33Ohg0brNDQUGv27NlWcnKytXPnTmvp0qVWfn5+PfU68FXnvpZ68sknrYsvvtgCrOXLl9dtRxsQX+/ptm3brD/96U/WypUrre+//95at26ddeaZZ1pXXnllPfY6sCxZssRyOBzWyy+/bG3fvt268cYbrVatWlkZGRke269fv96y2WzWY489ZqWkpFj33nuvFRQUZG3btq2eex7YfL2vf/7zn60FCxZYW7ZssXbs2GFdf/31VlhYmPXjjz/Wc88Dl6/3tFRqaqrVsWNH6/zzz7cuv/zyar23AksASklJsQDrq6++Krv23//+1zIMwzp48GCFz4uJibHuvffe+uhig1Td+2pZlrVlyxarY8eOVlpamgLLCWpyT0/0zjvvWA6HwyoqKqqLbga8IUOGWLfeemvZzy6Xy+rQoYM1e/Zsj+2vueYaa/To0eWuxcTEWDfffHOd9rOh8fW+nqy4uNgKCQmxXnvttbrqYoNTnXtaXFxsDRs2zHrxxRetyZMnVzuwaEooACUkJNCqVSsGDRpUdm3EiBGYpsmmTZs8PiczM5NNmzbRvn17hg0bRnh4OMOHD+fLL7+sr24HvOrcV4Bjx47x5z//mQULFhAREVEfXW0wqntPT5adnU1oaCh2e6M43swnhYWFbN68mREjRpRdM02TESNGkJCQ4PE5CQkJ5doDjBw5ssL2TVF17uvJjh07RlFREW3atKmrbjYo1b2n//d//0f79u2ZMmVKjd5fgSUApaen0759+3LX7HY7bdq0IT093eNzfvjhBwAeeOABbrzxRuLj4xkwYAC///3v2b17d533uSGozn0F+Mc//sGwYcO4/PLL67qLDU517+mJDh8+zIMPPshNN91UF10MeIcPH8blchEeHl7uenh4eIX3MD093af2TVF17uvJ7r77bjp06HBKOGyqqnNPv/zyS1566SUWLVpU4/dXYKlHM2bMwDCMSh87d+6s1mu73W4Abr75Zm644Qb69+/PU089RY8ePXj55Zdr82MEnLq8rytXruSTTz5h3rx5tdvpAFeX9/REOTk5jB49mujoaB544IGad1yklsyZM4clS5awfPlynE6nv7vTIOXm5jJx4kQWLVpEu3btavx6TW/81Y/uvPNOrr/++krbnHHGGURERJCZmVnuenFxMVlZWRVOSURGRgIQHR1d7vrZZ5/N/v37q9/pBqAu7+snn3zCnj17aNWqVbnrV155Jeeffz6fffZZDXoeuOrynpbKzc1l1KhRhISEsHz5coKCgmra7QapXbt22Gw2MjIyyl3PyMio8B5GRET41L4pqs59LTV37lzmzJnDxx9/zDnnnFOX3WxQfL2ne/bsYe/evYwZM6bsWulfru12O7t27aJbt27ed6BaK1+kTpUuZPz666/Lrn344YeVLmR0u91Whw4dTll0269fP2vmzJl12t+Gojr3NS0tzdq2bVu5B2D9+9//tn744Yf66nrAqs49tSzLys7OtoYOHWoNHz7cysvLq4+uBrQhQ4ZYt912W9nPLpfL6tixY6WLbi+99NJy12JjY7Xo9iS+3lfLsqxHH33UCg0NtRISEuqjiw2OL/f0+PHjp/z38/LLL7cuuugia9u2bVZBQYFP763AEqBGjRpl9e/f39q0aZP15ZdfWmeeeWa5raI//vij1aNHD2vTpk1l15566ikrNDTUWrZsmbV7927r3nvvtZxOp/X999/74yMEpOrc15OhXULl+HpPs7OzrZiYGKtPnz7W999/b6WlpZU9iouL/fUx/GrJkiVWcHCw9eqrr1opKSnWTTfdZLVq1cpKT0+3LMuyJk6caM2YMaOs/fr16y273W7NnTvX2rFjhxUXF6dtzR74el/nzJljORwO69133y33z2Vubq6/PkLA8fWenqwmu4QUWALUkSNHrPHjx1stW7a0QkNDrRtuuKHcvzSpqakWYH366aflnjd79mzr9NNPt5o3b27FxsZaX3zxRT33PLBV976eSIGlPF/v6aeffmoBHh+pqan++RAB4JlnnrE6d+5sORwOa8iQIdbGjRvLfjd8+HBr8uTJ5dq/88471llnnWU5HA6rV69e1gcffFDPPW4YfLmvXbp08fjPZVxcXP13PID5+s/qiWoSWAzLsizvJ5BERERE6p92CYmIiEjAU2ARERGRgKfAIiIiIgFPgUVEREQCngKLiIiIBDwFFhEREQl4CiwiIiIS8BRYREREJOApsIiIiEjAU2ARERGRgKfAIiIiIgFPgUVEREQC3v8HWFWvvCWgw14AAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(log_strikes, [w_60(i) for i in log_strikes])\n",
    "plt.scatter(log_strikes, his)\n",
    "plt.scatter(log_strikes, lows)\n",
    "print(sum([max(abs(w_60(log_strikes[i]) - mids[i]) - abs(his[i] - lows[i])/2, 0) for i in range(log_strikes.shape[0])])/ log_strikes.shape[0]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4246575342465753\n",
      "tensor([-0.2388, -0.2332, -0.2166, -0.2030, -0.1949, -0.1842, -0.1790, -0.1763,\n",
      "        -0.1685, -0.1658, -0.1607, -0.1529, -0.1478, -0.1452, -0.1427, -0.1401,\n",
      "        -0.1376, -0.1351, -0.1300, -0.1200, -0.1151, -0.1101, -0.1052, -0.1028,\n",
      "        -0.1003, -0.0906, -0.0739, -0.0668, -0.0644, -0.0620, -0.0597, -0.0574,\n",
      "        -0.0550, -0.0481, -0.0457, -0.0434, -0.0366, -0.0343, -0.0297, -0.0274,\n",
      "        -0.0252, -0.0207, -0.0184, -0.0162, -0.0139, -0.0117, -0.0072, -0.0050,\n",
      "         0.0016,  0.0038,  0.0060,  0.0082,  0.0104,  0.0126,  0.0191,  0.0212,\n",
      "         0.0255,  0.0298,  0.0320,  0.0341,  0.0405,  0.0447,  0.0468,  0.0510,\n",
      "         0.0531,  0.0552,  0.0573,  0.0656,  0.0677,  0.0718,  0.0738,  0.0759,\n",
      "         0.0779,  0.0820,  0.0840,  0.0860,  0.0901,  0.0921,  0.0941,  0.0961,\n",
      "         0.1021,  0.1041,  0.1061,  0.1120,  0.1160,  0.1179,  0.1199,  0.1218,\n",
      "         0.1257,  0.1277,  0.1296,  0.1335,  0.1354,  0.1373,  0.1431,  0.1469,\n",
      "         0.1526,  0.1545,  0.1602,  0.1934,  0.2291,  0.2970])\n",
      "(102,)\n",
      "(102,)\n",
      "Mid shape (102,)\n",
      "9.00380559592238e-05\n",
      "(102,) (102,)\n",
      "torch.Size([102]) torch.Size([309, 1])\n",
      "torch.Size([1, 309])\n",
      "0.0 0.0 nan\n",
      "Epoch: 0\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 5.336081008339822e-05\n",
      "MAPE:  2.025122665139538e-05\n",
      "Delta:  0.012498396752488488\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.006876115622071577 0.41844918471441883 nan\n",
      "Epoch: 1\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 3.10320226082993e-05\n",
      "MAPE:  9.927582427978847e-06\n",
      "Delta:  0.012412456331327853\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.00593280013364883 0.43752089566208496 nan\n",
      "Epoch: 2\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.7454864282510116e-05\n",
      "MAPE:  1.6366986360758563e-06\n",
      "Delta:  0.01233881570874644\n",
      "GRAD\n",
      " tensor([0., 0., 0., 0.])\n",
      "0.005176131636446812 0.46393640178001605 nan\n",
      "Epoch: 3\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 9.356917353723852e-06\n",
      "MAPE:  0.0\n",
      "Delta:  0.01227494837440011\n",
      "Breaking and plotting at epoch 3 with bounds loss tensor(9.3569e-06, grad_fn=<MulBackward0>) and arb loss tensor(0., grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import smilecorrector_gsvi_jo_mw_ar as smilenet\n",
    "import torch\n",
    "importlib.reload(smilenet)\n",
    "# For first try, we pass our boundaries as each strike price\n",
    "# boundaries = processed_50['strike_price'].apply(np.log).to_numpy()\n",
    "# ind = np.array([i for i in range(0,boundaries.shape[0],3)])\n",
    "# boundaries = boundaries[ind]\n",
    "# strikes = boundaries.copy()\n",
    "R = 0.0056 # Rate for > 122 day\n",
    "F = 2266.349134 # for ID 102434, Exp date 05/31/2022\n",
    "T = 5 * 31 / 365\n",
    "S = F * np.exp(-R * T)\n",
    "print(T)\n",
    "processed_50 = remove(processed, 0.50, F)\n",
    "log_strikes_50 = torch.tensor((processed_50['strike_price'].apply(np.log).to_numpy()- np.log(F))) #   \n",
    "print(log_strikes_50)\n",
    "S = torch.tensor(S).reshape(1,1)\n",
    "T = torch.tensor(T).reshape(1,1)\n",
    "R = torch.tensor(R).reshape(1,1)\n",
    "params = (0, 0.4, -0.6, 0, 0.2)\n",
    "# his_50, lows_50 = svi_with_noise(log_strikes_50, *params)\n",
    "# mids_50 = torch.tensor(his_50 + lows_50) / 2\n",
    "# mids_50 = mids_50 * T\n",
    "his_50 = processed_50['vol_high'].to_numpy() ** 2 * T.item()\n",
    "lows_50 = processed_50['vol_low'].to_numpy() ** 2 * T.item()\n",
    "# mids_50 = torch.tensor(((processed_50['vol_high'].to_numpy() + processed_50['vol_low'].to_numpy()) / 2))\n",
    "mids_50 = (his_50 + lows_50) / 2\n",
    "print(mids_50.shape)\n",
    "mids_50 = mids_50\n",
    "print(mids_50.shape)\n",
    "print('Mid shape', mids_50.shape)\n",
    "# print(mids_50)\n",
    "low = min(mids_50**2)/2\n",
    "print(low)\n",
    "print(his_50.shape, lows_50.shape)\n",
    "# datum, log_strikes_50 = pipeline.get_datum('2022-0') \n",
    "model = smilenet.SmileNet(5, log_strikes_50, mids_50, low)#, low)\n",
    "datum = torch.tensor(np.vstack([ his_50.reshape(-1,1) , lows_50.reshape(-1,1) , log_strikes_50.reshape(-1,1), np.log(S), T, R])).double()\n",
    "print(log_strikes_50.shape, datum.shape)\n",
    "print(datum.T.shape)\n",
    "w_50 = model.train(datum.T.double(), log_strikes_50, epochs=1601)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.001140161561049604\n",
      "0.01624480169823255\n",
      "0.23145279689306958\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x2000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(20,20))\n",
    "plt.plot(log_strikes, [w_50(i) for i in log_strikes])\n",
    "plt.scatter(log_strikes, his, s=10)\n",
    "plt.scatter(log_strikes, lows, s= 10)\n",
    "print(sum([max(abs(w_50(log_strikes[i]) - mids[i]) - abs(his[i] - lows[i])/2, 0) / mids[i] for i in range(log_strikes.shape[0])]).item() * 100 / log_strikes.shape[0]) \n",
    "print(np.sqrt(sum([(max(abs(w_50(log_strikes[i]).item() - mids[i]) - abs(his[i] - lows[i])/2, torch.tensor(0)).item() / mids[i])**2 for i in range(log_strikes.shape[0])])/ log_strikes.shape[0])* 100) \n",
    "print(max([max(abs(w_50(log_strikes[i]) - mids[i]) - abs(his[i] - lows[i])/2, 0) / mids[i] for i in range(log_strikes.shape[0])]).item() * 100) # Max \n",
    "# print([max(abs(w_50(log_strikes[i]) - mids[i]) - abs(his[i] - lows[i])/2, 0) * 100 / mids[i] for i in range(log_strikes.shape[0])]) # Max \n",
    "plt.savefig('./50perc.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4246575342465753\n",
      "tensor([-0.2360, -0.2304, -0.1976, -0.1869, -0.1790, -0.1763, -0.1711, -0.1685,\n",
      "        -0.1658, -0.1351, -0.1200, -0.1151, -0.1126, -0.1077, -0.0979, -0.0930,\n",
      "        -0.0906, -0.0810, -0.0786, -0.0739, -0.0668, -0.0644, -0.0620, -0.0597,\n",
      "        -0.0527, -0.0481, -0.0343, -0.0274, -0.0229, -0.0162, -0.0050,  0.0016,\n",
      "         0.0104,  0.0126,  0.0147,  0.0169,  0.0191,  0.0212,  0.0234,  0.0255,\n",
      "         0.0277,  0.0298,  0.0320,  0.0384,  0.0405,  0.0426,  0.0489,  0.0531,\n",
      "         0.0552,  0.0573,  0.0594,  0.0615,  0.0656,  0.0697,  0.0718,  0.0738,\n",
      "         0.0759,  0.0779,  0.0800,  0.0820,  0.0860,  0.0901,  0.0961,  0.0981,\n",
      "         0.1021,  0.1061,  0.1081,  0.1160,  0.1218,  0.1277,  0.1296,  0.1316,\n",
      "         0.1335,  0.1354,  0.1373,  0.1488,  0.1507,  0.1526,  0.1564,  0.1583,\n",
      "         0.2114,  0.2465])\n",
      "(82,)\n",
      "(82,)\n",
      "Mid shape (82,)\n",
      "9.012920106901195e-05\n",
      "(82,) (82,)\n",
      "torch.Size([82]) torch.Size([249, 1])\n",
      "torch.Size([1, 249])\n",
      "0.0 0.0 nan\n",
      "Epoch: 0\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.3184259484113129e-05\n",
      "MAPE:  0.0\n",
      "Delta:  0.005918867502998169\n",
      "Breaking and plotting at epoch 0 with bounds loss tensor(1.3184e-05, grad_fn=<MulBackward0>) and arb loss tensor(0., grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import smilecorrector_gsvi_jo_mw_ar as smilenet\n",
    "import torch\n",
    "importlib.reload(smilenet)\n",
    "# For first try, we pass our boundaries as each strike price\n",
    "# boundaries = processed_40['strike_price'].apply(np.log).to_numpy()\n",
    "# ind = np.array([i for i in range(0,boundaries.shape[0],3)])\n",
    "# boundaries = boundaries[ind]\n",
    "# strikes = boundaries.copy()\n",
    "R = 0.0056 # Rate for > 122 day\n",
    "F = 2266.349134 # for ID 102434, Exp date 05/31/2022\n",
    "T = 5 * 31 / 365\n",
    "S = F * np.exp(-R * T)\n",
    "print(T)\n",
    "processed_40 = remove(processed, 0.60, F)\n",
    "log_strikes_40 = torch.tensor((processed_40['strike_price'].apply(np.log).to_numpy()- np.log(F))) #   \n",
    "print(log_strikes_40)\n",
    "S = torch.tensor(S).reshape(1,1)\n",
    "T = torch.tensor(T).reshape(1,1)\n",
    "R = torch.tensor(R).reshape(1,1)\n",
    "params = (0, 0.4, -0.6, 0, 0.2)\n",
    "# his_40, lows_40 = svi_with_noise(log_strikes_40, *params)\n",
    "# mids_40 = torch.tensor(his_40 + lows_40) / 2\n",
    "# mids_40 = mids_40 * T\n",
    "his_40 = processed_40['vol_high'].to_numpy() ** 2 * T.item()\n",
    "lows_40 = processed_40['vol_low'].to_numpy() ** 2 * T.item()\n",
    "# mids_40 = torch.tensor(((processed_40['vol_high'].to_numpy() + processed_40['vol_low'].to_numpy()) / 2))\n",
    "mids_40 = (his_40 + lows_40) / 2\n",
    "print(mids_40.shape)\n",
    "mids_40 = mids_40\n",
    "print(mids_40.shape)\n",
    "print('Mid shape', mids_40.shape)\n",
    "# print(mids_40)\n",
    "low = min(mids_40**2)/2\n",
    "print(low)\n",
    "print(his_40.shape, lows_40.shape)\n",
    "# datum, log_strikes_40 = pipeline.get_datum('2022-0') \n",
    "model = smilenet.SmileNet(5, log_strikes_40, mids_40, low)#, low)\n",
    "datum = torch.tensor(np.vstack([ his_40.reshape(-1,1) , lows_40.reshape(-1,1) , log_strikes_40.reshape(-1,1), np.log(S), T, R])).double()\n",
    "print(log_strikes_40.shape, datum.shape)\n",
    "print(datum.T.shape)\n",
    "w_40 = model.train(datum.T.double(), log_strikes_40, epochs=1601)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([82]) torch.Size([203])\n",
      "0.021918012122892534\n",
      "0.1419749740299914\n",
      "1.3066229347143434\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(log_strikes, [w_40(i) for i in log_strikes])\n",
    "plt.scatter(log_strikes, his)\n",
    "plt.scatter(log_strikes, lows)\n",
    "print(log_strikes_40.shape, log_strikes.shape)\n",
    "print(sum([max(abs(w_40(log_strikes[i]) - mids[i]) - abs(his[i] - lows[i])/2, 0) / mids[i] for i in range(log_strikes.shape[0])]).item() * 100 / log_strikes.shape[0]) \n",
    "print(np.sqrt(sum([(max(abs(w_40(log_strikes[i]).item() - mids[i]) - abs(his[i] - lows[i])/2, torch.tensor(0)).item() / mids[i])**2 for i in range(log_strikes.shape[0])])/ log_strikes.shape[0])* 100) \n",
    "print(max([max(abs(w_40(log_strikes[i]) - mids[i]) - abs(his[i] - lows[i])/2, 0) / mids[i] for i in range(log_strikes.shape[0])]).item() * 100) # Max \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4246575342465753\n",
      "tensor([-0.2139, -0.1949, -0.1763, -0.1632, -0.1529, -0.1326, -0.1151, -0.1028,\n",
      "        -0.0882, -0.0834, -0.0810, -0.0786, -0.0715, -0.0597, -0.0574, -0.0504,\n",
      "        -0.0481, -0.0320, -0.0252, -0.0229, -0.0162, -0.0072, -0.0050, -0.0006,\n",
      "         0.0038,  0.0060,  0.0191,  0.0277,  0.0298,  0.0320,  0.0341,  0.0362,\n",
      "         0.0384,  0.0405,  0.0426,  0.0468,  0.0489,  0.0594,  0.0615,  0.0635,\n",
      "         0.0656,  0.0697,  0.0718,  0.0759,  0.0820,  0.0921,  0.1001,  0.1041,\n",
      "         0.1081,  0.1120,  0.1218,  0.1238,  0.1257,  0.1316,  0.1393,  0.1431,\n",
      "         0.1469,  0.1545,  0.1583,  0.1602,  0.2465])\n",
      "(61,)\n",
      "(61,)\n",
      "Mid shape (61,)\n",
      "9.00380559592238e-05\n",
      "(61,) (61,)\n",
      "torch.Size([61]) torch.Size([186, 1])\n",
      "torch.Size([1, 186])\n",
      "0.0 0.0 nan\n",
      "Epoch: 0\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 1.4013200982822088e-05\n",
      "MAPE:  0.0\n",
      "Delta:  0.08911612168155852\n",
      "Breaking and plotting at epoch 0 with bounds loss tensor(1.4013e-05, grad_fn=<MulBackward0>) and arb loss tensor(0., grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import smilecorrector_gsvi_jo_mw_ar as smilenet\n",
    "import torch\n",
    "importlib.reload(smilenet)\n",
    "# For first try, we pass our boundaries as each strike price\n",
    "# boundaries = processed_30['strike_price'].apply(np.log).to_numpy()\n",
    "# ind = np.array([i for i in range(0,boundaries.shape[0],3)])\n",
    "# boundaries = boundaries[ind]\n",
    "# strikes = boundaries.copy()\n",
    "R = 0.0056 # Rate for > 122 day\n",
    "F = 2266.349134 # for ID 102434, Exp date 05/31/2022\n",
    "T = 5 * 31 / 365\n",
    "S = F * np.exp(-R * T)\n",
    "print(T)\n",
    "processed_30 = remove(processed, 0.70, F)\n",
    "log_strikes_30 = torch.tensor((processed_30['strike_price'].apply(np.log).to_numpy()- np.log(F))) #   \n",
    "print(log_strikes_30)\n",
    "S = torch.tensor(S).reshape(1,1)\n",
    "T = torch.tensor(T).reshape(1,1)\n",
    "R = torch.tensor(R).reshape(1,1)\n",
    "params = (0, 0.4, -0.6, 0, 0.2)\n",
    "# his_30, lows_30 = svi_with_noise(log_strikes_30, *params)\n",
    "# mids_30 = torch.tensor(his_30 + lows_30) / 2\n",
    "# mids_30 = mids_30 * T\n",
    "his_30 = processed_30['vol_high'].to_numpy() ** 2 * T.item()\n",
    "lows_30 = processed_30['vol_low'].to_numpy() ** 2 * T.item()\n",
    "# mids_30 = torch.tensor(((processed_30['vol_high'].to_numpy() + processed_30['vol_low'].to_numpy()) / 2))\n",
    "mids_30 = (his_30 + lows_30) / 2\n",
    "print(mids_30.shape)\n",
    "mids_30 = mids_30\n",
    "print(mids_30.shape)\n",
    "print('Mid shape', mids_30.shape)\n",
    "# print(mids_30)\n",
    "low = min(mids_30**2)/2\n",
    "print(low)\n",
    "print(his_30.shape, lows_30.shape)\n",
    "# datum, log_strikes_30 = pipeline.get_datum('2022-0') \n",
    "model = smilenet.SmileNet(5, log_strikes_30, mids_30, low)#, low)\n",
    "datum = torch.tensor(np.vstack([ his_30.reshape(-1,1) , lows_30.reshape(-1,1) , log_strikes_30.reshape(-1,1), np.log(S), T, R])).double()\n",
    "print(log_strikes_30.shape, datum.shape)\n",
    "print(datum.T.shape)\n",
    "w_30 = model.train(datum.T.double(), log_strikes_30, epochs=1601)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Project\\smilecorrector_gsvi_jo_mw_ar.py:680: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ctx.save_for_backward(coeffs, torch.tensor(x))\n",
      "d:\\Project\\smilecorrector_gsvi_jo_mw_ar.py:684: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(poly(x))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([61]) torch.Size([203])\n",
      "0.1271842452150961\n",
      "0.8179485337884845\n",
      "7.743264025783439\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "plt.plot(log_strikes, [w_30(i) for i in log_strikes])\n",
    "plt.scatter(log_strikes, his)\n",
    "plt.scatter(log_strikes, lows)\n",
    "print(log_strikes_30.shape, log_strikes.shape)\n",
    "print(sum([max(abs(w_30(log_strikes[i]) - mids[i]) - abs(his[i] - lows[i])/2, 0) / mids[i] for i in range(log_strikes.shape[0])]).item() * 100 / log_strikes.shape[0]) \n",
    "print(np.sqrt(sum([(max(abs(w_30(log_strikes[i]).item() - mids[i]) - abs(his[i] - lows[i])/2, torch.tensor(0)).item() / mids[i])**2 for i in range(log_strikes.shape[0])])/ log_strikes.shape[0])* 100) \n",
    "print(max([max(abs(w_30(log_strikes[i]) - mids[i]) - abs(his[i] - lows[i])/2, 0) / mids[i] for i in range(log_strikes.shape[0])]).item() * 100) # Max \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4246575342465753\n",
      "tensor([-0.1225, -0.0644, -0.0504, -0.0366, -0.0274, -0.0184, -0.0139,  0.0104,\n",
      "         0.0169,  0.0191,  0.0212,  0.0277,  0.0298,  0.0384,  0.0489,  0.0552,\n",
      "         0.0594,  0.0615,  0.0635,  0.0718,  0.0840,  0.0860,  0.0981,  0.1001,\n",
      "         0.1041,  0.1120,  0.1160,  0.1179,  0.1218,  0.1257,  0.1277,  0.1316,\n",
      "         0.1335,  0.1450,  0.1469,  0.1488,  0.1583,  0.1602,  0.1751,  0.1934,\n",
      "         0.2970])\n",
      "(41,)\n",
      "(41,)\n",
      "Mid shape (41,)\n",
      "9.00380559592238e-05\n",
      "(41,) (41,)\n",
      "torch.Size([41]) torch.Size([126, 1])\n",
      "torch.Size([1, 126])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Project\\smilecorrector_gsvi_jo_mw_ar.py:115: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  mids = torch.sqrt(torch.max(torch.tensor(mids**2 - low),torch.tensor(0)))\n",
      "d:\\Project\\smilecorrector_gsvi_jo_mw_ar.py:292: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  bounds = torch.hstack([torch.tensor(self.strike_low).reshape(1,1), knots, torch.tensor(self.strike_high).reshape(1,1)])\n",
      "d:\\Project\\smilecorrector_gsvi_jo_mw_ar.py:680: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ctx.save_for_backward(coeffs, torch.tensor(x))\n",
      "d:\\Project\\smilecorrector_gsvi_jo_mw_ar.py:684: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(poly(x))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 0 nan\n",
      "Epoch: 0\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 0.0\n",
      "MAPE:  0.0\n",
      "Delta:  0.011318680392430398\n",
      "Breaking and plotting at epoch 0 with bounds loss tensor(0., grad_fn=<MulBackward0>) and arb loss tensor(0., grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import smilecorrector_gsvi_jo_mw_ar as smilenet\n",
    "import torch\n",
    "importlib.reload(smilenet)\n",
    "# For first try, we pass our boundaries as each strike price\n",
    "# boundaries = processed_20['strike_price'].apply(np.log).to_numpy()\n",
    "# ind = np.array([i for i in range(0,boundaries.shape[0],3)])\n",
    "# boundaries = boundaries[ind]\n",
    "# strikes = boundaries.copy()\n",
    "R = 0.0056 # Rate for > 122 day\n",
    "F = 2266.349134 # for ID 102434, Exp date 05/31/2022\n",
    "T = 5 * 31 / 365\n",
    "S = F * np.exp(-R * T)\n",
    "print(T)\n",
    "processed_20 = remove(processed, 0.80, F)\n",
    "log_strikes_20 = torch.tensor((processed_20['strike_price'].apply(np.log).to_numpy()- np.log(F))) #   \n",
    "print(log_strikes_20)\n",
    "S = torch.tensor(S).reshape(1,1)\n",
    "T = torch.tensor(T).reshape(1,1)\n",
    "R = torch.tensor(R).reshape(1,1)\n",
    "params = (0, 0.4, -0.6, 0, 0.2)\n",
    "# his_20, lows_20 = svi_with_noise(log_strikes_20, *params)\n",
    "# mids_20 = torch.tensor(his_20 + lows_20) / 2\n",
    "# mids_20 = mids_20 * T\n",
    "his_20 = processed_20['vol_high'].to_numpy() ** 2 * T.item()\n",
    "lows_20 = processed_20['vol_low'].to_numpy() ** 2 * T.item()\n",
    "# mids_20 = torch.tensor(((processed_20['vol_high'].to_numpy() + processed_20['vol_low'].to_numpy()) / 2))\n",
    "mids_20 = (his_20 + lows_20) / 2\n",
    "print(mids_20.shape)\n",
    "mids_20 = mids_20\n",
    "print(mids_20.shape)\n",
    "print('Mid shape', mids_20.shape)\n",
    "# print(mids_20)\n",
    "low = min(mids_20**2)/2\n",
    "print(low)\n",
    "print(his_20.shape, lows_20.shape)\n",
    "# datum, log_strikes_20 = pipeline.get_datum('2022-0') \n",
    "model = smilenet.SmileNet(5, log_strikes_20, mids_20, low)#, low)\n",
    "datum = torch.tensor(np.vstack([ his_20.reshape(-1,1) , lows_20.reshape(-1,1) , log_strikes_20.reshape(-1,1), np.log(S), T, R])).double()\n",
    "print(log_strikes_20.shape, datum.shape)\n",
    "print(datum.T.shape)\n",
    "w_20 = model.train(datum.T.double(), log_strikes_20, epochs=1601)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Project\\smilecorrector_gsvi_jo_mw_ar.py:680: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ctx.save_for_backward(coeffs, torch.tensor(x))\n",
      "d:\\Project\\smilecorrector_gsvi_jo_mw_ar.py:684: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(poly(x))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.3541312834700805\n",
      "5.273254272963689\n",
      "32.91751047728953\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(log_strikes, [w_20(i) for i in log_strikes])\n",
    "plt.scatter(log_strikes, his)\n",
    "plt.scatter(log_strikes, lows)\n",
    "print(sum([max(abs(w_20(log_strikes[i]) - mids[i]) - abs(his[i] - lows[i])/2, 0) / mids[i] for i in range(log_strikes.shape[0])]).item() * 100 / log_strikes.shape[0]) \n",
    "print(np.sqrt(sum([(max(abs(w_20(log_strikes[i]).item() - mids[i]) - abs(his[i] - lows[i])/2, torch.tensor(0)).item() / mids[i])**2 for i in range(log_strikes.shape[0])])/ log_strikes.shape[0])* 100) \n",
    "print(max([max(abs(w_20(log_strikes[i]) - mids[i]) - abs(his[i] - lows[i])/2, 0) / mids[i] for i in range(log_strikes.shape[0])]).item() * 100) # Max \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4246575342465753\n",
      "tensor([-0.0252, -0.0207, -0.0028,  0.0016,  0.0341,  0.0362,  0.0552,  0.0573,\n",
      "         0.0594,  0.0677,  0.0697,  0.0779,  0.0860,  0.0881,  0.0941,  0.0981,\n",
      "         0.1120,  0.1238,  0.1257,  0.1393,  0.1583])\n",
      "(21,)\n",
      "(21,)\n",
      "Mid shape (21,)\n",
      "9.020765539315359e-05\n",
      "(21,) (21,)\n",
      "torch.Size([21]) torch.Size([66, 1])\n",
      "torch.Size([1, 66])\n",
      "0.0 0 nan\n",
      "Epoch: 0\n",
      "Arb loss 0.0\n",
      "Real arb loss 0.0\n",
      "Bounds loss: 0.0\n",
      "MAPE:  0.0\n",
      "Delta:  0.25479369936968127\n",
      "Breaking and plotting at epoch 0 with bounds loss tensor(0., grad_fn=<MulBackward0>) and arb loss tensor(0., grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import smilecorrector_gsvi_jo_mw_ar as smilenet\n",
    "import torch\n",
    "importlib.reload(smilenet)\n",
    "# For first try, we pass our boundaries as each strike price\n",
    "# boundaries = processed_10['strike_price'].apply(np.log).to_numpy()\n",
    "# ind = np.array([i for i in range(0,boundaries.shape[0],3)])\n",
    "# boundaries = boundaries[ind]\n",
    "# strikes = boundaries.copy()\n",
    "R = 0.0056 # Rate for > 122 day\n",
    "F = 2266.349134 # for ID 102434, Exp date 05/31/2022\n",
    "T = 5 * 31 / 365\n",
    "S = F * np.exp(-R * T)\n",
    "print(T)\n",
    "processed_10 = remove(processed, 0.90, F)\n",
    "log_strikes_10 = torch.tensor((processed_10['strike_price'].apply(np.log).to_numpy()- np.log(F))) #   \n",
    "print(log_strikes_10)\n",
    "S = torch.tensor(S).reshape(1,1)\n",
    "T = torch.tensor(T).reshape(1,1)\n",
    "R = torch.tensor(R).reshape(1,1)\n",
    "params = (0, 0.4, -0.6, 0, 0.2)\n",
    "# his_10, lows_10 = svi_with_noise(log_strikes_10, *params)\n",
    "# mids_10 = torch.tensor(his_10 + lows_10) / 2\n",
    "# mids_10 = mids_10 * T\n",
    "his_10 = processed_10['vol_high'].to_numpy() ** 2 * T.item()\n",
    "lows_10 = processed_10['vol_low'].to_numpy() ** 2 * T.item()\n",
    "# mids_10 = torch.tensor(((processed_10['vol_high'].to_numpy() + processed_10['vol_low'].to_numpy()) / 2))\n",
    "mids_10 = (his_10 + lows_10) / 2\n",
    "print(mids_10.shape)\n",
    "mids_10 = mids_10\n",
    "print(mids_10.shape)\n",
    "print('Mid shape', mids_10.shape)\n",
    "# print(mids_10)\n",
    "low = min(mids_10**2)/2\n",
    "print(low)\n",
    "print(his_10.shape, lows_10.shape)\n",
    "# datum, log_strikes_10 = pipeline.get_datum('2022-0') \n",
    "model = smilenet.SmileNet(5, log_strikes_10, mids_10, low)#, low)\n",
    "datum = torch.tensor(np.vstack([ his_10.reshape(-1,1) , lows_10.reshape(-1,1) , log_strikes_10.reshape(-1,1), np.log(S), T, R])).double()\n",
    "print(log_strikes_10.shape, datum.shape)\n",
    "print(datum.T.shape)\n",
    "w_10 = model.train(datum.T.double(), log_strikes_10, epochs=1601)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Project\\smilecorrector_gsvi_jo_mw_ar.py:680: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ctx.save_for_backward(coeffs, torch.tensor(x))\n",
      "d:\\Project\\smilecorrector_gsvi_jo_mw_ar.py:684: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(poly(x))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.733797714832666\n",
      "7.115680075309731\n",
      "33.01094738761736\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(log_strikes, [w_10(i) for i in log_strikes])\n",
    "plt.scatter(log_strikes, his)\n",
    "plt.scatter(log_strikes, lows)\n",
    "print(sum([max(abs(w_10(log_strikes[i]) - mids[i]) - abs(his[i] - lows[i])/2, 0) / mids[i] for i in range(log_strikes.shape[0])]).item() * 100 / log_strikes.shape[0]) \n",
    "print(np.sqrt(sum([(max(abs(w_10(log_strikes[i]).item() - mids[i]) - abs(his[i] - lows[i])/2, torch.tensor(0)).item() / mids[i])**2 for i in range(log_strikes.shape[0])])/ log_strikes.shape[0])* 100) \n",
    "print(max([max(abs(w_10(log_strikes[i]) - mids[i]) - abs(his[i] - lows[i])/2, 0) / mids[i] for i in range(log_strikes.shape[0])]).item() * 100) # Max \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "norm = smilenet.differentiableNormCdf.apply\n",
    "\n",
    "def d_plus(k, w):\n",
    "    return -k / torch.sqrt(w(k)) + torch.sqrt(w(k)) / 2\n",
    "def d_sub(k,w):\n",
    "    return -k / torch.sqrt(w(k)) - torch.sqrt(w(k)) / 2\n",
    "\n",
    "\n",
    "def bsc_svi(k, w, S):\n",
    "    return S * (norm(d_plus(k, w)) - torch.exp(kreal) * norm(d_sub(k, w)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[64], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mfunctools\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m partial\n\u001b[1;32m----> 2\u001b[0m pred, boundaries \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mforward(datum\u001b[38;5;241m.\u001b[39mT\u001b[38;5;241m.\u001b[39mdouble())\n\u001b[0;32m      3\u001b[0m ttensor \u001b[38;5;241m=\u001b[39m smilenet\u001b[38;5;241m.\u001b[39mtransform(pred\u001b[38;5;241m.\u001b[39mdetach(),\u001b[38;5;241m1.0\u001b[39m)\n\u001b[0;32m      4\u001b[0m polys \u001b[38;5;241m=\u001b[39m [np\u001b[38;5;241m.\u001b[39mpolynomial\u001b[38;5;241m.\u001b[39mpolynomial\u001b[38;5;241m.\u001b[39mPolynomial(torch\u001b[38;5;241m.\u001b[39mflip((pred[:,\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m4\u001b[39m\u001b[38;5;241m*\u001b[39mi:\u001b[38;5;241m4\u001b[39m\u001b[38;5;241m*\u001b[39mi\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m4\u001b[39m]), dims\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m0\u001b[39m,))\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mnumpy()) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m((pred\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m4\u001b[39m)]\n",
      "\u001b[1;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "from functools import partial\n",
    "pred, boundaries, low, knots = model.forward(datum.T.double())\n",
    "ttensor = smilenet.transform(pred.detach(),1.0)\n",
    "polys = [np.polynomial.polynomial.Polynomial(torch.flip((pred[:,0][4*i:4*i+4]), dims=(0,)).detach().numpy()) for i in range((pred.shape[0])//4)]\n",
    "ts = [np.polynomial.polynomial.Polynomial(ttensor[i,:]) for i in range(ttensor.shape[0])]\n",
    "\n",
    "funcs = [partial(bsc_svi, w = polys[i], S=S) for i in range(len(polys))]\n",
    "\n",
    "boundaries = torch.hstack([torch.tensor(log_strikes[0]), boundaries.reshape(-1), torch.tensor(log_strikes[-1])])\n",
    "his = torch.tensor(his).reshape(-1)\n",
    "los = torch.tensor(los).reshape(-1)\n",
    "print(los[0], log_strikes[0], mids[0])\n",
    "print(type(mids), type(his))\n",
    "ppm = [bsc_svi(log_strikes[i], lambda k, const=mids[i]: const, S) for i in range(log_strikes.reshape(-1).shape[0])]\n",
    "pph = [bsc_svi(log_strikes[i], lambda k, const=his[i]: const, S) for i in range(log_strikes.reshape(-1).shape[0])]\n",
    "ppl = [bsc_svi(log_strikes[i], lambda k, const=los[i]: const, S) for i in range(log_strikes.reshape(-1).shape[0])]\n",
    "\n",
    "\n",
    "print(boundaries.shape)\n",
    "\n",
    "smilenet.plot_polys(funcs, boundaries, 0, 'bs', extra_points=[(log_strikes, processed['best_offer'].to_numpy(), 'raw low'), (log_strikes, processed['best_bid'].to_numpy(), 'raw high'), (log_strikes, ppm, 'calc mid'), (log_strikes, pph, 'calc hi'),(log_strikes, ppl, 'calc lo')], labels=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_5392\\2442275951.py:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  control = torch.tensor(model.translate @ model.xstar).reshape(1,-1).double()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42,) torch.Size([164])\n",
      "With remaining arb: 4.336808689942018e-11\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[53], line 11\u001b[0m\n\u001b[0;32m      9\u001b[0m boundaries \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mboundaries\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(model\u001b[38;5;241m.\u001b[39mboundaries\u001b[38;5;241m.\u001b[39mshape, res1\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m---> 11\u001b[0m sol, loss \u001b[38;5;241m=\u001b[39m sc\u001b[38;5;241m.\u001b[39mremove_arb(control, translate, boundaries)\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(control\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(sol\u001b[38;5;241m.\u001b[39mshape)\n",
      "\u001b[1;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "# Play with SmileCorrect\n",
    "import smilecorrector as sc\n",
    "importlib.reload(sc)\n",
    "control = torch.tensor(model.translate @ model.xstar).reshape(1,-1).double()\n",
    "# control = torch.zeros(control.shape)\n",
    "control.requires_grad_()\n",
    "translate = model.translate\n",
    "\n",
    "boundaries = model.boundaries\n",
    "print(model.boundaries.shape, res1.shape)\n",
    "sol, loss = sc.remove_arb(control, translate, boundaries)\n",
    "print(control.shape)\n",
    "print(sol.shape)\n",
    "print('Loss of', loss)\n",
    "loss2 = torch.sum(torch.abs(sol))\n",
    "print(\"l1 of\", loss2)\n",
    "\n",
    "print(torch.autograd.grad(loss2, control))\n",
    "polys = [np.polynomial.polynomial.Polynomial(list(reversed(sol[:,0].detach().numpy()[4*i:4*i+4]))) for i in range((sol.shape[0])//4)]\n",
    "sc.plot_polys(polys, boundaries, 0, 'test')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1a30f06c470>]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch \n",
    "\n",
    "a = torch.tensor([[1,2]]).T.double()\n",
    "xs = []\n",
    "ys = []\n",
    "for i in range(100):\n",
    "    a[0,0] = a[0,0] + 0.01\n",
    "    q, r = torch.linalg.qr(a, mode='complete')\n",
    "    xs += [q[0,1]]\n",
    "    ys += [q[1,1]]\n",
    "plt.plot(xs, ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3])\n",
      "(-0.8903900384902954, -0.358125239610672, -0.2809835374355316)\n",
      "tensor(1.0000)\n",
      "tensor([[-0.8904, -0.3581, -0.2810]])\n"
     ]
    }
   ],
   "source": [
    "xs = torch.normal(0, torch.ones(3,1))\n",
    "xs = (xs / xs.norm(dim=0)).T\n",
    "print(xs.shape)\n",
    "for i in xs:\n",
    "    print(\"(%s, %s, %s)\" % (i[0].item(), i[1].item(), i[2].item()))\n",
    "    print(torch.linalg.norm(i))\n",
    "\n",
    "print(xs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = torch.tensor((0.3009892404079437, 0.02299308031797409, -0.9533502459526062))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q, _ = torch.linalg.qr(torch.tensor([[1,-1,0],[0,1,-1]]).T.double())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.7071, -0.4082],\n",
      "        [ 0.7071, -0.4082],\n",
      "        [-0.0000,  0.8165]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "print(Q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.1667, 2.0000],\n",
      "        [1.1667, 2.0000],\n",
      "        [1.1667, 2.0000]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "v = torch.tensor([[1,0.5,2.0],[2,3,1]]).T.double()\n",
    "print(v - Q @ (Q.T @ v))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
